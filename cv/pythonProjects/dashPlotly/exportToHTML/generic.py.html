<html>
<head>
<title>generic.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
generic.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Define the SeriesGroupBy and DataFrameGroupBy 
classes that hold the groupby interfaces (and some implementations). 
 
These are user facing as the result of the ``df.groupby(...)`` operations, 
which here returns a DataFrameGroupBy object. 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">abc</span>
<span class="s2">from </span><span class="s1">functools </span><span class="s2">import </span><span class="s1">partial</span>
<span class="s2">from </span><span class="s1">textwrap </span><span class="s2">import </span><span class="s1">dedent</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Any</span><span class="s2">,</span>
    <span class="s1">Callable</span><span class="s2">,</span>
    <span class="s1">Hashable</span><span class="s2">,</span>
    <span class="s1">Iterable</span><span class="s2">,</span>
    <span class="s1">Mapping</span><span class="s2">,</span>
    <span class="s1">NamedTuple</span><span class="s2">,</span>
    <span class="s1">Sequence</span><span class="s2">,</span>
    <span class="s1">TypeVar</span><span class="s2">,</span>
    <span class="s1">Union</span><span class="s2">,</span>
    <span class="s1">cast</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">pandas._libs </span><span class="s2">import </span><span class="s1">reduction </span><span class="s2">as </span><span class="s1">libreduction</span>
<span class="s2">from </span><span class="s1">pandas._typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ArrayLike</span><span class="s2">,</span>
    <span class="s1">Manager</span><span class="s2">,</span>
    <span class="s1">Manager2D</span><span class="s2">,</span>
    <span class="s1">SingleManager</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.util._decorators </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Appender</span><span class="s2">,</span>
    <span class="s1">Substitution</span><span class="s2">,</span>
    <span class="s1">doc</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.util._exceptions </span><span class="s2">import </span><span class="s1">find_stack_level</span>

<span class="s2">from </span><span class="s1">pandas.core.dtypes.common </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ensure_int64</span><span class="s2">,</span>
    <span class="s1">is_bool</span><span class="s2">,</span>
    <span class="s1">is_categorical_dtype</span><span class="s2">,</span>
    <span class="s1">is_dict_like</span><span class="s2">,</span>
    <span class="s1">is_integer_dtype</span><span class="s2">,</span>
    <span class="s1">is_interval_dtype</span><span class="s2">,</span>
    <span class="s1">is_scalar</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.missing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">isna</span><span class="s2">,</span>
    <span class="s1">notna</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">from </span><span class="s1">pandas.core </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">algorithms</span><span class="s2">,</span>
    <span class="s1">nanops</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.apply </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">GroupByApply</span><span class="s2">,</span>
    <span class="s1">maybe_mangle_lambdas</span><span class="s2">,</span>
    <span class="s1">reconstruct_func</span><span class="s2">,</span>
    <span class="s1">validate_func_kwargs</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.base </span><span class="s2">import </span><span class="s1">SpecificationError</span>
<span class="s2">import </span><span class="s1">pandas.core.common </span><span class="s2">as </span><span class="s1">com</span>
<span class="s2">from </span><span class="s1">pandas.core.construction </span><span class="s2">import </span><span class="s1">create_series_with_explicit_dtype</span>
<span class="s2">from </span><span class="s1">pandas.core.frame </span><span class="s2">import </span><span class="s1">DataFrame</span>
<span class="s2">from </span><span class="s1">pandas.core.generic </span><span class="s2">import </span><span class="s1">NDFrame</span>
<span class="s2">from </span><span class="s1">pandas.core.groupby </span><span class="s2">import </span><span class="s1">base</span>
<span class="s2">from </span><span class="s1">pandas.core.groupby.groupby </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">GroupBy</span><span class="s2">,</span>
    <span class="s1">_agg_template</span><span class="s2">,</span>
    <span class="s1">_apply_docs</span><span class="s2">,</span>
    <span class="s1">_transform_template</span><span class="s2">,</span>
    <span class="s1">warn_dropping_nuisance_columns_deprecated</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.groupby.grouper </span><span class="s2">import </span><span class="s1">get_grouper</span>
<span class="s2">from </span><span class="s1">pandas.core.indexes.api </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Index</span><span class="s2">,</span>
    <span class="s1">MultiIndex</span><span class="s2">,</span>
    <span class="s1">all_indexes_same</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.series </span><span class="s2">import </span><span class="s1">Series</span>
<span class="s2">from </span><span class="s1">pandas.core.util.numba_ </span><span class="s2">import </span><span class="s1">maybe_use_numba</span>

<span class="s2">from </span><span class="s1">pandas.plotting </span><span class="s2">import </span><span class="s1">boxplot_frame_groupby</span>

<span class="s3"># TODO(typing) the return value on this callable should be any *scalar*.</span>
<span class="s1">AggScalar = Union[str</span><span class="s2">, </span><span class="s1">Callable[...</span><span class="s2">, </span><span class="s1">Any]]</span>
<span class="s3"># TODO: validate types on ScalarResult and move to _typing</span>
<span class="s3"># Blocked from using by https://github.com/python/mypy/issues/1484</span>
<span class="s3"># See note at _mangle_lambda_list</span>
<span class="s1">ScalarResult = TypeVar(</span><span class="s4">&quot;ScalarResult&quot;</span><span class="s1">)</span>


<span class="s2">class </span><span class="s1">NamedAgg(NamedTuple):</span>
    <span class="s1">column: Hashable</span>
    <span class="s1">aggfunc: AggScalar</span>


<span class="s2">def </span><span class="s1">generate_property(name: str</span><span class="s2">, </span><span class="s1">klass: type[DataFrame | Series]):</span>
    <span class="s0">&quot;&quot;&quot; 
    Create a property for a GroupBy subclass to dispatch to DataFrame/Series. 
 
    Parameters 
    ---------- 
    name : str 
    klass : {DataFrame, Series} 
 
    Returns 
    ------- 
    property 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">prop(self):</span>
        <span class="s2">return </span><span class="s1">self._make_wrapper(name)</span>

    <span class="s1">parent_method = getattr(klass</span><span class="s2">, </span><span class="s1">name)</span>
    <span class="s1">prop.__doc__ = parent_method.__doc__ </span><span class="s2">or </span><span class="s4">&quot;&quot;</span>
    <span class="s1">prop.__name__ = name</span>
    <span class="s2">return </span><span class="s1">property(prop)</span>


<span class="s2">def </span><span class="s1">pin_allowlisted_properties(</span>
    <span class="s1">klass: type[DataFrame | Series]</span><span class="s2">, </span><span class="s1">allowlist: frozenset[str]</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Create GroupBy member defs for DataFrame/Series names in a allowlist. 
 
    Parameters 
    ---------- 
    klass : DataFrame or Series class 
        class where members are defined. 
    allowlist : frozenset[str] 
        Set of names of klass methods to be constructed 
 
    Returns 
    ------- 
    class decorator 
 
    Notes 
    ----- 
    Since we don't want to override methods explicitly defined in the 
    base class, any such name is skipped. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">pinner(cls):</span>
        <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">allowlist:</span>
            <span class="s2">if </span><span class="s1">hasattr(cls</span><span class="s2">, </span><span class="s1">name):</span>
                <span class="s3"># don't override anything that was explicitly defined</span>
                <span class="s3">#  in the base class</span>
                <span class="s2">continue</span>

            <span class="s1">prop = generate_property(name</span><span class="s2">, </span><span class="s1">klass)</span>
            <span class="s1">setattr(cls</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">prop)</span>

        <span class="s2">return </span><span class="s1">cls</span>

    <span class="s2">return </span><span class="s1">pinner</span>


<span class="s1">@pin_allowlisted_properties(Series</span><span class="s2">, </span><span class="s1">base.series_apply_allowlist)</span>
<span class="s2">class </span><span class="s1">SeriesGroupBy(GroupBy[Series]):</span>
    <span class="s1">_apply_allowlist = base.series_apply_allowlist</span>

    <span class="s2">def </span><span class="s1">_wrap_agged_manager(self</span><span class="s2">, </span><span class="s1">mgr: Manager) -&gt; Series:</span>
        <span class="s2">if </span><span class="s1">mgr.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">mgr = cast(SingleManager</span><span class="s2">, </span><span class="s1">mgr)</span>
            <span class="s1">single = mgr</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">mgr = cast(Manager2D</span><span class="s2">, </span><span class="s1">mgr)</span>
            <span class="s1">single = mgr.iget(</span><span class="s5">0</span><span class="s1">)</span>
        <span class="s1">ser = self.obj._constructor(single</span><span class="s2">, </span><span class="s1">name=self.obj.name)</span>
        <span class="s3"># NB: caller is responsible for setting ser.index</span>
        <span class="s2">return </span><span class="s1">ser</span>

    <span class="s2">def </span><span class="s1">_get_data_to_aggregate(self) -&gt; SingleManager:</span>
        <span class="s1">ser = self._obj_with_exclusions</span>
        <span class="s1">single = ser._mgr</span>
        <span class="s2">return </span><span class="s1">single</span>

    <span class="s2">def </span><span class="s1">_iterate_slices(self) -&gt; Iterable[Series]:</span>
        <span class="s2">yield </span><span class="s1">self._selected_obj</span>

    <span class="s1">_agg_examples_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    Examples 
    -------- 
    &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4]) 
 
    &gt;&gt;&gt; s 
    0    1 
    1    2 
    2    3 
    3    4 
    dtype: int64 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).min() 
    1    1 
    2    3 
    dtype: int64 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg('min') 
    1    1 
    2    3 
    dtype: int64 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg(['min', 'max']) 
       min  max 
    1    1    2 
    2    3    4 
 
    The output column names can be controlled by passing 
    the desired column names and aggregations as keyword arguments. 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg( 
    ...     minimum='min', 
    ...     maximum='max', 
    ... ) 
       minimum  maximum 
    1        1        2 
    2        3        4 
 
    .. versionchanged:: 1.3.0 
 
        The resulting dtype will reflect the return value of the aggregating function. 
 
    &gt;&gt;&gt; s.groupby([1, 1, 2, 2]).agg(lambda x: x.astype(float).min()) 
    1    1.0 
    2    3.0 
    dtype: float64 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@Appender(</span>
        <span class="s1">_apply_docs[</span><span class="s4">&quot;template&quot;</span><span class="s1">].format(</span>
            <span class="s1">input=</span><span class="s4">&quot;series&quot;</span><span class="s2">, </span><span class="s1">examples=_apply_docs[</span><span class="s4">&quot;series_examples&quot;</span><span class="s1">]</span>
        <span class="s1">)</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">apply(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">return </span><span class="s1">super().apply(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s1">@doc(_agg_template</span><span class="s2">, </span><span class="s1">examples=_agg_examples_doc</span><span class="s2">, </span><span class="s1">klass=</span><span class="s4">&quot;Series&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">aggregate(self</span><span class="s2">, </span><span class="s1">func=</span><span class="s2">None, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>

        <span class="s2">if </span><span class="s1">maybe_use_numba(engine):</span>
            <span class="s2">with </span><span class="s1">self._group_selection_context():</span>
                <span class="s1">data = self._selected_obj</span>
            <span class="s1">result = self._aggregate_with_numba(</span>
                <span class="s1">data.to_frame()</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>
            <span class="s1">index = self.grouper.result_index</span>
            <span class="s2">return </span><span class="s1">self.obj._constructor(result.ravel()</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">name=data.name)</span>

        <span class="s1">relabeling = func </span><span class="s2">is None</span>
        <span class="s1">columns = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">relabeling:</span>
            <span class="s1">columns</span><span class="s2">, </span><span class="s1">func = validate_func_kwargs(kwargs)</span>
            <span class="s1">kwargs = {}</span>

        <span class="s2">if </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s2">return </span><span class="s1">getattr(self</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s2">elif </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">abc.Iterable):</span>
            <span class="s3"># Catch instances of lists / tuples</span>
            <span class="s3"># but not the class list / tuple itself.</span>
            <span class="s1">func = maybe_mangle_lambdas(func)</span>
            <span class="s1">ret = self._aggregate_multiple_funcs(func)</span>
            <span class="s2">if </span><span class="s1">relabeling:</span>
                <span class="s3"># error: Incompatible types in assignment (expression has type</span>
                <span class="s3"># &quot;Optional[List[str]]&quot;, variable has type &quot;Index&quot;)</span>
                <span class="s1">ret.columns = columns  </span><span class="s3"># type: ignore[assignment]</span>
            <span class="s2">return </span><span class="s1">ret</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">cyfunc = com.get_cython_func(func)</span>
            <span class="s2">if </span><span class="s1">cyfunc </span><span class="s2">and not </span><span class="s1">args </span><span class="s2">and not </span><span class="s1">kwargs:</span>
                <span class="s2">return </span><span class="s1">getattr(self</span><span class="s2">, </span><span class="s1">cyfunc)()</span>

            <span class="s2">if </span><span class="s1">self.grouper.nkeys &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self._python_agg_general(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s2">try</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self._python_agg_general(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s2">except </span><span class="s1">KeyError:</span>
                <span class="s3"># TODO: KeyError is raised in _python_agg_general,</span>
                <span class="s3">#  see test_groupby.test_basic</span>
                <span class="s1">result = self._aggregate_named(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

                <span class="s3"># result is a dict whose keys are the elements of result_index</span>
                <span class="s1">index = self.grouper.result_index</span>
                <span class="s2">return </span><span class="s1">create_series_with_explicit_dtype(</span>
                    <span class="s1">result</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">dtype_if_empty=object</span>
                <span class="s1">)</span>

    <span class="s1">agg = aggregate</span>

    <span class="s2">def </span><span class="s1">_aggregate_multiple_funcs(self</span><span class="s2">, </span><span class="s1">arg) -&gt; DataFrame:</span>
        <span class="s2">if </span><span class="s1">isinstance(arg</span><span class="s2">, </span><span class="s1">dict):</span>

            <span class="s3"># show the deprecation, but only if we</span>
            <span class="s3"># have not shown a higher level one</span>
            <span class="s3"># GH 15931</span>
            <span class="s2">raise </span><span class="s1">SpecificationError(</span><span class="s4">&quot;nested renamer is not supported&quot;</span><span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">any(isinstance(x</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">arg):</span>
            <span class="s1">arg = [(x</span><span class="s2">, </span><span class="s1">x) </span><span class="s2">if not </span><span class="s1">isinstance(x</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)) </span><span class="s2">else </span><span class="s1">x </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">arg]</span>

            <span class="s3"># indicated column order</span>
            <span class="s1">columns = next(zip(*arg))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># list of functions / function names</span>
            <span class="s1">columns = []</span>
            <span class="s2">for </span><span class="s1">f </span><span class="s2">in </span><span class="s1">arg:</span>
                <span class="s1">columns.append(com.get_callable_name(f) </span><span class="s2">or </span><span class="s1">f)</span>

            <span class="s1">arg = zip(columns</span><span class="s2">, </span><span class="s1">arg)</span>

        <span class="s1">results: dict[base.OutputKey</span><span class="s2">, </span><span class="s1">DataFrame | Series] = {}</span>
        <span class="s2">for </span><span class="s1">idx</span><span class="s2">, </span><span class="s1">(name</span><span class="s2">, </span><span class="s1">func) </span><span class="s2">in </span><span class="s1">enumerate(arg):</span>

            <span class="s1">key = base.OutputKey(label=name</span><span class="s2">, </span><span class="s1">position=idx)</span>
            <span class="s1">results[key] = self.aggregate(func)</span>

        <span class="s2">if </span><span class="s1">any(isinstance(x</span><span class="s2">, </span><span class="s1">DataFrame) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">results.values()):</span>
            <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">concat</span>

            <span class="s1">res_df = concat(</span>
                <span class="s1">results.values()</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">keys=[key.label </span><span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">results.keys()]</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">res_df</span>

        <span class="s1">indexed_output = {key.position: val </span><span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">val </span><span class="s2">in </span><span class="s1">results.items()}</span>
        <span class="s1">output = self.obj._constructor_expanddim(indexed_output</span><span class="s2">, </span><span class="s1">index=</span><span class="s2">None</span><span class="s1">)</span>
        <span class="s1">output.columns = Index(key.label </span><span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">results)</span>

        <span class="s1">output = self._reindex_output(output)</span>
        <span class="s2">return </span><span class="s1">output</span>

    <span class="s2">def </span><span class="s1">_indexed_output_to_ndframe(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">output: Mapping[base.OutputKey</span><span class="s2">, </span><span class="s1">ArrayLike]</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Wrap the dict result of a GroupBy aggregation into a Series. 
        &quot;&quot;&quot;</span>
        <span class="s2">assert </span><span class="s1">len(output) == </span><span class="s5">1</span>
        <span class="s1">values = next(iter(output.values()))</span>
        <span class="s1">result = self.obj._constructor(values)</span>
        <span class="s1">result.name = self.obj.name</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_wrap_applied_output(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">data: Series</span><span class="s2">,</span>
        <span class="s1">values: list[Any]</span><span class="s2">,</span>
        <span class="s1">not_indexed_same: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Wrap the output of SeriesGroupBy.apply into the expected result. 
 
        Parameters 
        ---------- 
        data : Series 
            Input data for groupby operation. 
        values : List[Any] 
            Applied output for each group. 
        not_indexed_same : bool, default False 
            Whether the applied outputs are not indexed the same as the group axes. 
 
        Returns 
        ------- 
        DataFrame or Series 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">len(values) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># GH #6265</span>
            <span class="s2">return </span><span class="s1">self.obj._constructor(</span>
                <span class="s1">[]</span><span class="s2">,</span>
                <span class="s1">name=self.obj.name</span><span class="s2">,</span>
                <span class="s1">index=self.grouper.result_index</span><span class="s2">,</span>
                <span class="s1">dtype=data.dtype</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">values </span><span class="s2">is not None</span>

        <span class="s2">if </span><span class="s1">isinstance(values[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s3"># GH #823 #24880</span>
            <span class="s1">index = self.grouper.result_index</span>
            <span class="s1">res_df = self.obj._constructor_expanddim(values</span><span class="s2">, </span><span class="s1">index=index)</span>
            <span class="s1">res_df = self._reindex_output(res_df)</span>
            <span class="s3"># if self.observed is False,</span>
            <span class="s3"># keep all-NaN rows created while re-indexing</span>
            <span class="s1">res_ser = res_df.stack(dropna=self.observed)</span>
            <span class="s1">res_ser.name = self.obj.name</span>
            <span class="s2">return </span><span class="s1">res_ser</span>
        <span class="s2">elif </span><span class="s1">isinstance(values[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(Series</span><span class="s2">, </span><span class="s1">DataFrame)):</span>
            <span class="s2">return </span><span class="s1">self._concat_objects(values</span><span class="s2">, </span><span class="s1">not_indexed_same=not_indexed_same)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># GH #6265 #24880</span>
            <span class="s1">result = self.obj._constructor(</span>
                <span class="s1">data=values</span><span class="s2">, </span><span class="s1">index=self.grouper.result_index</span><span class="s2">, </span><span class="s1">name=self.obj.name</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">self._reindex_output(result)</span>

    <span class="s2">def </span><span class="s1">_aggregate_named(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s3"># Note: this is very similar to _aggregate_series_pure_python,</span>
        <span class="s3">#  but that does not pin group.name</span>
        <span class="s1">result = {}</span>
        <span class="s1">initialized = </span><span class="s2">False</span>

        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">self:</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>

            <span class="s1">output = func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s1">output = libreduction.extract_result(output)</span>
            <span class="s2">if not </span><span class="s1">initialized:</span>
                <span class="s3"># We only do this validation on the first iteration</span>
                <span class="s1">libreduction.check_result_array(output</span><span class="s2">, </span><span class="s1">group.dtype)</span>
                <span class="s1">initialized = </span><span class="s2">True</span>
            <span class="s1">result[name] = output</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@Substitution(klass=</span><span class="s4">&quot;Series&quot;</span><span class="s1">)</span>
    <span class="s1">@Appender(_transform_template)</span>
    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s2">return </span><span class="s1">self._transform(</span>
            <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=engine</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_cython_transform(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">how: str</span><span class="s2">, </span><span class="s1">numeric_only: bool = </span><span class="s2">True, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">**kwargs</span>
    <span class="s1">):</span>
        <span class="s2">assert </span><span class="s1">axis == </span><span class="s5">0  </span><span class="s3"># handled by caller</span>

        <span class="s1">obj = self._selected_obj</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">result = self.grouper._cython_operation(</span>
                <span class="s4">&quot;transform&quot;</span><span class="s2">, </span><span class="s1">obj._values</span><span class="s2">, </span><span class="s1">how</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>
        <span class="s2">except </span><span class="s1">NotImplementedError </span><span class="s2">as </span><span class="s1">err:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">how</span><span class="s2">} </span><span class="s4">is not supported for </span><span class="s2">{</span><span class="s1">obj.dtype</span><span class="s2">} </span><span class="s4">dtype&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>

        <span class="s2">return </span><span class="s1">obj._constructor(result</span><span class="s2">, </span><span class="s1">index=self.obj.index</span><span class="s2">, </span><span class="s1">name=obj.name)</span>

    <span class="s2">def </span><span class="s1">_transform_general(self</span><span class="s2">, </span><span class="s1">func: Callable</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform with a callable func`. 
        &quot;&quot;&quot;</span>
        <span class="s2">assert </span><span class="s1">callable(func)</span>
        <span class="s1">klass = type(self.obj)</span>

        <span class="s1">results = []</span>
        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">self:</span>
            <span class="s3"># this setattr is needed for test_transform_lambda_with_datetimetz</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>
            <span class="s1">res = func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s1">results.append(klass(res</span><span class="s2">, </span><span class="s1">index=group.index))</span>

        <span class="s3"># check for empty &quot;results&quot; to avoid concat ValueError</span>
        <span class="s2">if </span><span class="s1">results:</span>
            <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

            <span class="s1">concatenated = concat(results)</span>
            <span class="s1">result = self._set_result_index_ordered(concatenated)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = self.obj._constructor(dtype=np.float64)</span>

        <span class="s1">result.name = self.obj.name</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_can_use_transform_fast(self</span><span class="s2">, </span><span class="s1">result) -&gt; bool:</span>
        <span class="s2">return True</span>

    <span class="s2">def </span><span class="s1">filter(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a copy of a Series excluding elements from groups that 
        do not satisfy the boolean criterion specified by func. 
 
        Parameters 
        ---------- 
        func : function 
            To apply to each group. Should return True or False. 
        dropna : Drop groups that do not pass the filter. True by default; 
            if False, groups that evaluate False are filled with NaNs. 
 
        Notes 
        ----- 
        Functions that mutate the passed object can produce unexpected 
        behavior or errors and are not supported. See :ref:`gotchas.udf-mutation` 
        for more details. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar', 
        ...                           'foo', 'bar'], 
        ...                    'B' : [1, 2, 3, 4, 5, 6], 
        ...                    'C' : [2.0, 5., 8., 1., 2., 9.]}) 
        &gt;&gt;&gt; grouped = df.groupby('A') 
        &gt;&gt;&gt; df.groupby('A').B.filter(lambda x: x.mean() &gt; 3.) 
        1    2 
        3    4 
        5    6 
        Name: B, dtype: int64 
 
        Returns 
        ------- 
        filtered : Series 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">wrapper = </span><span class="s2">lambda </span><span class="s1">x: getattr(x</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">wrapper = </span><span class="s2">lambda </span><span class="s1">x: func(x</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s3"># Interpret np.nan as False.</span>
        <span class="s2">def </span><span class="s1">true_and_notna(x) -&gt; bool:</span>
            <span class="s1">b = wrapper(x)</span>
            <span class="s2">return </span><span class="s1">b </span><span class="s2">and </span><span class="s1">notna(b)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">indices = [</span>
                <span class="s1">self._get_index(name) </span><span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">self </span><span class="s2">if </span><span class="s1">true_and_notna(group)</span>
            <span class="s1">]</span>
        <span class="s2">except </span><span class="s1">(ValueError</span><span class="s2">, </span><span class="s1">TypeError) </span><span class="s2">as </span><span class="s1">err:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;the filter must return a boolean result&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>

        <span class="s1">filtered = self._apply_filter(indices</span><span class="s2">, </span><span class="s1">dropna)</span>
        <span class="s2">return </span><span class="s1">filtered</span>

    <span class="s2">def </span><span class="s1">nunique(self</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return number of unique elements in the group. 
 
        Returns 
        ------- 
        Series 
            Number of unique values within each group. 
        &quot;&quot;&quot;</span>
        <span class="s1">ids</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = self.grouper.group_info</span>

        <span class="s1">val = self.obj._values</span>

        <span class="s1">codes</span><span class="s2">, </span><span class="s1">_ = algorithms.factorize(val</span><span class="s2">, </span><span class="s1">sort=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">sorter = np.lexsort((codes</span><span class="s2">, </span><span class="s1">ids))</span>
        <span class="s1">codes = codes[sorter]</span>
        <span class="s1">ids = ids[sorter]</span>

        <span class="s3"># group boundaries are where group ids change</span>
        <span class="s3"># unique observations are where sorted values change</span>
        <span class="s1">idx = np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1 </span><span class="s1">+ np.nonzero(ids[</span><span class="s5">1</span><span class="s1">:] != ids[:-</span><span class="s5">1</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">]]</span>
        <span class="s1">inc = np.r_[</span><span class="s5">1</span><span class="s2">, </span><span class="s1">codes[</span><span class="s5">1</span><span class="s1">:] != codes[:-</span><span class="s5">1</span><span class="s1">]]</span>

        <span class="s3"># 1st item of each group is a new unique observation</span>
        <span class="s1">mask = codes == -</span><span class="s5">1</span>
        <span class="s2">if </span><span class="s1">dropna:</span>
            <span class="s1">inc[idx] = </span><span class="s5">1</span>
            <span class="s1">inc[mask] = </span><span class="s5">0</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">inc[mask &amp; np.r_[</span><span class="s2">False, </span><span class="s1">mask[:-</span><span class="s5">1</span><span class="s1">]]] = </span><span class="s5">0</span>
            <span class="s1">inc[idx] = </span><span class="s5">1</span>

        <span class="s1">out = np.add.reduceat(inc</span><span class="s2">, </span><span class="s1">idx).astype(</span><span class="s4">&quot;int64&quot;</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">len(ids):</span>
            <span class="s3"># NaN/NaT group exists if the head of ids is -1,</span>
            <span class="s3"># so remove it from res and exclude its index from idx</span>
            <span class="s2">if </span><span class="s1">ids[</span><span class="s5">0</span><span class="s1">] == -</span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">res = out[</span><span class="s5">1</span><span class="s1">:]</span>
                <span class="s1">idx = idx[np.flatnonzero(idx)]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">res = out</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">res = out[</span><span class="s5">1</span><span class="s1">:]</span>
        <span class="s1">ri = self.grouper.result_index</span>

        <span class="s3"># we might have duplications among the bins</span>
        <span class="s2">if </span><span class="s1">len(res) != len(ri):</span>
            <span class="s1">res</span><span class="s2">, </span><span class="s1">out = np.zeros(len(ri)</span><span class="s2">, </span><span class="s1">dtype=out.dtype)</span><span class="s2">, </span><span class="s1">res</span>
            <span class="s1">res[ids[idx]] = out</span>

        <span class="s1">result = self.obj._constructor(res</span><span class="s2">, </span><span class="s1">index=ri</span><span class="s2">, </span><span class="s1">name=self.obj.name)</span>
        <span class="s2">return </span><span class="s1">self._reindex_output(result</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s5">0</span><span class="s1">)</span>

    <span class="s1">@doc(Series.describe)</span>
    <span class="s2">def </span><span class="s1">describe(self</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">return </span><span class="s1">super().describe(**kwargs)</span>

    <span class="s2">def </span><span class="s1">value_counts(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">normalize: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">True,</span>
        <span class="s1">ascending: bool = </span><span class="s2">False,</span>
        <span class="s1">bins=</span><span class="s2">None,</span>
        <span class="s1">dropna: bool = </span><span class="s2">True,</span>
    <span class="s1">):</span>

        <span class="s2">from </span><span class="s1">pandas.core.reshape.merge </span><span class="s2">import </span><span class="s1">get_join_indexers</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.tile </span><span class="s2">import </span><span class="s1">cut</span>

        <span class="s1">ids</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = self.grouper.group_info</span>
        <span class="s1">val = self.obj._values</span>

        <span class="s2">def </span><span class="s1">apply_series_value_counts():</span>
            <span class="s2">return </span><span class="s1">self.apply(</span>
                <span class="s1">Series.value_counts</span><span class="s2">,</span>
                <span class="s1">normalize=normalize</span><span class="s2">,</span>
                <span class="s1">sort=sort</span><span class="s2">,</span>
                <span class="s1">ascending=ascending</span><span class="s2">,</span>
                <span class="s1">bins=bins</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">bins </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">np.iterable(bins):</span>
                <span class="s3"># scalar bins cannot be done at top level</span>
                <span class="s3"># in a backward compatible way</span>
                <span class="s2">return </span><span class="s1">apply_series_value_counts()</span>
        <span class="s2">elif </span><span class="s1">is_categorical_dtype(val.dtype):</span>
            <span class="s3"># GH38672</span>
            <span class="s2">return </span><span class="s1">apply_series_value_counts()</span>

        <span class="s3"># groupby removes null keys from groupings</span>
        <span class="s1">mask = ids != -</span><span class="s5">1</span>
        <span class="s1">ids</span><span class="s2">, </span><span class="s1">val = ids[mask]</span><span class="s2">, </span><span class="s1">val[mask]</span>

        <span class="s2">if </span><span class="s1">bins </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">lab</span><span class="s2">, </span><span class="s1">lev = algorithms.factorize(val</span><span class="s2">, </span><span class="s1">sort=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">llab = </span><span class="s2">lambda </span><span class="s1">lab</span><span class="s2">, </span><span class="s1">inc: lab[inc]</span>
        <span class="s2">else</span><span class="s1">:</span>

            <span class="s3"># lab is a Categorical with categories an IntervalIndex</span>
            <span class="s1">lab = cut(Series(val)</span><span class="s2">, </span><span class="s1">bins</span><span class="s2">, </span><span class="s1">include_lowest=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s3"># error: &quot;ndarray&quot; has no attribute &quot;cat&quot;</span>
            <span class="s1">lev = lab.cat.categories  </span><span class="s3"># type: ignore[attr-defined]</span>
            <span class="s3"># error: No overload variant of &quot;take&quot; of &quot;_ArrayOrScalarCommon&quot; matches</span>
            <span class="s3"># argument types &quot;Any&quot;, &quot;bool&quot;, &quot;Union[Any, float]&quot;</span>
            <span class="s1">lab = lev.take(  </span><span class="s3"># type: ignore[call-overload]</span>
                <span class="s3"># error: &quot;ndarray&quot; has no attribute &quot;cat&quot;</span>
                <span class="s1">lab.cat.codes</span><span class="s2">,  </span><span class="s3"># type: ignore[attr-defined]</span>
                <span class="s1">allow_fill=</span><span class="s2">True,</span>
                <span class="s3"># error: Item &quot;ndarray&quot; of &quot;Union[ndarray, Index]&quot; has no attribute</span>
                <span class="s3"># &quot;_na_value&quot;</span>
                <span class="s1">fill_value=lev._na_value</span><span class="s2">,  </span><span class="s3"># type: ignore[union-attr]</span>
            <span class="s1">)</span>
            <span class="s1">llab = </span><span class="s2">lambda </span><span class="s1">lab</span><span class="s2">, </span><span class="s1">inc: lab[inc]._multiindex.codes[-</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s2">if </span><span class="s1">is_interval_dtype(lab.dtype):</span>
            <span class="s3"># TODO: should we do this inside II?</span>

            <span class="s3"># error: &quot;ndarray&quot; has no attribute &quot;left&quot;</span>
            <span class="s3"># error: &quot;ndarray&quot; has no attribute &quot;right&quot;</span>
            <span class="s1">sorter = np.lexsort(</span>
                <span class="s1">(lab.left</span><span class="s2">, </span><span class="s1">lab.right</span><span class="s2">, </span><span class="s1">ids)  </span><span class="s3"># type: ignore[attr-defined]</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">sorter = np.lexsort((lab</span><span class="s2">, </span><span class="s1">ids))</span>

        <span class="s1">ids</span><span class="s2">, </span><span class="s1">lab = ids[sorter]</span><span class="s2">, </span><span class="s1">lab[sorter]</span>

        <span class="s3"># group boundaries are where group ids change</span>
        <span class="s1">idchanges = </span><span class="s5">1 </span><span class="s1">+ np.nonzero(ids[</span><span class="s5">1</span><span class="s1">:] != ids[:-</span><span class="s5">1</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">idx = np.r_[</span><span class="s5">0</span><span class="s2">, </span><span class="s1">idchanges]</span>
        <span class="s2">if not </span><span class="s1">len(ids):</span>
            <span class="s1">idx = idchanges</span>

        <span class="s3"># new values are where sorted labels change</span>
        <span class="s1">lchanges = llab(lab</span><span class="s2">, </span><span class="s1">slice(</span><span class="s5">1</span><span class="s2">, None</span><span class="s1">)) != llab(lab</span><span class="s2">, </span><span class="s1">slice(</span><span class="s2">None, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">))</span>
        <span class="s1">inc = np.r_[</span><span class="s2">True, </span><span class="s1">lchanges]</span>
        <span class="s2">if not </span><span class="s1">len(val):</span>
            <span class="s1">inc = lchanges</span>
        <span class="s1">inc[idx] = </span><span class="s2">True  </span><span class="s3"># group boundaries are also new values</span>
        <span class="s1">out = np.diff(np.nonzero(np.r_[inc</span><span class="s2">, True</span><span class="s1">])[</span><span class="s5">0</span><span class="s1">])  </span><span class="s3"># value counts</span>

        <span class="s3"># num. of times each group should be repeated</span>
        <span class="s1">rep = partial(np.repeat</span><span class="s2">, </span><span class="s1">repeats=np.add.reduceat(inc</span><span class="s2">, </span><span class="s1">idx))</span>

        <span class="s3"># multi-index components</span>
        <span class="s1">codes = self.grouper.reconstructed_codes</span>
        <span class="s1">codes = [rep(level_codes) </span><span class="s2">for </span><span class="s1">level_codes </span><span class="s2">in </span><span class="s1">codes] + [llab(lab</span><span class="s2">, </span><span class="s1">inc)]</span>
        <span class="s3"># error: List item 0 has incompatible type &quot;Union[ndarray[Any, Any], Index]&quot;;</span>
        <span class="s3"># expected &quot;Index&quot;</span>
        <span class="s1">levels = [ping.group_index </span><span class="s2">for </span><span class="s1">ping </span><span class="s2">in </span><span class="s1">self.grouper.groupings] + [</span>
            <span class="s1">lev  </span><span class="s3"># type: ignore[list-item]</span>
        <span class="s1">]</span>
        <span class="s1">names = self.grouper.names + [self.obj.name]</span>

        <span class="s2">if </span><span class="s1">dropna:</span>
            <span class="s1">mask = codes[-</span><span class="s5">1</span><span class="s1">] != -</span><span class="s5">1</span>
            <span class="s2">if </span><span class="s1">mask.all():</span>
                <span class="s1">dropna = </span><span class="s2">False</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">out</span><span class="s2">, </span><span class="s1">codes = out[mask]</span><span class="s2">, </span><span class="s1">[level_codes[mask] </span><span class="s2">for </span><span class="s1">level_codes </span><span class="s2">in </span><span class="s1">codes]</span>

        <span class="s2">if </span><span class="s1">normalize:</span>
            <span class="s1">out = out.astype(</span><span class="s4">&quot;float&quot;</span><span class="s1">)</span>
            <span class="s1">d = np.diff(np.r_[idx</span><span class="s2">, </span><span class="s1">len(ids)])</span>
            <span class="s2">if </span><span class="s1">dropna:</span>
                <span class="s1">m = ids[lab == -</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s1">np.add.at(d</span><span class="s2">, </span><span class="s1">m</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">acc = rep(d)[mask]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">acc = rep(d)</span>
            <span class="s1">out /= acc</span>

        <span class="s2">if </span><span class="s1">sort </span><span class="s2">and </span><span class="s1">bins </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">cat = ids[inc][mask] </span><span class="s2">if </span><span class="s1">dropna </span><span class="s2">else </span><span class="s1">ids[inc]</span>
            <span class="s1">sorter = np.lexsort((out </span><span class="s2">if </span><span class="s1">ascending </span><span class="s2">else </span><span class="s1">-out</span><span class="s2">, </span><span class="s1">cat))</span>
            <span class="s1">out</span><span class="s2">, </span><span class="s1">codes[-</span><span class="s5">1</span><span class="s1">] = out[sorter]</span><span class="s2">, </span><span class="s1">codes[-</span><span class="s5">1</span><span class="s1">][sorter]</span>

        <span class="s2">if </span><span class="s1">bins </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># for compat. with libgroupby.value_counts need to ensure every</span>
            <span class="s3"># bin is present at every index level, null filled with zeros</span>
            <span class="s1">diff = np.zeros(len(out)</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;bool&quot;</span><span class="s1">)</span>
            <span class="s2">for </span><span class="s1">level_codes </span><span class="s2">in </span><span class="s1">codes[:-</span><span class="s5">1</span><span class="s1">]:</span>
                <span class="s1">diff |= np.r_[</span><span class="s2">True, </span><span class="s1">level_codes[</span><span class="s5">1</span><span class="s1">:] != level_codes[:-</span><span class="s5">1</span><span class="s1">]]</span>

            <span class="s1">ncat</span><span class="s2">, </span><span class="s1">nbin = diff.sum()</span><span class="s2">, </span><span class="s1">len(levels[-</span><span class="s5">1</span><span class="s1">])</span>

            <span class="s1">left = [np.repeat(np.arange(ncat)</span><span class="s2">, </span><span class="s1">nbin)</span><span class="s2">, </span><span class="s1">np.tile(np.arange(nbin)</span><span class="s2">, </span><span class="s1">ncat)]</span>

            <span class="s1">right = [diff.cumsum() - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">codes[-</span><span class="s5">1</span><span class="s1">]]</span>

            <span class="s1">_</span><span class="s2">, </span><span class="s1">idx = get_join_indexers(left</span><span class="s2">, </span><span class="s1">right</span><span class="s2">, </span><span class="s1">sort=</span><span class="s2">False, </span><span class="s1">how=</span><span class="s4">&quot;left&quot;</span><span class="s1">)</span>
            <span class="s1">out = np.where(idx != -</span><span class="s5">1</span><span class="s2">, </span><span class="s1">out[idx]</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>

            <span class="s2">if </span><span class="s1">sort:</span>
                <span class="s1">sorter = np.lexsort((out </span><span class="s2">if </span><span class="s1">ascending </span><span class="s2">else </span><span class="s1">-out</span><span class="s2">, </span><span class="s1">left[</span><span class="s5">0</span><span class="s1">]))</span>
                <span class="s1">out</span><span class="s2">, </span><span class="s1">left[-</span><span class="s5">1</span><span class="s1">] = out[sorter]</span><span class="s2">, </span><span class="s1">left[-</span><span class="s5">1</span><span class="s1">][sorter]</span>

            <span class="s3"># build the multi-index w/ full levels</span>
            <span class="s2">def </span><span class="s1">build_codes(lev_codes: np.ndarray) -&gt; np.ndarray:</span>
                <span class="s2">return </span><span class="s1">np.repeat(lev_codes[diff]</span><span class="s2">, </span><span class="s1">nbin)</span>

            <span class="s1">codes = [build_codes(lev_codes) </span><span class="s2">for </span><span class="s1">lev_codes </span><span class="s2">in </span><span class="s1">codes[:-</span><span class="s5">1</span><span class="s1">]]</span>
            <span class="s1">codes.append(left[-</span><span class="s5">1</span><span class="s1">])</span>

        <span class="s1">mi = MultiIndex(levels=levels</span><span class="s2">, </span><span class="s1">codes=codes</span><span class="s2">, </span><span class="s1">names=names</span><span class="s2">, </span><span class="s1">verify_integrity=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">is_integer_dtype(out.dtype):</span>
            <span class="s1">out = ensure_int64(out)</span>
        <span class="s2">return </span><span class="s1">self.obj._constructor(out</span><span class="s2">, </span><span class="s1">index=mi</span><span class="s2">, </span><span class="s1">name=self.obj.name)</span>

    <span class="s1">@doc(Series.nlargest)</span>
    <span class="s2">def </span><span class="s1">nlargest(self</span><span class="s2">, </span><span class="s1">n: int = </span><span class="s5">5</span><span class="s2">, </span><span class="s1">keep: str = </span><span class="s4">&quot;first&quot;</span><span class="s1">):</span>
        <span class="s1">f = partial(Series.nlargest</span><span class="s2">, </span><span class="s1">n=n</span><span class="s2">, </span><span class="s1">keep=keep)</span>
        <span class="s1">data = self._obj_with_exclusions</span>
        <span class="s3"># Don't change behavior if result index happens to be the same, i.e.</span>
        <span class="s3"># already ordered and n &gt;= all group sizes.</span>
        <span class="s1">result = self._python_apply_general(f</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">not_indexed_same=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(Series.nsmallest)</span>
    <span class="s2">def </span><span class="s1">nsmallest(self</span><span class="s2">, </span><span class="s1">n: int = </span><span class="s5">5</span><span class="s2">, </span><span class="s1">keep: str = </span><span class="s4">&quot;first&quot;</span><span class="s1">):</span>
        <span class="s1">f = partial(Series.nsmallest</span><span class="s2">, </span><span class="s1">n=n</span><span class="s2">, </span><span class="s1">keep=keep)</span>
        <span class="s1">data = self._obj_with_exclusions</span>
        <span class="s3"># Don't change behavior if result index happens to be the same, i.e.</span>
        <span class="s3"># already ordered and n &gt;= all group sizes.</span>
        <span class="s1">result = self._python_apply_general(f</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">not_indexed_same=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s1">@pin_allowlisted_properties(DataFrame</span><span class="s2">, </span><span class="s1">base.dataframe_apply_allowlist)</span>
<span class="s2">class </span><span class="s1">DataFrameGroupBy(GroupBy[DataFrame]):</span>

    <span class="s1">_apply_allowlist = base.dataframe_apply_allowlist</span>

    <span class="s1">_agg_examples_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    Examples 
    -------- 
    &gt;&gt;&gt; df = pd.DataFrame( 
    ...     { 
    ...         &quot;A&quot;: [1, 1, 2, 2], 
    ...         &quot;B&quot;: [1, 2, 3, 4], 
    ...         &quot;C&quot;: [0.362838, 0.227877, 1.267767, -0.562860], 
    ...     } 
    ... ) 
 
    &gt;&gt;&gt; df 
       A  B         C 
    0  1  1  0.362838 
    1  1  2  0.227877 
    2  2  3  1.267767 
    3  2  4 -0.562860 
 
    The aggregation is for each column. 
 
    &gt;&gt;&gt; df.groupby('A').agg('min') 
       B         C 
    A 
    1  1  0.227877 
    2  3 -0.562860 
 
    Multiple aggregations 
 
    &gt;&gt;&gt; df.groupby('A').agg(['min', 'max']) 
        B             C 
      min max       min       max 
    A 
    1   1   2  0.227877  0.362838 
    2   3   4 -0.562860  1.267767 
 
    Select a column for aggregation 
 
    &gt;&gt;&gt; df.groupby('A').B.agg(['min', 'max']) 
       min  max 
    A 
    1    1    2 
    2    3    4 
 
    Different aggregations per column 
 
    &gt;&gt;&gt; df.groupby('A').agg({'B': ['min', 'max'], 'C': 'sum'}) 
        B             C 
      min max       sum 
    A 
    1   1   2  0.590715 
    2   3   4  0.704907 
 
    To control the output names with different aggregations per column, 
    pandas supports &quot;named aggregation&quot; 
 
    &gt;&gt;&gt; df.groupby(&quot;A&quot;).agg( 
    ...     b_min=pd.NamedAgg(column=&quot;B&quot;, aggfunc=&quot;min&quot;), 
    ...     c_sum=pd.NamedAgg(column=&quot;C&quot;, aggfunc=&quot;sum&quot;)) 
       b_min     c_sum 
    A 
    1      1  0.590715 
    2      3  0.704907 
 
    - The keywords are the *output* column names 
    - The values are tuples whose first element is the column to select 
      and the second element is the aggregation to apply to that column. 
      Pandas provides the ``pandas.NamedAgg`` namedtuple with the fields 
      ``['column', 'aggfunc']`` to make it clearer what the arguments are. 
      As usual, the aggregation can be a callable or a string alias. 
 
    See :ref:`groupby.aggregate.named` for more. 
 
    .. versionchanged:: 1.3.0 
 
        The resulting dtype will reflect the return value of the aggregating function. 
 
    &gt;&gt;&gt; df.groupby(&quot;A&quot;)[[&quot;B&quot;]].agg(lambda x: x.astype(float).min()) 
          B 
    A 
    1   1.0 
    2   3.0 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@doc(_agg_template</span><span class="s2">, </span><span class="s1">examples=_agg_examples_doc</span><span class="s2">, </span><span class="s1">klass=</span><span class="s4">&quot;DataFrame&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">aggregate(self</span><span class="s2">, </span><span class="s1">func=</span><span class="s2">None, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>

        <span class="s2">if </span><span class="s1">maybe_use_numba(engine):</span>
            <span class="s2">with </span><span class="s1">self._group_selection_context():</span>
                <span class="s1">data = self._selected_obj</span>
            <span class="s1">result = self._aggregate_with_numba(</span>
                <span class="s1">data</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>
            <span class="s1">index = self.grouper.result_index</span>
            <span class="s2">return </span><span class="s1">self.obj._constructor(result</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">columns=data.columns)</span>

        <span class="s1">relabeling</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">order = reconstruct_func(func</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s1">func = maybe_mangle_lambdas(func)</span>

        <span class="s1">op = GroupByApply(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwargs)</span>
        <span class="s1">result = op.agg()</span>
        <span class="s2">if not </span><span class="s1">is_dict_like(func) </span><span class="s2">and </span><span class="s1">result </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">result</span>
        <span class="s2">elif </span><span class="s1">relabeling </span><span class="s2">and </span><span class="s1">result </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># this should be the only (non-raising) case with relabeling</span>
            <span class="s3"># used reordered index of columns</span>
            <span class="s1">result = result.iloc[:</span><span class="s2">, </span><span class="s1">order]</span>
            <span class="s1">result.columns = columns</span>

        <span class="s2">if </span><span class="s1">result </span><span class="s2">is None</span><span class="s1">:</span>

            <span class="s3"># grouper specific aggregations</span>
            <span class="s2">if </span><span class="s1">self.grouper.nkeys &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s3"># test_groupby_as_index_series_scalar gets here with 'not self.as_index'</span>
                <span class="s2">return </span><span class="s1">self._python_agg_general(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s2">elif </span><span class="s1">args </span><span class="s2">or </span><span class="s1">kwargs:</span>
                <span class="s3"># test_pass_args_kwargs gets here (with and without as_index)</span>
                <span class="s3"># can't return early</span>
                <span class="s1">result = self._aggregate_frame(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s2">elif </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s3"># _aggregate_multiple_funcs does not allow self.axis == 1</span>
                <span class="s3"># Note: axis == 1 precludes 'not self.as_index', see __init__</span>
                <span class="s1">result = self._aggregate_frame(func)</span>
                <span class="s2">return </span><span class="s1">result</span>

            <span class="s2">else</span><span class="s1">:</span>

                <span class="s3"># try to treat as if we are passing a list</span>
                <span class="s1">gba = GroupByApply(self</span><span class="s2">, </span><span class="s1">[func]</span><span class="s2">, </span><span class="s1">args=()</span><span class="s2">, </span><span class="s1">kwargs={})</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">result = gba.agg()</span>

                <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">err:</span>
                    <span class="s2">if </span><span class="s4">&quot;no results&quot; </span><span class="s2">not in </span><span class="s1">str(err):</span>
                        <span class="s3"># raised directly by _aggregate_multiple_funcs</span>
                        <span class="s2">raise</span>
                    <span class="s1">result = self._aggregate_frame(func)</span>

                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">sobj = self._selected_obj</span>

                    <span class="s2">if </span><span class="s1">isinstance(sobj</span><span class="s2">, </span><span class="s1">Series):</span>
                        <span class="s3"># GH#35246 test_groupby_as_index_select_column_sum_empty_df</span>
                        <span class="s1">result.columns = self._obj_with_exclusions.columns.copy()</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s3"># Retain our column names</span>
                        <span class="s1">result.columns._set_names(</span>
                            <span class="s1">sobj.columns.names</span><span class="s2">, </span><span class="s1">level=list(range(sobj.columns.nlevels))</span>
                        <span class="s1">)</span>
                        <span class="s3"># select everything except for the last level, which is the one</span>
                        <span class="s3"># containing the name of the function(s), see GH#32040</span>
                        <span class="s1">result.columns = result.columns.droplevel(-</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">self._insert_inaxis_grouper_inplace(result)</span>
            <span class="s1">result.index = Index(range(len(result)))</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">agg = aggregate</span>

    <span class="s2">def </span><span class="s1">_iterate_slices(self) -&gt; Iterable[Series]:</span>
        <span class="s1">obj = self._selected_obj</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">obj = obj.T</span>

        <span class="s2">if </span><span class="s1">isinstance(obj</span><span class="s2">, </span><span class="s1">Series) </span><span class="s2">and </span><span class="s1">obj.name </span><span class="s2">not in </span><span class="s1">self.exclusions:</span>
            <span class="s3"># Occurs when doing DataFrameGroupBy(...)[&quot;X&quot;]</span>
            <span class="s2">yield </span><span class="s1">obj</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">label</span><span class="s2">, </span><span class="s1">values </span><span class="s2">in </span><span class="s1">obj.items():</span>
                <span class="s2">if </span><span class="s1">label </span><span class="s2">in </span><span class="s1">self.exclusions:</span>
                    <span class="s2">continue</span>

                <span class="s2">yield </span><span class="s1">values</span>

    <span class="s2">def </span><span class="s1">_aggregate_frame(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; DataFrame:</span>
        <span class="s2">if </span><span class="s1">self.grouper.nkeys != </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">AssertionError(</span><span class="s4">&quot;Number of keys must be 1&quot;</span><span class="s1">)</span>

        <span class="s1">obj = self._obj_with_exclusions</span>

        <span class="s1">result: dict[Hashable</span><span class="s2">, </span><span class="s1">NDFrame | np.ndarray] = {}</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># test_pass_args_kwargs_duplicate_columns gets here with non-unique columns</span>
            <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">data </span><span class="s2">in </span><span class="s1">self:</span>
                <span class="s1">fres = func(data</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
                <span class="s1">result[name] = fres</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># we get here in a number of test_multilevel tests</span>
            <span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">self.indices:</span>
                <span class="s1">grp_df = self.get_group(name</span><span class="s2">, </span><span class="s1">obj=obj)</span>
                <span class="s1">fres = func(grp_df</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
                <span class="s1">result[name] = fres</span>

        <span class="s1">result_index = self.grouper.result_index</span>
        <span class="s1">other_ax = obj.axes[</span><span class="s5">1 </span><span class="s1">- self.axis]</span>
        <span class="s1">out = self.obj._constructor(result</span><span class="s2">, </span><span class="s1">index=other_ax</span><span class="s2">, </span><span class="s1">columns=result_index)</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">out = out.T</span>

        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">_aggregate_item_by_item(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; DataFrame:</span>
        <span class="s3"># only for axis==0</span>
        <span class="s3"># tests that get here with non-unique cols:</span>
        <span class="s3">#  test_resample_with_timedelta_yields_no_empty_groups,</span>
        <span class="s3">#  test_resample_apply_product</span>

        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s1">result: dict[int</span><span class="s2">, </span><span class="s1">NDFrame] = {}</span>

        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">(item</span><span class="s2">, </span><span class="s1">sgb) </span><span class="s2">in </span><span class="s1">enumerate(self._iterate_column_groupbys(obj)):</span>
            <span class="s1">result[i] = sgb.aggregate(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s1">res_df = self.obj._constructor(result)</span>
        <span class="s1">res_df.columns = obj.columns</span>
        <span class="s2">return </span><span class="s1">res_df</span>

    <span class="s2">def </span><span class="s1">_wrap_applied_output(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">data: DataFrame</span><span class="s2">, </span><span class="s1">values: list</span><span class="s2">, </span><span class="s1">not_indexed_same: bool = </span><span class="s2">False</span>
    <span class="s1">):</span>

        <span class="s2">if </span><span class="s1">len(values) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">result = self.obj._constructor(</span>
                <span class="s1">index=self.grouper.result_index</span><span class="s2">, </span><span class="s1">columns=data.columns</span>
            <span class="s1">)</span>
            <span class="s1">result = result.astype(data.dtypes</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s3"># GH12824</span>
        <span class="s1">first_not_none = next(com.not_none(*values)</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">first_not_none </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s3"># GH9684 - All values are None, return an empty frame.</span>
            <span class="s2">return </span><span class="s1">self.obj._constructor()</span>
        <span class="s2">elif </span><span class="s1">isinstance(first_not_none</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">return </span><span class="s1">self._concat_objects(values</span><span class="s2">, </span><span class="s1">not_indexed_same=not_indexed_same)</span>

        <span class="s1">key_index = self.grouper.result_index </span><span class="s2">if </span><span class="s1">self.as_index </span><span class="s2">else None</span>

        <span class="s2">if </span><span class="s1">isinstance(first_not_none</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">Index)):</span>
            <span class="s3"># GH#1738: values is list of arrays of unequal lengths</span>
            <span class="s3">#  fall through to the outer else clause</span>
            <span class="s3"># TODO: sure this is right?  we used to do this</span>
            <span class="s3">#  after raising AttributeError above</span>
            <span class="s2">return </span><span class="s1">self.obj._constructor_sliced(</span>
                <span class="s1">values</span><span class="s2">, </span><span class="s1">index=key_index</span><span class="s2">, </span><span class="s1">name=self._selection</span>
            <span class="s1">)</span>
        <span class="s2">elif not </span><span class="s1">isinstance(first_not_none</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s3"># values are not series or array-like but scalars</span>
            <span class="s3"># self._selection not passed through to Series as the</span>
            <span class="s3"># result should not take the name of original selection</span>
            <span class="s3"># of columns</span>
            <span class="s2">if </span><span class="s1">self.as_index:</span>
                <span class="s2">return </span><span class="s1">self.obj._constructor_sliced(values</span><span class="s2">, </span><span class="s1">index=key_index)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">result = self.obj._constructor(values</span><span class="s2">, </span><span class="s1">columns=[self._selection])</span>
                <span class="s1">self._insert_inaxis_grouper_inplace(result)</span>
                <span class="s2">return </span><span class="s1">result</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># values are Series</span>
            <span class="s2">return </span><span class="s1">self._wrap_applied_output_series(</span>
                <span class="s1">values</span><span class="s2">, </span><span class="s1">not_indexed_same</span><span class="s2">, </span><span class="s1">first_not_none</span><span class="s2">, </span><span class="s1">key_index</span>
            <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_wrap_applied_output_series(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">values: list[Series]</span><span class="s2">,</span>
        <span class="s1">not_indexed_same: bool</span><span class="s2">,</span>
        <span class="s1">first_not_none</span><span class="s2">,</span>
        <span class="s1">key_index</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s3"># this is to silence a DeprecationWarning</span>
        <span class="s3"># TODO(2.0): Remove when default dtype of empty Series is object</span>
        <span class="s1">kwargs = first_not_none._construct_axes_dict()</span>
        <span class="s1">backup = create_series_with_explicit_dtype(dtype_if_empty=object</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s1">values = [x </span><span class="s2">if </span><span class="s1">(x </span><span class="s2">is not None</span><span class="s1">) </span><span class="s2">else </span><span class="s1">backup </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">values]</span>

        <span class="s1">all_indexed_same = all_indexes_same(x.index </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">values)</span>

        <span class="s3"># GH3596</span>
        <span class="s3"># provide a reduction (Frame -&gt; Series) if groups are</span>
        <span class="s3"># unique</span>
        <span class="s2">if </span><span class="s1">self.squeeze:</span>
            <span class="s1">applied_index = self._selected_obj._get_axis(self.axis)</span>
            <span class="s1">singular_series = len(values) == </span><span class="s5">1 </span><span class="s2">and </span><span class="s1">applied_index.nlevels == </span><span class="s5">1</span>

            <span class="s2">if </span><span class="s1">singular_series:</span>
                <span class="s3"># GH2893</span>
                <span class="s3"># we have series in the values array, we want to</span>
                <span class="s3"># produce a series:</span>
                <span class="s3"># if any of the sub-series are not indexed the same</span>
                <span class="s3"># OR we don't have a multi-index and we have only a</span>
                <span class="s3"># single values</span>
                <span class="s2">return </span><span class="s1">self._concat_objects(values</span><span class="s2">, </span><span class="s1">not_indexed_same=not_indexed_same)</span>

            <span class="s3"># still a series</span>
            <span class="s3"># path added as of GH 5545</span>
            <span class="s2">elif </span><span class="s1">all_indexed_same:</span>
                <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

                <span class="s2">return </span><span class="s1">concat(values)</span>

        <span class="s2">if not </span><span class="s1">all_indexed_same:</span>
            <span class="s3"># GH 8467</span>
            <span class="s2">return </span><span class="s1">self._concat_objects(values</span><span class="s2">, </span><span class="s1">not_indexed_same=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s3"># Combine values</span>
        <span class="s3"># vstack+constructor is faster than concat and handles MI-columns</span>
        <span class="s1">stacked_values = np.vstack([np.asarray(v) </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">values])</span>

        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">index = key_index</span>
            <span class="s1">columns = first_not_none.index.copy()</span>
            <span class="s2">if </span><span class="s1">columns.name </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s3"># GH6124 - propagate name of Series when it's consistent</span>
                <span class="s1">names = {v.name </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">values}</span>
                <span class="s2">if </span><span class="s1">len(names) == </span><span class="s5">1</span><span class="s1">:</span>
                    <span class="s1">columns.name = list(names)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">index = first_not_none.index</span>
            <span class="s1">columns = key_index</span>
            <span class="s1">stacked_values = stacked_values.T</span>

        <span class="s2">if </span><span class="s1">stacked_values.dtype == object:</span>
            <span class="s3"># We'll have the DataFrame constructor do inference</span>
            <span class="s1">stacked_values = stacked_values.tolist()</span>
        <span class="s1">result = self.obj._constructor(stacked_values</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">columns=columns)</span>

        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">self._insert_inaxis_grouper_inplace(result)</span>

        <span class="s2">return </span><span class="s1">self._reindex_output(result)</span>

    <span class="s2">def </span><span class="s1">_cython_transform(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">how: str</span><span class="s2">, </span><span class="s1">numeric_only: bool = </span><span class="s2">True, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">**kwargs</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">assert </span><span class="s1">axis == </span><span class="s5">0  </span><span class="s3"># handled by caller</span>
        <span class="s3"># TODO: no tests with self.ndim == 1 for DataFrameGroupBy</span>

        <span class="s3"># With self.axis == 0, we have multi-block tests</span>
        <span class="s3">#  e.g. test_rank_min_int, test_cython_transform_frame</span>
        <span class="s3">#  test_transform_numeric_ret</span>
        <span class="s3"># With self.axis == 1, _get_data_to_aggregate does a transpose</span>
        <span class="s3">#  so we always have a single block.</span>
        <span class="s1">mgr: Manager2D = self._get_data_to_aggregate()</span>
        <span class="s2">if </span><span class="s1">numeric_only:</span>
            <span class="s1">mgr = mgr.get_numeric_data(copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">def </span><span class="s1">arr_func(bvalues: ArrayLike) -&gt; ArrayLike:</span>
            <span class="s2">return </span><span class="s1">self.grouper._cython_operation(</span>
                <span class="s4">&quot;transform&quot;</span><span class="s2">, </span><span class="s1">bvalues</span><span class="s2">, </span><span class="s1">how</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s1">**kwargs</span>
            <span class="s1">)</span>

        <span class="s3"># We could use `mgr.apply` here and not have to set_axis, but</span>
        <span class="s3">#  we would have to do shape gymnastics for ArrayManager compat</span>
        <span class="s1">res_mgr = mgr.grouped_reduce(arr_func</span><span class="s2">, </span><span class="s1">ignore_failures=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">res_mgr.set_axis(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">mgr.axes[</span><span class="s5">1</span><span class="s1">])</span>

        <span class="s2">if </span><span class="s1">len(res_mgr) &lt; len(mgr):</span>
            <span class="s1">warn_dropping_nuisance_columns_deprecated(type(self)</span><span class="s2">, </span><span class="s1">how)</span>

        <span class="s1">res_df = self.obj._constructor(res_mgr)</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">res_df = res_df.T</span>
        <span class="s2">return </span><span class="s1">res_df</span>

    <span class="s2">def </span><span class="s1">_transform_general(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

        <span class="s1">applied = []</span>
        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s1">gen = self.grouper.get_iterator(obj</span><span class="s2">, </span><span class="s1">axis=self.axis)</span>
        <span class="s1">fast_path</span><span class="s2">, </span><span class="s1">slow_path = self._define_paths(func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s3"># Determine whether to use slow or fast path by evaluating on the first group.</span>
        <span class="s3"># Need to handle the case of an empty generator and process the result so that</span>
        <span class="s3"># it does not need to be computed again.</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">name</span><span class="s2">, </span><span class="s1">group = next(gen)</span>
        <span class="s2">except </span><span class="s1">StopIteration:</span>
            <span class="s2">pass</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">path</span><span class="s2">, </span><span class="s1">res = self._choose_path(fast_path</span><span class="s2">, </span><span class="s1">slow_path</span><span class="s2">, </span><span class="s1">group)</span>
            <span class="s2">except </span><span class="s1">TypeError:</span>
                <span class="s2">return </span><span class="s1">self._transform_item_by_item(obj</span><span class="s2">, </span><span class="s1">fast_path)</span>
            <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">err:</span>
                <span class="s1">msg = </span><span class="s4">&quot;transform must return a scalar value for each group&quot;</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg) </span><span class="s2">from </span><span class="s1">err</span>
            <span class="s2">if </span><span class="s1">group.size &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">res = _wrap_transform_general_frame(self.obj</span><span class="s2">, </span><span class="s1">group</span><span class="s2">, </span><span class="s1">res)</span>
                <span class="s1">applied.append(res)</span>

        <span class="s3"># Compute and process with the remaining groups</span>
        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">gen:</span>
            <span class="s2">if </span><span class="s1">group.size == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">continue</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>
            <span class="s1">res = path(group)</span>
            <span class="s1">res = _wrap_transform_general_frame(self.obj</span><span class="s2">, </span><span class="s1">group</span><span class="s2">, </span><span class="s1">res)</span>
            <span class="s1">applied.append(res)</span>

        <span class="s1">concat_index = obj.columns </span><span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">obj.index</span>
        <span class="s1">other_axis = </span><span class="s5">1 </span><span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0  </span><span class="s3"># switches between 0 &amp; 1</span>
        <span class="s1">concatenated = concat(applied</span><span class="s2">, </span><span class="s1">axis=self.axis</span><span class="s2">, </span><span class="s1">verify_integrity=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">concatenated = concatenated.reindex(concat_index</span><span class="s2">, </span><span class="s1">axis=other_axis</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._set_result_index_ordered(concatenated)</span>

    <span class="s1">@Substitution(klass=</span><span class="s4">&quot;DataFrame&quot;</span><span class="s1">)</span>
    <span class="s1">@Appender(_transform_template)</span>
    <span class="s2">def </span><span class="s1">transform(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=</span><span class="s2">None, </span><span class="s1">engine_kwargs=</span><span class="s2">None, </span><span class="s1">**kwargs):</span>
        <span class="s2">return </span><span class="s1">self._transform(</span>
            <span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">engine=engine</span><span class="s2">, </span><span class="s1">engine_kwargs=engine_kwargs</span><span class="s2">, </span><span class="s1">**kwargs</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_can_use_transform_fast(self</span><span class="s2">, </span><span class="s1">result) -&gt; bool:</span>
        <span class="s2">return </span><span class="s1">isinstance(result</span><span class="s2">, </span><span class="s1">DataFrame) </span><span class="s2">and </span><span class="s1">result.columns.equals(</span>
            <span class="s1">self._obj_with_exclusions.columns</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_define_paths(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">if </span><span class="s1">isinstance(func</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">fast_path = </span><span class="s2">lambda </span><span class="s1">group: getattr(group</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s1">slow_path = </span><span class="s2">lambda </span><span class="s1">group: group.apply(</span>
                <span class="s2">lambda </span><span class="s1">x: getattr(x</span><span class="s2">, </span><span class="s1">func)(*args</span><span class="s2">, </span><span class="s1">**kwargs)</span><span class="s2">, </span><span class="s1">axis=self.axis</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fast_path = </span><span class="s2">lambda </span><span class="s1">group: func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>
            <span class="s1">slow_path = </span><span class="s2">lambda </span><span class="s1">group: group.apply(</span>
                <span class="s2">lambda </span><span class="s1">x: func(x</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span><span class="s2">, </span><span class="s1">axis=self.axis</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">fast_path</span><span class="s2">, </span><span class="s1">slow_path</span>

    <span class="s2">def </span><span class="s1">_choose_path(self</span><span class="s2">, </span><span class="s1">fast_path: Callable</span><span class="s2">, </span><span class="s1">slow_path: Callable</span><span class="s2">, </span><span class="s1">group: DataFrame):</span>
        <span class="s1">path = slow_path</span>
        <span class="s1">res = slow_path(group)</span>

        <span class="s3"># if we make it here, test if we can use the fast path</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">res_fast = fast_path(group)</span>
        <span class="s2">except </span><span class="s1">AssertionError:</span>
            <span class="s2">raise  </span><span class="s3"># pragma: no cover</span>
        <span class="s2">except </span><span class="s1">Exception:</span>
            <span class="s3"># GH#29631 For user-defined function, we can't predict what may be</span>
            <span class="s3">#  raised; see test_transform.test_transform_fastpath_raises</span>
            <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

        <span class="s3"># verify fast path does not change columns (and names), otherwise</span>
        <span class="s3"># its results cannot be joined with those of the slow path</span>
        <span class="s2">if not </span><span class="s1">isinstance(res_fast</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

        <span class="s2">if not </span><span class="s1">res_fast.columns.equals(group.columns):</span>
            <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

        <span class="s2">if </span><span class="s1">res_fast.equals(res):</span>
            <span class="s1">path = fast_path</span>

        <span class="s2">return </span><span class="s1">path</span><span class="s2">, </span><span class="s1">res</span>

    <span class="s2">def </span><span class="s1">_transform_item_by_item(self</span><span class="s2">, </span><span class="s1">obj: DataFrame</span><span class="s2">, </span><span class="s1">wrapper) -&gt; DataFrame:</span>
        <span class="s3"># iterate through columns, see test_transform_exclude_nuisance</span>
        <span class="s3">#  gets here with non-unique columns</span>
        <span class="s1">output = {}</span>
        <span class="s1">inds = []</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">(colname</span><span class="s2">, </span><span class="s1">sgb) </span><span class="s2">in </span><span class="s1">enumerate(self._iterate_column_groupbys(obj)):</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">output[i] = sgb.transform(wrapper)</span>
            <span class="s2">except </span><span class="s1">TypeError:</span>
                <span class="s3"># e.g. trying to call nanmean with string values</span>
                <span class="s1">warn_dropping_nuisance_columns_deprecated(type(self)</span><span class="s2">, </span><span class="s4">&quot;transform&quot;</span><span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">inds.append(i)</span>

        <span class="s2">if not </span><span class="s1">output:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Transform function invalid for data types&quot;</span><span class="s1">)</span>

        <span class="s1">columns = obj.columns.take(inds)</span>

        <span class="s1">result = self.obj._constructor(output</span><span class="s2">, </span><span class="s1">index=obj.index)</span>
        <span class="s1">result.columns = columns</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">filter(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">dropna=</span><span class="s2">True, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a copy of a DataFrame excluding filtered elements. 
 
        Elements from groups are filtered if they do not satisfy the 
        boolean criterion specified by func. 
 
        Parameters 
        ---------- 
        func : function 
            Function to apply to each subframe. Should return True or False. 
        dropna : Drop groups that do not pass the filter. True by default; 
            If False, groups that evaluate False are filled with NaNs. 
 
        Returns 
        ------- 
        filtered : DataFrame 
 
        Notes 
        ----- 
        Each subframe is endowed the attribute 'name' in case you need to know 
        which group you are working on. 
 
        Functions that mutate the passed object can produce unexpected 
        behavior or errors and are not supported. See :ref:`gotchas.udf-mutation` 
        for more details. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar', 
        ...                           'foo', 'bar'], 
        ...                    'B' : [1, 2, 3, 4, 5, 6], 
        ...                    'C' : [2.0, 5., 8., 1., 2., 9.]}) 
        &gt;&gt;&gt; grouped = df.groupby('A') 
        &gt;&gt;&gt; grouped.filter(lambda x: x['B'].mean() &gt; 3.) 
             A  B    C 
        1  bar  2  5.0 
        3  bar  4  1.0 
        5  bar  6  9.0 
        &quot;&quot;&quot;</span>
        <span class="s1">indices = []</span>

        <span class="s1">obj = self._selected_obj</span>
        <span class="s1">gen = self.grouper.get_iterator(obj</span><span class="s2">, </span><span class="s1">axis=self.axis)</span>

        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">group </span><span class="s2">in </span><span class="s1">gen:</span>
            <span class="s1">object.__setattr__(group</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, </span><span class="s1">name)</span>

            <span class="s1">res = func(group</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">res = res.squeeze()</span>
            <span class="s2">except </span><span class="s1">AttributeError:  </span><span class="s3"># allow e.g., scalars and frames to pass</span>
                <span class="s2">pass</span>

            <span class="s3"># interpret the result of the filter</span>
            <span class="s2">if </span><span class="s1">is_bool(res) </span><span class="s2">or </span><span class="s1">(is_scalar(res) </span><span class="s2">and </span><span class="s1">isna(res)):</span>
                <span class="s2">if </span><span class="s1">res </span><span class="s2">and </span><span class="s1">notna(res):</span>
                    <span class="s1">indices.append(self._get_index(name))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># non scalars aren't allowed</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span>
                    <span class="s4">f&quot;filter function returned a </span><span class="s2">{</span><span class="s1">type(res).__name__</span><span class="s2">}</span><span class="s4">, &quot;</span>
                    <span class="s4">&quot;but expected a scalar bool&quot;</span>
                <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">self._apply_filter(indices</span><span class="s2">, </span><span class="s1">dropna)</span>

    <span class="s2">def </span><span class="s1">__getitem__(self</span><span class="s2">, </span><span class="s1">key) -&gt; DataFrameGroupBy | SeriesGroupBy:</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3"># GH 37725</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Cannot subset columns when using axis=1&quot;</span><span class="s1">)</span>
        <span class="s3"># per GH 23566</span>
        <span class="s2">if </span><span class="s1">isinstance(key</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">and </span><span class="s1">len(key) &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3"># if len == 1, then it becomes a SeriesGroupBy and this is actually</span>
            <span class="s3"># valid syntax, so don't raise warning</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;Indexing with multiple keys (implicitly converted to a tuple &quot;</span>
                <span class="s4">&quot;of keys) will be deprecated, use a list instead.&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">super().__getitem__(key)</span>

    <span class="s2">def </span><span class="s1">_gotitem(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">ndim: int</span><span class="s2">, </span><span class="s1">subset=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        sub-classes to define 
        return a sliced object 
 
        Parameters 
        ---------- 
        key : string / list of selections 
        ndim : {1, 2} 
            requested ndim of result 
        subset : object, default None 
            subset to act on 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">ndim == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">subset </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">subset = self.obj</span>
            <span class="s2">return </span><span class="s1">DataFrameGroupBy(</span>
                <span class="s1">subset</span><span class="s2">,</span>
                <span class="s1">self.grouper</span><span class="s2">,</span>
                <span class="s1">axis=self.axis</span><span class="s2">,</span>
                <span class="s1">level=self.level</span><span class="s2">,</span>
                <span class="s1">grouper=self.grouper</span><span class="s2">,</span>
                <span class="s1">exclusions=self.exclusions</span><span class="s2">,</span>
                <span class="s1">selection=key</span><span class="s2">,</span>
                <span class="s1">as_index=self.as_index</span><span class="s2">,</span>
                <span class="s1">sort=self.sort</span><span class="s2">,</span>
                <span class="s1">group_keys=self.group_keys</span><span class="s2">,</span>
                <span class="s1">squeeze=self.squeeze</span><span class="s2">,</span>
                <span class="s1">observed=self.observed</span><span class="s2">,</span>
                <span class="s1">mutated=self.mutated</span><span class="s2">,</span>
                <span class="s1">dropna=self.dropna</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">subset </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">subset = self.obj[key]</span>
            <span class="s2">return </span><span class="s1">SeriesGroupBy(</span>
                <span class="s1">subset</span><span class="s2">,</span>
                <span class="s1">level=self.level</span><span class="s2">,</span>
                <span class="s1">grouper=self.grouper</span><span class="s2">,</span>
                <span class="s1">selection=key</span><span class="s2">,</span>
                <span class="s1">sort=self.sort</span><span class="s2">,</span>
                <span class="s1">group_keys=self.group_keys</span><span class="s2">,</span>
                <span class="s1">squeeze=self.squeeze</span><span class="s2">,</span>
                <span class="s1">observed=self.observed</span><span class="s2">,</span>
                <span class="s1">dropna=self.dropna</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s2">raise </span><span class="s1">AssertionError(</span><span class="s4">&quot;invalid ndim for _gotitem&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_data_to_aggregate(self) -&gt; Manager2D:</span>
        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">obj.T._mgr</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">obj._mgr</span>

    <span class="s2">def </span><span class="s1">_insert_inaxis_grouper_inplace(self</span><span class="s2">, </span><span class="s1">result: DataFrame) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s3"># zip in reverse so we can always insert at loc 0</span>
        <span class="s1">columns = result.columns</span>
        <span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">lev</span><span class="s2">, </span><span class="s1">in_axis </span><span class="s2">in </span><span class="s1">zip(</span>
            <span class="s1">reversed(self.grouper.names)</span><span class="s2">,</span>
            <span class="s1">reversed(self.grouper.get_group_levels())</span><span class="s2">,</span>
            <span class="s1">reversed([grp.in_axis </span><span class="s2">for </span><span class="s1">grp </span><span class="s2">in </span><span class="s1">self.grouper.groupings])</span><span class="s2">,</span>
        <span class="s1">):</span>
            <span class="s3"># GH #28549</span>
            <span class="s3"># When using .apply(-), name will be in columns already</span>
            <span class="s2">if </span><span class="s1">in_axis </span><span class="s2">and </span><span class="s1">name </span><span class="s2">not in </span><span class="s1">columns:</span>
                <span class="s1">result.insert(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">lev)</span>

    <span class="s2">def </span><span class="s1">_indexed_output_to_ndframe(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">output: Mapping[base.OutputKey</span><span class="s2">, </span><span class="s1">ArrayLike]</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Wrap the dict result of a GroupBy aggregation into a DataFrame. 
        &quot;&quot;&quot;</span>
        <span class="s1">indexed_output = {key.position: val </span><span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">val </span><span class="s2">in </span><span class="s1">output.items()}</span>
        <span class="s1">columns = Index([key.label </span><span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">output])</span>
        <span class="s1">columns._set_names(self._obj_with_exclusions._get_axis(</span><span class="s5">1 </span><span class="s1">- self.axis).names)</span>

        <span class="s1">result = self.obj._constructor(indexed_output)</span>
        <span class="s1">result.columns = columns</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_wrap_agged_manager(self</span><span class="s2">, </span><span class="s1">mgr: Manager2D) -&gt; DataFrame:</span>
        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s3"># GH 41998 - empty mgr always gets index of length 0</span>
            <span class="s1">rows = mgr.shape[</span><span class="s5">1</span><span class="s1">] </span><span class="s2">if </span><span class="s1">mgr.shape[</span><span class="s5">0</span><span class="s1">] &gt; </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
            <span class="s1">index = Index(range(rows))</span>
            <span class="s1">mgr.set_axis(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">index)</span>
            <span class="s1">result = self.obj._constructor(mgr)</span>

            <span class="s1">self._insert_inaxis_grouper_inplace(result)</span>
            <span class="s1">result = result._consolidate()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">index = self.grouper.result_index</span>
            <span class="s1">mgr.set_axis(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">index)</span>
            <span class="s1">result = self.obj._constructor(mgr)</span>

        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">result = result.T</span>

        <span class="s3"># Note: we only need to pass datetime=True in order to get numeric</span>
        <span class="s3">#  values converted</span>
        <span class="s2">return </span><span class="s1">self._reindex_output(result)._convert(datetime=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_iterate_column_groupbys(self</span><span class="s2">, </span><span class="s1">obj: DataFrame | Series):</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">colname </span><span class="s2">in </span><span class="s1">enumerate(obj.columns):</span>
            <span class="s2">yield </span><span class="s1">colname</span><span class="s2">, </span><span class="s1">SeriesGroupBy(</span>
                <span class="s1">obj.iloc[:</span><span class="s2">, </span><span class="s1">i]</span><span class="s2">,</span>
                <span class="s1">selection=colname</span><span class="s2">,</span>
                <span class="s1">grouper=self.grouper</span><span class="s2">,</span>
                <span class="s1">exclusions=self.exclusions</span><span class="s2">,</span>
                <span class="s1">observed=self.observed</span><span class="s2">,</span>
            <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_apply_to_column_groupbys(self</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">obj: DataFrame | Series) -&gt; DataFrame:</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

        <span class="s1">columns = obj.columns</span>
        <span class="s1">results = [</span>
            <span class="s1">func(col_groupby) </span><span class="s2">for </span><span class="s1">_</span><span class="s2">, </span><span class="s1">col_groupby </span><span class="s2">in </span><span class="s1">self._iterate_column_groupbys(obj)</span>
        <span class="s1">]</span>

        <span class="s2">if not </span><span class="s1">len(results):</span>
            <span class="s3"># concat would raise</span>
            <span class="s2">return </span><span class="s1">DataFrame([]</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">index=self.grouper.result_index)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">concat(results</span><span class="s2">, </span><span class="s1">keys=columns</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">nunique(self</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return DataFrame with counts of unique elements in each position. 
 
        Parameters 
        ---------- 
        dropna : bool, default True 
            Don't include NaN in the counts. 
 
        Returns 
        ------- 
        nunique: DataFrame 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'id': ['spam', 'egg', 'egg', 'spam', 
        ...                           'ham', 'ham'], 
        ...                    'value1': [1, 5, 5, 2, 5, 5], 
        ...                    'value2': list('abbaxy')}) 
        &gt;&gt;&gt; df 
             id  value1 value2 
        0  spam       1      a 
        1   egg       5      b 
        2   egg       5      b 
        3  spam       2      a 
        4   ham       5      x 
        5   ham       5      y 
 
        &gt;&gt;&gt; df.groupby('id').nunique() 
              value1  value2 
        id 
        egg        1       1 
        ham        1       2 
        spam       2       1 
 
        Check for rows with the same id but conflicting values: 
 
        &gt;&gt;&gt; df.groupby('id').filter(lambda g: (g.nunique() &gt; 1).any()) 
             id  value1 value2 
        0  spam       1      a 
        3  spam       2      a 
        4   ham       5      x 
        5   ham       5      y 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.axis != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># see test_groupby_crash_on_nunique</span>
            <span class="s2">return </span><span class="s1">self._python_agg_general(</span><span class="s2">lambda </span><span class="s1">sgb: sgb.nunique(dropna))</span>

        <span class="s1">obj = self._obj_with_exclusions</span>
        <span class="s1">results = self._apply_to_column_groupbys(</span>
            <span class="s2">lambda </span><span class="s1">sgb: sgb.nunique(dropna)</span><span class="s2">, </span><span class="s1">obj=obj</span>
        <span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">self.as_index:</span>
            <span class="s1">results.index = Index(range(len(results)))</span>
            <span class="s1">self._insert_inaxis_grouper_inplace(results)</span>

        <span class="s2">return </span><span class="s1">results</span>

    <span class="s1">@Appender(DataFrame.idxmax.__doc__)</span>
    <span class="s2">def </span><span class="s1">idxmax(self</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">skipna: bool = </span><span class="s2">True</span><span class="s1">):</span>
        <span class="s1">axis = DataFrame._get_axis_number(axis)</span>
        <span class="s1">numeric_only = </span><span class="s2">None if </span><span class="s1">axis == </span><span class="s5">0 </span><span class="s2">else False</span>

        <span class="s2">def </span><span class="s1">func(df):</span>
            <span class="s3"># NB: here we use numeric_only=None, in DataFrame it is False GH#38217</span>
            <span class="s1">res = df._reduce(</span>
                <span class="s1">nanops.nanargmax</span><span class="s2">,</span>
                <span class="s4">&quot;argmax&quot;</span><span class="s2">,</span>
                <span class="s1">axis=axis</span><span class="s2">,</span>
                <span class="s1">skipna=skipna</span><span class="s2">,</span>
                <span class="s1">numeric_only=numeric_only</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">indices = res._values</span>
            <span class="s1">index = df._get_axis(axis)</span>
            <span class="s1">result = [index[i] </span><span class="s2">if </span><span class="s1">i &gt;= </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">np.nan </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">indices]</span>
            <span class="s2">return </span><span class="s1">df._constructor_sliced(result</span><span class="s2">, </span><span class="s1">index=res.index)</span>

        <span class="s1">func.__name__ = </span><span class="s4">&quot;idxmax&quot;</span>
        <span class="s2">return </span><span class="s1">self._python_apply_general(func</span><span class="s2">, </span><span class="s1">self._obj_with_exclusions)</span>

    <span class="s1">@Appender(DataFrame.idxmin.__doc__)</span>
    <span class="s2">def </span><span class="s1">idxmin(self</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">skipna: bool = </span><span class="s2">True</span><span class="s1">):</span>
        <span class="s1">axis = DataFrame._get_axis_number(axis)</span>
        <span class="s1">numeric_only = </span><span class="s2">None if </span><span class="s1">axis == </span><span class="s5">0 </span><span class="s2">else False</span>

        <span class="s2">def </span><span class="s1">func(df):</span>
            <span class="s3"># NB: here we use numeric_only=None, in DataFrame it is False GH#38217</span>
            <span class="s1">res = df._reduce(</span>
                <span class="s1">nanops.nanargmin</span><span class="s2">,</span>
                <span class="s4">&quot;argmin&quot;</span><span class="s2">,</span>
                <span class="s1">axis=axis</span><span class="s2">,</span>
                <span class="s1">skipna=skipna</span><span class="s2">,</span>
                <span class="s1">numeric_only=numeric_only</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">indices = res._values</span>
            <span class="s1">index = df._get_axis(axis)</span>
            <span class="s1">result = [index[i] </span><span class="s2">if </span><span class="s1">i &gt;= </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">np.nan </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">indices]</span>
            <span class="s2">return </span><span class="s1">df._constructor_sliced(result</span><span class="s2">, </span><span class="s1">index=res.index)</span>

        <span class="s1">func.__name__ = </span><span class="s4">&quot;idxmin&quot;</span>
        <span class="s2">return </span><span class="s1">self._python_apply_general(func</span><span class="s2">, </span><span class="s1">self._obj_with_exclusions)</span>

    <span class="s1">boxplot = boxplot_frame_groupby</span>

    <span class="s2">def </span><span class="s1">value_counts(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">subset: Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">normalize: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">True,</span>
        <span class="s1">ascending: bool = </span><span class="s2">False,</span>
        <span class="s1">dropna: bool = </span><span class="s2">True,</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a Series or DataFrame containing counts of unique rows. 
 
        .. versionadded:: 1.4.0 
 
        Parameters 
        ---------- 
        subset : list-like, optional 
            Columns to use when counting unique combinations. 
        normalize : bool, default False 
            Return proportions rather than frequencies. 
        sort : bool, default True 
            Sort by frequencies. 
        ascending : bool, default False 
            Sort in ascending order. 
        dropna : bool, default True 
            Dont include counts of rows that contain NA values. 
 
        Returns 
        ------- 
        Series or DataFrame 
            Series if the groupby as_index is True, otherwise DataFrame. 
 
        See Also 
        -------- 
        Series.value_counts: Equivalent method on Series. 
        DataFrame.value_counts: Equivalent method on DataFrame. 
        SeriesGroupBy.value_counts: Equivalent method on SeriesGroupBy. 
 
        Notes 
        ----- 
        - If the groupby as_index is True then the returned Series will have a 
          MultiIndex with one level per input column. 
        - If the groupby as_index is False then the returned DataFrame will have an 
          additional column with the value_counts. The column is labelled 'count' or 
          'proportion', depending on the ``normalize`` parameter. 
 
        By default, rows that contain any NA values are omitted from 
        the result. 
 
        By default, the result will be in descending order so that the 
        first element of each group is the most frequently-occurring row. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({ 
        ...    'gender': ['male', 'male', 'female', 'male', 'female', 'male'], 
        ...    'education': ['low', 'medium', 'high', 'low', 'high', 'low'], 
        ...    'country': ['US', 'FR', 'US', 'FR', 'FR', 'FR'] 
        ... }) 
 
        &gt;&gt;&gt; df 
            gender  education   country 
        0   male    low         US 
        1   male    medium      FR 
        2   female  high        US 
        3   male    low         FR 
        4   female  high        FR 
        5   male    low         FR 
 
        &gt;&gt;&gt; df.groupby('gender').value_counts() 
        gender  education  country 
        female  high       FR         1 
                           US         1 
        male    low        FR         2 
                           US         1 
                medium     FR         1 
        dtype: int64 
 
        &gt;&gt;&gt; df.groupby('gender').value_counts(ascending=True) 
        gender  education  country 
        female  high       FR         1 
                           US         1 
        male    low        US         1 
                medium     FR         1 
                low        FR         2 
        dtype: int64 
 
        &gt;&gt;&gt; df.groupby('gender').value_counts(normalize=True) 
        gender  education  country 
        female  high       FR         0.50 
                           US         0.50 
        male    low        FR         0.50 
                           US         0.25 
                medium     FR         0.25 
        dtype: float64 
 
        &gt;&gt;&gt; df.groupby('gender', as_index=False).value_counts() 
           gender education country  count 
        0  female      high      FR      1 
        1  female      high      US      1 
        2    male       low      FR      2 
        3    male       low      US      1 
        4    male    medium      FR      1 
 
        &gt;&gt;&gt; df.groupby('gender', as_index=False).value_counts(normalize=True) 
           gender education country  proportion 
        0  female      high      FR        0.50 
        1  female      high      US        0.50 
        2    male       low      FR        0.50 
        3    male       low      US        0.25 
        4    male    medium      FR        0.25 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError(</span>
                <span class="s4">&quot;DataFrameGroupBy.value_counts only handles axis=0&quot;</span>
            <span class="s1">)</span>

        <span class="s2">with </span><span class="s1">self._group_selection_context():</span>
            <span class="s1">df = self.obj</span>

            <span class="s1">in_axis_names = {</span>
                <span class="s1">grouping.name </span><span class="s2">for </span><span class="s1">grouping </span><span class="s2">in </span><span class="s1">self.grouper.groupings </span><span class="s2">if </span><span class="s1">grouping.in_axis</span>
            <span class="s1">}</span>
            <span class="s2">if </span><span class="s1">isinstance(self._selected_obj</span><span class="s2">, </span><span class="s1">Series):</span>
                <span class="s1">name = self._selected_obj.name</span>
                <span class="s1">keys = [] </span><span class="s2">if </span><span class="s1">name </span><span class="s2">in </span><span class="s1">in_axis_names </span><span class="s2">else </span><span class="s1">[self._selected_obj]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">keys = [</span>
                    <span class="s3"># Can't use .values because the column label needs to be preserved</span>
                    <span class="s1">self._selected_obj.iloc[:</span><span class="s2">, </span><span class="s1">idx]</span>
                    <span class="s2">for </span><span class="s1">idx</span><span class="s2">, </span><span class="s1">name </span><span class="s2">in </span><span class="s1">enumerate(self._selected_obj.columns)</span>
                    <span class="s2">if </span><span class="s1">name </span><span class="s2">not in </span><span class="s1">in_axis_names</span>
                <span class="s1">]</span>

            <span class="s2">if </span><span class="s1">subset </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">clashing = set(subset) &amp; set(in_axis_names)</span>
                <span class="s2">if </span><span class="s1">clashing:</span>
                    <span class="s2">raise </span><span class="s1">ValueError(</span>
                        <span class="s4">f&quot;Keys </span><span class="s2">{</span><span class="s1">clashing</span><span class="s2">} </span><span class="s4">in subset cannot be in &quot;</span>
                        <span class="s4">&quot;the groupby column keys&quot;</span>
                    <span class="s1">)</span>

            <span class="s1">groupings = list(self.grouper.groupings)</span>
            <span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">keys:</span>
                <span class="s1">grouper</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = get_grouper(</span>
                    <span class="s1">df</span><span class="s2">,</span>
                    <span class="s1">key=key</span><span class="s2">,</span>
                    <span class="s1">axis=self.axis</span><span class="s2">,</span>
                    <span class="s1">sort=self.sort</span><span class="s2">,</span>
                    <span class="s1">dropna=dropna</span><span class="s2">,</span>
                <span class="s1">)</span>
                <span class="s1">groupings += list(grouper.groupings)</span>

            <span class="s3"># Take the size of the overall columns</span>
            <span class="s1">gb = df.groupby(</span>
                <span class="s1">groupings</span><span class="s2">,</span>
                <span class="s1">sort=self.sort</span><span class="s2">,</span>
                <span class="s1">observed=self.observed</span><span class="s2">,</span>
                <span class="s1">dropna=self.dropna</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">result = cast(Series</span><span class="s2">, </span><span class="s1">gb.size())</span>

            <span class="s2">if </span><span class="s1">normalize:</span>
                <span class="s3"># Normalize the results by dividing by the original group sizes.</span>
                <span class="s3"># We are guaranteed to have the first N levels be the</span>
                <span class="s3"># user-requested grouping.</span>
                <span class="s1">levels = list(range(len(self.grouper.groupings)</span><span class="s2">, </span><span class="s1">result.index.nlevels))</span>
                <span class="s1">indexed_group_size = result.groupby(</span>
                    <span class="s1">result.index.droplevel(levels)</span><span class="s2">,</span>
                    <span class="s1">sort=self.sort</span><span class="s2">,</span>
                    <span class="s1">observed=self.observed</span><span class="s2">,</span>
                    <span class="s1">dropna=self.dropna</span><span class="s2">,</span>
                <span class="s1">).transform(</span><span class="s4">&quot;sum&quot;</span><span class="s1">)</span>

                <span class="s1">result /= indexed_group_size</span>

            <span class="s2">if </span><span class="s1">sort:</span>
                <span class="s3"># Sort the values and then resort by the main grouping</span>
                <span class="s1">index_level = range(len(self.grouper.groupings))</span>
                <span class="s1">result = result.sort_values(ascending=ascending).sort_index(</span>
                    <span class="s1">level=index_level</span><span class="s2">, </span><span class="s1">sort_remaining=</span><span class="s2">False</span>
                <span class="s1">)</span>

            <span class="s2">if not </span><span class="s1">self.as_index:</span>
                <span class="s3"># Convert to frame</span>
                <span class="s1">result = result.reset_index(name=</span><span class="s4">&quot;proportion&quot; </span><span class="s2">if </span><span class="s1">normalize </span><span class="s2">else </span><span class="s4">&quot;count&quot;</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">result.__finalize__(self.obj</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;value_counts&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_wrap_transform_general_frame(</span>
    <span class="s1">obj: DataFrame</span><span class="s2">, </span><span class="s1">group: DataFrame</span><span class="s2">, </span><span class="s1">res: DataFrame | Series</span>
<span class="s1">) -&gt; DataFrame:</span>
    <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">concat</span>

    <span class="s2">if </span><span class="s1">isinstance(res</span><span class="s2">, </span><span class="s1">Series):</span>
        <span class="s3"># we need to broadcast across the</span>
        <span class="s3"># other dimension; this will preserve dtypes</span>
        <span class="s3"># GH14457</span>
        <span class="s2">if </span><span class="s1">res.index.is_(obj.index):</span>
            <span class="s1">res_frame = concat([res] * len(group.columns)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">res_frame.columns = group.columns</span>
            <span class="s1">res_frame.index = group.index</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">res_frame = obj._constructor(</span>
                <span class="s1">np.concatenate([res.values] * len(group.index)).reshape(group.shape)</span><span class="s2">,</span>
                <span class="s1">columns=group.columns</span><span class="s2">,</span>
                <span class="s1">index=group.index</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">isinstance(res_frame</span><span class="s2">, </span><span class="s1">DataFrame)</span>
        <span class="s2">return </span><span class="s1">res_frame</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">res</span>
</pre>
</body>
</html>