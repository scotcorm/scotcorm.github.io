<html>
<head>
<title>npyio.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #cc7832;}
.s1 { color: #a9b7c6;}
.s2 { color: #6a8759;}
.s3 { color: #629755; font-style: italic;}
.s4 { color: #808080;}
.s5 { color: #6897bb;}
.s6 { color: #a5c261;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
npyio.py</font>
</center></td></tr></table>
<pre><span class="s0">import </span><span class="s1">os</span>
<span class="s0">import </span><span class="s1">re</span>
<span class="s0">import </span><span class="s1">functools</span>
<span class="s0">import </span><span class="s1">itertools</span>
<span class="s0">import </span><span class="s1">warnings</span>
<span class="s0">import </span><span class="s1">weakref</span>
<span class="s0">import </span><span class="s1">contextlib</span>
<span class="s0">from </span><span class="s1">operator </span><span class="s0">import </span><span class="s1">itemgetter</span><span class="s0">, </span><span class="s1">index </span><span class="s0">as </span><span class="s1">opindex</span><span class="s0">, </span><span class="s1">methodcaller</span>
<span class="s0">from </span><span class="s1">collections.abc </span><span class="s0">import </span><span class="s1">Mapping</span>

<span class="s0">import </span><span class="s1">numpy </span><span class="s0">as </span><span class="s1">np</span>
<span class="s0">from </span><span class="s1">. </span><span class="s0">import </span><span class="s1">format</span>
<span class="s0">from </span><span class="s1">._datasource </span><span class="s0">import </span><span class="s1">DataSource</span>
<span class="s0">from </span><span class="s1">numpy.core </span><span class="s0">import </span><span class="s1">overrides</span>
<span class="s0">from </span><span class="s1">numpy.core.multiarray </span><span class="s0">import </span><span class="s1">packbits</span><span class="s0">, </span><span class="s1">unpackbits</span>
<span class="s0">from </span><span class="s1">numpy.core.overrides </span><span class="s0">import </span><span class="s1">set_array_function_like_doc</span><span class="s0">, </span><span class="s1">set_module</span>
<span class="s0">from </span><span class="s1">._iotools </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">LineSplitter</span><span class="s0">, </span><span class="s1">NameValidator</span><span class="s0">, </span><span class="s1">StringConverter</span><span class="s0">, </span><span class="s1">ConverterError</span><span class="s0">,</span>
    <span class="s1">ConverterLockError</span><span class="s0">, </span><span class="s1">ConversionWarning</span><span class="s0">, </span><span class="s1">_is_string_like</span><span class="s0">,</span>
    <span class="s1">has_nested_fields</span><span class="s0">, </span><span class="s1">flatten_dtype</span><span class="s0">, </span><span class="s1">easy_dtype</span><span class="s0">, </span><span class="s1">_decode_line</span>
    <span class="s1">)</span>

<span class="s0">from </span><span class="s1">numpy.compat </span><span class="s0">import </span><span class="s1">(</span>
    <span class="s1">asbytes</span><span class="s0">, </span><span class="s1">asstr</span><span class="s0">, </span><span class="s1">asunicode</span><span class="s0">, </span><span class="s1">os_fspath</span><span class="s0">, </span><span class="s1">os_PathLike</span><span class="s0">,</span>
    <span class="s1">pickle</span>
    <span class="s1">)</span>


<span class="s1">__all__ = [</span>
    <span class="s2">'savetxt'</span><span class="s0">, </span><span class="s2">'loadtxt'</span><span class="s0">, </span><span class="s2">'genfromtxt'</span><span class="s0">,</span>
    <span class="s2">'recfromtxt'</span><span class="s0">, </span><span class="s2">'recfromcsv'</span><span class="s0">, </span><span class="s2">'load'</span><span class="s0">, </span><span class="s2">'save'</span><span class="s0">, </span><span class="s2">'savez'</span><span class="s0">,</span>
    <span class="s2">'savez_compressed'</span><span class="s0">, </span><span class="s2">'packbits'</span><span class="s0">, </span><span class="s2">'unpackbits'</span><span class="s0">, </span><span class="s2">'fromregex'</span><span class="s0">, </span><span class="s2">'DataSource'</span>
    <span class="s1">]</span>


<span class="s1">array_function_dispatch = functools.partial(</span>
    <span class="s1">overrides.array_function_dispatch</span><span class="s0">, </span><span class="s1">module=</span><span class="s2">'numpy'</span><span class="s1">)</span>


<span class="s0">class </span><span class="s1">BagObj:</span>
    <span class="s3">&quot;&quot;&quot; 
    BagObj(obj) 
 
    Convert attribute look-ups to getitems on the object passed in. 
 
    Parameters 
    ---------- 
    obj : class instance 
        Object on which attribute look-up is performed. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from numpy.lib.npyio import BagObj as BO 
    &gt;&gt;&gt; class BagDemo: 
    ...     def __getitem__(self, key): # An instance of BagObj(BagDemo) 
    ...                                 # will call this method when any 
    ...                                 # attribute look-up is required 
    ...         result = &quot;Doesn't matter what you want, &quot; 
    ...         return result + &quot;you're gonna get this&quot; 
    ... 
    &gt;&gt;&gt; demo_obj = BagDemo() 
    &gt;&gt;&gt; bagobj = BO(demo_obj) 
    &gt;&gt;&gt; bagobj.hello_there 
    &quot;Doesn't matter what you want, you're gonna get this&quot; 
    &gt;&gt;&gt; bagobj.I_can_be_anything 
    &quot;Doesn't matter what you want, you're gonna get this&quot; 
 
    &quot;&quot;&quot;</span>

    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">obj):</span>
        <span class="s4"># Use weakref to make NpzFile objects collectable by refcount</span>
        <span class="s1">self._obj = weakref.proxy(obj)</span>

    <span class="s0">def </span><span class="s1">__getattribute__(self</span><span class="s0">, </span><span class="s1">key):</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">object.__getattribute__(self</span><span class="s0">, </span><span class="s2">'_obj'</span><span class="s1">)[key]</span>
        <span class="s0">except </span><span class="s1">KeyError:</span>
            <span class="s0">raise </span><span class="s1">AttributeError(key) </span><span class="s0">from None</span>

    <span class="s0">def </span><span class="s1">__dir__(self):</span>
        <span class="s3">&quot;&quot;&quot; 
        Enables dir(bagobj) to list the files in an NpzFile. 
 
        This also enables tab-completion in an interpreter or IPython. 
        &quot;&quot;&quot;</span>
        <span class="s0">return </span><span class="s1">list(object.__getattribute__(self</span><span class="s0">, </span><span class="s2">'_obj'</span><span class="s1">).keys())</span>


<span class="s0">def </span><span class="s1">zipfile_factory(file</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s3">&quot;&quot;&quot; 
    Create a ZipFile. 
 
    Allows for Zip64, and the `file` argument can accept file, str, or 
    pathlib.Path objects. `args` and `kwargs` are passed to the zipfile.ZipFile 
    constructor. 
    &quot;&quot;&quot;</span>
    <span class="s0">if not </span><span class="s1">hasattr(file</span><span class="s0">, </span><span class="s2">'read'</span><span class="s1">):</span>
        <span class="s1">file = os_fspath(file)</span>
    <span class="s0">import </span><span class="s1">zipfile</span>
    <span class="s1">kwargs[</span><span class="s2">'allowZip64'</span><span class="s1">] = </span><span class="s0">True</span>
    <span class="s0">return </span><span class="s1">zipfile.ZipFile(file</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwargs)</span>


<span class="s0">class </span><span class="s1">NpzFile(Mapping):</span>
    <span class="s3">&quot;&quot;&quot; 
    NpzFile(fid) 
 
    A dictionary-like object with lazy-loading of files in the zipped 
    archive provided on construction. 
 
    `NpzFile` is used to load files in the NumPy ``.npz`` data archive 
    format. It assumes that files in the archive have a ``.npy`` extension, 
    other files are ignored. 
 
    The arrays and file strings are lazily loaded on either 
    getitem access using ``obj['key']`` or attribute lookup using 
    ``obj.f.key``. A list of all files (without ``.npy`` extensions) can 
    be obtained with ``obj.files`` and the ZipFile object itself using 
    ``obj.zip``. 
 
    Attributes 
    ---------- 
    files : list of str 
        List of all files in the archive with a ``.npy`` extension. 
    zip : ZipFile instance 
        The ZipFile object initialized with the zipped archive. 
    f : BagObj instance 
        An object on which attribute can be performed as an alternative 
        to getitem access on the `NpzFile` instance itself. 
    allow_pickle : bool, optional 
        Allow loading pickled data. Default: False 
 
        .. versionchanged:: 1.16.3 
            Made default False in response to CVE-2019-6446. 
 
    pickle_kwargs : dict, optional 
        Additional keyword arguments to pass on to pickle.load. 
        These are only useful when loading object arrays saved on 
        Python 2 when using Python 3. 
 
    Parameters 
    ---------- 
    fid : file or str 
        The zipped archive to open. This is either a file-like object 
        or a string containing the path to the archive. 
    own_fid : bool, optional 
        Whether NpzFile should close the file handle. 
        Requires that `fid` is a file-like object. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from tempfile import TemporaryFile 
    &gt;&gt;&gt; outfile = TemporaryFile() 
    &gt;&gt;&gt; x = np.arange(10) 
    &gt;&gt;&gt; y = np.sin(x) 
    &gt;&gt;&gt; np.savez(outfile, x=x, y=y) 
    &gt;&gt;&gt; _ = outfile.seek(0) 
 
    &gt;&gt;&gt; npz = np.load(outfile) 
    &gt;&gt;&gt; isinstance(npz, np.lib.io.NpzFile) 
    True 
    &gt;&gt;&gt; sorted(npz.files) 
    ['x', 'y'] 
    &gt;&gt;&gt; npz['x']  # getitem access 
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 
    &gt;&gt;&gt; npz.f.x  # attribute lookup 
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 
 
    &quot;&quot;&quot;</span>
    <span class="s4"># Make __exit__ safe if zipfile_factory raises an exception</span>
    <span class="s1">zip = </span><span class="s0">None</span>
    <span class="s1">fid = </span><span class="s0">None</span>

    <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">fid</span><span class="s0">, </span><span class="s1">own_fid=</span><span class="s0">False, </span><span class="s1">allow_pickle=</span><span class="s0">False,</span>
                 <span class="s1">pickle_kwargs=</span><span class="s0">None</span><span class="s1">):</span>
        <span class="s4"># Import is postponed to here since zipfile depends on gzip, an</span>
        <span class="s4"># optional component of the so-called standard library.</span>
        <span class="s1">_zip = zipfile_factory(fid)</span>
        <span class="s1">self._files = _zip.namelist()</span>
        <span class="s1">self.files = []</span>
        <span class="s1">self.allow_pickle = allow_pickle</span>
        <span class="s1">self.pickle_kwargs = pickle_kwargs</span>
        <span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">self._files:</span>
            <span class="s0">if </span><span class="s1">x.endswith(</span><span class="s2">'.npy'</span><span class="s1">):</span>
                <span class="s1">self.files.append(x[:-</span><span class="s5">4</span><span class="s1">])</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">self.files.append(x)</span>
        <span class="s1">self.zip = _zip</span>
        <span class="s1">self.f = BagObj(self)</span>
        <span class="s0">if </span><span class="s1">own_fid:</span>
            <span class="s1">self.fid = fid</span>

    <span class="s0">def </span><span class="s1">__enter__(self):</span>
        <span class="s0">return </span><span class="s1">self</span>

    <span class="s0">def </span><span class="s1">__exit__(self</span><span class="s0">, </span><span class="s1">exc_type</span><span class="s0">, </span><span class="s1">exc_value</span><span class="s0">, </span><span class="s1">traceback):</span>
        <span class="s1">self.close()</span>

    <span class="s0">def </span><span class="s1">close(self):</span>
        <span class="s3">&quot;&quot;&quot; 
        Close the file. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">if </span><span class="s1">self.zip </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">self.zip.close()</span>
            <span class="s1">self.zip = </span><span class="s0">None</span>
        <span class="s0">if </span><span class="s1">self.fid </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">self.fid.close()</span>
            <span class="s1">self.fid = </span><span class="s0">None</span>
        <span class="s1">self.f = </span><span class="s0">None  </span><span class="s4"># break reference cycle</span>

    <span class="s0">def </span><span class="s1">__del__(self):</span>
        <span class="s1">self.close()</span>

    <span class="s4"># Implement the Mapping ABC</span>
    <span class="s0">def </span><span class="s1">__iter__(self):</span>
        <span class="s0">return </span><span class="s1">iter(self.files)</span>

    <span class="s0">def </span><span class="s1">__len__(self):</span>
        <span class="s0">return </span><span class="s1">len(self.files)</span>

    <span class="s0">def </span><span class="s1">__getitem__(self</span><span class="s0">, </span><span class="s1">key):</span>
        <span class="s4"># FIXME: This seems like it will copy strings around</span>
        <span class="s4">#   more than is strictly necessary.  The zipfile</span>
        <span class="s4">#   will read the string and then</span>
        <span class="s4">#   the format.read_array will copy the string</span>
        <span class="s4">#   to another place in memory.</span>
        <span class="s4">#   It would be better if the zipfile could read</span>
        <span class="s4">#   (or at least uncompress) the data</span>
        <span class="s4">#   directly into the array memory.</span>
        <span class="s1">member = </span><span class="s0">False</span>
        <span class="s0">if </span><span class="s1">key </span><span class="s0">in </span><span class="s1">self._files:</span>
            <span class="s1">member = </span><span class="s0">True</span>
        <span class="s0">elif </span><span class="s1">key </span><span class="s0">in </span><span class="s1">self.files:</span>
            <span class="s1">member = </span><span class="s0">True</span>
            <span class="s1">key += </span><span class="s2">'.npy'</span>
        <span class="s0">if </span><span class="s1">member:</span>
            <span class="s1">bytes = self.zip.open(key)</span>
            <span class="s1">magic = bytes.read(len(format.MAGIC_PREFIX))</span>
            <span class="s1">bytes.close()</span>
            <span class="s0">if </span><span class="s1">magic == format.MAGIC_PREFIX:</span>
                <span class="s1">bytes = self.zip.open(key)</span>
                <span class="s0">return </span><span class="s1">format.read_array(bytes</span><span class="s0">,</span>
                                         <span class="s1">allow_pickle=self.allow_pickle</span><span class="s0">,</span>
                                         <span class="s1">pickle_kwargs=self.pickle_kwargs)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">return </span><span class="s1">self.zip.read(key)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">KeyError(</span><span class="s2">&quot;%s is not a file in the archive&quot; </span><span class="s1">% key)</span>

    <span class="s4"># deprecate the python 2 dict apis that we supported by accident in</span>
    <span class="s4"># python 3. We forgot to implement itervalues() at all in earlier</span>
    <span class="s4"># versions of numpy, so no need to deprecated it here.</span>

    <span class="s0">def </span><span class="s1">iteritems(self):</span>
        <span class="s4"># Numpy 1.15, 2018-02-20</span>
        <span class="s1">warnings.warn(</span>
            <span class="s2">&quot;NpzFile.iteritems is deprecated in python 3, to match the &quot;</span>
            <span class="s2">&quot;removal of dict.itertems. Use .items() instead.&quot;</span><span class="s0">,</span>
            <span class="s1">DeprecationWarning</span><span class="s0">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s0">return </span><span class="s1">self.items()</span>

    <span class="s0">def </span><span class="s1">iterkeys(self):</span>
        <span class="s4"># Numpy 1.15, 2018-02-20</span>
        <span class="s1">warnings.warn(</span>
            <span class="s2">&quot;NpzFile.iterkeys is deprecated in python 3, to match the &quot;</span>
            <span class="s2">&quot;removal of dict.iterkeys. Use .keys() instead.&quot;</span><span class="s0">,</span>
            <span class="s1">DeprecationWarning</span><span class="s0">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>
        <span class="s0">return </span><span class="s1">self.keys()</span>


<span class="s1">@set_module(</span><span class="s2">'numpy'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">load(file</span><span class="s0">, </span><span class="s1">mmap_mode=</span><span class="s0">None, </span><span class="s1">allow_pickle=</span><span class="s0">False, </span><span class="s1">fix_imports=</span><span class="s0">True,</span>
         <span class="s1">encoding=</span><span class="s2">'ASCII'</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Load arrays or pickled objects from ``.npy``, ``.npz`` or pickled files. 
 
    .. warning:: Loading files that contain object arrays uses the ``pickle`` 
                 module, which is not secure against erroneous or maliciously 
                 constructed data. Consider passing ``allow_pickle=False`` to 
                 load data that is known not to contain object arrays for the 
                 safer handling of untrusted sources. 
 
    Parameters 
    ---------- 
    file : file-like object, string, or pathlib.Path 
        The file to read. File-like objects must support the 
        ``seek()`` and ``read()`` methods. Pickled files require that the 
        file-like object support the ``readline()`` method as well. 
    mmap_mode : {None, 'r+', 'r', 'w+', 'c'}, optional 
        If not None, then memory-map the file, using the given mode (see 
        `numpy.memmap` for a detailed description of the modes).  A 
        memory-mapped array is kept on disk. However, it can be accessed 
        and sliced like any ndarray.  Memory mapping is especially useful 
        for accessing small fragments of large files without reading the 
        entire file into memory. 
    allow_pickle : bool, optional 
        Allow loading pickled object arrays stored in npy files. Reasons for 
        disallowing pickles include security, as loading pickled data can 
        execute arbitrary code. If pickles are disallowed, loading object 
        arrays will fail. Default: False 
 
        .. versionchanged:: 1.16.3 
            Made default False in response to CVE-2019-6446. 
 
    fix_imports : bool, optional 
        Only useful when loading Python 2 generated pickled files on Python 3, 
        which includes npy/npz files containing object arrays. If `fix_imports` 
        is True, pickle will try to map the old Python 2 names to the new names 
        used in Python 3. 
    encoding : str, optional 
        What encoding to use when reading Python 2 strings. Only useful when 
        loading Python 2 generated pickled files in Python 3, which includes 
        npy/npz files containing object arrays. Values other than 'latin1', 
        'ASCII', and 'bytes' are not allowed, as they can corrupt numerical 
        data. Default: 'ASCII' 
 
    Returns 
    ------- 
    result : array, tuple, dict, etc. 
        Data stored in the file. For ``.npz`` files, the returned instance 
        of NpzFile class must be closed to avoid leaking file descriptors. 
 
    Raises 
    ------ 
    OSError 
        If the input file does not exist or cannot be read. 
    UnpicklingError 
        If ``allow_pickle=True``, but the file cannot be loaded as a pickle. 
    ValueError 
        The file contains an object array, but ``allow_pickle=False`` given. 
 
    See Also 
    -------- 
    save, savez, savez_compressed, loadtxt 
    memmap : Create a memory-map to an array stored in a file on disk. 
    lib.format.open_memmap : Create or load a memory-mapped ``.npy`` file. 
 
    Notes 
    ----- 
    - If the file contains pickle data, then whatever object is stored 
      in the pickle is returned. 
    - If the file is a ``.npy`` file, then a single array is returned. 
    - If the file is a ``.npz`` file, then a dictionary-like object is 
      returned, containing ``{filename: array}`` key-value pairs, one for 
      each file in the archive. 
    - If the file is a ``.npz`` file, the returned value supports the 
      context manager protocol in a similar fashion to the open function:: 
 
        with load('foo.npz') as data: 
            a = data['a'] 
 
      The underlying file descriptor is closed when exiting the 'with' 
      block. 
 
    Examples 
    -------- 
    Store data to disk, and load it again: 
 
    &gt;&gt;&gt; np.save('/tmp/123', np.array([[1, 2, 3], [4, 5, 6]])) 
    &gt;&gt;&gt; np.load('/tmp/123.npy') 
    array([[1, 2, 3], 
           [4, 5, 6]]) 
 
    Store compressed data to disk, and load it again: 
 
    &gt;&gt;&gt; a=np.array([[1, 2, 3], [4, 5, 6]]) 
    &gt;&gt;&gt; b=np.array([1, 2]) 
    &gt;&gt;&gt; np.savez('/tmp/123.npz', a=a, b=b) 
    &gt;&gt;&gt; data = np.load('/tmp/123.npz') 
    &gt;&gt;&gt; data['a'] 
    array([[1, 2, 3], 
           [4, 5, 6]]) 
    &gt;&gt;&gt; data['b'] 
    array([1, 2]) 
    &gt;&gt;&gt; data.close() 
 
    Mem-map the stored array, and then access the second row 
    directly from disk: 
 
    &gt;&gt;&gt; X = np.load('/tmp/123.npy', mmap_mode='r') 
    &gt;&gt;&gt; X[1, :] 
    memmap([4, 5, 6]) 
 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">encoding </span><span class="s0">not in </span><span class="s1">(</span><span class="s2">'ASCII'</span><span class="s0">, </span><span class="s2">'latin1'</span><span class="s0">, </span><span class="s2">'bytes'</span><span class="s1">):</span>
        <span class="s4"># The 'encoding' value for pickle also affects what encoding</span>
        <span class="s4"># the serialized binary data of NumPy arrays is loaded</span>
        <span class="s4"># in. Pickle does not pass on the encoding information to</span>
        <span class="s4"># NumPy. The unpickling code in numpy.core.multiarray is</span>
        <span class="s4"># written to assume that unicode data appearing where binary</span>
        <span class="s4"># should be is in 'latin1'. 'bytes' is also safe, as is 'ASCII'.</span>
        <span class="s4">#</span>
        <span class="s4"># Other encoding values can corrupt binary data, and we</span>
        <span class="s4"># purposefully disallow them. For the same reason, the errors=</span>
        <span class="s4"># argument is not exposed, as values other than 'strict'</span>
        <span class="s4"># result can similarly silently corrupt numerical data.</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;encoding must be 'ASCII', 'latin1', or 'bytes'&quot;</span><span class="s1">)</span>

    <span class="s1">pickle_kwargs = dict(encoding=encoding</span><span class="s0">, </span><span class="s1">fix_imports=fix_imports)</span>

    <span class="s0">with </span><span class="s1">contextlib.ExitStack() </span><span class="s0">as </span><span class="s1">stack:</span>
        <span class="s0">if </span><span class="s1">hasattr(file</span><span class="s0">, </span><span class="s2">'read'</span><span class="s1">):</span>
            <span class="s1">fid = file</span>
            <span class="s1">own_fid = </span><span class="s0">False</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">fid = stack.enter_context(open(os_fspath(file)</span><span class="s0">, </span><span class="s2">&quot;rb&quot;</span><span class="s1">))</span>
            <span class="s1">own_fid = </span><span class="s0">True</span>

        <span class="s4"># Code to distinguish from NumPy binary files and pickles.</span>
        <span class="s1">_ZIP_PREFIX = </span><span class="s6">b'PK</span><span class="s0">\x03\x04</span><span class="s6">'</span>
        <span class="s1">_ZIP_SUFFIX = </span><span class="s6">b'PK</span><span class="s0">\x05\x06</span><span class="s6">' </span><span class="s4"># empty zip files start with this</span>
        <span class="s1">N = len(format.MAGIC_PREFIX)</span>
        <span class="s1">magic = fid.read(N)</span>
        <span class="s4"># If the file size is less than N, we need to make sure not</span>
        <span class="s4"># to seek past the beginning of the file</span>
        <span class="s1">fid.seek(-min(N</span><span class="s0">, </span><span class="s1">len(magic))</span><span class="s0">, </span><span class="s5">1</span><span class="s1">)  </span><span class="s4"># back-up</span>
        <span class="s0">if </span><span class="s1">magic.startswith(_ZIP_PREFIX) </span><span class="s0">or </span><span class="s1">magic.startswith(_ZIP_SUFFIX):</span>
            <span class="s4"># zip-file (assume .npz)</span>
            <span class="s4"># Potentially transfer file ownership to NpzFile</span>
            <span class="s1">stack.pop_all()</span>
            <span class="s1">ret = NpzFile(fid</span><span class="s0">, </span><span class="s1">own_fid=own_fid</span><span class="s0">, </span><span class="s1">allow_pickle=allow_pickle</span><span class="s0">,</span>
                          <span class="s1">pickle_kwargs=pickle_kwargs)</span>
            <span class="s0">return </span><span class="s1">ret</span>
        <span class="s0">elif </span><span class="s1">magic == format.MAGIC_PREFIX:</span>
            <span class="s4"># .npy file</span>
            <span class="s0">if </span><span class="s1">mmap_mode:</span>
                <span class="s0">return </span><span class="s1">format.open_memmap(file</span><span class="s0">, </span><span class="s1">mode=mmap_mode)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">return </span><span class="s1">format.read_array(fid</span><span class="s0">, </span><span class="s1">allow_pickle=allow_pickle</span><span class="s0">,</span>
                                         <span class="s1">pickle_kwargs=pickle_kwargs)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># Try a pickle</span>
            <span class="s0">if not </span><span class="s1">allow_pickle:</span>
                <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;Cannot load file containing pickled data &quot;</span>
                                 <span class="s2">&quot;when allow_pickle=False&quot;</span><span class="s1">)</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s0">return </span><span class="s1">pickle.load(fid</span><span class="s0">, </span><span class="s1">**pickle_kwargs)</span>
            <span class="s0">except </span><span class="s1">Exception </span><span class="s0">as </span><span class="s1">e:</span>
                <span class="s0">raise </span><span class="s1">pickle.UnpicklingError(</span>
                    <span class="s2">f&quot;Failed to interpret file </span><span class="s0">{</span><span class="s1">file</span><span class="s0">!r} </span><span class="s2">as a pickle&quot;</span><span class="s1">) </span><span class="s0">from </span><span class="s1">e</span>


<span class="s0">def </span><span class="s1">_save_dispatcher(file</span><span class="s0">, </span><span class="s1">arr</span><span class="s0">, </span><span class="s1">allow_pickle=</span><span class="s0">None, </span><span class="s1">fix_imports=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">(arr</span><span class="s0">,</span><span class="s1">)</span>


<span class="s1">@array_function_dispatch(_save_dispatcher)</span>
<span class="s0">def </span><span class="s1">save(file</span><span class="s0">, </span><span class="s1">arr</span><span class="s0">, </span><span class="s1">allow_pickle=</span><span class="s0">True, </span><span class="s1">fix_imports=</span><span class="s0">True</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Save an array to a binary file in NumPy ``.npy`` format. 
 
    Parameters 
    ---------- 
    file : file, str, or pathlib.Path 
        File or filename to which the data is saved.  If file is a file-object, 
        then the filename is unchanged.  If file is a string or Path, a ``.npy`` 
        extension will be appended to the filename if it does not already 
        have one. 
    arr : array_like 
        Array data to be saved. 
    allow_pickle : bool, optional 
        Allow saving object arrays using Python pickles. Reasons for disallowing 
        pickles include security (loading pickled data can execute arbitrary 
        code) and portability (pickled objects may not be loadable on different 
        Python installations, for example if the stored objects require libraries 
        that are not available, and not all pickled data is compatible between 
        Python 2 and Python 3). 
        Default: True 
    fix_imports : bool, optional 
        Only useful in forcing objects in object arrays on Python 3 to be 
        pickled in a Python 2 compatible way. If `fix_imports` is True, pickle 
        will try to map the new Python 3 names to the old module names used in 
        Python 2, so that the pickle data stream is readable with Python 2. 
 
    See Also 
    -------- 
    savez : Save several arrays into a ``.npz`` archive 
    savetxt, load 
 
    Notes 
    ----- 
    For a description of the ``.npy`` format, see :py:mod:`numpy.lib.format`. 
 
    Any data saved to the file is appended to the end of the file. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from tempfile import TemporaryFile 
    &gt;&gt;&gt; outfile = TemporaryFile() 
 
    &gt;&gt;&gt; x = np.arange(10) 
    &gt;&gt;&gt; np.save(outfile, x) 
 
    &gt;&gt;&gt; _ = outfile.seek(0) # Only needed here to simulate closing &amp; reopening file 
    &gt;&gt;&gt; np.load(outfile) 
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 
 
 
    &gt;&gt;&gt; with open('test.npy', 'wb') as f: 
    ...     np.save(f, np.array([1, 2])) 
    ...     np.save(f, np.array([1, 3])) 
    &gt;&gt;&gt; with open('test.npy', 'rb') as f: 
    ...     a = np.load(f) 
    ...     b = np.load(f) 
    &gt;&gt;&gt; print(a, b) 
    # [1 2] [1 3] 
    &quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">hasattr(file</span><span class="s0">, </span><span class="s2">'write'</span><span class="s1">):</span>
        <span class="s1">file_ctx = contextlib.nullcontext(file)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">file = os_fspath(file)</span>
        <span class="s0">if not </span><span class="s1">file.endswith(</span><span class="s2">'.npy'</span><span class="s1">):</span>
            <span class="s1">file = file + </span><span class="s2">'.npy'</span>
        <span class="s1">file_ctx = open(file</span><span class="s0">, </span><span class="s2">&quot;wb&quot;</span><span class="s1">)</span>

    <span class="s0">with </span><span class="s1">file_ctx </span><span class="s0">as </span><span class="s1">fid:</span>
        <span class="s1">arr = np.asanyarray(arr)</span>
        <span class="s1">format.write_array(fid</span><span class="s0">, </span><span class="s1">arr</span><span class="s0">, </span><span class="s1">allow_pickle=allow_pickle</span><span class="s0">,</span>
                           <span class="s1">pickle_kwargs=dict(fix_imports=fix_imports))</span>


<span class="s0">def </span><span class="s1">_savez_dispatcher(file</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwds):</span>
    <span class="s0">yield from </span><span class="s1">args</span>
    <span class="s0">yield from </span><span class="s1">kwds.values()</span>


<span class="s1">@array_function_dispatch(_savez_dispatcher)</span>
<span class="s0">def </span><span class="s1">savez(file</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwds):</span>
    <span class="s3">&quot;&quot;&quot;Save several arrays into a single file in uncompressed ``.npz`` format. 
 
    Provide arrays as keyword arguments to store them under the 
    corresponding name in the output file: ``savez(fn, x=x, y=y)``. 
 
    If arrays are specified as positional arguments, i.e., ``savez(fn, 
    x, y)``, their names will be `arr_0`, `arr_1`, etc. 
 
    Parameters 
    ---------- 
    file : str or file 
        Either the filename (string) or an open file (file-like object) 
        where the data will be saved. If file is a string or a Path, the 
        ``.npz`` extension will be appended to the filename if it is not 
        already there. 
    args : Arguments, optional 
        Arrays to save to the file. Please use keyword arguments (see 
        `kwds` below) to assign names to arrays.  Arrays specified as 
        args will be named &quot;arr_0&quot;, &quot;arr_1&quot;, and so on. 
    kwds : Keyword arguments, optional 
        Arrays to save to the file. Each array will be saved to the 
        output file with its corresponding keyword name. 
 
    Returns 
    ------- 
    None 
 
    See Also 
    -------- 
    save : Save a single array to a binary file in NumPy format. 
    savetxt : Save an array to a file as plain text. 
    savez_compressed : Save several arrays into a compressed ``.npz`` archive 
 
    Notes 
    ----- 
    The ``.npz`` file format is a zipped archive of files named after the 
    variables they contain.  The archive is not compressed and each file 
    in the archive contains one variable in ``.npy`` format. For a 
    description of the ``.npy`` format, see :py:mod:`numpy.lib.format`. 
 
    When opening the saved ``.npz`` file with `load` a `NpzFile` object is 
    returned. This is a dictionary-like object which can be queried for 
    its list of arrays (with the ``.files`` attribute), and for the arrays 
    themselves. 
 
    Keys passed in `kwds` are used as filenames inside the ZIP archive. 
    Therefore, keys should be valid filenames; e.g., avoid keys that begin with 
    ``/`` or contain ``.``. 
 
    When naming variables with keyword arguments, it is not possible to name a 
    variable ``file``, as this would cause the ``file`` argument to be defined 
    twice in the call to ``savez``. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from tempfile import TemporaryFile 
    &gt;&gt;&gt; outfile = TemporaryFile() 
    &gt;&gt;&gt; x = np.arange(10) 
    &gt;&gt;&gt; y = np.sin(x) 
 
    Using `savez` with \\*args, the arrays are saved with default names. 
 
    &gt;&gt;&gt; np.savez(outfile, x, y) 
    &gt;&gt;&gt; _ = outfile.seek(0) # Only needed here to simulate closing &amp; reopening file 
    &gt;&gt;&gt; npzfile = np.load(outfile) 
    &gt;&gt;&gt; npzfile.files 
    ['arr_0', 'arr_1'] 
    &gt;&gt;&gt; npzfile['arr_0'] 
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 
 
    Using `savez` with \\**kwds, the arrays are saved with the keyword names. 
 
    &gt;&gt;&gt; outfile = TemporaryFile() 
    &gt;&gt;&gt; np.savez(outfile, x=x, y=y) 
    &gt;&gt;&gt; _ = outfile.seek(0) 
    &gt;&gt;&gt; npzfile = np.load(outfile) 
    &gt;&gt;&gt; sorted(npzfile.files) 
    ['x', 'y'] 
    &gt;&gt;&gt; npzfile['x'] 
    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_savez(file</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">kwds</span><span class="s0">, False</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">_savez_compressed_dispatcher(file</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwds):</span>
    <span class="s0">yield from </span><span class="s1">args</span>
    <span class="s0">yield from </span><span class="s1">kwds.values()</span>


<span class="s1">@array_function_dispatch(_savez_compressed_dispatcher)</span>
<span class="s0">def </span><span class="s1">savez_compressed(file</span><span class="s0">, </span><span class="s1">*args</span><span class="s0">, </span><span class="s1">**kwds):</span>
    <span class="s3">&quot;&quot;&quot; 
    Save several arrays into a single file in compressed ``.npz`` format. 
 
    Provide arrays as keyword arguments to store them under the 
    corresponding name in the output file: ``savez(fn, x=x, y=y)``. 
 
    If arrays are specified as positional arguments, i.e., ``savez(fn, 
    x, y)``, their names will be `arr_0`, `arr_1`, etc. 
 
    Parameters 
    ---------- 
    file : str or file 
        Either the filename (string) or an open file (file-like object) 
        where the data will be saved. If file is a string or a Path, the 
        ``.npz`` extension will be appended to the filename if it is not 
        already there. 
    args : Arguments, optional 
        Arrays to save to the file. Please use keyword arguments (see 
        `kwds` below) to assign names to arrays.  Arrays specified as 
        args will be named &quot;arr_0&quot;, &quot;arr_1&quot;, and so on. 
    kwds : Keyword arguments, optional 
        Arrays to save to the file. Each array will be saved to the 
        output file with its corresponding keyword name. 
 
    Returns 
    ------- 
    None 
 
    See Also 
    -------- 
    numpy.save : Save a single array to a binary file in NumPy format. 
    numpy.savetxt : Save an array to a file as plain text. 
    numpy.savez : Save several arrays into an uncompressed ``.npz`` file format 
    numpy.load : Load the files created by savez_compressed. 
 
    Notes 
    ----- 
    The ``.npz`` file format is a zipped archive of files named after the 
    variables they contain.  The archive is compressed with 
    ``zipfile.ZIP_DEFLATED`` and each file in the archive contains one variable 
    in ``.npy`` format. For a description of the ``.npy`` format, see 
    :py:mod:`numpy.lib.format`. 
 
 
    When opening the saved ``.npz`` file with `load` a `NpzFile` object is 
    returned. This is a dictionary-like object which can be queried for 
    its list of arrays (with the ``.files`` attribute), and for the arrays 
    themselves. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; test_array = np.random.rand(3, 2) 
    &gt;&gt;&gt; test_vector = np.random.rand(4) 
    &gt;&gt;&gt; np.savez_compressed('/tmp/123', a=test_array, b=test_vector) 
    &gt;&gt;&gt; loaded = np.load('/tmp/123.npz') 
    &gt;&gt;&gt; print(np.array_equal(test_array, loaded['a'])) 
    True 
    &gt;&gt;&gt; print(np.array_equal(test_vector, loaded['b'])) 
    True 
 
    &quot;&quot;&quot;</span>
    <span class="s1">_savez(file</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">kwds</span><span class="s0">, True</span><span class="s1">)</span>


<span class="s0">def </span><span class="s1">_savez(file</span><span class="s0">, </span><span class="s1">args</span><span class="s0">, </span><span class="s1">kwds</span><span class="s0">, </span><span class="s1">compress</span><span class="s0">, </span><span class="s1">allow_pickle=</span><span class="s0">True, </span><span class="s1">pickle_kwargs=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s4"># Import is postponed to here since zipfile depends on gzip, an optional</span>
    <span class="s4"># component of the so-called standard library.</span>
    <span class="s0">import </span><span class="s1">zipfile</span>

    <span class="s0">if not </span><span class="s1">hasattr(file</span><span class="s0">, </span><span class="s2">'write'</span><span class="s1">):</span>
        <span class="s1">file = os_fspath(file)</span>
        <span class="s0">if not </span><span class="s1">file.endswith(</span><span class="s2">'.npz'</span><span class="s1">):</span>
            <span class="s1">file = file + </span><span class="s2">'.npz'</span>

    <span class="s1">namedict = kwds</span>
    <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">val </span><span class="s0">in </span><span class="s1">enumerate(args):</span>
        <span class="s1">key = </span><span class="s2">'arr_%d' </span><span class="s1">% i</span>
        <span class="s0">if </span><span class="s1">key </span><span class="s0">in </span><span class="s1">namedict.keys():</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s2">&quot;Cannot use un-named variables and keyword %s&quot; </span><span class="s1">% key)</span>
        <span class="s1">namedict[key] = val</span>

    <span class="s0">if </span><span class="s1">compress:</span>
        <span class="s1">compression = zipfile.ZIP_DEFLATED</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">compression = zipfile.ZIP_STORED</span>

    <span class="s1">zipf = zipfile_factory(file</span><span class="s0">, </span><span class="s1">mode=</span><span class="s2">&quot;w&quot;</span><span class="s0">, </span><span class="s1">compression=compression)</span>

    <span class="s0">for </span><span class="s1">key</span><span class="s0">, </span><span class="s1">val </span><span class="s0">in </span><span class="s1">namedict.items():</span>
        <span class="s1">fname = key + </span><span class="s2">'.npy'</span>
        <span class="s1">val = np.asanyarray(val)</span>
        <span class="s4"># always force zip64, gh-10776</span>
        <span class="s0">with </span><span class="s1">zipf.open(fname</span><span class="s0">, </span><span class="s2">'w'</span><span class="s0">, </span><span class="s1">force_zip64=</span><span class="s0">True</span><span class="s1">) </span><span class="s0">as </span><span class="s1">fid:</span>
            <span class="s1">format.write_array(fid</span><span class="s0">, </span><span class="s1">val</span><span class="s0">,</span>
                               <span class="s1">allow_pickle=allow_pickle</span><span class="s0">,</span>
                               <span class="s1">pickle_kwargs=pickle_kwargs)</span>

    <span class="s1">zipf.close()</span>


<span class="s0">def </span><span class="s1">_floatconv(x):</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">float(x)  </span><span class="s4"># The fastest path.</span>
    <span class="s0">except </span><span class="s1">ValueError:</span>
        <span class="s0">if </span><span class="s2">'0x' </span><span class="s0">in </span><span class="s1">x:  </span><span class="s4"># Don't accidentally convert &quot;a&quot; (&quot;0xa&quot;) to 10.</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s0">return </span><span class="s1">float.fromhex(x)</span>
            <span class="s0">except </span><span class="s1">ValueError:</span>
                <span class="s0">pass</span>
        <span class="s0">raise  </span><span class="s4"># Raise the original exception, which makes more sense.</span>


<span class="s1">_CONVERTERS = [  </span><span class="s4"># These converters only ever get strs (not bytes) as input.</span>
    <span class="s1">(np.bool_</span><span class="s0">, lambda </span><span class="s1">x: bool(int(x)))</span><span class="s0">,</span>
    <span class="s1">(np.uint64</span><span class="s0">, </span><span class="s1">np.uint64)</span><span class="s0">,</span>
    <span class="s1">(np.int64</span><span class="s0">, </span><span class="s1">np.int64)</span><span class="s0">,</span>
    <span class="s1">(np.integer</span><span class="s0">, lambda </span><span class="s1">x: int(float(x)))</span><span class="s0">,</span>
    <span class="s1">(np.longdouble</span><span class="s0">, </span><span class="s1">np.longdouble)</span><span class="s0">,</span>
    <span class="s1">(np.floating</span><span class="s0">, </span><span class="s1">_floatconv)</span><span class="s0">,</span>
    <span class="s1">(complex</span><span class="s0">, lambda </span><span class="s1">x: complex(x.replace(</span><span class="s2">'+-'</span><span class="s0">, </span><span class="s2">'-'</span><span class="s1">)))</span><span class="s0">,</span>
    <span class="s1">(np.bytes_</span><span class="s0">, </span><span class="s1">methodcaller(</span><span class="s2">'encode'</span><span class="s0">, </span><span class="s2">'latin-1'</span><span class="s1">))</span><span class="s0">,</span>
    <span class="s1">(np.unicode_</span><span class="s0">, </span><span class="s1">str)</span><span class="s0">,</span>
<span class="s1">]</span>


<span class="s0">def </span><span class="s1">_getconv(dtype):</span>
    <span class="s3">&quot;&quot;&quot; 
    Find the correct dtype converter. Adapted from matplotlib. 
 
    Even when a lambda is returned, it is defined at the toplevel, to allow 
    testing for equality and enabling optimization for single-type data. 
    &quot;&quot;&quot;</span>
    <span class="s0">for </span><span class="s1">base</span><span class="s0">, </span><span class="s1">conv </span><span class="s0">in </span><span class="s1">_CONVERTERS:</span>
        <span class="s0">if </span><span class="s1">issubclass(dtype.type</span><span class="s0">, </span><span class="s1">base):</span>
            <span class="s0">return </span><span class="s1">conv</span>
    <span class="s0">return </span><span class="s1">str</span>


<span class="s4"># _loadtxt_flatten_dtype_internal and _loadtxt_pack_items are loadtxt helpers</span>
<span class="s4"># lifted to the toplevel because recursive inner functions cause either</span>
<span class="s4"># GC-dependent reference loops (because they are closures over loadtxt's</span>
<span class="s4"># internal variables) or large overheads if using a manual trampoline to hide</span>
<span class="s4"># the recursive calls.</span>


<span class="s4"># not to be confused with the flatten_dtype we import...</span>
<span class="s0">def </span><span class="s1">_loadtxt_flatten_dtype_internal(dt):</span>
    <span class="s3">&quot;&quot;&quot;Unpack a structured data-type, and produce a packer function.&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">dt.names </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s4"># If the dtype is flattened, return.</span>
        <span class="s4"># If the dtype has a shape, the dtype occurs</span>
        <span class="s4"># in the list more than once.</span>
        <span class="s1">shape = dt.shape</span>
        <span class="s0">if </span><span class="s1">len(shape) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">([dt.base]</span><span class="s0">, None</span><span class="s1">)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">packing = [(shape[-</span><span class="s5">1</span><span class="s1">]</span><span class="s0">, </span><span class="s1">list)]</span>
            <span class="s0">if </span><span class="s1">len(shape) &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s0">for </span><span class="s1">dim </span><span class="s0">in </span><span class="s1">dt.shape[-</span><span class="s5">2</span><span class="s1">::-</span><span class="s5">1</span><span class="s1">]:</span>
                    <span class="s1">packing = [(dim*packing[</span><span class="s5">0</span><span class="s1">][</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">packing*dim)]</span>
            <span class="s0">return </span><span class="s1">([dt.base] * int(np.prod(dt.shape))</span><span class="s0">,</span>
                    <span class="s1">functools.partial(_loadtxt_pack_items</span><span class="s0">, </span><span class="s1">packing))</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">types = []</span>
        <span class="s1">packing = []</span>
        <span class="s0">for </span><span class="s1">field </span><span class="s0">in </span><span class="s1">dt.names:</span>
            <span class="s1">tp</span><span class="s0">, </span><span class="s1">bytes = dt.fields[field]</span>
            <span class="s1">flat_dt</span><span class="s0">, </span><span class="s1">flat_packer = _loadtxt_flatten_dtype_internal(tp)</span>
            <span class="s1">types.extend(flat_dt)</span>
            <span class="s1">flat_packing = flat_packer.args[</span><span class="s5">0</span><span class="s1">] </span><span class="s0">if </span><span class="s1">flat_packer </span><span class="s0">else None</span>
            <span class="s4"># Avoid extra nesting for subarrays</span>
            <span class="s0">if </span><span class="s1">tp.ndim &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">packing.extend(flat_packing)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">packing.append((len(flat_dt)</span><span class="s0">, </span><span class="s1">flat_packing))</span>
        <span class="s0">return </span><span class="s1">(types</span><span class="s0">, </span><span class="s1">functools.partial(_loadtxt_pack_items</span><span class="s0">, </span><span class="s1">packing))</span>


<span class="s0">def </span><span class="s1">_loadtxt_pack_items(packing</span><span class="s0">, </span><span class="s1">items):</span>
    <span class="s3">&quot;&quot;&quot;Pack items into nested lists based on re-packing info.&quot;&quot;&quot;</span>
    <span class="s0">if </span><span class="s1">packing </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">items[</span><span class="s5">0</span><span class="s1">]</span>
    <span class="s0">elif </span><span class="s1">packing </span><span class="s0">is </span><span class="s1">tuple:</span>
        <span class="s0">return </span><span class="s1">tuple(items)</span>
    <span class="s0">elif </span><span class="s1">packing </span><span class="s0">is </span><span class="s1">list:</span>
        <span class="s0">return </span><span class="s1">list(items)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">start = </span><span class="s5">0</span>
        <span class="s1">ret = []</span>
        <span class="s0">for </span><span class="s1">length</span><span class="s0">, </span><span class="s1">subpacking </span><span class="s0">in </span><span class="s1">packing:</span>
            <span class="s1">ret.append(</span>
                <span class="s1">_loadtxt_pack_items(subpacking</span><span class="s0">, </span><span class="s1">items[start:start+length]))</span>
            <span class="s1">start += length</span>
        <span class="s0">return </span><span class="s1">tuple(ret)</span>


<span class="s4"># amount of lines loadtxt reads in one chunk, can be overridden for testing</span>
<span class="s1">_loadtxt_chunksize = </span><span class="s5">50000</span>


<span class="s0">def </span><span class="s1">_loadtxt_dispatcher(fname</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">comments=</span><span class="s0">None, </span><span class="s1">delimiter=</span><span class="s0">None,</span>
                        <span class="s1">converters=</span><span class="s0">None, </span><span class="s1">skiprows=</span><span class="s0">None, </span><span class="s1">usecols=</span><span class="s0">None, </span><span class="s1">unpack=</span><span class="s0">None,</span>
                        <span class="s1">ndmin=</span><span class="s0">None, </span><span class="s1">encoding=</span><span class="s0">None, </span><span class="s1">max_rows=</span><span class="s0">None, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">like=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">(like</span><span class="s0">,</span><span class="s1">)</span>


<span class="s1">@set_array_function_like_doc</span>
<span class="s1">@set_module(</span><span class="s2">'numpy'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">loadtxt(fname</span><span class="s0">, </span><span class="s1">dtype=float</span><span class="s0">, </span><span class="s1">comments=</span><span class="s2">'#'</span><span class="s0">, </span><span class="s1">delimiter=</span><span class="s0">None,</span>
            <span class="s1">converters=</span><span class="s0">None, </span><span class="s1">skiprows=</span><span class="s5">0</span><span class="s0">, </span><span class="s1">usecols=</span><span class="s0">None, </span><span class="s1">unpack=</span><span class="s0">False,</span>
            <span class="s1">ndmin=</span><span class="s5">0</span><span class="s0">, </span><span class="s1">encoding=</span><span class="s2">'bytes'</span><span class="s0">, </span><span class="s1">max_rows=</span><span class="s0">None, </span><span class="s1">*</span><span class="s0">, </span><span class="s1">like=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s3">r&quot;&quot;&quot; 
    Load data from a text file. 
 
    Each row in the text file must have the same number of values. 
 
    Parameters 
    ---------- 
    fname : file, str, pathlib.Path, list of str, generator 
        File, filename, list, or generator to read.  If the filename 
        extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note 
        that generators must return bytes or strings. The strings 
        in a list or produced by a generator are treated as lines. 
    dtype : data-type, optional 
        Data-type of the resulting array; default: float.  If this is a 
        structured data-type, the resulting array will be 1-dimensional, and 
        each row will be interpreted as an element of the array.  In this 
        case, the number of columns used must match the number of fields in 
        the data-type. 
    comments : str or sequence of str, optional 
        The characters or list of characters used to indicate the start of a 
        comment. None implies no comments. For backwards compatibility, byte 
        strings will be decoded as 'latin1'. The default is '#'. 
    delimiter : str, optional 
        The string used to separate values. For backwards compatibility, byte 
        strings will be decoded as 'latin1'. The default is whitespace. 
    converters : dict, optional 
        A dictionary mapping column number to a function that will parse the 
        column string into the desired value.  E.g., if column 0 is a date 
        string: ``converters = {0: datestr2num}``.  Converters can also be 
        used to provide a default value for missing data (but see also 
        `genfromtxt`): ``converters = {3: lambda s: float(s.strip() or 0)}``. 
        Default: None. 
    skiprows : int, optional 
        Skip the first `skiprows` lines, including comments; default: 0. 
    usecols : int or sequence, optional 
        Which columns to read, with 0 being the first. For example, 
        ``usecols = (1,4,5)`` will extract the 2nd, 5th and 6th columns. 
        The default, None, results in all columns being read. 
 
        .. versionchanged:: 1.11.0 
            When a single column has to be read it is possible to use 
            an integer instead of a tuple. E.g ``usecols = 3`` reads the 
            fourth column the same way as ``usecols = (3,)`` would. 
    unpack : bool, optional 
        If True, the returned array is transposed, so that arguments may be 
        unpacked using ``x, y, z = loadtxt(...)``.  When used with a 
        structured data-type, arrays are returned for each field. 
        Default is False. 
    ndmin : int, optional 
        The returned array will have at least `ndmin` dimensions. 
        Otherwise mono-dimensional axes will be squeezed. 
        Legal values: 0 (default), 1 or 2. 
 
        .. versionadded:: 1.6.0 
    encoding : str, optional 
        Encoding used to decode the inputfile. Does not apply to input streams. 
        The special value 'bytes' enables backward compatibility workarounds 
        that ensures you receive byte arrays as results if possible and passes 
        'latin1' encoded strings to converters. Override this value to receive 
        unicode arrays and pass strings as input to converters.  If set to None 
        the system default is used. The default value is 'bytes'. 
 
        .. versionadded:: 1.14.0 
    max_rows : int, optional 
        Read `max_rows` lines of content after `skiprows` lines. The default 
        is to read all the lines. 
 
        .. versionadded:: 1.16.0 
    ${ARRAY_FUNCTION_LIKE} 
 
        .. versionadded:: 1.20.0 
 
    Returns 
    ------- 
    out : ndarray 
        Data read from the text file. 
 
    See Also 
    -------- 
    load, fromstring, fromregex 
    genfromtxt : Load data with missing values handled as specified. 
    scipy.io.loadmat : reads MATLAB data files 
 
    Notes 
    ----- 
    This function aims to be a fast reader for simply formatted files.  The 
    `genfromtxt` function provides more sophisticated handling of, e.g., 
    lines with missing values. 
 
    .. versionadded:: 1.10.0 
 
    The strings produced by the Python float.hex method can be used as 
    input for floats. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from io import StringIO   # StringIO behaves like a file object 
    &gt;&gt;&gt; c = StringIO(&quot;0 1\n2 3&quot;) 
    &gt;&gt;&gt; np.loadtxt(c) 
    array([[0., 1.], 
           [2., 3.]]) 
 
    &gt;&gt;&gt; d = StringIO(&quot;M 21 72\nF 35 58&quot;) 
    &gt;&gt;&gt; np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'), 
    ...                      'formats': ('S1', 'i4', 'f4')}) 
    array([(b'M', 21, 72.), (b'F', 35, 58.)], 
          dtype=[('gender', 'S1'), ('age', '&lt;i4'), ('weight', '&lt;f4')]) 
 
    &gt;&gt;&gt; c = StringIO(&quot;1,0,2\n3,0,4&quot;) 
    &gt;&gt;&gt; x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True) 
    &gt;&gt;&gt; x 
    array([1., 3.]) 
    &gt;&gt;&gt; y 
    array([2., 4.]) 
 
    This example shows how `converters` can be used to convert a field 
    with a trailing minus sign into a negative number. 
 
    &gt;&gt;&gt; s = StringIO('10.01 31.25-\n19.22 64.31\n17.57- 63.94') 
    &gt;&gt;&gt; def conv(fld): 
    ...     return -float(fld[:-1]) if fld.endswith(b'-') else float(fld) 
    ... 
    &gt;&gt;&gt; np.loadtxt(s, converters={0: conv, 1: conv}) 
    array([[ 10.01, -31.25], 
           [ 19.22,  64.31], 
           [-17.57,  63.94]]) 
    &quot;&quot;&quot;</span>

    <span class="s0">if </span><span class="s1">like </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">_loadtxt_with_like(</span>
            <span class="s1">fname</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">comments=comments</span><span class="s0">, </span><span class="s1">delimiter=delimiter</span><span class="s0">,</span>
            <span class="s1">converters=converters</span><span class="s0">, </span><span class="s1">skiprows=skiprows</span><span class="s0">, </span><span class="s1">usecols=usecols</span><span class="s0">,</span>
            <span class="s1">unpack=unpack</span><span class="s0">, </span><span class="s1">ndmin=ndmin</span><span class="s0">, </span><span class="s1">encoding=encoding</span><span class="s0">,</span>
            <span class="s1">max_rows=max_rows</span><span class="s0">, </span><span class="s1">like=like</span>
        <span class="s1">)</span>

    <span class="s4"># - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</span>
    <span class="s4"># Nested functions used by loadtxt.</span>
    <span class="s4"># - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</span>

    <span class="s0">def </span><span class="s1">split_line(line: str):</span>
        <span class="s3">&quot;&quot;&quot;Chop off comments, strip, and split at delimiter.&quot;&quot;&quot;</span>
        <span class="s0">for </span><span class="s1">comment </span><span class="s0">in </span><span class="s1">comments:  </span><span class="s4"># Much faster than using a single regex.</span>
            <span class="s1">line = line.split(comment</span><span class="s0">, </span><span class="s5">1</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s1">line = line.strip(</span><span class="s2">'</span><span class="s0">\r\n</span><span class="s2">'</span><span class="s1">)</span>
        <span class="s0">return </span><span class="s1">line.split(delimiter) </span><span class="s0">if </span><span class="s1">line </span><span class="s0">else </span><span class="s1">[]</span>

    <span class="s4"># - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</span>
    <span class="s4"># Main body of loadtxt.</span>
    <span class="s4"># - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -</span>

    <span class="s4"># Check correctness of the values of `ndmin`</span>
    <span class="s0">if </span><span class="s1">ndmin </span><span class="s0">not in </span><span class="s1">[</span><span class="s5">0</span><span class="s0">, </span><span class="s5">1</span><span class="s0">, </span><span class="s5">2</span><span class="s1">]:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">'Illegal value of ndmin keyword: %s' </span><span class="s1">% ndmin)</span>

    <span class="s4"># Type conversions for Py3 convenience</span>
    <span class="s0">if </span><span class="s1">comments </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">isinstance(comments</span><span class="s0">, </span><span class="s1">(str</span><span class="s0">, </span><span class="s1">bytes)):</span>
            <span class="s1">comments = [comments]</span>
        <span class="s1">comments = [_decode_line(x) </span><span class="s0">for </span><span class="s1">x </span><span class="s0">in </span><span class="s1">comments]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">comments = []</span>

    <span class="s0">if </span><span class="s1">delimiter </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s1">delimiter = _decode_line(delimiter)</span>

    <span class="s1">user_converters = converters</span>

    <span class="s1">byte_converters = </span><span class="s0">False</span>
    <span class="s0">if </span><span class="s1">encoding == </span><span class="s2">'bytes'</span><span class="s1">:</span>
        <span class="s1">encoding = </span><span class="s0">None</span>
        <span class="s1">byte_converters = </span><span class="s0">True</span>

    <span class="s0">if </span><span class="s1">usecols </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s4"># Copy usecols, allowing it to be a single int or a sequence of ints.</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s1">usecols = list(usecols)</span>
        <span class="s0">except </span><span class="s1">TypeError:</span>
            <span class="s1">usecols = [usecols]</span>
        <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">col_idx </span><span class="s0">in </span><span class="s1">enumerate(usecols):</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">usecols[i] = opindex(col_idx)  </span><span class="s4"># Cast to builtin int now.</span>
            <span class="s0">except </span><span class="s1">TypeError </span><span class="s0">as </span><span class="s1">e:</span>
                <span class="s1">e.args = (</span>
                    <span class="s2">&quot;usecols must be an int or a sequence of ints but &quot;</span>
                    <span class="s2">&quot;it contains at least one element of type %s&quot; </span><span class="s1">%</span>
                    <span class="s1">type(col_idx)</span><span class="s0">,</span>
                    <span class="s1">)</span>
                <span class="s0">raise</span>
        <span class="s0">if </span><span class="s1">len(usecols) &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">usecols_getter = itemgetter(*usecols)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># Get an iterable back, even if using a single column.</span>
            <span class="s1">usecols_getter = </span><span class="s0">lambda </span><span class="s1">obj</span><span class="s0">, </span><span class="s1">c=usecols[</span><span class="s5">0</span><span class="s1">]: [obj[c]]</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">usecols_getter = </span><span class="s0">None</span>

    <span class="s4"># Make sure we're dealing with a proper dtype</span>
    <span class="s1">dtype = np.dtype(dtype)</span>
    <span class="s1">defconv = _getconv(dtype)</span>

    <span class="s1">dtype_types</span><span class="s0">, </span><span class="s1">packer = _loadtxt_flatten_dtype_internal(dtype)</span>

    <span class="s1">fh_closing_ctx = contextlib.nullcontext()</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">isinstance(fname</span><span class="s0">, </span><span class="s1">os_PathLike):</span>
            <span class="s1">fname = os_fspath(fname)</span>
        <span class="s0">if </span><span class="s1">_is_string_like(fname):</span>
            <span class="s1">fh = np.lib._datasource.open(fname</span><span class="s0">, </span><span class="s2">'rt'</span><span class="s0">, </span><span class="s1">encoding=encoding)</span>
            <span class="s1">fencoding = getattr(fh</span><span class="s0">, </span><span class="s2">'encoding'</span><span class="s0">, </span><span class="s2">'latin1'</span><span class="s1">)</span>
            <span class="s1">line_iter = iter(fh)</span>
            <span class="s1">fh_closing_ctx = contextlib.closing(fh)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">line_iter = iter(fname)</span>
            <span class="s1">fencoding = getattr(fname</span><span class="s0">, </span><span class="s2">'encoding'</span><span class="s0">, </span><span class="s2">'latin1'</span><span class="s1">)</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">first_line = next(line_iter)</span>
            <span class="s0">except </span><span class="s1">StopIteration:</span>
                <span class="s0">pass  </span><span class="s4"># Nothing matters if line_iter is empty.</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s4"># Put first_line back.</span>
                <span class="s1">line_iter = itertools.chain([first_line]</span><span class="s0">, </span><span class="s1">line_iter)</span>
                <span class="s0">if </span><span class="s1">isinstance(first_line</span><span class="s0">, </span><span class="s1">bytes):</span>
                    <span class="s4"># Using latin1 matches _decode_line's behavior.</span>
                    <span class="s1">decoder = methodcaller(</span>
                        <span class="s2">&quot;decode&quot;</span><span class="s0">,</span>
                        <span class="s1">encoding </span><span class="s0">if </span><span class="s1">encoding </span><span class="s0">is not None else </span><span class="s2">&quot;latin1&quot;</span><span class="s1">)</span>
                    <span class="s1">line_iter = map(decoder</span><span class="s0">, </span><span class="s1">line_iter)</span>
    <span class="s0">except </span><span class="s1">TypeError </span><span class="s0">as </span><span class="s1">e:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span>
            <span class="s2">f&quot;fname must be a string, filehandle, list of strings,</span><span class="s0">\n</span><span class="s2">&quot;</span>
            <span class="s2">f&quot;or generator. Got </span><span class="s0">{</span><span class="s1">type(fname)</span><span class="s0">} </span><span class="s2">instead.&quot;</span>
        <span class="s1">) </span><span class="s0">from </span><span class="s1">e</span>

    <span class="s0">with </span><span class="s1">fh_closing_ctx:</span>

        <span class="s4"># input may be a python2 io stream</span>
        <span class="s0">if </span><span class="s1">encoding </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">fencoding = encoding</span>
        <span class="s4"># we must assume local encoding</span>
        <span class="s4"># TODO emit portability warning?</span>
        <span class="s0">elif </span><span class="s1">fencoding </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">import </span><span class="s1">locale</span>
            <span class="s1">fencoding = locale.getpreferredencoding()</span>

        <span class="s4"># Skip the first `skiprows` lines</span>
        <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(skiprows):</span>
            <span class="s1">next(line_iter)</span>

        <span class="s4"># Read until we find a line with some values, and use it to determine</span>
        <span class="s4"># the need for decoding and estimate the number of columns.</span>
        <span class="s0">for </span><span class="s1">first_line </span><span class="s0">in </span><span class="s1">line_iter:</span>
            <span class="s1">ncols = len(usecols </span><span class="s0">or </span><span class="s1">split_line(first_line))</span>
            <span class="s0">if </span><span class="s1">ncols:</span>
                <span class="s4"># Put first_line back.</span>
                <span class="s1">line_iter = itertools.chain([first_line]</span><span class="s0">, </span><span class="s1">line_iter)</span>
                <span class="s0">break</span>
        <span class="s0">else</span><span class="s1">:  </span><span class="s4"># End of lines reached</span>
            <span class="s1">ncols = len(usecols </span><span class="s0">or </span><span class="s1">[])</span>
            <span class="s1">warnings.warn(</span><span class="s2">'loadtxt: Empty input file: &quot;%s&quot;' </span><span class="s1">% fname</span><span class="s0">,</span>
                          <span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s1">line_iter = itertools.islice(line_iter</span><span class="s0">, </span><span class="s1">max_rows)</span>
        <span class="s1">lineno_words_iter = filter(</span>
            <span class="s1">itemgetter(</span><span class="s5">1</span><span class="s1">)</span><span class="s0">,  </span><span class="s4"># item[1] is words; filter skips empty lines.</span>
            <span class="s1">enumerate(map(split_line</span><span class="s0">, </span><span class="s1">line_iter)</span><span class="s0">, </span><span class="s5">1 </span><span class="s1">+ skiprows))</span>

        <span class="s4"># Now that we know ncols, create the default converters list, and</span>
        <span class="s4"># set packing, if necessary.</span>
        <span class="s0">if </span><span class="s1">len(dtype_types) &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s4"># We're dealing with a structured array, each field of</span>
            <span class="s4"># the dtype matches a column</span>
            <span class="s1">converters = [_getconv(dt) </span><span class="s0">for </span><span class="s1">dt </span><span class="s0">in </span><span class="s1">dtype_types]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># All fields have the same dtype; use specialized packers which are</span>
            <span class="s4"># much faster than those using _loadtxt_pack_items.</span>
            <span class="s1">converters = [defconv </span><span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(ncols)]</span>
            <span class="s0">if </span><span class="s1">ncols == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">packer = itemgetter(</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">def </span><span class="s1">packer(row): </span><span class="s0">return </span><span class="s1">row</span>

        <span class="s4"># By preference, use the converters specified by the user</span>
        <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">conv </span><span class="s0">in </span><span class="s1">(user_converters </span><span class="s0">or </span><span class="s1">{}).items():</span>
            <span class="s0">if </span><span class="s1">usecols:</span>
                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">i = usecols.index(i)</span>
                <span class="s0">except </span><span class="s1">ValueError:</span>
                    <span class="s4"># Unused converter specified</span>
                    <span class="s0">continue</span>
            <span class="s0">if </span><span class="s1">byte_converters:</span>
                <span class="s4"># converters may use decode to workaround numpy's old</span>
                <span class="s4"># behaviour, so encode the string again (converters are only</span>
                <span class="s4"># called with strings) before passing to the user converter.</span>
                <span class="s0">def </span><span class="s1">tobytes_first(conv</span><span class="s0">, </span><span class="s1">x):</span>
                    <span class="s0">return </span><span class="s1">conv(x.encode(</span><span class="s2">&quot;latin1&quot;</span><span class="s1">))</span>
                <span class="s1">converters[i] = functools.partial(tobytes_first</span><span class="s0">, </span><span class="s1">conv)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">converters[i] = conv</span>

        <span class="s1">fencode = methodcaller(</span><span class="s2">&quot;encode&quot;</span><span class="s0">, </span><span class="s1">fencoding)</span>
        <span class="s1">converters = [conv </span><span class="s0">if </span><span class="s1">conv </span><span class="s0">is not </span><span class="s1">bytes </span><span class="s0">else </span><span class="s1">fencode</span>
                      <span class="s0">for </span><span class="s1">conv </span><span class="s0">in </span><span class="s1">converters]</span>
        <span class="s0">if </span><span class="s1">len(set(converters)) == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s4"># Optimize single-type data. Note that this is only reached if</span>
            <span class="s4"># `_getconv` returns equal callables (i.e. not local lambdas) on</span>
            <span class="s4"># equal dtypes.</span>
            <span class="s0">def </span><span class="s1">convert_row(vals</span><span class="s0">, </span><span class="s1">_conv=converters[</span><span class="s5">0</span><span class="s1">]):</span>
                <span class="s0">return </span><span class="s1">[*map(_conv</span><span class="s0">, </span><span class="s1">vals)]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">def </span><span class="s1">convert_row(vals):</span>
                <span class="s0">return </span><span class="s1">[conv(val) </span><span class="s0">for </span><span class="s1">conv</span><span class="s0">, </span><span class="s1">val </span><span class="s0">in </span><span class="s1">zip(converters</span><span class="s0">, </span><span class="s1">vals)]</span>

        <span class="s4"># read data in chunks and fill it into an array via resize</span>
        <span class="s4"># over-allocating and shrinking the array later may be faster but is</span>
        <span class="s4"># probably not relevant compared to the cost of actually reading and</span>
        <span class="s4"># converting the data</span>
        <span class="s1">X = </span><span class="s0">None</span>
        <span class="s0">while True</span><span class="s1">:</span>
            <span class="s1">chunk = []</span>
            <span class="s0">for </span><span class="s1">lineno</span><span class="s0">, </span><span class="s1">words </span><span class="s0">in </span><span class="s1">itertools.islice(</span>
                    <span class="s1">lineno_words_iter</span><span class="s0">, </span><span class="s1">_loadtxt_chunksize):</span>
                <span class="s0">if </span><span class="s1">usecols_getter </span><span class="s0">is not None</span><span class="s1">:</span>
                    <span class="s1">words = usecols_getter(words)</span>
                <span class="s0">elif </span><span class="s1">len(words) != ncols:</span>
                    <span class="s0">raise </span><span class="s1">ValueError(</span>
                        <span class="s2">f&quot;Wrong number of columns at line </span><span class="s0">{</span><span class="s1">lineno</span><span class="s0">}</span><span class="s2">&quot;</span><span class="s1">)</span>
                <span class="s4"># Convert each value according to its column, then pack it</span>
                <span class="s4"># according to the dtype's nesting, and store it.</span>
                <span class="s1">chunk.append(packer(convert_row(words)))</span>
            <span class="s0">if not </span><span class="s1">chunk:  </span><span class="s4"># The islice is empty, i.e. we're done.</span>
                <span class="s0">break</span>

            <span class="s0">if </span><span class="s1">X </span><span class="s0">is None</span><span class="s1">:</span>
                <span class="s1">X = np.array(chunk</span><span class="s0">, </span><span class="s1">dtype)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">nshape = list(X.shape)</span>
                <span class="s1">pos = nshape[</span><span class="s5">0</span><span class="s1">]</span>
                <span class="s1">nshape[</span><span class="s5">0</span><span class="s1">] += len(chunk)</span>
                <span class="s1">X.resize(nshape</span><span class="s0">, </span><span class="s1">refcheck=</span><span class="s0">False</span><span class="s1">)</span>
                <span class="s1">X[pos:</span><span class="s0">, </span><span class="s1">...] = chunk</span>

    <span class="s0">if </span><span class="s1">X </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s1">X = np.array([]</span><span class="s0">, </span><span class="s1">dtype)</span>

    <span class="s4"># Multicolumn data are returned with shape (1, N, M), i.e.</span>
    <span class="s4"># (1, 1, M) for a single row - remove the singleton dimension there</span>
    <span class="s0">if </span><span class="s1">X.ndim == </span><span class="s5">3 </span><span class="s0">and </span><span class="s1">X.shape[:</span><span class="s5">2</span><span class="s1">] == (</span><span class="s5">1</span><span class="s0">, </span><span class="s5">1</span><span class="s1">):</span>
        <span class="s1">X.shape = (</span><span class="s5">1</span><span class="s0">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s4"># Verify that the array has at least dimensions `ndmin`.</span>
    <span class="s4"># Tweak the size and shape of the arrays - remove extraneous dimensions</span>
    <span class="s0">if </span><span class="s1">X.ndim &gt; ndmin:</span>
        <span class="s1">X = np.squeeze(X)</span>
    <span class="s4"># and ensure we have the minimum number of dimensions asked for</span>
    <span class="s4"># - has to be in this order for the odd case ndmin=1, X.squeeze().ndim=0</span>
    <span class="s0">if </span><span class="s1">X.ndim &lt; ndmin:</span>
        <span class="s0">if </span><span class="s1">ndmin == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">X = np.atleast_1d(X)</span>
        <span class="s0">elif </span><span class="s1">ndmin == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">X = np.atleast_2d(X).T</span>

    <span class="s0">if </span><span class="s1">unpack:</span>
        <span class="s0">if </span><span class="s1">len(dtype_types) &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s4"># For structured arrays, return an array for each field.</span>
            <span class="s0">return </span><span class="s1">[X[field] </span><span class="s0">for </span><span class="s1">field </span><span class="s0">in </span><span class="s1">dtype.names]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">X.T</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">X</span>


<span class="s1">_loadtxt_with_like = array_function_dispatch(</span>
    <span class="s1">_loadtxt_dispatcher</span>
<span class="s1">)(loadtxt)</span>


<span class="s0">def </span><span class="s1">_savetxt_dispatcher(fname</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">fmt=</span><span class="s0">None, </span><span class="s1">delimiter=</span><span class="s0">None, </span><span class="s1">newline=</span><span class="s0">None,</span>
                        <span class="s1">header=</span><span class="s0">None, </span><span class="s1">footer=</span><span class="s0">None, </span><span class="s1">comments=</span><span class="s0">None,</span>
                        <span class="s1">encoding=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">(X</span><span class="s0">,</span><span class="s1">)</span>


<span class="s1">@array_function_dispatch(_savetxt_dispatcher)</span>
<span class="s0">def </span><span class="s1">savetxt(fname</span><span class="s0">, </span><span class="s1">X</span><span class="s0">, </span><span class="s1">fmt=</span><span class="s2">'%.18e'</span><span class="s0">, </span><span class="s1">delimiter=</span><span class="s2">' '</span><span class="s0">, </span><span class="s1">newline=</span><span class="s2">'</span><span class="s0">\n</span><span class="s2">'</span><span class="s0">, </span><span class="s1">header=</span><span class="s2">''</span><span class="s0">,</span>
            <span class="s1">footer=</span><span class="s2">''</span><span class="s0">, </span><span class="s1">comments=</span><span class="s2">'# '</span><span class="s0">, </span><span class="s1">encoding=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Save an array to a text file. 
 
    Parameters 
    ---------- 
    fname : filename or file handle 
        If the filename ends in ``.gz``, the file is automatically saved in 
        compressed gzip format.  `loadtxt` understands gzipped files 
        transparently. 
    X : 1D or 2D array_like 
        Data to be saved to a text file. 
    fmt : str or sequence of strs, optional 
        A single format (%10.5f), a sequence of formats, or a 
        multi-format string, e.g. 'Iteration %d -- %10.5f', in which 
        case `delimiter` is ignored. For complex `X`, the legal options 
        for `fmt` are: 
 
        * a single specifier, `fmt='%.4e'`, resulting in numbers formatted 
          like `' (%s+%sj)' % (fmt, fmt)` 
        * a full string specifying every real and imaginary part, e.g. 
          `' %.4e %+.4ej %.4e %+.4ej %.4e %+.4ej'` for 3 columns 
        * a list of specifiers, one per column - in this case, the real 
          and imaginary part must have separate specifiers, 
          e.g. `['%.3e + %.3ej', '(%.15e%+.15ej)']` for 2 columns 
    delimiter : str, optional 
        String or character separating columns. 
    newline : str, optional 
        String or character separating lines. 
 
        .. versionadded:: 1.5.0 
    header : str, optional 
        String that will be written at the beginning of the file. 
 
        .. versionadded:: 1.7.0 
    footer : str, optional 
        String that will be written at the end of the file. 
 
        .. versionadded:: 1.7.0 
    comments : str, optional 
        String that will be prepended to the ``header`` and ``footer`` strings, 
        to mark them as comments. Default: '# ',  as expected by e.g. 
        ``numpy.loadtxt``. 
 
        .. versionadded:: 1.7.0 
    encoding : {None, str}, optional 
        Encoding used to encode the outputfile. Does not apply to output 
        streams. If the encoding is something other than 'bytes' or 'latin1' 
        you will not be able to load the file in NumPy versions &lt; 1.14. Default 
        is 'latin1'. 
 
        .. versionadded:: 1.14.0 
 
 
    See Also 
    -------- 
    save : Save an array to a binary file in NumPy ``.npy`` format 
    savez : Save several arrays into an uncompressed ``.npz`` archive 
    savez_compressed : Save several arrays into a compressed ``.npz`` archive 
 
    Notes 
    ----- 
    Further explanation of the `fmt` parameter 
    (``%[flag]width[.precision]specifier``): 
 
    flags: 
        ``-`` : left justify 
 
        ``+`` : Forces to precede result with + or -. 
 
        ``0`` : Left pad the number with zeros instead of space (see width). 
 
    width: 
        Minimum number of characters to be printed. The value is not truncated 
        if it has more characters. 
 
    precision: 
        - For integer specifiers (eg. ``d,i,o,x``), the minimum number of 
          digits. 
        - For ``e, E`` and ``f`` specifiers, the number of digits to print 
          after the decimal point. 
        - For ``g`` and ``G``, the maximum number of significant digits. 
        - For ``s``, the maximum number of characters. 
 
    specifiers: 
        ``c`` : character 
 
        ``d`` or ``i`` : signed decimal integer 
 
        ``e`` or ``E`` : scientific notation with ``e`` or ``E``. 
 
        ``f`` : decimal floating point 
 
        ``g,G`` : use the shorter of ``e,E`` or ``f`` 
 
        ``o`` : signed octal 
 
        ``s`` : string of characters 
 
        ``u`` : unsigned decimal integer 
 
        ``x,X`` : unsigned hexadecimal integer 
 
    This explanation of ``fmt`` is not complete, for an exhaustive 
    specification see [1]_. 
 
    References 
    ---------- 
    .. [1] `Format Specification Mini-Language 
           &lt;https://docs.python.org/library/string.html#format-specification-mini-language&gt;`_, 
           Python Documentation. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; x = y = z = np.arange(0.0,5.0,1.0) 
    &gt;&gt;&gt; np.savetxt('test.out', x, delimiter=',')   # X is an array 
    &gt;&gt;&gt; np.savetxt('test.out', (x,y,z))   # x,y,z equal sized 1D arrays 
    &gt;&gt;&gt; np.savetxt('test.out', x, fmt='%1.4e')   # use exponential notation 
 
    &quot;&quot;&quot;</span>

    <span class="s4"># Py3 conversions first</span>
    <span class="s0">if </span><span class="s1">isinstance(fmt</span><span class="s0">, </span><span class="s1">bytes):</span>
        <span class="s1">fmt = asstr(fmt)</span>
    <span class="s1">delimiter = asstr(delimiter)</span>

    <span class="s0">class </span><span class="s1">WriteWrap:</span>
        <span class="s3">&quot;&quot;&quot;Convert to bytes on bytestream inputs. 
 
        &quot;&quot;&quot;</span>
        <span class="s0">def </span><span class="s1">__init__(self</span><span class="s0">, </span><span class="s1">fh</span><span class="s0">, </span><span class="s1">encoding):</span>
            <span class="s1">self.fh = fh</span>
            <span class="s1">self.encoding = encoding</span>
            <span class="s1">self.do_write = self.first_write</span>

        <span class="s0">def </span><span class="s1">close(self):</span>
            <span class="s1">self.fh.close()</span>

        <span class="s0">def </span><span class="s1">write(self</span><span class="s0">, </span><span class="s1">v):</span>
            <span class="s1">self.do_write(v)</span>

        <span class="s0">def </span><span class="s1">write_bytes(self</span><span class="s0">, </span><span class="s1">v):</span>
            <span class="s0">if </span><span class="s1">isinstance(v</span><span class="s0">, </span><span class="s1">bytes):</span>
                <span class="s1">self.fh.write(v)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">self.fh.write(v.encode(self.encoding))</span>

        <span class="s0">def </span><span class="s1">write_normal(self</span><span class="s0">, </span><span class="s1">v):</span>
            <span class="s1">self.fh.write(asunicode(v))</span>

        <span class="s0">def </span><span class="s1">first_write(self</span><span class="s0">, </span><span class="s1">v):</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">self.write_normal(v)</span>
                <span class="s1">self.write = self.write_normal</span>
            <span class="s0">except </span><span class="s1">TypeError:</span>
                <span class="s4"># input is probably a bytestream</span>
                <span class="s1">self.write_bytes(v)</span>
                <span class="s1">self.write = self.write_bytes</span>

    <span class="s1">own_fh = </span><span class="s0">False</span>
    <span class="s0">if </span><span class="s1">isinstance(fname</span><span class="s0">, </span><span class="s1">os_PathLike):</span>
        <span class="s1">fname = os_fspath(fname)</span>
    <span class="s0">if </span><span class="s1">_is_string_like(fname):</span>
        <span class="s4"># datasource doesn't support creating a new file ...</span>
        <span class="s1">open(fname</span><span class="s0">, </span><span class="s2">'wt'</span><span class="s1">).close()</span>
        <span class="s1">fh = np.lib._datasource.open(fname</span><span class="s0">, </span><span class="s2">'wt'</span><span class="s0">, </span><span class="s1">encoding=encoding)</span>
        <span class="s1">own_fh = </span><span class="s0">True</span>
    <span class="s0">elif </span><span class="s1">hasattr(fname</span><span class="s0">, </span><span class="s2">'write'</span><span class="s1">):</span>
        <span class="s4"># wrap to handle byte output streams</span>
        <span class="s1">fh = WriteWrap(fname</span><span class="s0">, </span><span class="s1">encoding </span><span class="s0">or </span><span class="s2">'latin1'</span><span class="s1">)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">'fname must be a string or file handle'</span><span class="s1">)</span>

    <span class="s0">try</span><span class="s1">:</span>
        <span class="s1">X = np.asarray(X)</span>

        <span class="s4"># Handle 1-dimensional arrays</span>
        <span class="s0">if </span><span class="s1">X.ndim == </span><span class="s5">0 </span><span class="s0">or </span><span class="s1">X.ndim &gt; </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                <span class="s2">&quot;Expected 1D or 2D array, got %dD array instead&quot; </span><span class="s1">% X.ndim)</span>
        <span class="s0">elif </span><span class="s1">X.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s4"># Common case -- 1d array of numbers</span>
            <span class="s0">if </span><span class="s1">X.dtype.names </span><span class="s0">is None</span><span class="s1">:</span>
                <span class="s1">X = np.atleast_2d(X).T</span>
                <span class="s1">ncol = </span><span class="s5">1</span>

            <span class="s4"># Complex dtype -- each field indicates a separate column</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">ncol = len(X.dtype.names)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">ncol = X.shape[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">iscomplex_X = np.iscomplexobj(X)</span>
        <span class="s4"># `fmt` can be a string with multiple insertion points or a</span>
        <span class="s4"># list of formats.  E.g. '%10.5f\t%10d' or ('%10.5f', '$10d')</span>
        <span class="s0">if </span><span class="s1">type(fmt) </span><span class="s0">in </span><span class="s1">(list</span><span class="s0">, </span><span class="s1">tuple):</span>
            <span class="s0">if </span><span class="s1">len(fmt) != ncol:</span>
                <span class="s0">raise </span><span class="s1">AttributeError(</span><span class="s2">'fmt has wrong shape.  %s' </span><span class="s1">% str(fmt))</span>
            <span class="s1">format = asstr(delimiter).join(map(asstr</span><span class="s0">, </span><span class="s1">fmt))</span>
        <span class="s0">elif </span><span class="s1">isinstance(fmt</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s1">n_fmt_chars = fmt.count(</span><span class="s2">'%'</span><span class="s1">)</span>
            <span class="s1">error = ValueError(</span><span class="s2">'fmt has wrong number of %% formats:  %s' </span><span class="s1">% fmt)</span>
            <span class="s0">if </span><span class="s1">n_fmt_chars == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s0">if </span><span class="s1">iscomplex_X:</span>
                    <span class="s1">fmt = [</span><span class="s2">' (%s+%sj)' </span><span class="s1">% (fmt</span><span class="s0">, </span><span class="s1">fmt)</span><span class="s0">, </span><span class="s1">] * ncol</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">fmt = [fmt</span><span class="s0">, </span><span class="s1">] * ncol</span>
                <span class="s1">format = delimiter.join(fmt)</span>
            <span class="s0">elif </span><span class="s1">iscomplex_X </span><span class="s0">and </span><span class="s1">n_fmt_chars != (</span><span class="s5">2 </span><span class="s1">* ncol):</span>
                <span class="s0">raise </span><span class="s1">error</span>
            <span class="s0">elif </span><span class="s1">((</span><span class="s0">not </span><span class="s1">iscomplex_X) </span><span class="s0">and </span><span class="s1">n_fmt_chars != ncol):</span>
                <span class="s0">raise </span><span class="s1">error</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">format = fmt</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">'invalid fmt: %r' </span><span class="s1">% (fmt</span><span class="s0">,</span><span class="s1">))</span>

        <span class="s0">if </span><span class="s1">len(header) &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">header = header.replace(</span><span class="s2">'</span><span class="s0">\n</span><span class="s2">'</span><span class="s0">, </span><span class="s2">'</span><span class="s0">\n</span><span class="s2">' </span><span class="s1">+ comments)</span>
            <span class="s1">fh.write(comments + header + newline)</span>
        <span class="s0">if </span><span class="s1">iscomplex_X:</span>
            <span class="s0">for </span><span class="s1">row </span><span class="s0">in </span><span class="s1">X:</span>
                <span class="s1">row2 = []</span>
                <span class="s0">for </span><span class="s1">number </span><span class="s0">in </span><span class="s1">row:</span>
                    <span class="s1">row2.append(number.real)</span>
                    <span class="s1">row2.append(number.imag)</span>
                <span class="s1">s = format % tuple(row2) + newline</span>
                <span class="s1">fh.write(s.replace(</span><span class="s2">'+-'</span><span class="s0">, </span><span class="s2">'-'</span><span class="s1">))</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">for </span><span class="s1">row </span><span class="s0">in </span><span class="s1">X:</span>
                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">v = format % tuple(row) + newline</span>
                <span class="s0">except </span><span class="s1">TypeError </span><span class="s0">as </span><span class="s1">e:</span>
                    <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s2">&quot;Mismatch between array dtype ('%s') and &quot;</span>
                                    <span class="s2">&quot;format specifier ('%s')&quot;</span>
                                    <span class="s1">% (str(X.dtype)</span><span class="s0">, </span><span class="s1">format)) </span><span class="s0">from </span><span class="s1">e</span>
                <span class="s1">fh.write(v)</span>

        <span class="s0">if </span><span class="s1">len(footer) &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">footer = footer.replace(</span><span class="s2">'</span><span class="s0">\n</span><span class="s2">'</span><span class="s0">, </span><span class="s2">'</span><span class="s0">\n</span><span class="s2">' </span><span class="s1">+ comments)</span>
            <span class="s1">fh.write(comments + footer + newline)</span>
    <span class="s0">finally</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">own_fh:</span>
            <span class="s1">fh.close()</span>


<span class="s1">@set_module(</span><span class="s2">'numpy'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">fromregex(file</span><span class="s0">, </span><span class="s1">regexp</span><span class="s0">, </span><span class="s1">dtype</span><span class="s0">, </span><span class="s1">encoding=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s3">r&quot;&quot;&quot; 
    Construct an array from a text file, using regular expression parsing. 
 
    The returned array is always a structured array, and is constructed from 
    all matches of the regular expression in the file. Groups in the regular 
    expression are converted to fields of the structured array. 
 
    Parameters 
    ---------- 
    file : path or file 
        Filename or file object to read. 
 
        .. versionchanged:: 1.22.0 
            Now accepts `os.PathLike` implementations. 
    regexp : str or regexp 
        Regular expression used to parse the file. 
        Groups in the regular expression correspond to fields in the dtype. 
    dtype : dtype or list of dtypes 
        Dtype for the structured array; must be a structured datatype. 
    encoding : str, optional 
        Encoding used to decode the inputfile. Does not apply to input streams. 
 
        .. versionadded:: 1.14.0 
 
    Returns 
    ------- 
    output : ndarray 
        The output array, containing the part of the content of `file` that 
        was matched by `regexp`. `output` is always a structured array. 
 
    Raises 
    ------ 
    TypeError 
        When `dtype` is not a valid dtype for a structured array. 
 
    See Also 
    -------- 
    fromstring, loadtxt 
 
    Notes 
    ----- 
    Dtypes for structured arrays can be specified in several forms, but all 
    forms specify at least the data type and field name. For details see 
    `basics.rec`. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from io import StringIO 
    &gt;&gt;&gt; text = StringIO(&quot;1312 foo\n1534  bar\n444   qux&quot;) 
 
    &gt;&gt;&gt; regexp = r&quot;(\d+)\s+(...)&quot;  # match [digits, whitespace, anything] 
    &gt;&gt;&gt; output = np.fromregex(text, regexp, 
    ...                       [('num', np.int64), ('key', 'S3')]) 
    &gt;&gt;&gt; output 
    array([(1312, b'foo'), (1534, b'bar'), ( 444, b'qux')], 
          dtype=[('num', '&lt;i8'), ('key', 'S3')]) 
    &gt;&gt;&gt; output['num'] 
    array([1312, 1534,  444]) 
 
    &quot;&quot;&quot;</span>
    <span class="s1">own_fh = </span><span class="s0">False</span>
    <span class="s0">if not </span><span class="s1">hasattr(file</span><span class="s0">, </span><span class="s2">&quot;read&quot;</span><span class="s1">):</span>
        <span class="s1">file = os.fspath(file)</span>
        <span class="s1">file = np.lib._datasource.open(file</span><span class="s0">, </span><span class="s2">'rt'</span><span class="s0">, </span><span class="s1">encoding=encoding)</span>
        <span class="s1">own_fh = </span><span class="s0">True</span>

    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">if not </span><span class="s1">isinstance(dtype</span><span class="s0">, </span><span class="s1">np.dtype):</span>
            <span class="s1">dtype = np.dtype(dtype)</span>
        <span class="s0">if </span><span class="s1">dtype.names </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">TypeError(</span><span class="s2">'dtype must be a structured datatype.'</span><span class="s1">)</span>

        <span class="s1">content = file.read()</span>
        <span class="s0">if </span><span class="s1">isinstance(content</span><span class="s0">, </span><span class="s1">bytes) </span><span class="s0">and </span><span class="s1">isinstance(regexp</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s1">regexp = asbytes(regexp)</span>
        <span class="s0">elif </span><span class="s1">isinstance(content</span><span class="s0">, </span><span class="s1">str) </span><span class="s0">and </span><span class="s1">isinstance(regexp</span><span class="s0">, </span><span class="s1">bytes):</span>
            <span class="s1">regexp = asstr(regexp)</span>

        <span class="s0">if not </span><span class="s1">hasattr(regexp</span><span class="s0">, </span><span class="s2">'match'</span><span class="s1">):</span>
            <span class="s1">regexp = re.compile(regexp)</span>
        <span class="s1">seq = regexp.findall(content)</span>
        <span class="s0">if </span><span class="s1">seq </span><span class="s0">and not </span><span class="s1">isinstance(seq[</span><span class="s5">0</span><span class="s1">]</span><span class="s0">, </span><span class="s1">tuple):</span>
            <span class="s4"># Only one group is in the regexp.</span>
            <span class="s4"># Create the new array as a single data-type and then</span>
            <span class="s4">#   re-interpret as a single-field structured array.</span>
            <span class="s1">newdtype = np.dtype(dtype[dtype.names[</span><span class="s5">0</span><span class="s1">]])</span>
            <span class="s1">output = np.array(seq</span><span class="s0">, </span><span class="s1">dtype=newdtype)</span>
            <span class="s1">output.dtype = dtype</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">output = np.array(seq</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>

        <span class="s0">return </span><span class="s1">output</span>
    <span class="s0">finally</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">own_fh:</span>
            <span class="s1">file.close()</span>


<span class="s4">#####--------------------------------------------------------------------------</span>
<span class="s4">#---- --- ASCII functions ---</span>
<span class="s4">#####--------------------------------------------------------------------------</span>


<span class="s0">def </span><span class="s1">_genfromtxt_dispatcher(fname</span><span class="s0">, </span><span class="s1">dtype=</span><span class="s0">None, </span><span class="s1">comments=</span><span class="s0">None, </span><span class="s1">delimiter=</span><span class="s0">None,</span>
                           <span class="s1">skip_header=</span><span class="s0">None, </span><span class="s1">skip_footer=</span><span class="s0">None, </span><span class="s1">converters=</span><span class="s0">None,</span>
                           <span class="s1">missing_values=</span><span class="s0">None, </span><span class="s1">filling_values=</span><span class="s0">None, </span><span class="s1">usecols=</span><span class="s0">None,</span>
                           <span class="s1">names=</span><span class="s0">None, </span><span class="s1">excludelist=</span><span class="s0">None, </span><span class="s1">deletechars=</span><span class="s0">None,</span>
                           <span class="s1">replace_space=</span><span class="s0">None, </span><span class="s1">autostrip=</span><span class="s0">None, </span><span class="s1">case_sensitive=</span><span class="s0">None,</span>
                           <span class="s1">defaultfmt=</span><span class="s0">None, </span><span class="s1">unpack=</span><span class="s0">None, </span><span class="s1">usemask=</span><span class="s0">None, </span><span class="s1">loose=</span><span class="s0">None,</span>
                           <span class="s1">invalid_raise=</span><span class="s0">None, </span><span class="s1">max_rows=</span><span class="s0">None, </span><span class="s1">encoding=</span><span class="s0">None, </span><span class="s1">*</span><span class="s0">,</span>
                           <span class="s1">like=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s0">return </span><span class="s1">(like</span><span class="s0">,</span><span class="s1">)</span>


<span class="s1">@set_array_function_like_doc</span>
<span class="s1">@set_module(</span><span class="s2">'numpy'</span><span class="s1">)</span>
<span class="s0">def </span><span class="s1">genfromtxt(fname</span><span class="s0">, </span><span class="s1">dtype=float</span><span class="s0">, </span><span class="s1">comments=</span><span class="s2">'#'</span><span class="s0">, </span><span class="s1">delimiter=</span><span class="s0">None,</span>
               <span class="s1">skip_header=</span><span class="s5">0</span><span class="s0">, </span><span class="s1">skip_footer=</span><span class="s5">0</span><span class="s0">, </span><span class="s1">converters=</span><span class="s0">None,</span>
               <span class="s1">missing_values=</span><span class="s0">None, </span><span class="s1">filling_values=</span><span class="s0">None, </span><span class="s1">usecols=</span><span class="s0">None,</span>
               <span class="s1">names=</span><span class="s0">None, </span><span class="s1">excludelist=</span><span class="s0">None,</span>
               <span class="s1">deletechars=</span><span class="s2">''</span><span class="s1">.join(sorted(NameValidator.defaultdeletechars))</span><span class="s0">,</span>
               <span class="s1">replace_space=</span><span class="s2">'_'</span><span class="s0">, </span><span class="s1">autostrip=</span><span class="s0">False, </span><span class="s1">case_sensitive=</span><span class="s0">True,</span>
               <span class="s1">defaultfmt=</span><span class="s2">&quot;f%i&quot;</span><span class="s0">, </span><span class="s1">unpack=</span><span class="s0">None, </span><span class="s1">usemask=</span><span class="s0">False, </span><span class="s1">loose=</span><span class="s0">True,</span>
               <span class="s1">invalid_raise=</span><span class="s0">True, </span><span class="s1">max_rows=</span><span class="s0">None, </span><span class="s1">encoding=</span><span class="s2">'bytes'</span><span class="s0">, </span><span class="s1">*</span><span class="s0">,</span>
               <span class="s1">like=</span><span class="s0">None</span><span class="s1">):</span>
    <span class="s3">&quot;&quot;&quot; 
    Load data from a text file, with missing values handled as specified. 
 
    Each line past the first `skip_header` lines is split at the `delimiter` 
    character, and characters following the `comments` character are discarded. 
 
    Parameters 
    ---------- 
    fname : file, str, pathlib.Path, list of str, generator 
        File, filename, list, or generator to read.  If the filename 
        extension is ``.gz`` or ``.bz2``, the file is first decompressed. Note 
        that generators must return bytes or strings. The strings 
        in a list or produced by a generator are treated as lines. 
    dtype : dtype, optional 
        Data type of the resulting array. 
        If None, the dtypes will be determined by the contents of each 
        column, individually. 
    comments : str, optional 
        The character used to indicate the start of a comment. 
        All the characters occurring on a line after a comment are discarded. 
    delimiter : str, int, or sequence, optional 
        The string used to separate values.  By default, any consecutive 
        whitespaces act as delimiter.  An integer or sequence of integers 
        can also be provided as width(s) of each field. 
    skiprows : int, optional 
        `skiprows` was removed in numpy 1.10. Please use `skip_header` instead. 
    skip_header : int, optional 
        The number of lines to skip at the beginning of the file. 
    skip_footer : int, optional 
        The number of lines to skip at the end of the file. 
    converters : variable, optional 
        The set of functions that convert the data of a column to a value. 
        The converters can also be used to provide a default value 
        for missing data: ``converters = {3: lambda s: float(s or 0)}``. 
    missing : variable, optional 
        `missing` was removed in numpy 1.10. Please use `missing_values` 
        instead. 
    missing_values : variable, optional 
        The set of strings corresponding to missing data. 
    filling_values : variable, optional 
        The set of values to be used as default when the data are missing. 
    usecols : sequence, optional 
        Which columns to read, with 0 being the first.  For example, 
        ``usecols = (1, 4, 5)`` will extract the 2nd, 5th and 6th columns. 
    names : {None, True, str, sequence}, optional 
        If `names` is True, the field names are read from the first line after 
        the first `skip_header` lines. This line can optionally be preceded 
        by a comment delimiter. If `names` is a sequence or a single-string of 
        comma-separated names, the names will be used to define the field names 
        in a structured dtype. If `names` is None, the names of the dtype 
        fields will be used, if any. 
    excludelist : sequence, optional 
        A list of names to exclude. This list is appended to the default list 
        ['return','file','print']. Excluded names are appended with an 
        underscore: for example, `file` would become `file_`. 
    deletechars : str, optional 
        A string combining invalid characters that must be deleted from the 
        names. 
    defaultfmt : str, optional 
        A format used to define default field names, such as &quot;f%i&quot; or &quot;f_%02i&quot;. 
    autostrip : bool, optional 
        Whether to automatically strip white spaces from the variables. 
    replace_space : char, optional 
        Character(s) used in replacement of white spaces in the variable 
        names. By default, use a '_'. 
    case_sensitive : {True, False, 'upper', 'lower'}, optional 
        If True, field names are case sensitive. 
        If False or 'upper', field names are converted to upper case. 
        If 'lower', field names are converted to lower case. 
    unpack : bool, optional 
        If True, the returned array is transposed, so that arguments may be 
        unpacked using ``x, y, z = genfromtxt(...)``.  When used with a 
        structured data-type, arrays are returned for each field. 
        Default is False. 
    usemask : bool, optional 
        If True, return a masked array. 
        If False, return a regular array. 
    loose : bool, optional 
        If True, do not raise errors for invalid values. 
    invalid_raise : bool, optional 
        If True, an exception is raised if an inconsistency is detected in the 
        number of columns. 
        If False, a warning is emitted and the offending lines are skipped. 
    max_rows : int,  optional 
        The maximum number of rows to read. Must not be used with skip_footer 
        at the same time.  If given, the value must be at least 1. Default is 
        to read the entire file. 
 
        .. versionadded:: 1.10.0 
    encoding : str, optional 
        Encoding used to decode the inputfile. Does not apply when `fname` is 
        a file object.  The special value 'bytes' enables backward compatibility 
        workarounds that ensure that you receive byte arrays when possible 
        and passes latin1 encoded strings to converters. Override this value to 
        receive unicode arrays and pass strings as input to converters.  If set 
        to None the system default is used. The default value is 'bytes'. 
 
        .. versionadded:: 1.14.0 
    ${ARRAY_FUNCTION_LIKE} 
 
        .. versionadded:: 1.20.0 
 
    Returns 
    ------- 
    out : ndarray 
        Data read from the text file. If `usemask` is True, this is a 
        masked array. 
 
    See Also 
    -------- 
    numpy.loadtxt : equivalent function when no data is missing. 
 
    Notes 
    ----- 
    * When spaces are used as delimiters, or when no delimiter has been given 
      as input, there should not be any missing data between two fields. 
    * When the variables are named (either by a flexible dtype or with `names`), 
      there must not be any header in the file (else a ValueError 
      exception is raised). 
    * Individual values are not stripped of spaces by default. 
      When using a custom converter, make sure the function does remove spaces. 
 
    References 
    ---------- 
    .. [1] NumPy User Guide, section `I/O with NumPy 
           &lt;https://docs.scipy.org/doc/numpy/user/basics.io.genfromtxt.html&gt;`_. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from io import StringIO 
    &gt;&gt;&gt; import numpy as np 
 
    Comma delimited file with mixed dtype 
 
    &gt;&gt;&gt; s = StringIO(u&quot;1,1.3,abcde&quot;) 
    &gt;&gt;&gt; data = np.genfromtxt(s, dtype=[('myint','i8'),('myfloat','f8'), 
    ... ('mystring','S5')], delimiter=&quot;,&quot;) 
    &gt;&gt;&gt; data 
    array((1, 1.3, b'abcde'), 
          dtype=[('myint', '&lt;i8'), ('myfloat', '&lt;f8'), ('mystring', 'S5')]) 
 
    Using dtype = None 
 
    &gt;&gt;&gt; _ = s.seek(0) # needed for StringIO example only 
    &gt;&gt;&gt; data = np.genfromtxt(s, dtype=None, 
    ... names = ['myint','myfloat','mystring'], delimiter=&quot;,&quot;) 
    &gt;&gt;&gt; data 
    array((1, 1.3, b'abcde'), 
          dtype=[('myint', '&lt;i8'), ('myfloat', '&lt;f8'), ('mystring', 'S5')]) 
 
    Specifying dtype and names 
 
    &gt;&gt;&gt; _ = s.seek(0) 
    &gt;&gt;&gt; data = np.genfromtxt(s, dtype=&quot;i8,f8,S5&quot;, 
    ... names=['myint','myfloat','mystring'], delimiter=&quot;,&quot;) 
    &gt;&gt;&gt; data 
    array((1, 1.3, b'abcde'), 
          dtype=[('myint', '&lt;i8'), ('myfloat', '&lt;f8'), ('mystring', 'S5')]) 
 
    An example with fixed-width columns 
 
    &gt;&gt;&gt; s = StringIO(u&quot;11.3abcde&quot;) 
    &gt;&gt;&gt; data = np.genfromtxt(s, dtype=None, names=['intvar','fltvar','strvar'], 
    ...     delimiter=[1,3,5]) 
    &gt;&gt;&gt; data 
    array((1, 1.3, b'abcde'), 
          dtype=[('intvar', '&lt;i8'), ('fltvar', '&lt;f8'), ('strvar', 'S5')]) 
 
    An example to show comments 
 
    &gt;&gt;&gt; f = StringIO(''' 
    ... text,# of chars 
    ... hello world,11 
    ... numpy,5''') 
    &gt;&gt;&gt; np.genfromtxt(f, dtype='S12,S12', delimiter=',') 
    array([(b'text', b''), (b'hello world', b'11'), (b'numpy', b'5')], 
      dtype=[('f0', 'S12'), ('f1', 'S12')]) 
 
    &quot;&quot;&quot;</span>

    <span class="s0">if </span><span class="s1">like </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">return </span><span class="s1">_genfromtxt_with_like(</span>
            <span class="s1">fname</span><span class="s0">, </span><span class="s1">dtype=dtype</span><span class="s0">, </span><span class="s1">comments=comments</span><span class="s0">, </span><span class="s1">delimiter=delimiter</span><span class="s0">,</span>
            <span class="s1">skip_header=skip_header</span><span class="s0">, </span><span class="s1">skip_footer=skip_footer</span><span class="s0">,</span>
            <span class="s1">converters=converters</span><span class="s0">, </span><span class="s1">missing_values=missing_values</span><span class="s0">,</span>
            <span class="s1">filling_values=filling_values</span><span class="s0">, </span><span class="s1">usecols=usecols</span><span class="s0">, </span><span class="s1">names=names</span><span class="s0">,</span>
            <span class="s1">excludelist=excludelist</span><span class="s0">, </span><span class="s1">deletechars=deletechars</span><span class="s0">,</span>
            <span class="s1">replace_space=replace_space</span><span class="s0">, </span><span class="s1">autostrip=autostrip</span><span class="s0">,</span>
            <span class="s1">case_sensitive=case_sensitive</span><span class="s0">, </span><span class="s1">defaultfmt=defaultfmt</span><span class="s0">,</span>
            <span class="s1">unpack=unpack</span><span class="s0">, </span><span class="s1">usemask=usemask</span><span class="s0">, </span><span class="s1">loose=loose</span><span class="s0">,</span>
            <span class="s1">invalid_raise=invalid_raise</span><span class="s0">, </span><span class="s1">max_rows=max_rows</span><span class="s0">, </span><span class="s1">encoding=encoding</span><span class="s0">,</span>
            <span class="s1">like=like</span>
        <span class="s1">)</span>

    <span class="s0">if </span><span class="s1">max_rows </span><span class="s0">is not None</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">skip_footer:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span>
                    <span class="s2">&quot;The keywords 'skip_footer' and 'max_rows' can not be &quot;</span>
                    <span class="s2">&quot;specified at the same time.&quot;</span><span class="s1">)</span>
        <span class="s0">if </span><span class="s1">max_rows &lt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s0">raise </span><span class="s1">ValueError(</span><span class="s2">&quot;'max_rows' must be at least 1.&quot;</span><span class="s1">)</span>

    <span class="s0">if </span><span class="s1">usemask:</span>
        <span class="s0">from </span><span class="s1">numpy.ma </span><span class="s0">import </span><span class="s1">MaskedArray</span><span class="s0">, </span><span class="s1">make_mask_descr</span>
    <span class="s4"># Check the input dictionary of converters</span>
    <span class="s1">user_converters = converters </span><span class="s0">or </span><span class="s1">{}</span>
    <span class="s0">if not </span><span class="s1">isinstance(user_converters</span><span class="s0">, </span><span class="s1">dict):</span>
        <span class="s0">raise </span><span class="s1">TypeError(</span>
            <span class="s2">&quot;The input argument 'converter' should be a valid dictionary &quot;</span>
            <span class="s2">&quot;(got '%s' instead)&quot; </span><span class="s1">% type(user_converters))</span>

    <span class="s0">if </span><span class="s1">encoding == </span><span class="s2">'bytes'</span><span class="s1">:</span>
        <span class="s1">encoding = </span><span class="s0">None</span>
        <span class="s1">byte_converters = </span><span class="s0">True</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">byte_converters = </span><span class="s0">False</span>

    <span class="s4"># Initialize the filehandle, the LineSplitter and the NameValidator</span>
    <span class="s0">try</span><span class="s1">:</span>
        <span class="s0">if </span><span class="s1">isinstance(fname</span><span class="s0">, </span><span class="s1">os_PathLike):</span>
            <span class="s1">fname = os_fspath(fname)</span>
        <span class="s0">if </span><span class="s1">isinstance(fname</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s1">fid = np.lib._datasource.open(fname</span><span class="s0">, </span><span class="s2">'rt'</span><span class="s0">, </span><span class="s1">encoding=encoding)</span>
            <span class="s1">fid_ctx = contextlib.closing(fid)</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">fid = fname</span>
            <span class="s1">fid_ctx = contextlib.nullcontext(fid)</span>
        <span class="s1">fhd = iter(fid)</span>
    <span class="s0">except </span><span class="s1">TypeError </span><span class="s0">as </span><span class="s1">e:</span>
        <span class="s0">raise </span><span class="s1">TypeError(</span>
            <span class="s2">f&quot;fname must be a string, filehandle, list of strings,</span><span class="s0">\n</span><span class="s2">&quot;</span>
            <span class="s2">f&quot;or generator. Got </span><span class="s0">{</span><span class="s1">type(fname)</span><span class="s0">} </span><span class="s2">instead.&quot;</span>
        <span class="s1">) </span><span class="s0">from </span><span class="s1">e</span>

    <span class="s0">with </span><span class="s1">fid_ctx:</span>
        <span class="s1">split_line = LineSplitter(delimiter=delimiter</span><span class="s0">, </span><span class="s1">comments=comments</span><span class="s0">,</span>
                                  <span class="s1">autostrip=autostrip</span><span class="s0">, </span><span class="s1">encoding=encoding)</span>
        <span class="s1">validate_names = NameValidator(excludelist=excludelist</span><span class="s0">,</span>
                                       <span class="s1">deletechars=deletechars</span><span class="s0">,</span>
                                       <span class="s1">case_sensitive=case_sensitive</span><span class="s0">,</span>
                                       <span class="s1">replace_space=replace_space)</span>

        <span class="s4"># Skip the first `skip_header` rows</span>
        <span class="s0">try</span><span class="s1">:</span>
            <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">range(skip_header):</span>
                <span class="s1">next(fhd)</span>

            <span class="s4"># Keep on until we find the first valid values</span>
            <span class="s1">first_values = </span><span class="s0">None</span>

            <span class="s0">while not </span><span class="s1">first_values:</span>
                <span class="s1">first_line = _decode_line(next(fhd)</span><span class="s0">, </span><span class="s1">encoding)</span>
                <span class="s0">if </span><span class="s1">(names </span><span class="s0">is True</span><span class="s1">) </span><span class="s0">and </span><span class="s1">(comments </span><span class="s0">is not None</span><span class="s1">):</span>
                    <span class="s0">if </span><span class="s1">comments </span><span class="s0">in </span><span class="s1">first_line:</span>
                        <span class="s1">first_line = (</span>
                            <span class="s2">''</span><span class="s1">.join(first_line.split(comments)[</span><span class="s5">1</span><span class="s1">:]))</span>
                <span class="s1">first_values = split_line(first_line)</span>
        <span class="s0">except </span><span class="s1">StopIteration:</span>
            <span class="s4"># return an empty array if the datafile is empty</span>
            <span class="s1">first_line = </span><span class="s2">''</span>
            <span class="s1">first_values = []</span>
            <span class="s1">warnings.warn(</span><span class="s2">'genfromtxt: Empty input file: &quot;%s&quot;' </span><span class="s1">% fname</span><span class="s0">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>

        <span class="s4"># Should we take the first values as names ?</span>
        <span class="s0">if </span><span class="s1">names </span><span class="s0">is True</span><span class="s1">:</span>
            <span class="s1">fval = first_values[</span><span class="s5">0</span><span class="s1">].strip()</span>
            <span class="s0">if </span><span class="s1">comments </span><span class="s0">is not None</span><span class="s1">:</span>
                <span class="s0">if </span><span class="s1">fval </span><span class="s0">in </span><span class="s1">comments:</span>
                    <span class="s0">del </span><span class="s1">first_values[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s4"># Check the columns to use: make sure `usecols` is a list</span>
        <span class="s0">if </span><span class="s1">usecols </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">usecols = [_.strip() </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">usecols.split(</span><span class="s2">&quot;,&quot;</span><span class="s1">)]</span>
            <span class="s0">except </span><span class="s1">AttributeError:</span>
                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">usecols = list(usecols)</span>
                <span class="s0">except </span><span class="s1">TypeError:</span>
                    <span class="s1">usecols = [usecols</span><span class="s0">, </span><span class="s1">]</span>
        <span class="s1">nbcols = len(usecols </span><span class="s0">or </span><span class="s1">first_values)</span>

        <span class="s4"># Check the names and overwrite the dtype.names if needed</span>
        <span class="s0">if </span><span class="s1">names </span><span class="s0">is True</span><span class="s1">:</span>
            <span class="s1">names = validate_names([str(_.strip()) </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">first_values])</span>
            <span class="s1">first_line = </span><span class="s2">''</span>
        <span class="s0">elif </span><span class="s1">_is_string_like(names):</span>
            <span class="s1">names = validate_names([_.strip() </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">names.split(</span><span class="s2">','</span><span class="s1">)])</span>
        <span class="s0">elif </span><span class="s1">names:</span>
            <span class="s1">names = validate_names(names)</span>
        <span class="s4"># Get the dtype</span>
        <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">dtype = easy_dtype(dtype</span><span class="s0">, </span><span class="s1">defaultfmt=defaultfmt</span><span class="s0">, </span><span class="s1">names=names</span><span class="s0">,</span>
                               <span class="s1">excludelist=excludelist</span><span class="s0">,</span>
                               <span class="s1">deletechars=deletechars</span><span class="s0">,</span>
                               <span class="s1">case_sensitive=case_sensitive</span><span class="s0">,</span>
                               <span class="s1">replace_space=replace_space)</span>
        <span class="s4"># Make sure the names is a list (for 2.5)</span>
        <span class="s0">if </span><span class="s1">names </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">names = list(names)</span>

        <span class="s0">if </span><span class="s1">usecols:</span>
            <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">current) </span><span class="s0">in </span><span class="s1">enumerate(usecols):</span>
                <span class="s4"># if usecols is a list of names, convert to a list of indices</span>
                <span class="s0">if </span><span class="s1">_is_string_like(current):</span>
                    <span class="s1">usecols[i] = names.index(current)</span>
                <span class="s0">elif </span><span class="s1">current &lt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">usecols[i] = current + len(first_values)</span>
            <span class="s4"># If the dtype is not None, make sure we update it</span>
            <span class="s0">if </span><span class="s1">(dtype </span><span class="s0">is not None</span><span class="s1">) </span><span class="s0">and </span><span class="s1">(len(dtype) &gt; nbcols):</span>
                <span class="s1">descr = dtype.descr</span>
                <span class="s1">dtype = np.dtype([descr[_] </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">usecols])</span>
                <span class="s1">names = list(dtype.names)</span>
            <span class="s4"># If `names` is not None, update the names</span>
            <span class="s0">elif </span><span class="s1">(names </span><span class="s0">is not None</span><span class="s1">) </span><span class="s0">and </span><span class="s1">(len(names) &gt; nbcols):</span>
                <span class="s1">names = [names[_] </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">usecols]</span>
        <span class="s0">elif </span><span class="s1">(names </span><span class="s0">is not None</span><span class="s1">) </span><span class="s0">and </span><span class="s1">(dtype </span><span class="s0">is not None</span><span class="s1">):</span>
            <span class="s1">names = list(dtype.names)</span>

        <span class="s4"># Process the missing values ...............................</span>
        <span class="s4"># Rename missing_values for convenience</span>
        <span class="s1">user_missing_values = missing_values </span><span class="s0">or </span><span class="s1">()</span>
        <span class="s0">if </span><span class="s1">isinstance(user_missing_values</span><span class="s0">, </span><span class="s1">bytes):</span>
            <span class="s1">user_missing_values = user_missing_values.decode(</span><span class="s2">'latin1'</span><span class="s1">)</span>

        <span class="s4"># Define the list of missing_values (one column: one list)</span>
        <span class="s1">missing_values = [list([</span><span class="s2">''</span><span class="s1">]) </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">range(nbcols)]</span>

        <span class="s4"># We have a dictionary: process it field by field</span>
        <span class="s0">if </span><span class="s1">isinstance(user_missing_values</span><span class="s0">, </span><span class="s1">dict):</span>
            <span class="s4"># Loop on the items</span>
            <span class="s0">for </span><span class="s1">(key</span><span class="s0">, </span><span class="s1">val) </span><span class="s0">in </span><span class="s1">user_missing_values.items():</span>
                <span class="s4"># Is the key a string ?</span>
                <span class="s0">if </span><span class="s1">_is_string_like(key):</span>
                    <span class="s0">try</span><span class="s1">:</span>
                        <span class="s4"># Transform it into an integer</span>
                        <span class="s1">key = names.index(key)</span>
                    <span class="s0">except </span><span class="s1">ValueError:</span>
                        <span class="s4"># We couldn't find it: the name must have been dropped</span>
                        <span class="s0">continue</span>
                <span class="s4"># Redefine the key as needed if it's a column number</span>
                <span class="s0">if </span><span class="s1">usecols:</span>
                    <span class="s0">try</span><span class="s1">:</span>
                        <span class="s1">key = usecols.index(key)</span>
                    <span class="s0">except </span><span class="s1">ValueError:</span>
                        <span class="s0">pass</span>
                <span class="s4"># Transform the value as a list of string</span>
                <span class="s0">if </span><span class="s1">isinstance(val</span><span class="s0">, </span><span class="s1">(list</span><span class="s0">, </span><span class="s1">tuple)):</span>
                    <span class="s1">val = [str(_) </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">val]</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">val = [str(val)</span><span class="s0">, </span><span class="s1">]</span>
                <span class="s4"># Add the value(s) to the current list of missing</span>
                <span class="s0">if </span><span class="s1">key </span><span class="s0">is None</span><span class="s1">:</span>
                    <span class="s4"># None acts as default</span>
                    <span class="s0">for </span><span class="s1">miss </span><span class="s0">in </span><span class="s1">missing_values:</span>
                        <span class="s1">miss.extend(val)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">missing_values[key].extend(val)</span>
        <span class="s4"># We have a sequence : each item matches a column</span>
        <span class="s0">elif </span><span class="s1">isinstance(user_missing_values</span><span class="s0">, </span><span class="s1">(list</span><span class="s0">, </span><span class="s1">tuple)):</span>
            <span class="s0">for </span><span class="s1">(value</span><span class="s0">, </span><span class="s1">entry) </span><span class="s0">in </span><span class="s1">zip(user_missing_values</span><span class="s0">, </span><span class="s1">missing_values):</span>
                <span class="s1">value = str(value)</span>
                <span class="s0">if </span><span class="s1">value </span><span class="s0">not in </span><span class="s1">entry:</span>
                    <span class="s1">entry.append(value)</span>
        <span class="s4"># We have a string : apply it to all entries</span>
        <span class="s0">elif </span><span class="s1">isinstance(user_missing_values</span><span class="s0">, </span><span class="s1">str):</span>
            <span class="s1">user_value = user_missing_values.split(</span><span class="s2">&quot;,&quot;</span><span class="s1">)</span>
            <span class="s0">for </span><span class="s1">entry </span><span class="s0">in </span><span class="s1">missing_values:</span>
                <span class="s1">entry.extend(user_value)</span>
        <span class="s4"># We have something else: apply it to all entries</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s0">for </span><span class="s1">entry </span><span class="s0">in </span><span class="s1">missing_values:</span>
                <span class="s1">entry.extend([str(user_missing_values)])</span>

        <span class="s4"># Process the filling_values ...............................</span>
        <span class="s4"># Rename the input for convenience</span>
        <span class="s1">user_filling_values = filling_values</span>
        <span class="s0">if </span><span class="s1">user_filling_values </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s1">user_filling_values = []</span>
        <span class="s4"># Define the default</span>
        <span class="s1">filling_values = [</span><span class="s0">None</span><span class="s1">] * nbcols</span>
        <span class="s4"># We have a dictionary : update each entry individually</span>
        <span class="s0">if </span><span class="s1">isinstance(user_filling_values</span><span class="s0">, </span><span class="s1">dict):</span>
            <span class="s0">for </span><span class="s1">(key</span><span class="s0">, </span><span class="s1">val) </span><span class="s0">in </span><span class="s1">user_filling_values.items():</span>
                <span class="s0">if </span><span class="s1">_is_string_like(key):</span>
                    <span class="s0">try</span><span class="s1">:</span>
                        <span class="s4"># Transform it into an integer</span>
                        <span class="s1">key = names.index(key)</span>
                    <span class="s0">except </span><span class="s1">ValueError:</span>
                        <span class="s4"># We couldn't find it: the name must have been dropped,</span>
                        <span class="s0">continue</span>
                <span class="s4"># Redefine the key if it's a column number and usecols is defined</span>
                <span class="s0">if </span><span class="s1">usecols:</span>
                    <span class="s0">try</span><span class="s1">:</span>
                        <span class="s1">key = usecols.index(key)</span>
                    <span class="s0">except </span><span class="s1">ValueError:</span>
                        <span class="s0">pass</span>
                <span class="s4"># Add the value to the list</span>
                <span class="s1">filling_values[key] = val</span>
        <span class="s4"># We have a sequence : update on a one-to-one basis</span>
        <span class="s0">elif </span><span class="s1">isinstance(user_filling_values</span><span class="s0">, </span><span class="s1">(list</span><span class="s0">, </span><span class="s1">tuple)):</span>
            <span class="s1">n = len(user_filling_values)</span>
            <span class="s0">if </span><span class="s1">(n &lt;= nbcols):</span>
                <span class="s1">filling_values[:n] = user_filling_values</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">filling_values = user_filling_values[:nbcols]</span>
        <span class="s4"># We have something else : use it for all entries</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">filling_values = [user_filling_values] * nbcols</span>

        <span class="s4"># Initialize the converters ................................</span>
        <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s4"># Note: we can't use a [...]*nbcols, as we would have 3 times the same</span>
            <span class="s4"># ... converter, instead of 3 different converters.</span>
            <span class="s1">converters = [StringConverter(</span><span class="s0">None, </span><span class="s1">missing_values=miss</span><span class="s0">, </span><span class="s1">default=fill)</span>
                          <span class="s0">for </span><span class="s1">(miss</span><span class="s0">, </span><span class="s1">fill) </span><span class="s0">in </span><span class="s1">zip(missing_values</span><span class="s0">, </span><span class="s1">filling_values)]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">dtype_flat = flatten_dtype(dtype</span><span class="s0">, </span><span class="s1">flatten_base=</span><span class="s0">True</span><span class="s1">)</span>
            <span class="s4"># Initialize the converters</span>
            <span class="s0">if </span><span class="s1">len(dtype_flat) &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s4"># Flexible type : get a converter from each dtype</span>
                <span class="s1">zipit = zip(dtype_flat</span><span class="s0">, </span><span class="s1">missing_values</span><span class="s0">, </span><span class="s1">filling_values)</span>
                <span class="s1">converters = [StringConverter(dt</span><span class="s0">, </span><span class="s1">locked=</span><span class="s0">True,</span>
                                              <span class="s1">missing_values=miss</span><span class="s0">, </span><span class="s1">default=fill)</span>
                              <span class="s0">for </span><span class="s1">(dt</span><span class="s0">, </span><span class="s1">miss</span><span class="s0">, </span><span class="s1">fill) </span><span class="s0">in </span><span class="s1">zipit]</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s4"># Set to a default converter (but w/ different missing values)</span>
                <span class="s1">zipit = zip(missing_values</span><span class="s0">, </span><span class="s1">filling_values)</span>
                <span class="s1">converters = [StringConverter(dtype</span><span class="s0">, </span><span class="s1">locked=</span><span class="s0">True,</span>
                                              <span class="s1">missing_values=miss</span><span class="s0">, </span><span class="s1">default=fill)</span>
                              <span class="s0">for </span><span class="s1">(miss</span><span class="s0">, </span><span class="s1">fill) </span><span class="s0">in </span><span class="s1">zipit]</span>
        <span class="s4"># Update the converters to use the user-defined ones</span>
        <span class="s1">uc_update = []</span>
        <span class="s0">for </span><span class="s1">(j</span><span class="s0">, </span><span class="s1">conv) </span><span class="s0">in </span><span class="s1">user_converters.items():</span>
            <span class="s4"># If the converter is specified by column names, use the index instead</span>
            <span class="s0">if </span><span class="s1">_is_string_like(j):</span>
                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">j = names.index(j)</span>
                    <span class="s1">i = j</span>
                <span class="s0">except </span><span class="s1">ValueError:</span>
                    <span class="s0">continue</span>
            <span class="s0">elif </span><span class="s1">usecols:</span>
                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">i = usecols.index(j)</span>
                <span class="s0">except </span><span class="s1">ValueError:</span>
                    <span class="s4"># Unused converter specified</span>
                    <span class="s0">continue</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">i = j</span>
            <span class="s4"># Find the value to test - first_line is not filtered by usecols:</span>
            <span class="s0">if </span><span class="s1">len(first_line):</span>
                <span class="s1">testing_value = first_values[j]</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">testing_value = </span><span class="s0">None</span>
            <span class="s0">if </span><span class="s1">conv </span><span class="s0">is </span><span class="s1">bytes:</span>
                <span class="s1">user_conv = asbytes</span>
            <span class="s0">elif </span><span class="s1">byte_converters:</span>
                <span class="s4"># converters may use decode to workaround numpy's old behaviour,</span>
                <span class="s4"># so encode the string again before passing to the user converter</span>
                <span class="s0">def </span><span class="s1">tobytes_first(x</span><span class="s0">, </span><span class="s1">conv):</span>
                    <span class="s0">if </span><span class="s1">type(x) </span><span class="s0">is </span><span class="s1">bytes:</span>
                        <span class="s0">return </span><span class="s1">conv(x)</span>
                    <span class="s0">return </span><span class="s1">conv(x.encode(</span><span class="s2">&quot;latin1&quot;</span><span class="s1">))</span>
                <span class="s1">user_conv = functools.partial(tobytes_first</span><span class="s0">, </span><span class="s1">conv=conv)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">user_conv = conv</span>
            <span class="s1">converters[i].update(user_conv</span><span class="s0">, </span><span class="s1">locked=</span><span class="s0">True,</span>
                                 <span class="s1">testing_value=testing_value</span><span class="s0">,</span>
                                 <span class="s1">default=filling_values[i]</span><span class="s0">,</span>
                                 <span class="s1">missing_values=missing_values[i]</span><span class="s0">,</span><span class="s1">)</span>
            <span class="s1">uc_update.append((i</span><span class="s0">, </span><span class="s1">user_conv))</span>
        <span class="s4"># Make sure we have the corrected keys in user_converters...</span>
        <span class="s1">user_converters.update(uc_update)</span>

        <span class="s4"># Fixme: possible error as following variable never used.</span>
        <span class="s4"># miss_chars = [_.missing_values for _ in converters]</span>

        <span class="s4"># Initialize the output lists ...</span>
        <span class="s4"># ... rows</span>
        <span class="s1">rows = []</span>
        <span class="s1">append_to_rows = rows.append</span>
        <span class="s4"># ... masks</span>
        <span class="s0">if </span><span class="s1">usemask:</span>
            <span class="s1">masks = []</span>
            <span class="s1">append_to_masks = masks.append</span>
        <span class="s4"># ... invalid</span>
        <span class="s1">invalid = []</span>
        <span class="s1">append_to_invalid = invalid.append</span>

        <span class="s4"># Parse each line</span>
        <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">line) </span><span class="s0">in </span><span class="s1">enumerate(itertools.chain([first_line</span><span class="s0">, </span><span class="s1">]</span><span class="s0">, </span><span class="s1">fhd)):</span>
            <span class="s1">values = split_line(line)</span>
            <span class="s1">nbvalues = len(values)</span>
            <span class="s4"># Skip an empty line</span>
            <span class="s0">if </span><span class="s1">nbvalues == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s0">continue</span>
            <span class="s0">if </span><span class="s1">usecols:</span>
                <span class="s4"># Select only the columns we need</span>
                <span class="s0">try</span><span class="s1">:</span>
                    <span class="s1">values = [values[_] </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">usecols]</span>
                <span class="s0">except </span><span class="s1">IndexError:</span>
                    <span class="s1">append_to_invalid((i + skip_header + </span><span class="s5">1</span><span class="s0">, </span><span class="s1">nbvalues))</span>
                    <span class="s0">continue</span>
            <span class="s0">elif </span><span class="s1">nbvalues != nbcols:</span>
                <span class="s1">append_to_invalid((i + skip_header + </span><span class="s5">1</span><span class="s0">, </span><span class="s1">nbvalues))</span>
                <span class="s0">continue</span>
            <span class="s4"># Store the values</span>
            <span class="s1">append_to_rows(tuple(values))</span>
            <span class="s0">if </span><span class="s1">usemask:</span>
                <span class="s1">append_to_masks(tuple([v.strip() </span><span class="s0">in </span><span class="s1">m</span>
                                       <span class="s0">for </span><span class="s1">(v</span><span class="s0">, </span><span class="s1">m) </span><span class="s0">in </span><span class="s1">zip(values</span><span class="s0">,</span>
                                                         <span class="s1">missing_values)]))</span>
            <span class="s0">if </span><span class="s1">len(rows) == max_rows:</span>
                <span class="s0">break</span>

    <span class="s4"># Upgrade the converters (if needed)</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">converter) </span><span class="s0">in </span><span class="s1">enumerate(converters):</span>
            <span class="s1">current_column = [itemgetter(i)(_m) </span><span class="s0">for </span><span class="s1">_m </span><span class="s0">in </span><span class="s1">rows]</span>
            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">converter.iterupgrade(current_column)</span>
            <span class="s0">except </span><span class="s1">ConverterLockError:</span>
                <span class="s1">errmsg = </span><span class="s2">&quot;Converter #%i is locked and cannot be upgraded: &quot; </span><span class="s1">% i</span>
                <span class="s1">current_column = map(itemgetter(i)</span><span class="s0">, </span><span class="s1">rows)</span>
                <span class="s0">for </span><span class="s1">(j</span><span class="s0">, </span><span class="s1">value) </span><span class="s0">in </span><span class="s1">enumerate(current_column):</span>
                    <span class="s0">try</span><span class="s1">:</span>
                        <span class="s1">converter.upgrade(value)</span>
                    <span class="s0">except </span><span class="s1">(ConverterError</span><span class="s0">, </span><span class="s1">ValueError):</span>
                        <span class="s1">errmsg += </span><span class="s2">&quot;(occurred line #%i for value '%s')&quot;</span>
                        <span class="s1">errmsg %= (j + </span><span class="s5">1 </span><span class="s1">+ skip_header</span><span class="s0">, </span><span class="s1">value)</span>
                        <span class="s0">raise </span><span class="s1">ConverterError(errmsg)</span>

    <span class="s4"># Check that we don't have invalid values</span>
    <span class="s1">nbinvalid = len(invalid)</span>
    <span class="s0">if </span><span class="s1">nbinvalid &gt; </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s1">nbrows = len(rows) + nbinvalid - skip_footer</span>
        <span class="s4"># Construct the error message</span>
        <span class="s1">template = </span><span class="s2">&quot;    Line #%%i (got %%i columns instead of %i)&quot; </span><span class="s1">% nbcols</span>
        <span class="s0">if </span><span class="s1">skip_footer &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">nbinvalid_skipped = len([_ </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">invalid</span>
                                     <span class="s0">if </span><span class="s1">_[</span><span class="s5">0</span><span class="s1">] &gt; nbrows + skip_header])</span>
            <span class="s1">invalid = invalid[:nbinvalid - nbinvalid_skipped]</span>
            <span class="s1">skip_footer -= nbinvalid_skipped</span>
<span class="s4">#</span>
<span class="s4">#            nbrows -= skip_footer</span>
<span class="s4">#            errmsg = [template % (i, nb)</span>
<span class="s4">#                      for (i, nb) in invalid if i &lt; nbrows]</span>
<span class="s4">#        else:</span>
        <span class="s1">errmsg = [template % (i</span><span class="s0">, </span><span class="s1">nb)</span>
                  <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">nb) </span><span class="s0">in </span><span class="s1">invalid]</span>
        <span class="s0">if </span><span class="s1">len(errmsg):</span>
            <span class="s1">errmsg.insert(</span><span class="s5">0</span><span class="s0">, </span><span class="s2">&quot;Some errors were detected !&quot;</span><span class="s1">)</span>
            <span class="s1">errmsg = </span><span class="s2">&quot;</span><span class="s0">\n</span><span class="s2">&quot;</span><span class="s1">.join(errmsg)</span>
            <span class="s4"># Raise an exception ?</span>
            <span class="s0">if </span><span class="s1">invalid_raise:</span>
                <span class="s0">raise </span><span class="s1">ValueError(errmsg)</span>
            <span class="s4"># Issue a warning ?</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">warnings.warn(errmsg</span><span class="s0">, </span><span class="s1">ConversionWarning</span><span class="s0">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>

    <span class="s4"># Strip the last skip_footer data</span>
    <span class="s0">if </span><span class="s1">skip_footer &gt; </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s1">rows = rows[:-skip_footer]</span>
        <span class="s0">if </span><span class="s1">usemask:</span>
            <span class="s1">masks = masks[:-skip_footer]</span>

    <span class="s4"># Convert each value according to the converter:</span>
    <span class="s4"># We want to modify the list in place to avoid creating a new one...</span>
    <span class="s0">if </span><span class="s1">loose:</span>
        <span class="s1">rows = list(</span>
            <span class="s1">zip(*[[conv._loose_call(_r) </span><span class="s0">for </span><span class="s1">_r </span><span class="s0">in </span><span class="s1">map(itemgetter(i)</span><span class="s0">, </span><span class="s1">rows)]</span>
                  <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">conv) </span><span class="s0">in </span><span class="s1">enumerate(converters)]))</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">rows = list(</span>
            <span class="s1">zip(*[[conv._strict_call(_r) </span><span class="s0">for </span><span class="s1">_r </span><span class="s0">in </span><span class="s1">map(itemgetter(i)</span><span class="s0">, </span><span class="s1">rows)]</span>
                  <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">conv) </span><span class="s0">in </span><span class="s1">enumerate(converters)]))</span>

    <span class="s4"># Reset the dtype</span>
    <span class="s1">data = rows</span>
    <span class="s0">if </span><span class="s1">dtype </span><span class="s0">is None</span><span class="s1">:</span>
        <span class="s4"># Get the dtypes from the types of the converters</span>
        <span class="s1">column_types = [conv.type </span><span class="s0">for </span><span class="s1">conv </span><span class="s0">in </span><span class="s1">converters]</span>
        <span class="s4"># Find the columns with strings...</span>
        <span class="s1">strcolidx = [i </span><span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">v) </span><span class="s0">in </span><span class="s1">enumerate(column_types)</span>
                     <span class="s0">if </span><span class="s1">v == np.unicode_]</span>

        <span class="s0">if </span><span class="s1">byte_converters </span><span class="s0">and </span><span class="s1">strcolidx:</span>
            <span class="s4"># convert strings back to bytes for backward compatibility</span>
            <span class="s1">warnings.warn(</span>
                <span class="s2">&quot;Reading unicode strings without specifying the encoding &quot;</span>
                <span class="s2">&quot;argument is deprecated. Set the encoding, use None for the &quot;</span>
                <span class="s2">&quot;system default.&quot;</span><span class="s0">,</span>
                <span class="s1">np.VisibleDeprecationWarning</span><span class="s0">, </span><span class="s1">stacklevel=</span><span class="s5">2</span><span class="s1">)</span>
            <span class="s0">def </span><span class="s1">encode_unicode_cols(row_tup):</span>
                <span class="s1">row = list(row_tup)</span>
                <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">strcolidx:</span>
                    <span class="s1">row[i] = row[i].encode(</span><span class="s2">'latin1'</span><span class="s1">)</span>
                <span class="s0">return </span><span class="s1">tuple(row)</span>

            <span class="s0">try</span><span class="s1">:</span>
                <span class="s1">data = [encode_unicode_cols(r) </span><span class="s0">for </span><span class="s1">r </span><span class="s0">in </span><span class="s1">data]</span>
            <span class="s0">except </span><span class="s1">UnicodeEncodeError:</span>
                <span class="s0">pass</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s0">for </span><span class="s1">i </span><span class="s0">in </span><span class="s1">strcolidx:</span>
                    <span class="s1">column_types[i] = np.bytes_</span>

        <span class="s4"># Update string types to be the right length</span>
        <span class="s1">sized_column_types = column_types[:]</span>
        <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">col_type </span><span class="s0">in </span><span class="s1">enumerate(column_types):</span>
            <span class="s0">if </span><span class="s1">np.issubdtype(col_type</span><span class="s0">, </span><span class="s1">np.character):</span>
                <span class="s1">n_chars = max(len(row[i]) </span><span class="s0">for </span><span class="s1">row </span><span class="s0">in </span><span class="s1">data)</span>
                <span class="s1">sized_column_types[i] = (col_type</span><span class="s0">, </span><span class="s1">n_chars)</span>

        <span class="s0">if </span><span class="s1">names </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s4"># If the dtype is uniform (before sizing strings)</span>
            <span class="s1">base = {</span>
                <span class="s1">c_type</span>
                <span class="s0">for </span><span class="s1">c</span><span class="s0">, </span><span class="s1">c_type </span><span class="s0">in </span><span class="s1">zip(converters</span><span class="s0">, </span><span class="s1">column_types)</span>
                <span class="s0">if </span><span class="s1">c._checked}</span>
            <span class="s0">if </span><span class="s1">len(base) == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">uniform_type</span><span class="s0">, </span><span class="s1">= base</span>
                <span class="s1">(ddtype</span><span class="s0">, </span><span class="s1">mdtype) = (uniform_type</span><span class="s0">, </span><span class="s1">bool)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">ddtype = [(defaultfmt % i</span><span class="s0">, </span><span class="s1">dt)</span>
                          <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">dt) </span><span class="s0">in </span><span class="s1">enumerate(sized_column_types)]</span>
                <span class="s0">if </span><span class="s1">usemask:</span>
                    <span class="s1">mdtype = [(defaultfmt % i</span><span class="s0">, </span><span class="s1">bool)</span>
                              <span class="s0">for </span><span class="s1">(i</span><span class="s0">, </span><span class="s1">dt) </span><span class="s0">in </span><span class="s1">enumerate(sized_column_types)]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s1">ddtype = list(zip(names</span><span class="s0">, </span><span class="s1">sized_column_types))</span>
            <span class="s1">mdtype = list(zip(names</span><span class="s0">, </span><span class="s1">[bool] * len(sized_column_types)))</span>
        <span class="s1">output = np.array(data</span><span class="s0">, </span><span class="s1">dtype=ddtype)</span>
        <span class="s0">if </span><span class="s1">usemask:</span>
            <span class="s1">outputmask = np.array(masks</span><span class="s0">, </span><span class="s1">dtype=mdtype)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s4"># Overwrite the initial dtype names if needed</span>
        <span class="s0">if </span><span class="s1">names </span><span class="s0">and </span><span class="s1">dtype.names </span><span class="s0">is not None</span><span class="s1">:</span>
            <span class="s1">dtype.names = names</span>
        <span class="s4"># Case 1. We have a structured type</span>
        <span class="s0">if </span><span class="s1">len(dtype_flat) &gt; </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s4"># Nested dtype, eg [('a', int), ('b', [('b0', int), ('b1', 'f4')])]</span>
            <span class="s4"># First, create the array using a flattened dtype:</span>
            <span class="s4"># [('a', int), ('b1', int), ('b2', float)]</span>
            <span class="s4"># Then, view the array using the specified dtype.</span>
            <span class="s0">if </span><span class="s2">'O' </span><span class="s0">in </span><span class="s1">(_.char </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">dtype_flat):</span>
                <span class="s0">if </span><span class="s1">has_nested_fields(dtype):</span>
                    <span class="s0">raise </span><span class="s1">NotImplementedError(</span>
                        <span class="s2">&quot;Nested fields involving objects are not supported...&quot;</span><span class="s1">)</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">output = np.array(data</span><span class="s0">, </span><span class="s1">dtype=dtype)</span>
            <span class="s0">else</span><span class="s1">:</span>
                <span class="s1">rows = np.array(data</span><span class="s0">, </span><span class="s1">dtype=[(</span><span class="s2">''</span><span class="s0">, </span><span class="s1">_) </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">dtype_flat])</span>
                <span class="s1">output = rows.view(dtype)</span>
            <span class="s4"># Now, process the rowmasks the same way</span>
            <span class="s0">if </span><span class="s1">usemask:</span>
                <span class="s1">rowmasks = np.array(</span>
                    <span class="s1">masks</span><span class="s0">, </span><span class="s1">dtype=np.dtype([(</span><span class="s2">''</span><span class="s0">, </span><span class="s1">bool) </span><span class="s0">for </span><span class="s1">t </span><span class="s0">in </span><span class="s1">dtype_flat]))</span>
                <span class="s4"># Construct the new dtype</span>
                <span class="s1">mdtype = make_mask_descr(dtype)</span>
                <span class="s1">outputmask = rowmasks.view(mdtype)</span>
        <span class="s4"># Case #2. We have a basic dtype</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># We used some user-defined converters</span>
            <span class="s0">if </span><span class="s1">user_converters:</span>
                <span class="s1">ishomogeneous = </span><span class="s0">True</span>
                <span class="s1">descr = []</span>
                <span class="s0">for </span><span class="s1">i</span><span class="s0">, </span><span class="s1">ttype </span><span class="s0">in </span><span class="s1">enumerate([conv.type </span><span class="s0">for </span><span class="s1">conv </span><span class="s0">in </span><span class="s1">converters]):</span>
                    <span class="s4"># Keep the dtype of the current converter</span>
                    <span class="s0">if </span><span class="s1">i </span><span class="s0">in </span><span class="s1">user_converters:</span>
                        <span class="s1">ishomogeneous &amp;= (ttype == dtype.type)</span>
                        <span class="s0">if </span><span class="s1">np.issubdtype(ttype</span><span class="s0">, </span><span class="s1">np.character):</span>
                            <span class="s1">ttype = (ttype</span><span class="s0">, </span><span class="s1">max(len(row[i]) </span><span class="s0">for </span><span class="s1">row </span><span class="s0">in </span><span class="s1">data))</span>
                        <span class="s1">descr.append((</span><span class="s2">''</span><span class="s0">, </span><span class="s1">ttype))</span>
                    <span class="s0">else</span><span class="s1">:</span>
                        <span class="s1">descr.append((</span><span class="s2">''</span><span class="s0">, </span><span class="s1">dtype))</span>
                <span class="s4"># So we changed the dtype ?</span>
                <span class="s0">if not </span><span class="s1">ishomogeneous:</span>
                    <span class="s4"># We have more than one field</span>
                    <span class="s0">if </span><span class="s1">len(descr) &gt; </span><span class="s5">1</span><span class="s1">:</span>
                        <span class="s1">dtype = np.dtype(descr)</span>
                    <span class="s4"># We have only one field: drop the name if not needed.</span>
                    <span class="s0">else</span><span class="s1">:</span>
                        <span class="s1">dtype = np.dtype(ttype)</span>
            <span class="s4">#</span>
            <span class="s1">output = np.array(data</span><span class="s0">, </span><span class="s1">dtype)</span>
            <span class="s0">if </span><span class="s1">usemask:</span>
                <span class="s0">if </span><span class="s1">dtype.names </span><span class="s0">is not None</span><span class="s1">:</span>
                    <span class="s1">mdtype = [(_</span><span class="s0">, </span><span class="s1">bool) </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">dtype.names]</span>
                <span class="s0">else</span><span class="s1">:</span>
                    <span class="s1">mdtype = bool</span>
                <span class="s1">outputmask = np.array(masks</span><span class="s0">, </span><span class="s1">dtype=mdtype)</span>
    <span class="s4"># Try to take care of the missing data we missed</span>
    <span class="s1">names = output.dtype.names</span>
    <span class="s0">if </span><span class="s1">usemask </span><span class="s0">and </span><span class="s1">names:</span>
        <span class="s0">for </span><span class="s1">(name</span><span class="s0">, </span><span class="s1">conv) </span><span class="s0">in </span><span class="s1">zip(names</span><span class="s0">, </span><span class="s1">converters):</span>
            <span class="s1">missing_values = [conv(_) </span><span class="s0">for </span><span class="s1">_ </span><span class="s0">in </span><span class="s1">conv.missing_values</span>
                              <span class="s0">if </span><span class="s1">_ != </span><span class="s2">''</span><span class="s1">]</span>
            <span class="s0">for </span><span class="s1">mval </span><span class="s0">in </span><span class="s1">missing_values:</span>
                <span class="s1">outputmask[name] |= (output[name] == mval)</span>
    <span class="s4"># Construct the final array</span>
    <span class="s0">if </span><span class="s1">usemask:</span>
        <span class="s1">output = output.view(MaskedArray)</span>
        <span class="s1">output._mask = outputmask</span>
    <span class="s1">output = np.squeeze(output)</span>
    <span class="s0">if </span><span class="s1">unpack:</span>
        <span class="s0">if </span><span class="s1">names </span><span class="s0">is None</span><span class="s1">:</span>
            <span class="s0">return </span><span class="s1">output.T</span>
        <span class="s0">elif </span><span class="s1">len(names) == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s4"># squeeze single-name dtypes too</span>
            <span class="s0">return </span><span class="s1">output[names[</span><span class="s5">0</span><span class="s1">]]</span>
        <span class="s0">else</span><span class="s1">:</span>
            <span class="s4"># For structured arrays with multiple fields,</span>
            <span class="s4"># return an array for each field.</span>
            <span class="s0">return </span><span class="s1">[output[field] </span><span class="s0">for </span><span class="s1">field </span><span class="s0">in </span><span class="s1">names]</span>
    <span class="s0">return </span><span class="s1">output</span>


<span class="s1">_genfromtxt_with_like = array_function_dispatch(</span>
    <span class="s1">_genfromtxt_dispatcher</span>
<span class="s1">)(genfromtxt)</span>


<span class="s0">def </span><span class="s1">recfromtxt(fname</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s3">&quot;&quot;&quot; 
    Load ASCII data from a file and return it in a record array. 
 
    If ``usemask=False`` a standard `recarray` is returned, 
    if ``usemask=True`` a MaskedRecords array is returned. 
 
    Parameters 
    ---------- 
    fname, kwargs : For a description of input parameters, see `genfromtxt`. 
 
    See Also 
    -------- 
    numpy.genfromtxt : generic function 
 
    Notes 
    ----- 
    By default, `dtype` is None, which means that the data-type of the output 
    array will be determined from the data. 
 
    &quot;&quot;&quot;</span>
    <span class="s1">kwargs.setdefault(</span><span class="s2">&quot;dtype&quot;</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s1">usemask = kwargs.get(</span><span class="s2">'usemask'</span><span class="s0">, False</span><span class="s1">)</span>
    <span class="s1">output = genfromtxt(fname</span><span class="s0">, </span><span class="s1">**kwargs)</span>
    <span class="s0">if </span><span class="s1">usemask:</span>
        <span class="s0">from </span><span class="s1">numpy.ma.mrecords </span><span class="s0">import </span><span class="s1">MaskedRecords</span>
        <span class="s1">output = output.view(MaskedRecords)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">output = output.view(np.recarray)</span>
    <span class="s0">return </span><span class="s1">output</span>


<span class="s0">def </span><span class="s1">recfromcsv(fname</span><span class="s0">, </span><span class="s1">**kwargs):</span>
    <span class="s3">&quot;&quot;&quot; 
    Load ASCII data stored in a comma-separated file. 
 
    The returned array is a record array (if ``usemask=False``, see 
    `recarray`) or a masked record array (if ``usemask=True``, 
    see `ma.mrecords.MaskedRecords`). 
 
    Parameters 
    ---------- 
    fname, kwargs : For a description of input parameters, see `genfromtxt`. 
 
    See Also 
    -------- 
    numpy.genfromtxt : generic function to load ASCII data. 
 
    Notes 
    ----- 
    By default, `dtype` is None, which means that the data-type of the output 
    array will be determined from the data. 
 
    &quot;&quot;&quot;</span>
    <span class="s4"># Set default kwargs for genfromtxt as relevant to csv import.</span>
    <span class="s1">kwargs.setdefault(</span><span class="s2">&quot;case_sensitive&quot;</span><span class="s0">, </span><span class="s2">&quot;lower&quot;</span><span class="s1">)</span>
    <span class="s1">kwargs.setdefault(</span><span class="s2">&quot;names&quot;</span><span class="s0">, True</span><span class="s1">)</span>
    <span class="s1">kwargs.setdefault(</span><span class="s2">&quot;delimiter&quot;</span><span class="s0">, </span><span class="s2">&quot;,&quot;</span><span class="s1">)</span>
    <span class="s1">kwargs.setdefault(</span><span class="s2">&quot;dtype&quot;</span><span class="s0">, None</span><span class="s1">)</span>
    <span class="s1">output = genfromtxt(fname</span><span class="s0">, </span><span class="s1">**kwargs)</span>

    <span class="s1">usemask = kwargs.get(</span><span class="s2">&quot;usemask&quot;</span><span class="s0">, False</span><span class="s1">)</span>
    <span class="s0">if </span><span class="s1">usemask:</span>
        <span class="s0">from </span><span class="s1">numpy.ma.mrecords </span><span class="s0">import </span><span class="s1">MaskedRecords</span>
        <span class="s1">output = output.view(MaskedRecords)</span>
    <span class="s0">else</span><span class="s1">:</span>
        <span class="s1">output = output.view(np.recarray)</span>
    <span class="s0">return </span><span class="s1">output</span>
</pre>
</body>
</html>