<html>
<head>
<title>test_parquet.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
.s6 { color: #a5c261;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_parquet.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; test parquet compat &quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">datetime</span>
<span class="s2">from </span><span class="s1">io </span><span class="s2">import </span><span class="s1">BytesIO</span>
<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">pathlib</span>
<span class="s2">from </span><span class="s1">warnings </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">catch_warnings</span><span class="s2">,</span>
    <span class="s1">filterwarnings</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">from </span><span class="s1">pandas._config </span><span class="s2">import </span><span class="s1">get_option</span>

<span class="s2">from </span><span class="s1">pandas.compat.pyarrow </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">pa_version_under2p0</span><span class="s2">,</span>
    <span class="s1">pa_version_under5p0</span><span class="s2">,</span>
    <span class="s1">pa_version_under6p0</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">import </span><span class="s1">pandas.util._test_decorators </span><span class="s2">as </span><span class="s1">td</span>

<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">pandas._testing </span><span class="s2">as </span><span class="s1">tm</span>
<span class="s2">from </span><span class="s1">pandas.util.version </span><span class="s2">import </span><span class="s1">Version</span>

<span class="s2">from </span><span class="s1">pandas.io.parquet </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">FastParquetImpl</span><span class="s2">,</span>
    <span class="s1">PyArrowImpl</span><span class="s2">,</span>
    <span class="s1">get_engine</span><span class="s2">,</span>
    <span class="s1">read_parquet</span><span class="s2">,</span>
    <span class="s1">to_parquet</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">try</span><span class="s1">:</span>
    <span class="s2">import </span><span class="s1">pyarrow</span>

    <span class="s1">_HAVE_PYARROW = </span><span class="s2">True</span>
<span class="s2">except </span><span class="s1">ImportError:</span>
    <span class="s1">_HAVE_PYARROW = </span><span class="s2">False</span>

<span class="s2">try</span><span class="s1">:</span>
    <span class="s2">with </span><span class="s1">catch_warnings():</span>
        <span class="s3"># `np.bool` is a deprecated alias...</span>
        <span class="s1">filterwarnings(</span><span class="s4">&quot;ignore&quot;</span><span class="s2">, </span><span class="s4">&quot;`np.bool`&quot;</span><span class="s2">, </span><span class="s1">category=DeprecationWarning)</span>
        <span class="s3"># accessing pd.Int64Index in pd namespace</span>
        <span class="s1">filterwarnings(</span><span class="s4">&quot;ignore&quot;</span><span class="s2">, </span><span class="s4">&quot;.*Int64Index.*&quot;</span><span class="s2">, </span><span class="s1">category=FutureWarning)</span>

        <span class="s2">import </span><span class="s1">fastparquet</span>

    <span class="s1">_HAVE_FASTPARQUET = </span><span class="s2">True</span>
<span class="s2">except </span><span class="s1">ImportError:</span>
    <span class="s1">_HAVE_FASTPARQUET = </span><span class="s2">False</span>


<span class="s1">pytestmark = pytest.mark.filterwarnings(</span>
    <span class="s4">&quot;ignore:RangeIndex.* is deprecated:DeprecationWarning&quot;</span>
<span class="s1">)</span>


<span class="s3"># TODO(ArrayManager) fastparquet relies on BlockManager internals</span>

<span class="s3"># setup engines &amp; skips</span>
<span class="s1">@pytest.fixture(</span>
    <span class="s1">params=[</span>
        <span class="s1">pytest.param(</span>
            <span class="s4">&quot;fastparquet&quot;</span><span class="s2">,</span>
            <span class="s1">marks=pytest.mark.skipif(</span>
                <span class="s2">not </span><span class="s1">_HAVE_FASTPARQUET </span><span class="s2">or </span><span class="s1">get_option(</span><span class="s4">&quot;mode.data_manager&quot;</span><span class="s1">) == </span><span class="s4">&quot;array&quot;</span><span class="s2">,</span>
                <span class="s1">reason=</span><span class="s4">&quot;fastparquet is not installed or ArrayManager is used&quot;</span><span class="s2">,</span>
            <span class="s1">)</span><span class="s2">,</span>
        <span class="s1">)</span><span class="s2">,</span>
        <span class="s1">pytest.param(</span>
            <span class="s4">&quot;pyarrow&quot;</span><span class="s2">,</span>
            <span class="s1">marks=pytest.mark.skipif(</span>
                <span class="s2">not </span><span class="s1">_HAVE_PYARROW</span><span class="s2">, </span><span class="s1">reason=</span><span class="s4">&quot;pyarrow is not installed&quot;</span>
            <span class="s1">)</span><span class="s2">,</span>
        <span class="s1">)</span><span class="s2">,</span>
    <span class="s1">]</span>
<span class="s1">)</span>
<span class="s2">def </span><span class="s1">engine(request):</span>
    <span class="s2">return </span><span class="s1">request.param</span>


<span class="s1">@pytest.fixture</span>
<span class="s2">def </span><span class="s1">pa():</span>
    <span class="s2">if not </span><span class="s1">_HAVE_PYARROW:</span>
        <span class="s1">pytest.skip(</span><span class="s4">&quot;pyarrow is not installed&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s4">&quot;pyarrow&quot;</span>


<span class="s1">@pytest.fixture</span>
<span class="s2">def </span><span class="s1">fp():</span>
    <span class="s2">if not </span><span class="s1">_HAVE_FASTPARQUET:</span>
        <span class="s1">pytest.skip(</span><span class="s4">&quot;fastparquet is not installed&quot;</span><span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">get_option(</span><span class="s4">&quot;mode.data_manager&quot;</span><span class="s1">) == </span><span class="s4">&quot;array&quot;</span><span class="s1">:</span>
        <span class="s1">pytest.skip(</span><span class="s4">&quot;ArrayManager is not supported with fastparquet&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s4">&quot;fastparquet&quot;</span>


<span class="s1">@pytest.fixture</span>
<span class="s2">def </span><span class="s1">df_compat():</span>
    <span class="s2">return </span><span class="s1">pd.DataFrame({</span><span class="s4">&quot;A&quot;</span><span class="s1">: [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s4">&quot;B&quot;</span><span class="s1">: </span><span class="s4">&quot;foo&quot;</span><span class="s1">})</span>


<span class="s1">@pytest.fixture</span>
<span class="s2">def </span><span class="s1">df_cross_compat():</span>
    <span class="s1">df = pd.DataFrame(</span>
        <span class="s1">{</span>
            <span class="s4">&quot;a&quot;</span><span class="s1">: list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s4">&quot;b&quot;</span><span class="s1">: list(range(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">4</span><span class="s1">))</span><span class="s2">,</span>
            <span class="s3"># 'c': np.arange(3, 6).astype('u1'),</span>
            <span class="s4">&quot;d&quot;</span><span class="s1">: np.arange(</span><span class="s5">4.0</span><span class="s2">, </span><span class="s5">7.0</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;float64&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s4">&quot;e&quot;</span><span class="s1">: [</span><span class="s2">True, False, True</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">&quot;f&quot;</span><span class="s1">: pd.date_range(</span><span class="s4">&quot;20130101&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s3"># 'g': pd.date_range('20130101', periods=3,</span>
            <span class="s3">#                    tz='US/Eastern'),</span>
            <span class="s3"># 'h': pd.date_range('20130101', periods=3, freq='ns')</span>
        <span class="s1">}</span>
    <span class="s1">)</span>
    <span class="s2">return </span><span class="s1">df</span>


<span class="s1">@pytest.fixture</span>
<span class="s2">def </span><span class="s1">df_full():</span>
    <span class="s2">return </span><span class="s1">pd.DataFrame(</span>
        <span class="s1">{</span>
            <span class="s4">&quot;string&quot;</span><span class="s1">: list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s4">&quot;string_with_nan&quot;</span><span class="s1">: [</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s4">&quot;c&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">&quot;string_with_none&quot;</span><span class="s1">: [</span><span class="s4">&quot;a&quot;</span><span class="s2">, None, </span><span class="s4">&quot;c&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">&quot;bytes&quot;</span><span class="s1">: [</span><span class="s6">b&quot;foo&quot;</span><span class="s2">, </span><span class="s6">b&quot;bar&quot;</span><span class="s2">, </span><span class="s6">b&quot;baz&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">&quot;unicode&quot;</span><span class="s1">: [</span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">&quot;int&quot;</span><span class="s1">: list(range(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">4</span><span class="s1">))</span><span class="s2">,</span>
            <span class="s4">&quot;uint&quot;</span><span class="s1">: np.arange(</span><span class="s5">3</span><span class="s2">, </span><span class="s5">6</span><span class="s1">).astype(</span><span class="s4">&quot;u1&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s4">&quot;float&quot;</span><span class="s1">: np.arange(</span><span class="s5">4.0</span><span class="s2">, </span><span class="s5">7.0</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;float64&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s4">&quot;float_with_nan&quot;</span><span class="s1">: [</span><span class="s5">2.0</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s5">3.0</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">&quot;bool&quot;</span><span class="s1">: [</span><span class="s2">True, False, True</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s4">&quot;datetime&quot;</span><span class="s1">: pd.date_range(</span><span class="s4">&quot;20130101&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s4">&quot;datetime_with_nat&quot;</span><span class="s1">: [</span>
                <span class="s1">pd.Timestamp(</span><span class="s4">&quot;20130101&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s1">pd.NaT</span><span class="s2">,</span>
                <span class="s1">pd.Timestamp(</span><span class="s4">&quot;20130103&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">]</span><span class="s2">,</span>
        <span class="s1">}</span>
    <span class="s1">)</span>


<span class="s1">@pytest.fixture(</span>
    <span class="s1">params=[</span>
        <span class="s1">datetime.datetime.now(datetime.timezone.utc)</span><span class="s2">,</span>
        <span class="s1">datetime.datetime.now(datetime.timezone.min)</span><span class="s2">,</span>
        <span class="s1">datetime.datetime.now(datetime.timezone.max)</span><span class="s2">,</span>
        <span class="s1">datetime.datetime.strptime(</span><span class="s4">&quot;2019-01-04T16:41:24+0200&quot;</span><span class="s2">, </span><span class="s4">&quot;%Y-%m-%dT%H:%M:%S%z&quot;</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">datetime.datetime.strptime(</span><span class="s4">&quot;2019-01-04T16:41:24+0215&quot;</span><span class="s2">, </span><span class="s4">&quot;%Y-%m-%dT%H:%M:%S%z&quot;</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">datetime.datetime.strptime(</span><span class="s4">&quot;2019-01-04T16:41:24-0200&quot;</span><span class="s2">, </span><span class="s4">&quot;%Y-%m-%dT%H:%M:%S%z&quot;</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">datetime.datetime.strptime(</span><span class="s4">&quot;2019-01-04T16:41:24-0215&quot;</span><span class="s2">, </span><span class="s4">&quot;%Y-%m-%dT%H:%M:%S%z&quot;</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">]</span>
<span class="s1">)</span>
<span class="s2">def </span><span class="s1">timezone_aware_date_list(request):</span>
    <span class="s2">return </span><span class="s1">request.param</span>


<span class="s2">def </span><span class="s1">check_round_trip(</span>
    <span class="s1">df</span><span class="s2">,</span>
    <span class="s1">engine=</span><span class="s2">None,</span>
    <span class="s1">path=</span><span class="s2">None,</span>
    <span class="s1">write_kwargs=</span><span class="s2">None,</span>
    <span class="s1">read_kwargs=</span><span class="s2">None,</span>
    <span class="s1">expected=</span><span class="s2">None,</span>
    <span class="s1">check_names=</span><span class="s2">True,</span>
    <span class="s1">check_like=</span><span class="s2">False,</span>
    <span class="s1">check_dtype=</span><span class="s2">True,</span>
    <span class="s1">repeat=</span><span class="s5">2</span><span class="s2">,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot;Verify parquet serializer and deserializer produce the same results. 
 
    Performs a pandas to disk and disk to pandas round trip, 
    then compares the 2 resulting DataFrames to verify equality. 
 
    Parameters 
    ---------- 
    df: Dataframe 
    engine: str, optional 
        'pyarrow' or 'fastparquet' 
    path: str, optional 
    write_kwargs: dict of str:str, optional 
    read_kwargs: dict of str:str, optional 
    expected: DataFrame, optional 
        Expected deserialization result, otherwise will be equal to `df` 
    check_names: list of str, optional 
        Closed set of column names to be compared 
    check_like: bool, optional 
        If True, ignore the order of index &amp; columns. 
    repeat: int, optional 
        How many times to repeat the test 
    &quot;&quot;&quot;</span>
    <span class="s1">write_kwargs = write_kwargs </span><span class="s2">or </span><span class="s1">{</span><span class="s4">&quot;compression&quot;</span><span class="s1">: </span><span class="s2">None</span><span class="s1">}</span>
    <span class="s1">read_kwargs = read_kwargs </span><span class="s2">or </span><span class="s1">{}</span>

    <span class="s2">if </span><span class="s1">expected </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">expected = df</span>

    <span class="s2">if </span><span class="s1">engine:</span>
        <span class="s1">write_kwargs[</span><span class="s4">&quot;engine&quot;</span><span class="s1">] = engine</span>
        <span class="s1">read_kwargs[</span><span class="s4">&quot;engine&quot;</span><span class="s1">] = engine</span>

    <span class="s2">def </span><span class="s1">compare(repeat):</span>
        <span class="s2">for </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">range(repeat):</span>
            <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">**write_kwargs)</span>
            <span class="s2">with </span><span class="s1">catch_warnings(record=</span><span class="s2">True</span><span class="s1">):</span>
                <span class="s1">actual = read_parquet(path</span><span class="s2">, </span><span class="s1">**read_kwargs)</span>

            <span class="s1">tm.assert_frame_equal(</span>
                <span class="s1">expected</span><span class="s2">,</span>
                <span class="s1">actual</span><span class="s2">,</span>
                <span class="s1">check_names=check_names</span><span class="s2">,</span>
                <span class="s1">check_like=check_like</span><span class="s2">,</span>
                <span class="s1">check_dtype=check_dtype</span><span class="s2">,</span>
            <span class="s1">)</span>

    <span class="s2">if </span><span class="s1">path </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">compare(repeat)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">compare(repeat)</span>


<span class="s2">def </span><span class="s1">check_partition_names(path</span><span class="s2">, </span><span class="s1">expected):</span>
    <span class="s0">&quot;&quot;&quot;Check partitions of a parquet file are as expected. 
 
    Parameters 
    ---------- 
    path: str 
        Path of the dataset. 
    expected: iterable of str 
        Expected partition names. 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">pa_version_under5p0:</span>
        <span class="s2">import </span><span class="s1">pyarrow.parquet </span><span class="s2">as </span><span class="s1">pq</span>

        <span class="s1">dataset = pq.ParquetDataset(path</span><span class="s2">, </span><span class="s1">validate_schema=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">len(dataset.partitions.partition_names) == len(expected)</span>
        <span class="s2">assert </span><span class="s1">dataset.partitions.partition_names == set(expected)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">import </span><span class="s1">pyarrow.dataset </span><span class="s2">as </span><span class="s1">ds</span>

        <span class="s1">dataset = ds.dataset(path</span><span class="s2">, </span><span class="s1">partitioning=</span><span class="s4">&quot;hive&quot;</span><span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">dataset.partitioning.schema.names == expected</span>


<span class="s2">def </span><span class="s1">test_invalid_engine(df_compat):</span>
    <span class="s1">msg = </span><span class="s4">&quot;engine must be one of 'pyarrow', 'fastparquet'&quot;</span>
    <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
        <span class="s1">check_round_trip(df_compat</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_options_py(df_compat</span><span class="s2">, </span><span class="s1">pa):</span>
    <span class="s3"># use the set option</span>

    <span class="s2">with </span><span class="s1">pd.option_context(</span><span class="s4">&quot;io.parquet.engine&quot;</span><span class="s2">, </span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">):</span>
        <span class="s1">check_round_trip(df_compat)</span>


<span class="s2">def </span><span class="s1">test_options_fp(df_compat</span><span class="s2">, </span><span class="s1">fp):</span>
    <span class="s3"># use the set option</span>

    <span class="s2">with </span><span class="s1">pd.option_context(</span><span class="s4">&quot;io.parquet.engine&quot;</span><span class="s2">, </span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">):</span>
        <span class="s1">check_round_trip(df_compat)</span>


<span class="s2">def </span><span class="s1">test_options_auto(df_compat</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">pa):</span>
    <span class="s3"># use the set option</span>

    <span class="s2">with </span><span class="s1">pd.option_context(</span><span class="s4">&quot;io.parquet.engine&quot;</span><span class="s2">, </span><span class="s4">&quot;auto&quot;</span><span class="s1">):</span>
        <span class="s1">check_round_trip(df_compat)</span>


<span class="s2">def </span><span class="s1">test_options_get_engine(fp</span><span class="s2">, </span><span class="s1">pa):</span>
    <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">PyArrowImpl)</span>
    <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">FastParquetImpl)</span>

    <span class="s2">with </span><span class="s1">pd.option_context(</span><span class="s4">&quot;io.parquet.engine&quot;</span><span class="s2">, </span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">):</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">PyArrowImpl)</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">PyArrowImpl)</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">FastParquetImpl)</span>

    <span class="s2">with </span><span class="s1">pd.option_context(</span><span class="s4">&quot;io.parquet.engine&quot;</span><span class="s2">, </span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">):</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">FastParquetImpl)</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">PyArrowImpl)</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">FastParquetImpl)</span>

    <span class="s2">with </span><span class="s1">pd.option_context(</span><span class="s4">&quot;io.parquet.engine&quot;</span><span class="s2">, </span><span class="s4">&quot;auto&quot;</span><span class="s1">):</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">PyArrowImpl)</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">PyArrowImpl)</span>
        <span class="s2">assert </span><span class="s1">isinstance(get_engine(</span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">FastParquetImpl)</span>


<span class="s2">def </span><span class="s1">test_get_engine_auto_error_message():</span>
    <span class="s3"># Expect different error messages from get_engine(engine=&quot;auto&quot;)</span>
    <span class="s3"># if engines aren't installed vs. are installed but bad version</span>
    <span class="s2">from </span><span class="s1">pandas.compat._optional </span><span class="s2">import </span><span class="s1">VERSIONS</span>

    <span class="s3"># Do we have engines installed, but a bad version of them?</span>
    <span class="s1">pa_min_ver = VERSIONS.get(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span>
    <span class="s1">fp_min_ver = VERSIONS.get(</span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">)</span>
    <span class="s1">have_pa_bad_version = (</span>
        <span class="s2">False</span>
        <span class="s2">if not </span><span class="s1">_HAVE_PYARROW</span>
        <span class="s2">else </span><span class="s1">Version(pyarrow.__version__) &lt; Version(pa_min_ver)</span>
    <span class="s1">)</span>
    <span class="s1">have_fp_bad_version = (</span>
        <span class="s2">False</span>
        <span class="s2">if not </span><span class="s1">_HAVE_FASTPARQUET</span>
        <span class="s2">else </span><span class="s1">Version(fastparquet.__version__) &lt; Version(fp_min_ver)</span>
    <span class="s1">)</span>
    <span class="s3"># Do we have usable engines installed?</span>
    <span class="s1">have_usable_pa = _HAVE_PYARROW </span><span class="s2">and not </span><span class="s1">have_pa_bad_version</span>
    <span class="s1">have_usable_fp = _HAVE_FASTPARQUET </span><span class="s2">and not </span><span class="s1">have_fp_bad_version</span>

    <span class="s2">if not </span><span class="s1">have_usable_pa </span><span class="s2">and not </span><span class="s1">have_usable_fp:</span>
        <span class="s3"># No usable engines found.</span>
        <span class="s2">if </span><span class="s1">have_pa_bad_version:</span>
            <span class="s1">match = </span><span class="s4">f&quot;Pandas requires version .</span><span class="s2">{</span><span class="s1">pa_min_ver</span><span class="s2">}</span><span class="s4">. or newer of .pyarrow.&quot;</span>
            <span class="s2">with </span><span class="s1">pytest.raises(ImportError</span><span class="s2">, </span><span class="s1">match=match):</span>
                <span class="s1">get_engine(</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">match = </span><span class="s4">&quot;Missing optional dependency .pyarrow.&quot;</span>
            <span class="s2">with </span><span class="s1">pytest.raises(ImportError</span><span class="s2">, </span><span class="s1">match=match):</span>
                <span class="s1">get_engine(</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">have_fp_bad_version:</span>
            <span class="s1">match = </span><span class="s4">f&quot;Pandas requires version .</span><span class="s2">{</span><span class="s1">fp_min_ver</span><span class="s2">}</span><span class="s4">. or newer of .fastparquet.&quot;</span>
            <span class="s2">with </span><span class="s1">pytest.raises(ImportError</span><span class="s2">, </span><span class="s1">match=match):</span>
                <span class="s1">get_engine(</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">match = </span><span class="s4">&quot;Missing optional dependency .fastparquet.&quot;</span>
            <span class="s2">with </span><span class="s1">pytest.raises(ImportError</span><span class="s2">, </span><span class="s1">match=match):</span>
                <span class="s1">get_engine(</span><span class="s4">&quot;auto&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">test_cross_engine_pa_fp(df_cross_compat</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">fp):</span>
    <span class="s3"># cross-compat with differing reading/writing engines</span>

    <span class="s1">df = df_cross_compat</span>
    <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
        <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">engine=pa</span><span class="s2">, </span><span class="s1">compression=</span><span class="s2">None</span><span class="s1">)</span>

        <span class="s1">result = read_parquet(path</span><span class="s2">, </span><span class="s1">engine=fp)</span>
        <span class="s1">tm.assert_frame_equal(result</span><span class="s2">, </span><span class="s1">df)</span>

        <span class="s1">result = read_parquet(path</span><span class="s2">, </span><span class="s1">engine=fp</span><span class="s2">, </span><span class="s1">columns=[</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;d&quot;</span><span class="s1">])</span>
        <span class="s1">tm.assert_frame_equal(result</span><span class="s2">, </span><span class="s1">df[[</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;d&quot;</span><span class="s1">]])</span>


<span class="s2">def </span><span class="s1">test_cross_engine_fp_pa(request</span><span class="s2">, </span><span class="s1">df_cross_compat</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">fp):</span>
    <span class="s3"># cross-compat with differing reading/writing engines</span>
    <span class="s1">df = df_cross_compat</span>
    <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
        <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">engine=fp</span><span class="s2">, </span><span class="s1">compression=</span><span class="s2">None</span><span class="s1">)</span>

        <span class="s2">with </span><span class="s1">catch_warnings(record=</span><span class="s2">True</span><span class="s1">):</span>
            <span class="s1">result = read_parquet(path</span><span class="s2">, </span><span class="s1">engine=pa)</span>
            <span class="s1">tm.assert_frame_equal(result</span><span class="s2">, </span><span class="s1">df)</span>

            <span class="s1">result = read_parquet(path</span><span class="s2">, </span><span class="s1">engine=pa</span><span class="s2">, </span><span class="s1">columns=[</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;d&quot;</span><span class="s1">])</span>
            <span class="s1">tm.assert_frame_equal(result</span><span class="s2">, </span><span class="s1">df[[</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;d&quot;</span><span class="s1">]])</span>


<span class="s2">class </span><span class="s1">Base:</span>
    <span class="s2">def </span><span class="s1">check_error_on_write(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">exc</span><span class="s2">, </span><span class="s1">err_msg):</span>
        <span class="s3"># check that we are raising the exception on writing</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s2">with </span><span class="s1">pytest.raises(exc</span><span class="s2">, </span><span class="s1">match=err_msg):</span>
                <span class="s1">to_parquet(df</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">compression=</span><span class="s2">None</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">check_external_error_on_write(self</span><span class="s2">, </span><span class="s1">df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">exc):</span>
        <span class="s3"># check that an external library is raising the exception on writing</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s2">with </span><span class="s1">tm.external_error_raised(exc):</span>
                <span class="s1">to_parquet(df</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">compression=</span><span class="s2">None</span><span class="s1">)</span>

    <span class="s1">@tm.network</span>
    <span class="s2">def </span><span class="s1">test_parquet_read_from_url(self</span><span class="s2">, </span><span class="s1">df_compat</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s2">if </span><span class="s1">engine != </span><span class="s4">&quot;auto&quot;</span><span class="s1">:</span>
            <span class="s1">pytest.importorskip(engine)</span>
        <span class="s1">url = (</span>
            <span class="s4">&quot;https://raw.githubusercontent.com/pandas-dev/pandas/&quot;</span>
            <span class="s4">&quot;main/pandas/tests/io/data/parquet/simple.parquet&quot;</span>
        <span class="s1">)</span>
        <span class="s1">df = read_parquet(url)</span>
        <span class="s1">tm.assert_frame_equal(df</span><span class="s2">, </span><span class="s1">df_compat)</span>


<span class="s2">class </span><span class="s1">TestBasic(Base):</span>
    <span class="s2">def </span><span class="s1">test_error(self</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s2">for </span><span class="s1">obj </span><span class="s2">in </span><span class="s1">[</span>
            <span class="s1">pd.Series([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span><span class="s2">,</span>
            <span class="s5">1</span><span class="s2">,</span>
            <span class="s4">&quot;foo&quot;</span><span class="s2">,</span>
            <span class="s1">pd.Timestamp(</span><span class="s4">&quot;20130101&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">np.array([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">])</span><span class="s2">,</span>
        <span class="s1">]:</span>
            <span class="s1">msg = </span><span class="s4">&quot;to_parquet only supports IO with DataFrames&quot;</span>
            <span class="s1">self.check_error_on_write(obj</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

    <span class="s2">def </span><span class="s1">test_columns_dtypes(self</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;string&quot;</span><span class="s1">: list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">: list(range(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">4</span><span class="s1">))})</span>

        <span class="s3"># unicode</span>
        <span class="s1">df.columns = [</span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s1">]</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine)</span>

    <span class="s2">def </span><span class="s1">test_columns_dtypes_invalid(self</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;string&quot;</span><span class="s1">: list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">: list(range(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">4</span><span class="s1">))})</span>

        <span class="s1">msg = </span><span class="s4">&quot;parquet must have string column names&quot;</span>
        <span class="s3"># numeric</span>
        <span class="s1">df.columns = [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

        <span class="s3"># bytes</span>
        <span class="s1">df.columns = [</span><span class="s6">b&quot;foo&quot;</span><span class="s2">, </span><span class="s6">b&quot;bar&quot;</span><span class="s1">]</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

        <span class="s3"># python object</span>
        <span class="s1">df.columns = [</span>
            <span class="s1">datetime.datetime(</span><span class="s5">2011</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">0</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">datetime.datetime(</span><span class="s5">2011</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">]</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;compression&quot;</span><span class="s2">, </span><span class="s1">[</span><span class="s2">None, </span><span class="s4">&quot;gzip&quot;</span><span class="s2">, </span><span class="s4">&quot;snappy&quot;</span><span class="s2">, </span><span class="s4">&quot;brotli&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">test_compression(self</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">compression):</span>

        <span class="s2">if </span><span class="s1">compression == </span><span class="s4">&quot;snappy&quot;</span><span class="s1">:</span>
            <span class="s1">pytest.importorskip(</span><span class="s4">&quot;snappy&quot;</span><span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">compression == </span><span class="s4">&quot;brotli&quot;</span><span class="s1">:</span>
            <span class="s1">pytest.importorskip(</span><span class="s4">&quot;brotli&quot;</span><span class="s1">)</span>

        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;A&quot;</span><span class="s1">: [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]})</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">write_kwargs={</span><span class="s4">&quot;compression&quot;</span><span class="s1">: compression})</span>

    <span class="s2">def </span><span class="s1">test_read_columns(self</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s3"># GH18154</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;string&quot;</span><span class="s1">: list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">: list(range(</span><span class="s5">1</span><span class="s2">, </span><span class="s5">4</span><span class="s1">))})</span>

        <span class="s1">expected = pd.DataFrame({</span><span class="s4">&quot;string&quot;</span><span class="s1">: list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">)})</span>
        <span class="s1">check_round_trip(</span>
            <span class="s1">df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">expected=expected</span><span class="s2">, </span><span class="s1">read_kwargs={</span><span class="s4">&quot;columns&quot;</span><span class="s1">: [</span><span class="s4">&quot;string&quot;</span><span class="s1">]}</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_write_index(self</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s1">check_names = engine != </span><span class="s4">&quot;fastparquet&quot;</span>

        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;A&quot;</span><span class="s1">: [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]})</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine)</span>

        <span class="s1">indexes = [</span>
            <span class="s1">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">pd.date_range(</span><span class="s4">&quot;20130101&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">]</span>
        <span class="s3"># non-default index</span>
        <span class="s2">for </span><span class="s1">index </span><span class="s2">in </span><span class="s1">indexes:</span>
            <span class="s1">df.index = index</span>
            <span class="s2">if </span><span class="s1">isinstance(index</span><span class="s2">, </span><span class="s1">pd.DatetimeIndex):</span>
                <span class="s1">df.index = df.index._with_freq(</span><span class="s2">None</span><span class="s1">)  </span><span class="s3"># freq doesn't round-trip</span>
            <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">check_names=check_names)</span>

        <span class="s3"># index with meta-data</span>
        <span class="s1">df.index = [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span>
        <span class="s1">df.index.name = </span><span class="s4">&quot;foo&quot;</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine)</span>

    <span class="s2">def </span><span class="s1">test_write_multiindex(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># Not supported in fastparquet as of 0.1.3 or older pyarrow version</span>
        <span class="s1">engine = pa</span>

        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;A&quot;</span><span class="s1">: [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]})</span>
        <span class="s1">index = pd.MultiIndex.from_tuples([(</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s4">&quot;b&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)])</span>
        <span class="s1">df.index = index</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine)</span>

    <span class="s2">def </span><span class="s1">test_multiindex_with_columns(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s1">engine = pa</span>
        <span class="s1">dates = pd.date_range(</span><span class="s4">&quot;01-Jan-2018&quot;</span><span class="s2">, </span><span class="s4">&quot;01-Dec-2018&quot;</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">&quot;MS&quot;</span><span class="s1">)</span>
        <span class="s1">df = pd.DataFrame(np.random.randn(</span><span class="s5">2 </span><span class="s1">* len(dates)</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=list(</span><span class="s4">&quot;ABC&quot;</span><span class="s1">))</span>
        <span class="s1">index1 = pd.MultiIndex.from_product(</span>
            <span class="s1">[[</span><span class="s4">&quot;Level1&quot;</span><span class="s2">, </span><span class="s4">&quot;Level2&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dates]</span><span class="s2">, </span><span class="s1">names=[</span><span class="s4">&quot;level&quot;</span><span class="s2">, </span><span class="s4">&quot;date&quot;</span><span class="s1">]</span>
        <span class="s1">)</span>
        <span class="s1">index2 = index1.copy(names=</span><span class="s2">None</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">index </span><span class="s2">in </span><span class="s1">[index1</span><span class="s2">, </span><span class="s1">index2]:</span>
            <span class="s1">df.index = index</span>

            <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine)</span>
            <span class="s1">check_round_trip(</span>
                <span class="s1">df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">read_kwargs={</span><span class="s4">&quot;columns&quot;</span><span class="s1">: [</span><span class="s4">&quot;A&quot;</span><span class="s2">, </span><span class="s4">&quot;B&quot;</span><span class="s1">]}</span><span class="s2">, </span><span class="s1">expected=df[[</span><span class="s4">&quot;A&quot;</span><span class="s2">, </span><span class="s4">&quot;B&quot;</span><span class="s1">]]</span>
            <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_write_ignoring_index(self</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s3"># ENH 20768</span>
        <span class="s3"># Ensure index=False omits the index from the written Parquet file.</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s4">&quot;b&quot;</span><span class="s1">: [</span><span class="s4">&quot;q&quot;</span><span class="s2">, </span><span class="s4">&quot;r&quot;</span><span class="s2">, </span><span class="s4">&quot;s&quot;</span><span class="s1">]})</span>

        <span class="s1">write_kwargs = {</span><span class="s4">&quot;compression&quot;</span><span class="s1">: </span><span class="s2">None, </span><span class="s4">&quot;index&quot;</span><span class="s1">: </span><span class="s2">False</span><span class="s1">}</span>

        <span class="s3"># Because we're dropping the index, we expect the loaded dataframe to</span>
        <span class="s3"># have the default integer index.</span>
        <span class="s1">expected = df.reset_index(drop=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">write_kwargs=write_kwargs</span><span class="s2">, </span><span class="s1">expected=expected)</span>

        <span class="s3"># Ignore custom index</span>
        <span class="s1">df = pd.DataFrame(</span>
            <span class="s1">{</span><span class="s4">&quot;a&quot;</span><span class="s1">: [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s4">&quot;b&quot;</span><span class="s1">: [</span><span class="s4">&quot;q&quot;</span><span class="s2">, </span><span class="s4">&quot;r&quot;</span><span class="s2">, </span><span class="s4">&quot;s&quot;</span><span class="s1">]}</span><span class="s2">, </span><span class="s1">index=[</span><span class="s4">&quot;zyx&quot;</span><span class="s2">, </span><span class="s4">&quot;wvu&quot;</span><span class="s2">, </span><span class="s4">&quot;tsr&quot;</span><span class="s1">]</span>
        <span class="s1">)</span>

        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">write_kwargs=write_kwargs</span><span class="s2">, </span><span class="s1">expected=expected)</span>

        <span class="s3"># Ignore multi-indexes as well.</span>
        <span class="s1">arrays = [</span>
            <span class="s1">[</span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;qux&quot;</span><span class="s2">, </span><span class="s4">&quot;qux&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[</span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s2">, </span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s2">, </span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s2">, </span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">]</span>
        <span class="s1">df = pd.DataFrame(</span>
            <span class="s1">{</span><span class="s4">&quot;one&quot;</span><span class="s1">: list(range(</span><span class="s5">8</span><span class="s1">))</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s1">: [-i </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s5">8</span><span class="s1">)]}</span><span class="s2">, </span><span class="s1">index=arrays</span>
        <span class="s1">)</span>

        <span class="s1">expected = df.reset_index(drop=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">write_kwargs=write_kwargs</span><span class="s2">, </span><span class="s1">expected=expected)</span>

    <span class="s2">def </span><span class="s1">test_write_column_multiindex(self</span><span class="s2">, </span><span class="s1">engine):</span>
        <span class="s3"># Not able to write column multi-indexes with non-string column names.</span>
        <span class="s1">mi_columns = pd.MultiIndex.from_tuples([(</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s5">2</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(</span><span class="s4">&quot;b&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)])</span>
        <span class="s1">df = pd.DataFrame(np.random.randn(</span><span class="s5">4</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=mi_columns)</span>
        <span class="s1">msg = (</span>
            <span class="s4">r&quot;\s*parquet must have string column names for all values in\s*&quot;</span>
            <span class="s4">&quot;each level of the MultiIndex&quot;</span>
        <span class="s1">)</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

    <span class="s2">def </span><span class="s1">test_write_column_multiindex_nonstring(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># GH #34777</span>
        <span class="s3"># Not supported in fastparquet as of 0.1.3</span>
        <span class="s1">engine = pa</span>

        <span class="s3"># Not able to write column multi-indexes with non-string column names</span>
        <span class="s1">arrays = [</span>
            <span class="s1">[</span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;qux&quot;</span><span class="s2">, </span><span class="s4">&quot;qux&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">]</span>
        <span class="s1">df = pd.DataFrame(np.random.randn(</span><span class="s5">8</span><span class="s2">, </span><span class="s5">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=arrays)</span>
        <span class="s1">df.columns.names = [</span><span class="s4">&quot;Level1&quot;</span><span class="s2">, </span><span class="s4">&quot;Level2&quot;</span><span class="s1">]</span>
        <span class="s1">msg = (</span>
            <span class="s4">r&quot;\s*parquet must have string column names for all values in\s*&quot;</span>
            <span class="s4">&quot;each level of the MultiIndex&quot;</span>
        <span class="s1">)</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

    <span class="s2">def </span><span class="s1">test_write_column_multiindex_string(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># GH #34777</span>
        <span class="s3"># Not supported in fastparquet as of 0.1.3</span>
        <span class="s1">engine = pa</span>

        <span class="s3"># Write column multi-indexes with string column names</span>
        <span class="s1">arrays = [</span>
            <span class="s1">[</span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;qux&quot;</span><span class="s2">, </span><span class="s4">&quot;qux&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[</span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s2">, </span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s2">, </span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s2">, </span><span class="s4">&quot;one&quot;</span><span class="s2">, </span><span class="s4">&quot;two&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">]</span>
        <span class="s1">df = pd.DataFrame(np.random.randn(</span><span class="s5">8</span><span class="s2">, </span><span class="s5">8</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=arrays)</span>
        <span class="s1">df.columns.names = [</span><span class="s4">&quot;ColLevel1&quot;</span><span class="s2">, </span><span class="s4">&quot;ColLevel2&quot;</span><span class="s1">]</span>

        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine)</span>

    <span class="s2">def </span><span class="s1">test_write_column_index_string(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># GH #34777</span>
        <span class="s3"># Not supported in fastparquet as of 0.1.3</span>
        <span class="s1">engine = pa</span>

        <span class="s3"># Write column indexes with string column names</span>
        <span class="s1">arrays = [</span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;qux&quot;</span><span class="s1">]</span>
        <span class="s1">df = pd.DataFrame(np.random.randn(</span><span class="s5">8</span><span class="s2">, </span><span class="s5">4</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=arrays)</span>
        <span class="s1">df.columns.name = </span><span class="s4">&quot;StringCol&quot;</span>

        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">engine)</span>

    <span class="s2">def </span><span class="s1">test_write_column_index_nonstring(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># GH #34777</span>
        <span class="s3"># Not supported in fastparquet as of 0.1.3</span>
        <span class="s1">engine = pa</span>

        <span class="s3"># Write column indexes with string column names</span>
        <span class="s1">arrays = [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s1">]</span>
        <span class="s1">df = pd.DataFrame(np.random.randn(</span><span class="s5">8</span><span class="s2">, </span><span class="s5">4</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=arrays)</span>
        <span class="s1">df.columns.name = </span><span class="s4">&quot;NonStringCol&quot;</span>
        <span class="s1">msg = </span><span class="s4">r&quot;parquet must have string column names&quot;</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

    <span class="s2">def </span><span class="s1">test_use_nullable_dtypes(self</span><span class="s2">, </span><span class="s1">engine</span><span class="s2">, </span><span class="s1">request):</span>
        <span class="s2">import </span><span class="s1">pyarrow.parquet </span><span class="s2">as </span><span class="s1">pq</span>

        <span class="s2">if </span><span class="s1">engine == </span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">:</span>
            <span class="s3"># We are manually disabling fastparquet's</span>
            <span class="s3"># nullable dtype support pending discussion</span>
            <span class="s1">mark = pytest.mark.xfail(</span>
                <span class="s1">reason=</span><span class="s4">&quot;Fastparquet nullable dtype support is disabled&quot;</span>
            <span class="s1">)</span>
            <span class="s1">request.node.add_marker(mark)</span>

        <span class="s1">table = pyarrow.table(</span>
            <span class="s1">{</span>
                <span class="s4">&quot;a&quot;</span><span class="s1">: pyarrow.array([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s4">&quot;int64&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;b&quot;</span><span class="s1">: pyarrow.array([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s4">&quot;uint8&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;c&quot;</span><span class="s1">: pyarrow.array([</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;b&quot;</span><span class="s2">, </span><span class="s4">&quot;c&quot;</span><span class="s2">, None</span><span class="s1">])</span><span class="s2">,</span>
                <span class="s4">&quot;d&quot;</span><span class="s1">: pyarrow.array([</span><span class="s2">True, False, True, None</span><span class="s1">])</span><span class="s2">,</span>
                <span class="s3"># Test that nullable dtypes used even in absence of nulls</span>
                <span class="s4">&quot;e&quot;</span><span class="s1">: pyarrow.array([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s1">]</span><span class="s2">, </span><span class="s4">&quot;int64&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">}</span>
        <span class="s1">)</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s3"># write manually with pyarrow to write integers</span>
            <span class="s1">pq.write_table(table</span><span class="s2">, </span><span class="s1">path)</span>
            <span class="s1">result1 = read_parquet(path</span><span class="s2">, </span><span class="s1">engine=engine)</span>
            <span class="s1">result2 = read_parquet(path</span><span class="s2">, </span><span class="s1">engine=engine</span><span class="s2">, </span><span class="s1">use_nullable_dtypes=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s2">assert </span><span class="s1">result1[</span><span class="s4">&quot;a&quot;</span><span class="s1">].dtype == np.dtype(</span><span class="s4">&quot;float64&quot;</span><span class="s1">)</span>
        <span class="s1">expected = pd.DataFrame(</span>
            <span class="s1">{</span>
                <span class="s4">&quot;a&quot;</span><span class="s1">: pd.array([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;Int64&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;b&quot;</span><span class="s1">: pd.array([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;UInt8&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;c&quot;</span><span class="s1">: pd.array([</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;b&quot;</span><span class="s2">, </span><span class="s4">&quot;c&quot;</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;string&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;d&quot;</span><span class="s1">: pd.array([</span><span class="s2">True, False, True, None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;boolean&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;e&quot;</span><span class="s1">: pd.array([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, </span><span class="s5">4</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;Int64&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">}</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">engine == </span><span class="s4">&quot;fastparquet&quot;</span><span class="s1">:</span>
            <span class="s3"># Fastparquet doesn't support string columns yet</span>
            <span class="s3"># Only int and boolean</span>
            <span class="s1">result2 = result2.drop(</span><span class="s4">&quot;c&quot;</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">expected = expected.drop(</span><span class="s4">&quot;c&quot;</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">tm.assert_frame_equal(result2</span><span class="s2">, </span><span class="s1">expected)</span>

    <span class="s1">@pytest.mark.parametrize(</span>
        <span class="s4">&quot;dtype&quot;</span><span class="s2">,</span>
        <span class="s1">[</span>
            <span class="s4">&quot;Int64&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;UInt8&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;boolean&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;object&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;datetime64[ns, UTC]&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;float&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;period[D]&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;Float64&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;string&quot;</span><span class="s2">,</span>
        <span class="s1">]</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_read_empty_array(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">dtype):</span>
        <span class="s3"># GH #41241</span>
        <span class="s1">df = pd.DataFrame(</span>
            <span class="s1">{</span>
                <span class="s4">&quot;value&quot;</span><span class="s1">: pd.array([]</span><span class="s2">, </span><span class="s1">dtype=dtype)</span><span class="s2">,</span>
            <span class="s1">}</span>
        <span class="s1">)</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">read_kwargs={</span><span class="s4">&quot;use_nullable_dtypes&quot;</span><span class="s1">: </span><span class="s2">True</span><span class="s1">})</span>


<span class="s1">@pytest.mark.filterwarnings(</span><span class="s4">&quot;ignore:CategoricalBlock is deprecated:DeprecationWarning&quot;</span><span class="s1">)</span>
<span class="s2">class </span><span class="s1">TestParquetPyArrow(Base):</span>
    <span class="s2">def </span><span class="s1">test_basic(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">df_full):</span>

        <span class="s1">df = df_full</span>

        <span class="s3"># additional supported types for pyarrow</span>
        <span class="s1">dti = pd.date_range(</span><span class="s4">&quot;20130101&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">tz=</span><span class="s4">&quot;Europe/Brussels&quot;</span><span class="s1">)</span>
        <span class="s1">dti = dti._with_freq(</span><span class="s2">None</span><span class="s1">)  </span><span class="s3"># freq doesn't round-trip</span>
        <span class="s1">df[</span><span class="s4">&quot;datetime_tz&quot;</span><span class="s1">] = dti</span>
        <span class="s1">df[</span><span class="s4">&quot;bool_with_none&quot;</span><span class="s1">] = [</span><span class="s2">True, None, True</span><span class="s1">]</span>

        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa)</span>

    <span class="s2">def </span><span class="s1">test_basic_subset_columns(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH18628</span>

        <span class="s1">df = df_full</span>
        <span class="s3"># additional supported types for pyarrow</span>
        <span class="s1">df[</span><span class="s4">&quot;datetime_tz&quot;</span><span class="s1">] = pd.date_range(</span><span class="s4">&quot;20130101&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">tz=</span><span class="s4">&quot;Europe/Brussels&quot;</span><span class="s1">)</span>

        <span class="s1">check_round_trip(</span>
            <span class="s1">df</span><span class="s2">,</span>
            <span class="s1">pa</span><span class="s2">,</span>
            <span class="s1">expected=df[[</span><span class="s4">&quot;string&quot;</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">]]</span><span class="s2">,</span>
            <span class="s1">read_kwargs={</span><span class="s4">&quot;columns&quot;</span><span class="s1">: [</span><span class="s4">&quot;string&quot;</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">]}</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_to_bytes_without_path_or_buf_provided(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH 37105</span>

        <span class="s1">buf_bytes = df_full.to_parquet(engine=pa)</span>
        <span class="s2">assert </span><span class="s1">isinstance(buf_bytes</span><span class="s2">, </span><span class="s1">bytes)</span>

        <span class="s1">buf_stream = BytesIO(buf_bytes)</span>
        <span class="s1">res = read_parquet(buf_stream)</span>

        <span class="s1">tm.assert_frame_equal(df_full</span><span class="s2">, </span><span class="s1">res)</span>

    <span class="s2">def </span><span class="s1">test_duplicate_columns(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># not currently able to handle duplicate columns</span>
        <span class="s1">df = pd.DataFrame(np.arange(</span><span class="s5">12</span><span class="s1">).reshape(</span><span class="s5">4</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=list(</span><span class="s4">&quot;aaa&quot;</span><span class="s1">)).copy()</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s4">&quot;Duplicate column names found&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_unsupported(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># timedelta</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: pd.timedelta_range(</span><span class="s4">&quot;1 day&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s1">)})</span>
        <span class="s1">self.check_external_error_on_write(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">NotImplementedError)</span>

        <span class="s3"># mixed python objects</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: [</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2.0</span><span class="s1">]})</span>
        <span class="s3"># pyarrow 0.11 raises ArrowTypeError</span>
        <span class="s3"># older pyarrows raise ArrowInvalid</span>
        <span class="s1">self.check_external_error_on_write(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">pyarrow.ArrowException)</span>

    <span class="s2">def </span><span class="s1">test_categorical(self</span><span class="s2">, </span><span class="s1">pa):</span>

        <span class="s3"># supported in &gt;= 0.7.0</span>
        <span class="s1">df = pd.DataFrame()</span>
        <span class="s1">df[</span><span class="s4">&quot;a&quot;</span><span class="s1">] = pd.Categorical(list(</span><span class="s4">&quot;abcdef&quot;</span><span class="s1">))</span>

        <span class="s3"># test for null, out-of-order values, and unobserved category</span>
        <span class="s1">df[</span><span class="s4">&quot;b&quot;</span><span class="s1">] = pd.Categorical(</span>
            <span class="s1">[</span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s2">, None, </span><span class="s4">&quot;bar&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">dtype=pd.CategoricalDtype([</span><span class="s4">&quot;foo&quot;</span><span class="s2">, </span><span class="s4">&quot;bar&quot;</span><span class="s2">, </span><span class="s4">&quot;baz&quot;</span><span class="s1">])</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s3"># test for ordered flag</span>
        <span class="s1">df[</span><span class="s4">&quot;c&quot;</span><span class="s1">] = pd.Categorical(</span>
            <span class="s1">[</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;b&quot;</span><span class="s2">, </span><span class="s4">&quot;c&quot;</span><span class="s2">, </span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;c&quot;</span><span class="s2">, </span><span class="s4">&quot;b&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s1">categories=[</span><span class="s4">&quot;b&quot;</span><span class="s2">, </span><span class="s4">&quot;c&quot;</span><span class="s2">, </span><span class="s4">&quot;d&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s1">ordered=</span><span class="s2">True</span>
        <span class="s1">)</span>

        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa)</span>

    <span class="s2">def </span><span class="s1">test_s3_roundtrip_explicit_fs(self</span><span class="s2">, </span><span class="s1">df_compat</span><span class="s2">, </span><span class="s1">s3_resource</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">s3so):</span>
        <span class="s1">s3fs = pytest.importorskip(</span><span class="s4">&quot;s3fs&quot;</span><span class="s1">)</span>
        <span class="s1">s3 = s3fs.S3FileSystem(**s3so)</span>
        <span class="s1">kw = {</span><span class="s4">&quot;filesystem&quot;</span><span class="s1">: s3}</span>
        <span class="s1">check_round_trip(</span>
            <span class="s1">df_compat</span><span class="s2">,</span>
            <span class="s1">pa</span><span class="s2">,</span>
            <span class="s1">path=</span><span class="s4">&quot;pandas-test/pyarrow.parquet&quot;</span><span class="s2">,</span>
            <span class="s1">read_kwargs=kw</span><span class="s2">,</span>
            <span class="s1">write_kwargs=kw</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_s3_roundtrip(self</span><span class="s2">, </span><span class="s1">df_compat</span><span class="s2">, </span><span class="s1">s3_resource</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">s3so):</span>
        <span class="s3"># GH #19134</span>
        <span class="s1">s3so = {</span><span class="s4">&quot;storage_options&quot;</span><span class="s1">: s3so}</span>
        <span class="s1">check_round_trip(</span>
            <span class="s1">df_compat</span><span class="s2">,</span>
            <span class="s1">pa</span><span class="s2">,</span>
            <span class="s1">path=</span><span class="s4">&quot;s3://pandas-test/pyarrow.parquet&quot;</span><span class="s2">,</span>
            <span class="s1">read_kwargs=s3so</span><span class="s2">,</span>
            <span class="s1">write_kwargs=s3so</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@td.skip_if_no(</span><span class="s4">&quot;s3fs&quot;</span><span class="s1">)  </span><span class="s3"># also requires flask</span>
    <span class="s1">@pytest.mark.parametrize(</span>
        <span class="s4">&quot;partition_col&quot;</span><span class="s2">,</span>
        <span class="s1">[</span>
            <span class="s1">[</span><span class="s4">&quot;A&quot;</span><span class="s1">]</span><span class="s2">,</span>
            <span class="s1">[]</span><span class="s2">,</span>
        <span class="s1">]</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_s3_roundtrip_for_dir(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">df_compat</span><span class="s2">, </span><span class="s1">s3_resource</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">partition_col</span><span class="s2">, </span><span class="s1">s3so</span>
    <span class="s1">):</span>
        <span class="s3"># GH #26388</span>
        <span class="s1">expected_df = df_compat.copy()</span>

        <span class="s3"># GH #35791</span>
        <span class="s3"># read_table uses the new Arrow Datasets API since pyarrow 1.0.0</span>
        <span class="s3"># Previous behaviour was pyarrow partitioned columns become 'category' dtypes</span>
        <span class="s3"># These are added to back of dataframe on read. In new API category dtype is</span>
        <span class="s3"># only used if partition field is string, but this changed again to use</span>
        <span class="s3"># category dtype for all types (not only strings) in pyarrow 2.0.0</span>
        <span class="s2">if </span><span class="s1">partition_col:</span>
            <span class="s1">partition_col_type = </span><span class="s4">&quot;int32&quot; </span><span class="s2">if </span><span class="s1">pa_version_under2p0 </span><span class="s2">else </span><span class="s4">&quot;category&quot;</span>

            <span class="s1">expected_df[partition_col] = expected_df[partition_col].astype(</span>
                <span class="s1">partition_col_type</span>
            <span class="s1">)</span>

        <span class="s1">check_round_trip(</span>
            <span class="s1">df_compat</span><span class="s2">,</span>
            <span class="s1">pa</span><span class="s2">,</span>
            <span class="s1">expected=expected_df</span><span class="s2">,</span>
            <span class="s1">path=</span><span class="s4">&quot;s3://pandas-test/parquet_dir&quot;</span><span class="s2">,</span>
            <span class="s1">read_kwargs={</span><span class="s4">&quot;storage_options&quot;</span><span class="s1">: s3so}</span><span class="s2">,</span>
            <span class="s1">write_kwargs={</span>
                <span class="s4">&quot;partition_cols&quot;</span><span class="s1">: partition_col</span><span class="s2">,</span>
                <span class="s4">&quot;compression&quot;</span><span class="s1">: </span><span class="s2">None,</span>
                <span class="s4">&quot;storage_options&quot;</span><span class="s1">: s3so</span><span class="s2">,</span>
            <span class="s1">}</span><span class="s2">,</span>
            <span class="s1">check_like=</span><span class="s2">True,</span>
            <span class="s1">repeat=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@td.skip_if_no(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_read_file_like_obj_support(self</span><span class="s2">, </span><span class="s1">df_compat):</span>
        <span class="s1">buffer = BytesIO()</span>
        <span class="s1">df_compat.to_parquet(buffer)</span>
        <span class="s1">df_from_buf = read_parquet(buffer)</span>
        <span class="s1">tm.assert_frame_equal(df_compat</span><span class="s2">, </span><span class="s1">df_from_buf)</span>

    <span class="s1">@td.skip_if_no(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_expand_user(self</span><span class="s2">, </span><span class="s1">df_compat</span><span class="s2">, </span><span class="s1">monkeypatch):</span>
        <span class="s1">monkeypatch.setenv(</span><span class="s4">&quot;HOME&quot;</span><span class="s2">, </span><span class="s4">&quot;TestingUser&quot;</span><span class="s1">)</span>
        <span class="s1">monkeypatch.setenv(</span><span class="s4">&quot;USERPROFILE&quot;</span><span class="s2">, </span><span class="s4">&quot;TestingUser&quot;</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">pytest.raises(OSError</span><span class="s2">, </span><span class="s1">match=</span><span class="s4">r&quot;.*TestingUser.*&quot;</span><span class="s1">):</span>
            <span class="s1">read_parquet(</span><span class="s4">&quot;~/file.parquet&quot;</span><span class="s1">)</span>
        <span class="s2">with </span><span class="s1">pytest.raises(OSError</span><span class="s2">, </span><span class="s1">match=</span><span class="s4">r&quot;.*TestingUser.*&quot;</span><span class="s1">):</span>
            <span class="s1">df_compat.to_parquet(</span><span class="s4">&quot;~/file.parquet&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_partition_cols_supported(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH #23283</span>
        <span class="s1">partition_cols = [</span><span class="s4">&quot;bool&quot;</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">]</span>
        <span class="s1">df = df_full</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean_dir() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">partition_cols=partition_cols</span><span class="s2">, </span><span class="s1">compression=</span><span class="s2">None</span><span class="s1">)</span>
            <span class="s1">check_partition_names(path</span><span class="s2">, </span><span class="s1">partition_cols)</span>
            <span class="s2">assert </span><span class="s1">read_parquet(path).shape == df.shape</span>

    <span class="s2">def </span><span class="s1">test_partition_cols_string(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH #27117</span>
        <span class="s1">partition_cols = </span><span class="s4">&quot;bool&quot;</span>
        <span class="s1">partition_cols_list = [partition_cols]</span>
        <span class="s1">df = df_full</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean_dir() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">partition_cols=partition_cols</span><span class="s2">, </span><span class="s1">compression=</span><span class="s2">None</span><span class="s1">)</span>
            <span class="s1">check_partition_names(path</span><span class="s2">, </span><span class="s1">partition_cols_list)</span>
            <span class="s2">assert </span><span class="s1">read_parquet(path).shape == df.shape</span>

    <span class="s1">@pytest.mark.parametrize(</span><span class="s4">&quot;path_type&quot;</span><span class="s2">, </span><span class="s1">[str</span><span class="s2">, </span><span class="s1">pathlib.Path])</span>
    <span class="s2">def </span><span class="s1">test_partition_cols_pathlib(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">df_compat</span><span class="s2">, </span><span class="s1">path_type):</span>
        <span class="s3"># GH 35902</span>

        <span class="s1">partition_cols = </span><span class="s4">&quot;B&quot;</span>
        <span class="s1">partition_cols_list = [partition_cols]</span>
        <span class="s1">df = df_compat</span>

        <span class="s2">with </span><span class="s1">tm.ensure_clean_dir() </span><span class="s2">as </span><span class="s1">path_str:</span>
            <span class="s1">path = path_type(path_str)</span>
            <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">partition_cols=partition_cols_list)</span>
            <span class="s2">assert </span><span class="s1">read_parquet(path).shape == df.shape</span>

    <span class="s2">def </span><span class="s1">test_empty_dataframe(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># GH #27339</span>
        <span class="s1">df = pd.DataFrame()</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa)</span>

    <span class="s2">def </span><span class="s1">test_write_with_schema(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s2">import </span><span class="s1">pyarrow</span>

        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;x&quot;</span><span class="s1">: [</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]})</span>
        <span class="s1">schema = pyarrow.schema([pyarrow.field(</span><span class="s4">&quot;x&quot;</span><span class="s2">, </span><span class="s1">type=pyarrow.bool_())])</span>
        <span class="s1">out_df = df.astype(bool)</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">write_kwargs={</span><span class="s4">&quot;schema&quot;</span><span class="s1">: schema}</span><span class="s2">, </span><span class="s1">expected=out_df)</span>

    <span class="s1">@td.skip_if_no(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_additional_extension_arrays(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># test additional ExtensionArrays that are supported through the</span>
        <span class="s3"># __arrow_array__ protocol</span>
        <span class="s1">df = pd.DataFrame(</span>
            <span class="s1">{</span>
                <span class="s4">&quot;a&quot;</span><span class="s1">: pd.Series([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;Int64&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;b&quot;</span><span class="s1">: pd.Series([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;UInt32&quot;</span><span class="s1">)</span><span class="s2">,</span>
                <span class="s4">&quot;c&quot;</span><span class="s1">: pd.Series([</span><span class="s4">&quot;a&quot;</span><span class="s2">, None, </span><span class="s4">&quot;c&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;string&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">}</span>
        <span class="s1">)</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa)</span>

        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: pd.Series([</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s2">, </span><span class="s5">3</span><span class="s2">, None</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;Int64&quot;</span><span class="s1">)})</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa)</span>

    <span class="s1">@td.skip_if_no(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s2">, </span><span class="s1">min_version=</span><span class="s4">&quot;1.0.0&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_pyarrow_backed_string_array(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">string_storage):</span>
        <span class="s3"># test ArrowStringArray supported through the __arrow_array__ protocol</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: pd.Series([</span><span class="s4">&quot;a&quot;</span><span class="s2">, None, </span><span class="s4">&quot;c&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;string[pyarrow]&quot;</span><span class="s1">)})</span>
        <span class="s2">with </span><span class="s1">pd.option_context(</span><span class="s4">&quot;string_storage&quot;</span><span class="s2">, </span><span class="s1">string_storage):</span>
            <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">expected=df.astype(</span><span class="s4">f&quot;string[</span><span class="s2">{</span><span class="s1">string_storage</span><span class="s2">}</span><span class="s4">]&quot;</span><span class="s1">))</span>

    <span class="s1">@td.skip_if_no(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_additional_extension_types(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># test additional ExtensionArrays that are supported through the</span>
        <span class="s3"># __arrow_array__ protocol + by defining a custom ExtensionType</span>
        <span class="s1">df = pd.DataFrame(</span>
            <span class="s1">{</span>
                <span class="s3"># Arrow does not yet support struct in writing to Parquet (ARROW-1644)</span>
                <span class="s3"># &quot;c&quot;: pd.arrays.IntervalArray.from_tuples([(0, 1), (1, 2), (3, 4)]),</span>
                <span class="s4">&quot;d&quot;</span><span class="s1">: pd.period_range(</span><span class="s4">&quot;2012-01-01&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">&quot;D&quot;</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">}</span>
        <span class="s1">)</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa)</span>

    <span class="s2">def </span><span class="s1">test_timestamp_nanoseconds(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># with version 2.6, pyarrow defaults to writing the nanoseconds, so</span>
        <span class="s3"># this should work without error</span>
        <span class="s3"># Note in previous pyarrows(&lt;6.0.0), only the pseudo-version 2.0 was available</span>
        <span class="s2">if not </span><span class="s1">pa_version_under6p0:</span>
            <span class="s1">ver = </span><span class="s4">&quot;2.6&quot;</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">ver = </span><span class="s4">&quot;2.0&quot;</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: pd.date_range(</span><span class="s4">&quot;2017-01-01&quot;</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">&quot;1n&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">10</span><span class="s1">)})</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">write_kwargs={</span><span class="s4">&quot;version&quot;</span><span class="s1">: ver})</span>

    <span class="s2">def </span><span class="s1">test_timezone_aware_index(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">timezone_aware_date_list):</span>
        <span class="s2">if not </span><span class="s1">pa_version_under2p0:</span>
            <span class="s3"># temporary skip this test until it is properly resolved</span>
            <span class="s3"># https://github.com/pandas-dev/pandas/issues/37286</span>
            <span class="s1">pytest.skip()</span>
        <span class="s1">idx = </span><span class="s5">5 </span><span class="s1">* [timezone_aware_date_list]</span>
        <span class="s1">df = pd.DataFrame(index=idx</span><span class="s2">, </span><span class="s1">data={</span><span class="s4">&quot;index_as_col&quot;</span><span class="s1">: idx})</span>

        <span class="s3"># see gh-36004</span>
        <span class="s3"># compare time(zone) values only, skip their class:</span>
        <span class="s3"># pyarrow always creates fixed offset timezones using pytz.FixedOffset()</span>
        <span class="s3"># even if it was datetime.timezone() originally</span>
        <span class="s3">#</span>
        <span class="s3"># technically they are the same:</span>
        <span class="s3"># they both implement datetime.tzinfo</span>
        <span class="s3"># they both wrap datetime.timedelta()</span>
        <span class="s3"># this use-case sets the resolution to 1 minute</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">check_dtype=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s1">@td.skip_if_no(</span><span class="s4">&quot;pyarrow&quot;</span><span class="s2">, </span><span class="s1">min_version=</span><span class="s4">&quot;1.0.0&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_filter_row_groups(self</span><span class="s2">, </span><span class="s1">pa):</span>
        <span class="s3"># https://github.com/pandas-dev/pandas/issues/26551</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: list(range(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">3</span><span class="s1">))})</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">pa)</span>
            <span class="s1">result = read_parquet(</span>
                <span class="s1">path</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">filters=[(</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;==&quot;</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)]</span><span class="s2">, </span><span class="s1">use_legacy_dataset=</span><span class="s2">False</span>
            <span class="s1">)</span>
        <span class="s2">assert </span><span class="s1">len(result) == </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">test_read_parquet_manager(self</span><span class="s2">, </span><span class="s1">pa</span><span class="s2">, </span><span class="s1">using_array_manager):</span>
        <span class="s3"># ensure that read_parquet honors the pandas.options.mode.data_manager option</span>
        <span class="s1">df = pd.DataFrame(np.random.randn(</span><span class="s5">10</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=[</span><span class="s4">&quot;A&quot;</span><span class="s2">, </span><span class="s4">&quot;B&quot;</span><span class="s2">, </span><span class="s4">&quot;C&quot;</span><span class="s1">])</span>

        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">pa)</span>
            <span class="s1">result = read_parquet(path</span><span class="s2">, </span><span class="s1">pa)</span>
        <span class="s2">if </span><span class="s1">using_array_manager:</span>
            <span class="s2">assert </span><span class="s1">isinstance(result._mgr</span><span class="s2">, </span><span class="s1">pd.core.internals.ArrayManager)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">assert </span><span class="s1">isinstance(result._mgr</span><span class="s2">, </span><span class="s1">pd.core.internals.BlockManager)</span>


<span class="s2">class </span><span class="s1">TestParquetFastParquet(Base):</span>
    <span class="s2">def </span><span class="s1">test_basic(self</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s1">df = df_full</span>

        <span class="s1">dti = pd.date_range(</span><span class="s4">&quot;20130101&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s2">, </span><span class="s1">tz=</span><span class="s4">&quot;US/Eastern&quot;</span><span class="s1">)</span>
        <span class="s1">dti = dti._with_freq(</span><span class="s2">None</span><span class="s1">)  </span><span class="s3"># freq doesn't round-trip</span>
        <span class="s1">df[</span><span class="s4">&quot;datetime_tz&quot;</span><span class="s1">] = dti</span>
        <span class="s1">df[</span><span class="s4">&quot;timedelta&quot;</span><span class="s1">] = pd.timedelta_range(</span><span class="s4">&quot;1 day&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s1">)</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">fp)</span>

    <span class="s1">@pytest.mark.skip(reason=</span><span class="s4">&quot;not supported&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">test_duplicate_columns(self</span><span class="s2">, </span><span class="s1">fp):</span>

        <span class="s3"># not currently able to handle duplicate columns</span>
        <span class="s1">df = pd.DataFrame(np.arange(</span><span class="s5">12</span><span class="s1">).reshape(</span><span class="s5">4</span><span class="s2">, </span><span class="s5">3</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=list(</span><span class="s4">&quot;aaa&quot;</span><span class="s1">)).copy()</span>
        <span class="s1">msg = </span><span class="s4">&quot;Cannot create parquet dataset with duplicate column names&quot;</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

    <span class="s2">def </span><span class="s1">test_bool_with_none(self</span><span class="s2">, </span><span class="s1">fp):</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: [</span><span class="s2">True, None, False</span><span class="s1">]})</span>
        <span class="s1">expected = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: [</span><span class="s5">1.0</span><span class="s2">, </span><span class="s1">np.nan</span><span class="s2">, </span><span class="s5">0.0</span><span class="s1">]}</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;float16&quot;</span><span class="s1">)</span>
        <span class="s3"># Fastparquet bug in 0.7.1 makes it so that this dtype becomes</span>
        <span class="s3"># float64</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">expected=expected</span><span class="s2">, </span><span class="s1">check_dtype=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_unsupported(self</span><span class="s2">, </span><span class="s1">fp):</span>

        <span class="s3"># period</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: pd.period_range(</span><span class="s4">&quot;2013&quot;</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">&quot;M&quot;</span><span class="s2">, </span><span class="s1">periods=</span><span class="s5">3</span><span class="s1">)})</span>
        <span class="s3"># error from fastparquet -&gt; don't check exact error message</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, None</span><span class="s1">)</span>

        <span class="s3"># mixed</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: [</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">2.0</span><span class="s1">]})</span>
        <span class="s1">msg = </span><span class="s4">&quot;Can't infer object conversion type&quot;</span>
        <span class="s1">self.check_error_on_write(df</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">ValueError</span><span class="s2">, </span><span class="s1">msg)</span>

    <span class="s2">def </span><span class="s1">test_categorical(self</span><span class="s2">, </span><span class="s1">fp):</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: pd.Categorical(list(</span><span class="s4">&quot;abc&quot;</span><span class="s1">))})</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">fp)</span>

    <span class="s2">def </span><span class="s1">test_filter_row_groups(self</span><span class="s2">, </span><span class="s1">fp):</span>
        <span class="s1">d = {</span><span class="s4">&quot;a&quot;</span><span class="s1">: list(range(</span><span class="s5">0</span><span class="s2">, </span><span class="s5">3</span><span class="s1">))}</span>
        <span class="s1">df = pd.DataFrame(d)</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(path</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">compression=</span><span class="s2">None, </span><span class="s1">row_group_offsets=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">result = read_parquet(path</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">filters=[(</span><span class="s4">&quot;a&quot;</span><span class="s2">, </span><span class="s4">&quot;==&quot;</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)])</span>
        <span class="s2">assert </span><span class="s1">len(result) == </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">test_s3_roundtrip(self</span><span class="s2">, </span><span class="s1">df_compat</span><span class="s2">, </span><span class="s1">s3_resource</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">s3so):</span>
        <span class="s3"># GH #19134</span>
        <span class="s1">check_round_trip(</span>
            <span class="s1">df_compat</span><span class="s2">,</span>
            <span class="s1">fp</span><span class="s2">,</span>
            <span class="s1">path=</span><span class="s4">&quot;s3://pandas-test/fastparquet.parquet&quot;</span><span class="s2">,</span>
            <span class="s1">read_kwargs={</span><span class="s4">&quot;storage_options&quot;</span><span class="s1">: s3so}</span><span class="s2">,</span>
            <span class="s1">write_kwargs={</span><span class="s4">&quot;compression&quot;</span><span class="s1">: </span><span class="s2">None, </span><span class="s4">&quot;storage_options&quot;</span><span class="s1">: s3so}</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_partition_cols_supported(self</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH #23283</span>
        <span class="s1">partition_cols = [</span><span class="s4">&quot;bool&quot;</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">]</span>
        <span class="s1">df = df_full</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean_dir() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(</span>
                <span class="s1">path</span><span class="s2">,</span>
                <span class="s1">engine=</span><span class="s4">&quot;fastparquet&quot;</span><span class="s2">,</span>
                <span class="s1">partition_cols=partition_cols</span><span class="s2">,</span>
                <span class="s1">compression=</span><span class="s2">None,</span>
            <span class="s1">)</span>
            <span class="s2">assert </span><span class="s1">os.path.exists(path)</span>
            <span class="s2">import </span><span class="s1">fastparquet</span>

            <span class="s1">actual_partition_cols = fastparquet.ParquetFile(path</span><span class="s2">, False</span><span class="s1">).cats</span>
            <span class="s2">assert </span><span class="s1">len(actual_partition_cols) == </span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">test_partition_cols_string(self</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH #27117</span>
        <span class="s1">partition_cols = </span><span class="s4">&quot;bool&quot;</span>
        <span class="s1">df = df_full</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean_dir() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(</span>
                <span class="s1">path</span><span class="s2">,</span>
                <span class="s1">engine=</span><span class="s4">&quot;fastparquet&quot;</span><span class="s2">,</span>
                <span class="s1">partition_cols=partition_cols</span><span class="s2">,</span>
                <span class="s1">compression=</span><span class="s2">None,</span>
            <span class="s1">)</span>
            <span class="s2">assert </span><span class="s1">os.path.exists(path)</span>
            <span class="s2">import </span><span class="s1">fastparquet</span>

            <span class="s1">actual_partition_cols = fastparquet.ParquetFile(path</span><span class="s2">, False</span><span class="s1">).cats</span>
            <span class="s2">assert </span><span class="s1">len(actual_partition_cols) == </span><span class="s5">1</span>

    <span class="s2">def </span><span class="s1">test_partition_on_supported(self</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH #23283</span>
        <span class="s1">partition_cols = [</span><span class="s4">&quot;bool&quot;</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">]</span>
        <span class="s1">df = df_full</span>
        <span class="s2">with </span><span class="s1">tm.ensure_clean_dir() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(</span>
                <span class="s1">path</span><span class="s2">,</span>
                <span class="s1">engine=</span><span class="s4">&quot;fastparquet&quot;</span><span class="s2">,</span>
                <span class="s1">compression=</span><span class="s2">None,</span>
                <span class="s1">partition_on=partition_cols</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">assert </span><span class="s1">os.path.exists(path)</span>
            <span class="s2">import </span><span class="s1">fastparquet</span>

            <span class="s1">actual_partition_cols = fastparquet.ParquetFile(path</span><span class="s2">, False</span><span class="s1">).cats</span>
            <span class="s2">assert </span><span class="s1">len(actual_partition_cols) == </span><span class="s5">2</span>

    <span class="s2">def </span><span class="s1">test_error_on_using_partition_cols_and_partition_on(self</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">df_full):</span>
        <span class="s3"># GH #23283</span>
        <span class="s1">partition_cols = [</span><span class="s4">&quot;bool&quot;</span><span class="s2">, </span><span class="s4">&quot;int&quot;</span><span class="s1">]</span>
        <span class="s1">df = df_full</span>
        <span class="s1">msg = (</span>
            <span class="s4">&quot;Cannot use both partition_on and partition_cols. Use partition_cols for &quot;</span>
            <span class="s4">&quot;partitioning data&quot;</span>
        <span class="s1">)</span>
        <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=msg):</span>
            <span class="s2">with </span><span class="s1">tm.ensure_clean_dir() </span><span class="s2">as </span><span class="s1">path:</span>
                <span class="s1">df.to_parquet(</span>
                    <span class="s1">path</span><span class="s2">,</span>
                    <span class="s1">engine=</span><span class="s4">&quot;fastparquet&quot;</span><span class="s2">,</span>
                    <span class="s1">compression=</span><span class="s2">None,</span>
                    <span class="s1">partition_on=partition_cols</span><span class="s2">,</span>
                    <span class="s1">partition_cols=partition_cols</span><span class="s2">,</span>
                <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">test_empty_dataframe(self</span><span class="s2">, </span><span class="s1">fp):</span>
        <span class="s3"># GH #27339</span>
        <span class="s1">df = pd.DataFrame()</span>
        <span class="s1">expected = df.copy()</span>
        <span class="s1">expected.index.name = </span><span class="s4">&quot;index&quot;</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">expected=expected)</span>

    <span class="s2">def </span><span class="s1">test_timezone_aware_index(self</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">timezone_aware_date_list):</span>
        <span class="s1">idx = </span><span class="s5">5 </span><span class="s1">* [timezone_aware_date_list]</span>

        <span class="s1">df = pd.DataFrame(index=idx</span><span class="s2">, </span><span class="s1">data={</span><span class="s4">&quot;index_as_col&quot;</span><span class="s1">: idx})</span>

        <span class="s1">expected = df.copy()</span>
        <span class="s1">expected.index.name = </span><span class="s4">&quot;index&quot;</span>
        <span class="s1">check_round_trip(df</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">expected=expected)</span>

    <span class="s2">def </span><span class="s1">test_use_nullable_dtypes_not_supported(self</span><span class="s2">, </span><span class="s1">monkeypatch</span><span class="s2">, </span><span class="s1">fp):</span>
        <span class="s1">df = pd.DataFrame({</span><span class="s4">&quot;a&quot;</span><span class="s1">: [</span><span class="s5">1</span><span class="s2">, </span><span class="s5">2</span><span class="s1">]})</span>

        <span class="s2">with </span><span class="s1">tm.ensure_clean() </span><span class="s2">as </span><span class="s1">path:</span>
            <span class="s1">df.to_parquet(path)</span>
            <span class="s2">with </span><span class="s1">pytest.raises(ValueError</span><span class="s2">, </span><span class="s1">match=</span><span class="s4">&quot;not supported for the fastparquet&quot;</span><span class="s1">):</span>
                <span class="s1">read_parquet(path</span><span class="s2">, </span><span class="s1">engine=</span><span class="s4">&quot;fastparquet&quot;</span><span class="s2">, </span><span class="s1">use_nullable_dtypes=</span><span class="s2">True</span><span class="s1">)</span>
</pre>
</body>
</html>