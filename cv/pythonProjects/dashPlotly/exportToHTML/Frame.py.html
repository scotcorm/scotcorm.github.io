<html>
<head>
<title>frame.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
frame.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
DataFrame 
--------- 
An efficient 2D container for potentially mixed-type time series or other 
labeled data series. 
 
Similar to its R counterpart, data.frame, except providing automatic data 
alignment and a host of useful data manipulation methods having to do with the 
labeling information 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">import </span><span class="s1">collections</span>
<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">abc</span>
<span class="s2">import </span><span class="s1">datetime</span>
<span class="s2">import </span><span class="s1">functools</span>
<span class="s2">from </span><span class="s1">io </span><span class="s2">import </span><span class="s1">StringIO</span>
<span class="s2">import </span><span class="s1">itertools</span>
<span class="s2">from </span><span class="s1">textwrap </span><span class="s2">import </span><span class="s1">dedent</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">IO</span><span class="s2">,</span>
    <span class="s1">TYPE_CHECKING</span><span class="s2">,</span>
    <span class="s1">Any</span><span class="s2">,</span>
    <span class="s1">Callable</span><span class="s2">,</span>
    <span class="s1">Hashable</span><span class="s2">,</span>
    <span class="s1">Iterable</span><span class="s2">,</span>
    <span class="s1">Iterator</span><span class="s2">,</span>
    <span class="s1">Literal</span><span class="s2">,</span>
    <span class="s1">Sequence</span><span class="s2">,</span>
    <span class="s1">cast</span><span class="s2">,</span>
    <span class="s1">overload</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">import </span><span class="s1">warnings</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">numpy.ma </span><span class="s2">as </span><span class="s1">ma</span>

<span class="s2">from </span><span class="s1">pandas._config </span><span class="s2">import </span><span class="s1">get_option</span>

<span class="s2">from </span><span class="s1">pandas._libs </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">algos </span><span class="s2">as </span><span class="s1">libalgos</span><span class="s2">,</span>
    <span class="s1">lib</span><span class="s2">,</span>
    <span class="s1">properties</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas._libs.hashtable </span><span class="s2">import </span><span class="s1">duplicated</span>
<span class="s2">from </span><span class="s1">pandas._libs.lib </span><span class="s2">import </span><span class="s1">no_default</span>
<span class="s2">from </span><span class="s1">pandas._typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">AggFuncType</span><span class="s2">,</span>
    <span class="s1">AnyArrayLike</span><span class="s2">,</span>
    <span class="s1">ArrayLike</span><span class="s2">,</span>
    <span class="s1">Axes</span><span class="s2">,</span>
    <span class="s1">Axis</span><span class="s2">,</span>
    <span class="s1">ColspaceArgType</span><span class="s2">,</span>
    <span class="s1">CompressionOptions</span><span class="s2">,</span>
    <span class="s1">Dtype</span><span class="s2">,</span>
    <span class="s1">DtypeObj</span><span class="s2">,</span>
    <span class="s1">FilePath</span><span class="s2">,</span>
    <span class="s1">FillnaOptions</span><span class="s2">,</span>
    <span class="s1">FloatFormatType</span><span class="s2">,</span>
    <span class="s1">FormattersType</span><span class="s2">,</span>
    <span class="s1">Frequency</span><span class="s2">,</span>
    <span class="s1">IndexKeyFunc</span><span class="s2">,</span>
    <span class="s1">IndexLabel</span><span class="s2">,</span>
    <span class="s1">Level</span><span class="s2">,</span>
    <span class="s1">PythonFuncType</span><span class="s2">,</span>
    <span class="s1">ReadBuffer</span><span class="s2">,</span>
    <span class="s1">Renamer</span><span class="s2">,</span>
    <span class="s1">Scalar</span><span class="s2">,</span>
    <span class="s1">StorageOptions</span><span class="s2">,</span>
    <span class="s1">Suffixes</span><span class="s2">,</span>
    <span class="s1">TimedeltaConvertibleTypes</span><span class="s2">,</span>
    <span class="s1">TimestampConvertibleTypes</span><span class="s2">,</span>
    <span class="s1">ValueKeyFunc</span><span class="s2">,</span>
    <span class="s1">WriteBuffer</span><span class="s2">,</span>
    <span class="s1">npt</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.compat._optional </span><span class="s2">import </span><span class="s1">import_optional_dependency</span>
<span class="s2">from </span><span class="s1">pandas.compat.numpy </span><span class="s2">import </span><span class="s1">function </span><span class="s2">as </span><span class="s1">nv</span>
<span class="s2">from </span><span class="s1">pandas.util._decorators </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Appender</span><span class="s2">,</span>
    <span class="s1">Substitution</span><span class="s2">,</span>
    <span class="s1">deprecate_kwarg</span><span class="s2">,</span>
    <span class="s1">deprecate_nonkeyword_arguments</span><span class="s2">,</span>
    <span class="s1">doc</span><span class="s2">,</span>
    <span class="s1">rewrite_axis_style_signature</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.util._exceptions </span><span class="s2">import </span><span class="s1">find_stack_level</span>
<span class="s2">from </span><span class="s1">pandas.util._validators </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">validate_ascending</span><span class="s2">,</span>
    <span class="s1">validate_axis_style_args</span><span class="s2">,</span>
    <span class="s1">validate_bool_kwarg</span><span class="s2">,</span>
    <span class="s1">validate_percentile</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">from </span><span class="s1">pandas.core.dtypes.cast </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">can_hold_element</span><span class="s2">,</span>
    <span class="s1">construct_1d_arraylike_from_scalar</span><span class="s2">,</span>
    <span class="s1">construct_2d_arraylike_from_scalar</span><span class="s2">,</span>
    <span class="s1">find_common_type</span><span class="s2">,</span>
    <span class="s1">infer_dtype_from_scalar</span><span class="s2">,</span>
    <span class="s1">invalidate_string_dtypes</span><span class="s2">,</span>
    <span class="s1">maybe_box_native</span><span class="s2">,</span>
    <span class="s1">maybe_downcast_to_dtype</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.common </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ensure_platform_int</span><span class="s2">,</span>
    <span class="s1">infer_dtype_from_object</span><span class="s2">,</span>
    <span class="s1">is_1d_only_ea_dtype</span><span class="s2">,</span>
    <span class="s1">is_1d_only_ea_obj</span><span class="s2">,</span>
    <span class="s1">is_bool_dtype</span><span class="s2">,</span>
    <span class="s1">is_dataclass</span><span class="s2">,</span>
    <span class="s1">is_datetime64_any_dtype</span><span class="s2">,</span>
    <span class="s1">is_dict_like</span><span class="s2">,</span>
    <span class="s1">is_dtype_equal</span><span class="s2">,</span>
    <span class="s1">is_extension_array_dtype</span><span class="s2">,</span>
    <span class="s1">is_float</span><span class="s2">,</span>
    <span class="s1">is_float_dtype</span><span class="s2">,</span>
    <span class="s1">is_hashable</span><span class="s2">,</span>
    <span class="s1">is_integer</span><span class="s2">,</span>
    <span class="s1">is_integer_dtype</span><span class="s2">,</span>
    <span class="s1">is_iterator</span><span class="s2">,</span>
    <span class="s1">is_list_like</span><span class="s2">,</span>
    <span class="s1">is_object_dtype</span><span class="s2">,</span>
    <span class="s1">is_scalar</span><span class="s2">,</span>
    <span class="s1">is_sequence</span><span class="s2">,</span>
    <span class="s1">pandas_dtype</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.dtypes </span><span class="s2">import </span><span class="s1">ExtensionDtype</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.missing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">isna</span><span class="s2">,</span>
    <span class="s1">notna</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">from </span><span class="s1">pandas.core </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">algorithms</span><span class="s2">,</span>
    <span class="s1">common </span><span class="s2">as </span><span class="s1">com</span><span class="s2">,</span>
    <span class="s1">nanops</span><span class="s2">,</span>
    <span class="s1">ops</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.accessor </span><span class="s2">import </span><span class="s1">CachedAccessor</span>
<span class="s2">from </span><span class="s1">pandas.core.apply </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">reconstruct_func</span><span class="s2">,</span>
    <span class="s1">relabel_result</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.array_algos.take </span><span class="s2">import </span><span class="s1">take_2d_multi</span>
<span class="s2">from </span><span class="s1">pandas.core.arraylike </span><span class="s2">import </span><span class="s1">OpsMixin</span>
<span class="s2">from </span><span class="s1">pandas.core.arrays </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">DatetimeArray</span><span class="s2">,</span>
    <span class="s1">ExtensionArray</span><span class="s2">,</span>
    <span class="s1">TimedeltaArray</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.arrays.sparse </span><span class="s2">import </span><span class="s1">SparseFrameAccessor</span>
<span class="s2">from </span><span class="s1">pandas.core.construction </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">extract_array</span><span class="s2">,</span>
    <span class="s1">sanitize_array</span><span class="s2">,</span>
    <span class="s1">sanitize_masked_array</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.generic </span><span class="s2">import </span><span class="s1">NDFrame</span>
<span class="s2">from </span><span class="s1">pandas.core.indexers </span><span class="s2">import </span><span class="s1">check_key_length</span>
<span class="s2">from </span><span class="s1">pandas.core.indexes.api </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">DatetimeIndex</span><span class="s2">,</span>
    <span class="s1">Index</span><span class="s2">,</span>
    <span class="s1">PeriodIndex</span><span class="s2">,</span>
    <span class="s1">default_index</span><span class="s2">,</span>
    <span class="s1">ensure_index</span><span class="s2">,</span>
    <span class="s1">ensure_index_from_sequences</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.indexes.multi </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">MultiIndex</span><span class="s2">,</span>
    <span class="s1">maybe_droplevels</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.indexing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">check_bool_indexer</span><span class="s2">,</span>
    <span class="s1">check_deprecated_indexers</span><span class="s2">,</span>
    <span class="s1">convert_to_index_sliceable</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.internals </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ArrayManager</span><span class="s2">,</span>
    <span class="s1">BlockManager</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.internals.construction </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">arrays_to_mgr</span><span class="s2">,</span>
    <span class="s1">dataclasses_to_dicts</span><span class="s2">,</span>
    <span class="s1">dict_to_mgr</span><span class="s2">,</span>
    <span class="s1">mgr_to_mgr</span><span class="s2">,</span>
    <span class="s1">ndarray_to_mgr</span><span class="s2">,</span>
    <span class="s1">nested_data_to_arrays</span><span class="s2">,</span>
    <span class="s1">rec_array_to_mgr</span><span class="s2">,</span>
    <span class="s1">reorder_arrays</span><span class="s2">,</span>
    <span class="s1">to_arrays</span><span class="s2">,</span>
    <span class="s1">treat_as_nested</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.reshape.melt </span><span class="s2">import </span><span class="s1">melt</span>
<span class="s2">from </span><span class="s1">pandas.core.series </span><span class="s2">import </span><span class="s1">Series</span>
<span class="s2">from </span><span class="s1">pandas.core.shared_docs </span><span class="s2">import </span><span class="s1">_shared_docs</span>
<span class="s2">from </span><span class="s1">pandas.core.sorting </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">get_group_index</span><span class="s2">,</span>
    <span class="s1">lexsort_indexer</span><span class="s2">,</span>
    <span class="s1">nargsort</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">from </span><span class="s1">pandas.io.common </span><span class="s2">import </span><span class="s1">get_handle</span>
<span class="s2">from </span><span class="s1">pandas.io.formats </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">console</span><span class="s2">,</span>
    <span class="s1">format </span><span class="s2">as </span><span class="s1">fmt</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.io.formats.info </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">INFO_DOCSTRING</span><span class="s2">,</span>
    <span class="s1">DataFrameInfo</span><span class="s2">,</span>
    <span class="s1">frame_sub_kwargs</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">import </span><span class="s1">pandas.plotting</span>

<span class="s2">if </span><span class="s1">TYPE_CHECKING:</span>

    <span class="s2">from </span><span class="s1">pandas.core.groupby.generic </span><span class="s2">import </span><span class="s1">DataFrameGroupBy</span>
    <span class="s2">from </span><span class="s1">pandas.core.internals </span><span class="s2">import </span><span class="s1">SingleDataManager</span>
    <span class="s2">from </span><span class="s1">pandas.core.resample </span><span class="s2">import </span><span class="s1">Resampler</span>

    <span class="s2">from </span><span class="s1">pandas.io.formats.style </span><span class="s2">import </span><span class="s1">Styler</span>

<span class="s3"># ---------------------------------------------------------------------</span>
<span class="s3"># Docstring templates</span>

<span class="s1">_shared_doc_kwargs = {</span>
    <span class="s4">&quot;axes&quot;</span><span class="s1">: </span><span class="s4">&quot;index, columns&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;klass&quot;</span><span class="s1">: </span><span class="s4">&quot;DataFrame&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;axes_single_arg&quot;</span><span class="s1">: </span><span class="s4">&quot;{0 or 'index', 1 or 'columns'}&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;axis&quot;</span><span class="s1">: </span><span class="s4">&quot;&quot;&quot;axis : {0 or 'index', 1 or 'columns'}, default 0 
        If 0 or 'index': apply function to each column. 
        If 1 or 'columns': apply function to each row.&quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;inplace&quot;</span><span class="s1">: </span><span class="s4">&quot;&quot;&quot; 
    inplace : bool, default False 
        If True, performs operation inplace and returns None.&quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;optional_by&quot;</span><span class="s1">: </span><span class="s4">&quot;&quot;&quot; 
        by : str or list of str 
            Name or list of names to sort by. 
 
            - if `axis` is 0 or `'index'` then `by` may contain index 
              levels and/or column labels. 
            - if `axis` is 1 or `'columns'` then `by` may contain column 
              levels and/or index labels.&quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;optional_labels&quot;</span><span class="s1">: </span><span class="s4">&quot;&quot;&quot;labels : array-like, optional 
            New labels / index to conform the axis specified by 'axis' to.&quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;optional_axis&quot;</span><span class="s1">: </span><span class="s4">&quot;&quot;&quot;axis : int or str, optional 
            Axis to target. Can be either the axis name ('index', 'columns') 
            or number (0, 1).&quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s4">&quot;replace_iloc&quot;</span><span class="s1">: </span><span class="s4">&quot;&quot;&quot; 
    This differs from updating with ``.loc`` or ``.iloc``, which require 
    you to specify a location to update with some value.&quot;&quot;&quot;</span><span class="s2">,</span>
<span class="s1">}</span>

<span class="s1">_numeric_only_doc = </span><span class="s4">&quot;&quot;&quot;numeric_only : bool or None, default None 
    Include only float, int, boolean data. If None, will attempt to use 
    everything, then use only numeric data 
&quot;&quot;&quot;</span>

<span class="s1">_merge_doc = </span><span class="s4">&quot;&quot;&quot; 
Merge DataFrame or named Series objects with a database-style join. 
 
A named Series object is treated as a DataFrame with a single named column. 
 
The join is done on columns or indexes. If joining columns on 
columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes 
on indexes or indexes on a column or columns, the index will be passed on. 
When performing a cross merge, no column specifications to merge on are 
allowed. 
 
.. warning:: 
 
    If both key columns contain rows where the key is a null value, those 
    rows will be matched against each other. This is different from usual SQL 
    join behaviour and can lead to unexpected results. 
 
Parameters 
----------%s 
right : DataFrame or named Series 
    Object to merge with. 
how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner' 
    Type of merge to be performed. 
 
    * left: use only keys from left frame, similar to a SQL left outer join; 
      preserve key order. 
    * right: use only keys from right frame, similar to a SQL right outer join; 
      preserve key order. 
    * outer: use union of keys from both frames, similar to a SQL full outer 
      join; sort keys lexicographically. 
    * inner: use intersection of keys from both frames, similar to a SQL inner 
      join; preserve the order of the left keys. 
    * cross: creates the cartesian product from both frames, preserves the order 
      of the left keys. 
 
      .. versionadded:: 1.2.0 
 
on : label or list 
    Column or index level names to join on. These must be found in both 
    DataFrames. If `on` is None and not merging on indexes then this defaults 
    to the intersection of the columns in both DataFrames. 
left_on : label or list, or array-like 
    Column or index level names to join on in the left DataFrame. Can also 
    be an array or list of arrays of the length of the left DataFrame. 
    These arrays are treated as if they are columns. 
right_on : label or list, or array-like 
    Column or index level names to join on in the right DataFrame. Can also 
    be an array or list of arrays of the length of the right DataFrame. 
    These arrays are treated as if they are columns. 
left_index : bool, default False 
    Use the index from the left DataFrame as the join key(s). If it is a 
    MultiIndex, the number of keys in the other DataFrame (either the index 
    or a number of columns) must match the number of levels. 
right_index : bool, default False 
    Use the index from the right DataFrame as the join key. Same caveats as 
    left_index. 
sort : bool, default False 
    Sort the join keys lexicographically in the result DataFrame. If False, 
    the order of the join keys depends on the join type (how keyword). 
suffixes : list-like, default is (&quot;_x&quot;, &quot;_y&quot;) 
    A length-2 sequence where each element is optionally a string 
    indicating the suffix to add to overlapping column names in 
    `left` and `right` respectively. Pass a value of `None` instead 
    of a string to indicate that the column name from `left` or 
    `right` should be left as-is, with no suffix. At least one of the 
    values must not be None. 
copy : bool, default True 
    If False, avoid copy if possible. 
indicator : bool or str, default False 
    If True, adds a column to the output DataFrame called &quot;_merge&quot; with 
    information on the source of each row. The column can be given a different 
    name by providing a string argument. The column will have a Categorical 
    type with the value of &quot;left_only&quot; for observations whose merge key only 
    appears in the left DataFrame, &quot;right_only&quot; for observations 
    whose merge key only appears in the right DataFrame, and &quot;both&quot; 
    if the observation's merge key is found in both DataFrames. 
 
validate : str, optional 
    If specified, checks if merge is of specified type. 
 
    * &quot;one_to_one&quot; or &quot;1:1&quot;: check if merge keys are unique in both 
      left and right datasets. 
    * &quot;one_to_many&quot; or &quot;1:m&quot;: check if merge keys are unique in left 
      dataset. 
    * &quot;many_to_one&quot; or &quot;m:1&quot;: check if merge keys are unique in right 
      dataset. 
    * &quot;many_to_many&quot; or &quot;m:m&quot;: allowed, but does not result in checks. 
 
Returns 
------- 
DataFrame 
    A DataFrame of the two merged objects. 
 
See Also 
-------- 
merge_ordered : Merge with optional filling/interpolation. 
merge_asof : Merge on nearest keys. 
DataFrame.join : Similar method using indices. 
 
Notes 
----- 
Support for specifying index levels as the `on`, `left_on`, and 
`right_on` parameters was added in version 0.23.0 
Support for merging named Series objects was added in version 0.24.0 
 
Examples 
-------- 
&gt;&gt;&gt; df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'], 
...                     'value': [1, 2, 3, 5]}) 
&gt;&gt;&gt; df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'], 
...                     'value': [5, 6, 7, 8]}) 
&gt;&gt;&gt; df1 
    lkey value 
0   foo      1 
1   bar      2 
2   baz      3 
3   foo      5 
&gt;&gt;&gt; df2 
    rkey value 
0   foo      5 
1   bar      6 
2   baz      7 
3   foo      8 
 
Merge df1 and df2 on the lkey and rkey columns. The value columns have 
the default suffixes, _x and _y, appended. 
 
&gt;&gt;&gt; df1.merge(df2, left_on='lkey', right_on='rkey') 
  lkey  value_x rkey  value_y 
0  foo        1  foo        5 
1  foo        1  foo        8 
2  foo        5  foo        5 
3  foo        5  foo        8 
4  bar        2  bar        6 
5  baz        3  baz        7 
 
Merge DataFrames df1 and df2 with specified left and right suffixes 
appended to any overlapping columns. 
 
&gt;&gt;&gt; df1.merge(df2, left_on='lkey', right_on='rkey', 
...           suffixes=('_left', '_right')) 
  lkey  value_left rkey  value_right 
0  foo           1  foo            5 
1  foo           1  foo            8 
2  foo           5  foo            5 
3  foo           5  foo            8 
4  bar           2  bar            6 
5  baz           3  baz            7 
 
Merge DataFrames df1 and df2, but raise an exception if the DataFrames have 
any overlapping columns. 
 
&gt;&gt;&gt; df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False)) 
Traceback (most recent call last): 
... 
ValueError: columns overlap but no suffix specified: 
    Index(['value'], dtype='object') 
 
&gt;&gt;&gt; df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]}) 
&gt;&gt;&gt; df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]}) 
&gt;&gt;&gt; df1 
      a  b 
0   foo  1 
1   bar  2 
&gt;&gt;&gt; df2 
      a  c 
0   foo  3 
1   baz  4 
 
&gt;&gt;&gt; df1.merge(df2, how='inner', on='a') 
      a  b  c 
0   foo  1  3 
 
&gt;&gt;&gt; df1.merge(df2, how='left', on='a') 
      a  b  c 
0   foo  1  3.0 
1   bar  2  NaN 
 
&gt;&gt;&gt; df1 = pd.DataFrame({'left': ['foo', 'bar']}) 
&gt;&gt;&gt; df2 = pd.DataFrame({'right': [7, 8]}) 
&gt;&gt;&gt; df1 
    left 
0   foo 
1   bar 
&gt;&gt;&gt; df2 
    right 
0   7 
1   8 
 
&gt;&gt;&gt; df1.merge(df2, how='cross') 
   left  right 
0   foo      7 
1   foo      8 
2   bar      7 
3   bar      8 
&quot;&quot;&quot;</span>


<span class="s3"># -----------------------------------------------------------------------</span>
<span class="s3"># DataFrame class</span>


<span class="s2">class </span><span class="s1">DataFrame(NDFrame</span><span class="s2">, </span><span class="s1">OpsMixin):</span>
    <span class="s0">&quot;&quot;&quot; 
    Two-dimensional, size-mutable, potentially heterogeneous tabular data. 
 
    Data structure also contains labeled axes (rows and columns). 
    Arithmetic operations align on both row and column labels. Can be 
    thought of as a dict-like container for Series objects. The primary 
    pandas data structure. 
 
    Parameters 
    ---------- 
    data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame 
        Dict can contain Series, arrays, constants, dataclass or list-like objects. If 
        data is a dict, column order follows insertion-order. If a dict contains Series 
        which have an index defined, it is aligned by its index. 
 
        .. versionchanged:: 0.25.0 
           If data is a list of dicts, column order follows insertion-order. 
 
    index : Index or array-like 
        Index to use for resulting frame. Will default to RangeIndex if 
        no indexing information part of input data and no index provided. 
    columns : Index or array-like 
        Column labels to use for resulting frame when data does not have them, 
        defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels, 
        will perform column selection instead. 
    dtype : dtype, default None 
        Data type to force. Only a single dtype is allowed. If None, infer. 
    copy : bool or None, default None 
        Copy data from inputs. 
        For dict data, the default of None behaves like ``copy=True``.  For DataFrame 
        or 2d ndarray input, the default of None behaves like ``copy=False``. 
 
        .. versionchanged:: 1.3.0 
 
    See Also 
    -------- 
    DataFrame.from_records : Constructor from tuples, also record arrays. 
    DataFrame.from_dict : From dicts of Series, arrays, or dicts. 
    read_csv : Read a comma-separated values (csv) file into DataFrame. 
    read_table : Read general delimited file into DataFrame. 
    read_clipboard : Read text from clipboard into DataFrame. 
 
    Examples 
    -------- 
    Constructing DataFrame from a dictionary. 
 
    &gt;&gt;&gt; d = {'col1': [1, 2], 'col2': [3, 4]} 
    &gt;&gt;&gt; df = pd.DataFrame(data=d) 
    &gt;&gt;&gt; df 
       col1  col2 
    0     1     3 
    1     2     4 
 
    Notice that the inferred dtype is int64. 
 
    &gt;&gt;&gt; df.dtypes 
    col1    int64 
    col2    int64 
    dtype: object 
 
    To enforce a single dtype: 
 
    &gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8) 
    &gt;&gt;&gt; df.dtypes 
    col1    int8 
    col2    int8 
    dtype: object 
 
    Constructing DataFrame from a dictionary including Series: 
 
    &gt;&gt;&gt; d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])} 
    &gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3]) 
       col1  col2 
    0     0   NaN 
    1     1   NaN 
    2     2   2.0 
    3     3   3.0 
 
    Constructing DataFrame from numpy ndarray: 
 
    &gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), 
    ...                    columns=['a', 'b', 'c']) 
    &gt;&gt;&gt; df2 
       a  b  c 
    0  1  2  3 
    1  4  5  6 
    2  7  8  9 
 
    Constructing DataFrame from a numpy ndarray that has labeled columns: 
 
    &gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)], 
    ...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)]) 
    &gt;&gt;&gt; df3 = pd.DataFrame(data, columns=['c', 'a']) 
    ... 
    &gt;&gt;&gt; df3 
       c  a 
    0  3  1 
    1  6  4 
    2  9  7 
 
    Constructing DataFrame from dataclass: 
 
    &gt;&gt;&gt; from dataclasses import make_dataclass 
    &gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)]) 
    &gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)]) 
       x  y 
    0  0  0 
    1  0  3 
    2  2  3 
    &quot;&quot;&quot;</span>

    <span class="s1">_internal_names_set = {</span><span class="s4">&quot;columns&quot;</span><span class="s2">, </span><span class="s4">&quot;index&quot;</span><span class="s1">} | NDFrame._internal_names_set</span>
    <span class="s1">_typ = </span><span class="s4">&quot;dataframe&quot;</span>
    <span class="s1">_HANDLED_TYPES = (Series</span><span class="s2">, </span><span class="s1">Index</span><span class="s2">, </span><span class="s1">ExtensionArray</span><span class="s2">, </span><span class="s1">np.ndarray)</span>
    <span class="s1">_accessors: set[str] = {</span><span class="s4">&quot;sparse&quot;</span><span class="s1">}</span>
    <span class="s1">_hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])</span>
    <span class="s1">_mgr: BlockManager | ArrayManager</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_constructor(self) -&gt; type[DataFrame]:</span>
        <span class="s2">return </span><span class="s1">DataFrame</span>

    <span class="s1">_constructor_sliced: type[Series] = Series</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Constructors</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">data=</span><span class="s2">None,</span>
        <span class="s1">index: Axes | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">columns: Axes | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">dtype: Dtype | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">copy: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">):</span>

        <span class="s2">if </span><span class="s1">data </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">data = {}</span>
        <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">dtype = self._validate_dtype(dtype)</span>

        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s1">data = data._mgr</span>

        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">(BlockManager</span><span class="s2">, </span><span class="s1">ArrayManager)):</span>
            <span class="s3"># first check if a Manager is passed without any other arguments</span>
            <span class="s3"># -&gt; use fastpath (without checking Manager type)</span>
            <span class="s2">if </span><span class="s1">index </span><span class="s2">is None and </span><span class="s1">columns </span><span class="s2">is None and </span><span class="s1">dtype </span><span class="s2">is None and not </span><span class="s1">copy:</span>
                <span class="s3"># GH#33357 fastpath</span>
                <span class="s1">NDFrame.__init__(self</span><span class="s2">, </span><span class="s1">data)</span>
                <span class="s2">return</span>

        <span class="s1">manager = get_option(</span><span class="s4">&quot;mode.data_manager&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">copy </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">dict):</span>
                <span class="s3"># retain pre-GH#38939 default behavior</span>
                <span class="s1">copy = </span><span class="s2">True</span>
            <span class="s2">elif </span><span class="s1">(</span>
                <span class="s1">manager == </span><span class="s4">&quot;array&quot;</span>
                <span class="s2">and </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">ExtensionArray))</span>
                <span class="s2">and </span><span class="s1">data.ndim == </span><span class="s5">2</span>
            <span class="s1">):</span>
                <span class="s3"># INFO(ArrayManager) by default copy the 2D input array to get</span>
                <span class="s3"># contiguous 1D arrays</span>
                <span class="s1">copy = </span><span class="s2">True</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">copy = </span><span class="s2">False</span>

        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">(BlockManager</span><span class="s2">, </span><span class="s1">ArrayManager)):</span>
            <span class="s1">mgr = self._init_mgr(</span>
                <span class="s1">data</span><span class="s2">, </span><span class="s1">axes={</span><span class="s4">&quot;index&quot;</span><span class="s1">: index</span><span class="s2">, </span><span class="s4">&quot;columns&quot;</span><span class="s1">: columns}</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">copy=copy</span>
            <span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s3"># GH#38939 de facto copy defaults to False only in non-dict cases</span>
            <span class="s1">mgr = dict_to_mgr(data</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">copy=copy</span><span class="s2">, </span><span class="s1">typ=manager)</span>
        <span class="s2">elif </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">ma.MaskedArray):</span>
            <span class="s2">import </span><span class="s1">numpy.ma.mrecords </span><span class="s2">as </span><span class="s1">mrecords</span>

            <span class="s3"># masked recarray</span>
            <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">mrecords.MaskedRecords):</span>
                <span class="s1">mgr = rec_array_to_mgr(</span>
                    <span class="s1">data</span><span class="s2">,</span>
                    <span class="s1">index</span><span class="s2">,</span>
                    <span class="s1">columns</span><span class="s2">,</span>
                    <span class="s1">dtype</span><span class="s2">,</span>
                    <span class="s1">copy</span><span class="s2">,</span>
                    <span class="s1">typ=manager</span><span class="s2">,</span>
                <span class="s1">)</span>
                <span class="s1">warnings.warn(</span>
                    <span class="s4">&quot;Support for MaskedRecords is deprecated and will be &quot;</span>
                    <span class="s4">&quot;removed in a future version.  Pass &quot;</span>
                    <span class="s4">&quot;{name: data[name] for name in data.dtype.names} instead.&quot;</span><span class="s2">,</span>
                    <span class="s1">FutureWarning</span><span class="s2">,</span>
                    <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
                <span class="s1">)</span>

            <span class="s3"># a masked array</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">data = sanitize_masked_array(data)</span>
                <span class="s1">mgr = ndarray_to_mgr(</span>
                    <span class="s1">data</span><span class="s2">,</span>
                    <span class="s1">index</span><span class="s2">,</span>
                    <span class="s1">columns</span><span class="s2">,</span>
                    <span class="s1">dtype=dtype</span><span class="s2">,</span>
                    <span class="s1">copy=copy</span><span class="s2">,</span>
                    <span class="s1">typ=manager</span><span class="s2">,</span>
                <span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">Series</span><span class="s2">, </span><span class="s1">Index</span><span class="s2">, </span><span class="s1">ExtensionArray)):</span>
            <span class="s2">if </span><span class="s1">data.dtype.names:</span>
                <span class="s3"># i.e. numpy structured array</span>
                <span class="s1">data = cast(np.ndarray</span><span class="s2">, </span><span class="s1">data)</span>
                <span class="s1">mgr = rec_array_to_mgr(</span>
                    <span class="s1">data</span><span class="s2">,</span>
                    <span class="s1">index</span><span class="s2">,</span>
                    <span class="s1">columns</span><span class="s2">,</span>
                    <span class="s1">dtype</span><span class="s2">,</span>
                    <span class="s1">copy</span><span class="s2">,</span>
                    <span class="s1">typ=manager</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s2">elif </span><span class="s1">getattr(data</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, None</span><span class="s1">) </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s3"># i.e. Series/Index with non-None name</span>
                <span class="s1">mgr = dict_to_mgr(</span>
                    <span class="s3"># error: Item &quot;ndarray&quot; of &quot;Union[ndarray, Series, Index]&quot; has no</span>
                    <span class="s3"># attribute &quot;name&quot;</span>
                    <span class="s1">{data.name: data}</span><span class="s2">,  </span><span class="s3"># type: ignore[union-attr]</span>
                    <span class="s1">index</span><span class="s2">,</span>
                    <span class="s1">columns</span><span class="s2">,</span>
                    <span class="s1">dtype=dtype</span><span class="s2">,</span>
                    <span class="s1">typ=manager</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">mgr = ndarray_to_mgr(</span>
                    <span class="s1">data</span><span class="s2">,</span>
                    <span class="s1">index</span><span class="s2">,</span>
                    <span class="s1">columns</span><span class="s2">,</span>
                    <span class="s1">dtype=dtype</span><span class="s2">,</span>
                    <span class="s1">copy=copy</span><span class="s2">,</span>
                    <span class="s1">typ=manager</span><span class="s2">,</span>
                <span class="s1">)</span>

        <span class="s3"># For data is list-like, or Iterable (will consume into list)</span>
        <span class="s2">elif </span><span class="s1">is_list_like(data):</span>
            <span class="s2">if not </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">(abc.Sequence</span><span class="s2">, </span><span class="s1">ExtensionArray)):</span>
                <span class="s2">if </span><span class="s1">hasattr(data</span><span class="s2">, </span><span class="s4">&quot;__array__&quot;</span><span class="s1">):</span>
                    <span class="s3"># GH#44616 big perf improvement for e.g. pytorch tensor</span>
                    <span class="s1">data = np.asarray(data)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">data = list(data)</span>
            <span class="s2">if </span><span class="s1">len(data) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">is_dataclass(data[</span><span class="s5">0</span><span class="s1">]):</span>
                    <span class="s1">data = dataclasses_to_dicts(data)</span>
                <span class="s2">if not </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">np.ndarray) </span><span class="s2">and </span><span class="s1">treat_as_nested(data):</span>
                    <span class="s3"># exclude ndarray as we may have cast it a few lines above</span>
                    <span class="s2">if </span><span class="s1">columns </span><span class="s2">is not None</span><span class="s1">:</span>
                        <span class="s3"># error: Argument 1 to &quot;ensure_index&quot; has incompatible type</span>
                        <span class="s3"># &quot;Collection[Any]&quot;; expected &quot;Union[Union[Union[ExtensionArray,</span>
                        <span class="s3"># ndarray], Index, Series], Sequence[Any]]&quot;</span>
                        <span class="s1">columns = ensure_index(columns)  </span><span class="s3"># type: ignore[arg-type]</span>
                    <span class="s1">arrays</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">index = nested_data_to_arrays(</span>
                        <span class="s3"># error: Argument 3 to &quot;nested_data_to_arrays&quot; has incompatible</span>
                        <span class="s3"># type &quot;Optional[Collection[Any]]&quot;; expected &quot;Optional[Index]&quot;</span>
                        <span class="s1">data</span><span class="s2">,</span>
                        <span class="s1">columns</span><span class="s2">,</span>
                        <span class="s1">index</span><span class="s2">,  </span><span class="s3"># type: ignore[arg-type]</span>
                        <span class="s1">dtype</span><span class="s2">,</span>
                    <span class="s1">)</span>
                    <span class="s1">mgr = arrays_to_mgr(</span>
                        <span class="s1">arrays</span><span class="s2">,</span>
                        <span class="s1">columns</span><span class="s2">,</span>
                        <span class="s1">index</span><span class="s2">,</span>
                        <span class="s1">dtype=dtype</span><span class="s2">,</span>
                        <span class="s1">typ=manager</span><span class="s2">,</span>
                    <span class="s1">)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">mgr = ndarray_to_mgr(</span>
                        <span class="s1">data</span><span class="s2">,</span>
                        <span class="s1">index</span><span class="s2">,</span>
                        <span class="s1">columns</span><span class="s2">,</span>
                        <span class="s1">dtype=dtype</span><span class="s2">,</span>
                        <span class="s1">copy=copy</span><span class="s2">,</span>
                        <span class="s1">typ=manager</span><span class="s2">,</span>
                    <span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">mgr = dict_to_mgr(</span>
                    <span class="s1">{}</span><span class="s2">,</span>
                    <span class="s1">index</span><span class="s2">,</span>
                    <span class="s1">columns</span><span class="s2">,</span>
                    <span class="s1">dtype=dtype</span><span class="s2">,</span>
                    <span class="s1">typ=manager</span><span class="s2">,</span>
                <span class="s1">)</span>
        <span class="s3"># For data is scalar</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">index </span><span class="s2">is None or </span><span class="s1">columns </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;DataFrame constructor not properly called!&quot;</span><span class="s1">)</span>

            <span class="s3"># Argument 1 to &quot;ensure_index&quot; has incompatible type &quot;Collection[Any]&quot;;</span>
            <span class="s3"># expected &quot;Union[Union[Union[ExtensionArray, ndarray],</span>
            <span class="s3"># Index, Series], Sequence[Any]]&quot;</span>
            <span class="s1">index = ensure_index(index)  </span><span class="s3"># type: ignore[arg-type]</span>
            <span class="s3"># Argument 1 to &quot;ensure_index&quot; has incompatible type &quot;Collection[Any]&quot;;</span>
            <span class="s3"># expected &quot;Union[Union[Union[ExtensionArray, ndarray],</span>
            <span class="s3"># Index, Series], Sequence[Any]]&quot;</span>
            <span class="s1">columns = ensure_index(columns)  </span><span class="s3"># type: ignore[arg-type]</span>

            <span class="s2">if not </span><span class="s1">dtype:</span>
                <span class="s1">dtype</span><span class="s2">, </span><span class="s1">_ = infer_dtype_from_scalar(data</span><span class="s2">, </span><span class="s1">pandas_dtype=</span><span class="s2">True</span><span class="s1">)</span>

            <span class="s3"># For data is a scalar extension dtype</span>
            <span class="s2">if </span><span class="s1">isinstance(dtype</span><span class="s2">, </span><span class="s1">ExtensionDtype):</span>
                <span class="s3"># TODO(EA2D): special case not needed with 2D EAs</span>

                <span class="s1">values = [</span>
                    <span class="s1">construct_1d_arraylike_from_scalar(data</span><span class="s2">, </span><span class="s1">len(index)</span><span class="s2">, </span><span class="s1">dtype)</span>
                    <span class="s2">for </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">range(len(columns))</span>
                <span class="s1">]</span>
                <span class="s1">mgr = arrays_to_mgr(values</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s2">None, </span><span class="s1">typ=manager)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">arr2d = construct_2d_arraylike_from_scalar(</span>
                    <span class="s1">data</span><span class="s2">,</span>
                    <span class="s1">len(index)</span><span class="s2">,</span>
                    <span class="s1">len(columns)</span><span class="s2">,</span>
                    <span class="s1">dtype</span><span class="s2">,</span>
                    <span class="s1">copy</span><span class="s2">,</span>
                <span class="s1">)</span>

                <span class="s1">mgr = ndarray_to_mgr(</span>
                    <span class="s1">arr2d</span><span class="s2">,</span>
                    <span class="s1">index</span><span class="s2">,</span>
                    <span class="s1">columns</span><span class="s2">,</span>
                    <span class="s1">dtype=arr2d.dtype</span><span class="s2">,</span>
                    <span class="s1">copy=</span><span class="s2">False,</span>
                    <span class="s1">typ=manager</span><span class="s2">,</span>
                <span class="s1">)</span>

        <span class="s3"># ensure correct Manager type according to settings</span>
        <span class="s1">mgr = mgr_to_mgr(mgr</span><span class="s2">, </span><span class="s1">typ=manager)</span>

        <span class="s1">NDFrame.__init__(self</span><span class="s2">, </span><span class="s1">mgr)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">axes(self) -&gt; list[Index]:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a list representing the axes of the DataFrame. 
 
        It has the row axis labels and column axis labels as the only members. 
        They are returned in that order. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]}) 
        &gt;&gt;&gt; df.axes 
        [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'], 
        dtype='object')] 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">[self.index</span><span class="s2">, </span><span class="s1">self.columns]</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">shape(self) -&gt; tuple[int</span><span class="s2">, </span><span class="s1">int]:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a tuple representing the dimensionality of the DataFrame. 
 
        See Also 
        -------- 
        ndarray.shape : Tuple of array dimensions. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]}) 
        &gt;&gt;&gt; df.shape 
        (2, 2) 
 
        &gt;&gt;&gt; df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4], 
        ...                    'col3': [5, 6]}) 
        &gt;&gt;&gt; df.shape 
        (2, 3) 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">len(self.index)</span><span class="s2">, </span><span class="s1">len(self.columns)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_is_homogeneous_type(self) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot; 
        Whether all the columns in a DataFrame have the same type. 
 
        Returns 
        ------- 
        bool 
 
        See Also 
        -------- 
        Index._is_homogeneous_type : Whether the object has a single 
            dtype. 
        MultiIndex._is_homogeneous_type : Whether all the levels of a 
            MultiIndex have the same dtype. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [3, 4]})._is_homogeneous_type 
        True 
        &gt;&gt;&gt; DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [3.0, 4.0]})._is_homogeneous_type 
        False 
 
        Items with the same type but different sizes are considered 
        different types. 
 
        &gt;&gt;&gt; DataFrame({ 
        ...    &quot;A&quot;: np.array([1, 2], dtype=np.int32), 
        ...    &quot;B&quot;: np.array([1, 2], dtype=np.int64)})._is_homogeneous_type 
        False 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(self._mgr</span><span class="s2">, </span><span class="s1">ArrayManager):</span>
            <span class="s2">return </span><span class="s1">len({arr.dtype </span><span class="s2">for </span><span class="s1">arr </span><span class="s2">in </span><span class="s1">self._mgr.arrays}) == </span><span class="s5">1</span>
        <span class="s2">if </span><span class="s1">self._mgr.any_extension_types:</span>
            <span class="s2">return </span><span class="s1">len({block.dtype </span><span class="s2">for </span><span class="s1">block </span><span class="s2">in </span><span class="s1">self._mgr.blocks}) == </span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return not </span><span class="s1">self._is_mixed_type</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_can_fast_transpose(self) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot; 
        Can we transpose this DataFrame without creating any new array objects. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(self._mgr</span><span class="s2">, </span><span class="s1">ArrayManager):</span>
            <span class="s2">return False</span>
        <span class="s1">blocks = self._mgr.blocks</span>
        <span class="s2">if </span><span class="s1">len(blocks) != </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return False</span>

        <span class="s1">dtype = blocks[</span><span class="s5">0</span><span class="s1">].dtype</span>
        <span class="s3"># TODO(EA2D) special case would be unnecessary with 2D EAs</span>
        <span class="s2">return not </span><span class="s1">is_1d_only_ea_dtype(dtype)</span>

    <span class="s3"># error: Return type &quot;Union[ndarray, DatetimeArray, TimedeltaArray]&quot; of</span>
    <span class="s3"># &quot;_values&quot; incompatible with return type &quot;ndarray&quot; in supertype &quot;NDFrame&quot;</span>
    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_values(  </span><span class="s3"># type: ignore[override]</span>
        <span class="s1">self</span><span class="s2">,</span>
    <span class="s1">) -&gt; np.ndarray | DatetimeArray | TimedeltaArray:</span>
        <span class="s0">&quot;&quot;&quot; 
        Analogue to ._values that may return a 2D ExtensionArray. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._consolidate_inplace()</span>

        <span class="s1">mgr = self._mgr</span>

        <span class="s2">if </span><span class="s1">isinstance(mgr</span><span class="s2">, </span><span class="s1">ArrayManager):</span>
            <span class="s2">if </span><span class="s1">len(mgr.arrays) == </span><span class="s5">1 </span><span class="s2">and not </span><span class="s1">is_1d_only_ea_obj(mgr.arrays[</span><span class="s5">0</span><span class="s1">]):</span>
                <span class="s3"># error: Item &quot;ExtensionArray&quot; of &quot;Union[ndarray, ExtensionArray]&quot;</span>
                <span class="s3"># has no attribute &quot;reshape&quot;</span>
                <span class="s2">return </span><span class="s1">mgr.arrays[</span><span class="s5">0</span><span class="s1">].reshape(-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)  </span><span class="s3"># type: ignore[union-attr]</span>
            <span class="s2">return </span><span class="s1">self.values</span>

        <span class="s1">blocks = mgr.blocks</span>
        <span class="s2">if </span><span class="s1">len(blocks) != </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.values</span>

        <span class="s1">arr = blocks[</span><span class="s5">0</span><span class="s1">].values</span>
        <span class="s2">if </span><span class="s1">arr.ndim == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3"># non-2D ExtensionArray</span>
            <span class="s2">return </span><span class="s1">self.values</span>

        <span class="s3"># more generally, whatever we allow in NDArrayBackedExtensionBlock</span>
        <span class="s1">arr = cast(</span><span class="s4">&quot;np.ndarray | DatetimeArray | TimedeltaArray&quot;</span><span class="s2">, </span><span class="s1">arr)</span>
        <span class="s2">return </span><span class="s1">arr.T</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Rendering Methods</span>

    <span class="s2">def </span><span class="s1">_repr_fits_vertical_(self) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot; 
        Check length against max_rows. 
        &quot;&quot;&quot;</span>
        <span class="s1">max_rows = get_option(</span><span class="s4">&quot;display.max_rows&quot;</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">len(self) &lt;= max_rows</span>

    <span class="s2">def </span><span class="s1">_repr_fits_horizontal_(self</span><span class="s2">, </span><span class="s1">ignore_width: bool = </span><span class="s2">False</span><span class="s1">) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot; 
        Check if full repr fits in horizontal boundaries imposed by the display 
        options width and max_columns. 
 
        In case of non-interactive session, no boundaries apply. 
 
        `ignore_width` is here so ipynb+HTML output can behave the way 
        users expect. display.max_columns remains in effect. 
        GH3541, GH3573 
        &quot;&quot;&quot;</span>
        <span class="s1">width</span><span class="s2">, </span><span class="s1">height = console.get_console_size()</span>
        <span class="s1">max_columns = get_option(</span><span class="s4">&quot;display.max_columns&quot;</span><span class="s1">)</span>
        <span class="s1">nb_columns = len(self.columns)</span>

        <span class="s3"># exceed max columns</span>
        <span class="s2">if </span><span class="s1">(max_columns </span><span class="s2">and </span><span class="s1">nb_columns &gt; max_columns) </span><span class="s2">or </span><span class="s1">(</span>
            <span class="s1">(</span><span class="s2">not </span><span class="s1">ignore_width) </span><span class="s2">and </span><span class="s1">width </span><span class="s2">and </span><span class="s1">nb_columns &gt; (width // </span><span class="s5">2</span><span class="s1">)</span>
        <span class="s1">):</span>
            <span class="s2">return False</span>

        <span class="s3"># used by repr_html under IPython notebook or scripts ignore terminal</span>
        <span class="s3"># dims</span>
        <span class="s2">if </span><span class="s1">ignore_width </span><span class="s2">or not </span><span class="s1">console.in_interactive_session():</span>
            <span class="s2">return True</span>

        <span class="s2">if </span><span class="s1">get_option(</span><span class="s4">&quot;display.width&quot;</span><span class="s1">) </span><span class="s2">is not None or </span><span class="s1">console.in_ipython_frontend():</span>
            <span class="s3"># check at least the column row for excessive width</span>
            <span class="s1">max_rows = </span><span class="s5">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">max_rows = get_option(</span><span class="s4">&quot;display.max_rows&quot;</span><span class="s1">)</span>

        <span class="s3"># when auto-detecting, so width=None and not in ipython front end</span>
        <span class="s3"># check whether repr fits horizontal by actually checking</span>
        <span class="s3"># the width of the rendered repr</span>
        <span class="s1">buf = StringIO()</span>

        <span class="s3"># only care about the stuff we'll actually print out</span>
        <span class="s3"># and to_string on entire frame may be expensive</span>
        <span class="s1">d = self</span>

        <span class="s2">if </span><span class="s1">max_rows </span><span class="s2">is not None</span><span class="s1">:  </span><span class="s3"># unlimited rows</span>
            <span class="s3"># min of two, where one may be None</span>
            <span class="s1">d = d.iloc[: min(max_rows</span><span class="s2">, </span><span class="s1">len(d))]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return True</span>

        <span class="s1">d.to_string(buf=buf)</span>
        <span class="s1">value = buf.getvalue()</span>
        <span class="s1">repr_width = max(len(line) </span><span class="s2">for </span><span class="s1">line </span><span class="s2">in </span><span class="s1">value.split(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">))</span>

        <span class="s2">return </span><span class="s1">repr_width &lt; width</span>

    <span class="s2">def </span><span class="s1">_info_repr(self) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot; 
        True if the repr should show the info view. 
        &quot;&quot;&quot;</span>
        <span class="s1">info_repr_option = get_option(</span><span class="s4">&quot;display.large_repr&quot;</span><span class="s1">) == </span><span class="s4">&quot;info&quot;</span>
        <span class="s2">return </span><span class="s1">info_repr_option </span><span class="s2">and not </span><span class="s1">(</span>
            <span class="s1">self._repr_fits_horizontal_() </span><span class="s2">and </span><span class="s1">self._repr_fits_vertical_()</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">__repr__(self) -&gt; str:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a string representation for a particular DataFrame. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self._info_repr():</span>
            <span class="s1">buf = StringIO()</span>
            <span class="s1">self.info(buf=buf)</span>
            <span class="s2">return </span><span class="s1">buf.getvalue()</span>

        <span class="s1">repr_params = fmt.get_dataframe_repr_params()</span>
        <span class="s2">return </span><span class="s1">self.to_string(**repr_params)</span>

    <span class="s2">def </span><span class="s1">_repr_html_(self) -&gt; str | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a html representation for a particular DataFrame. 
 
        Mainly for IPython notebook. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self._info_repr():</span>
            <span class="s1">buf = StringIO()</span>
            <span class="s1">self.info(buf=buf)</span>
            <span class="s3"># need to escape the &lt;class&gt;, should be the first line.</span>
            <span class="s1">val = buf.getvalue().replace(</span><span class="s4">&quot;&lt;&quot;</span><span class="s2">, </span><span class="s4">r&quot;&amp;lt;&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s1">val = val.replace(</span><span class="s4">&quot;&gt;&quot;</span><span class="s2">, </span><span class="s4">r&quot;&amp;gt;&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s4">&quot;&lt;pre&gt;&quot; </span><span class="s1">+ val + </span><span class="s4">&quot;&lt;/pre&gt;&quot;</span>

        <span class="s2">if </span><span class="s1">get_option(</span><span class="s4">&quot;display.notebook_repr_html&quot;</span><span class="s1">):</span>
            <span class="s1">max_rows = get_option(</span><span class="s4">&quot;display.max_rows&quot;</span><span class="s1">)</span>
            <span class="s1">min_rows = get_option(</span><span class="s4">&quot;display.min_rows&quot;</span><span class="s1">)</span>
            <span class="s1">max_cols = get_option(</span><span class="s4">&quot;display.max_columns&quot;</span><span class="s1">)</span>
            <span class="s1">show_dimensions = get_option(</span><span class="s4">&quot;display.show_dimensions&quot;</span><span class="s1">)</span>

            <span class="s1">formatter = fmt.DataFrameFormatter(</span>
                <span class="s1">self</span><span class="s2">,</span>
                <span class="s1">columns=</span><span class="s2">None,</span>
                <span class="s1">col_space=</span><span class="s2">None,</span>
                <span class="s1">na_rep=</span><span class="s4">&quot;NaN&quot;</span><span class="s2">,</span>
                <span class="s1">formatters=</span><span class="s2">None,</span>
                <span class="s1">float_format=</span><span class="s2">None,</span>
                <span class="s1">sparsify=</span><span class="s2">None,</span>
                <span class="s1">justify=</span><span class="s2">None,</span>
                <span class="s1">index_names=</span><span class="s2">True,</span>
                <span class="s1">header=</span><span class="s2">True,</span>
                <span class="s1">index=</span><span class="s2">True,</span>
                <span class="s1">bold_rows=</span><span class="s2">True,</span>
                <span class="s1">escape=</span><span class="s2">True,</span>
                <span class="s1">max_rows=max_rows</span><span class="s2">,</span>
                <span class="s1">min_rows=min_rows</span><span class="s2">,</span>
                <span class="s1">max_cols=max_cols</span><span class="s2">,</span>
                <span class="s1">show_dimensions=show_dimensions</span><span class="s2">,</span>
                <span class="s1">decimal=</span><span class="s4">&quot;.&quot;</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">fmt.DataFrameRenderer(formatter).to_html(notebook=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return None</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">to_string(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">buf: </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">columns: Sequence[str] | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">col_space: int | list[int] | dict[Hashable</span><span class="s2">, </span><span class="s1">int] | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">header: bool | Sequence[str] = ...</span><span class="s2">,</span>
        <span class="s1">index: bool = ...</span><span class="s2">,</span>
        <span class="s1">na_rep: str = ...</span><span class="s2">,</span>
        <span class="s1">formatters: fmt.FormattersType | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">float_format: fmt.FloatFormatType | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">sparsify: bool | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">index_names: bool = ...</span><span class="s2">,</span>
        <span class="s1">justify: str | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">max_rows: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">max_cols: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">show_dimensions: bool = ...</span><span class="s2">,</span>
        <span class="s1">decimal: str = ...</span><span class="s2">,</span>
        <span class="s1">line_width: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">min_rows: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">max_colwidth: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">encoding: str | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; str:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">to_string(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">buf: FilePath | WriteBuffer[str]</span><span class="s2">,</span>
        <span class="s1">columns: Sequence[str] | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">col_space: int | list[int] | dict[Hashable</span><span class="s2">, </span><span class="s1">int] | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">header: bool | Sequence[str] = ...</span><span class="s2">,</span>
        <span class="s1">index: bool = ...</span><span class="s2">,</span>
        <span class="s1">na_rep: str = ...</span><span class="s2">,</span>
        <span class="s1">formatters: fmt.FormattersType | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">float_format: fmt.FloatFormatType | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">sparsify: bool | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">index_names: bool = ...</span><span class="s2">,</span>
        <span class="s1">justify: str | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">max_rows: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">max_cols: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">show_dimensions: bool = ...</span><span class="s2">,</span>
        <span class="s1">decimal: str = ...</span><span class="s2">,</span>
        <span class="s1">line_width: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">min_rows: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">max_colwidth: int | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">encoding: str | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@Substitution(</span>
        <span class="s1">header_type=</span><span class="s4">&quot;bool or sequence of str&quot;</span><span class="s2">,</span>
        <span class="s1">header=</span><span class="s4">&quot;Write out the column names. If a list of strings &quot;</span>
        <span class="s4">&quot;is given, it is assumed to be aliases for the &quot;</span>
        <span class="s4">&quot;column names&quot;</span><span class="s2">,</span>
        <span class="s1">col_space_type=</span><span class="s4">&quot;int, list or dict of int&quot;</span><span class="s2">,</span>
        <span class="s1">col_space=</span><span class="s4">&quot;The minimum width of each column. If a list of ints is given &quot;</span>
        <span class="s4">&quot;every integers corresponds with one column. If a dict is given, the key &quot;</span>
        <span class="s4">&quot;references the column, while the value defines the space to use.&quot;</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">@Substitution(shared_params=fmt.common_docstring</span><span class="s2">, </span><span class="s1">returns=fmt.return_docstring)</span>
    <span class="s2">def </span><span class="s1">to_string(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">buf: FilePath | WriteBuffer[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">columns: Sequence[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">col_space: int | list[int] | dict[Hashable</span><span class="s2">, </span><span class="s1">int] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">header: bool | Sequence[str] = </span><span class="s2">True,</span>
        <span class="s1">index: bool = </span><span class="s2">True,</span>
        <span class="s1">na_rep: str = </span><span class="s4">&quot;NaN&quot;</span><span class="s2">,</span>
        <span class="s1">formatters: fmt.FormattersType | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">float_format: fmt.FloatFormatType | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">sparsify: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">index_names: bool = </span><span class="s2">True,</span>
        <span class="s1">justify: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">max_rows: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">max_cols: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">show_dimensions: bool = </span><span class="s2">False,</span>
        <span class="s1">decimal: str = </span><span class="s4">&quot;.&quot;</span><span class="s2">,</span>
        <span class="s1">line_width: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">min_rows: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">max_colwidth: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">encoding: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; str | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Render a DataFrame to a console-friendly tabular output. 
        %(shared_params)s 
        line_width : int, optional 
            Width to wrap a line in characters. 
        min_rows : int, optional 
            The number of rows to display in the console in a truncated repr 
            (when number of rows is above `max_rows`). 
        max_colwidth : int, optional 
            Max width to truncate each column in characters. By default, no limit. 
 
            .. versionadded:: 1.0.0 
        encoding : str, default &quot;utf-8&quot; 
            Set character encoding. 
 
            .. versionadded:: 1.0 
        %(returns)s 
        See Also 
        -------- 
        to_html : Convert DataFrame to HTML. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]} 
        &gt;&gt;&gt; df = pd.DataFrame(d) 
        &gt;&gt;&gt; print(df.to_string()) 
           col1  col2 
        0     1     4 
        1     2     5 
        2     3     6 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">option_context</span>

        <span class="s2">with </span><span class="s1">option_context(</span><span class="s4">&quot;display.max_colwidth&quot;</span><span class="s2">, </span><span class="s1">max_colwidth):</span>
            <span class="s1">formatter = fmt.DataFrameFormatter(</span>
                <span class="s1">self</span><span class="s2">,</span>
                <span class="s1">columns=columns</span><span class="s2">,</span>
                <span class="s1">col_space=col_space</span><span class="s2">,</span>
                <span class="s1">na_rep=na_rep</span><span class="s2">,</span>
                <span class="s1">formatters=formatters</span><span class="s2">,</span>
                <span class="s1">float_format=float_format</span><span class="s2">,</span>
                <span class="s1">sparsify=sparsify</span><span class="s2">,</span>
                <span class="s1">justify=justify</span><span class="s2">,</span>
                <span class="s1">index_names=index_names</span><span class="s2">,</span>
                <span class="s1">header=header</span><span class="s2">,</span>
                <span class="s1">index=index</span><span class="s2">,</span>
                <span class="s1">min_rows=min_rows</span><span class="s2">,</span>
                <span class="s1">max_rows=max_rows</span><span class="s2">,</span>
                <span class="s1">max_cols=max_cols</span><span class="s2">,</span>
                <span class="s1">show_dimensions=show_dimensions</span><span class="s2">,</span>
                <span class="s1">decimal=decimal</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">fmt.DataFrameRenderer(formatter).to_string(</span>
                <span class="s1">buf=buf</span><span class="s2">,</span>
                <span class="s1">encoding=encoding</span><span class="s2">,</span>
                <span class="s1">line_width=line_width</span><span class="s2">,</span>
            <span class="s1">)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">style(self) -&gt; Styler:</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns a Styler object. 
 
        Contains methods for building a styled HTML representation of the DataFrame. 
 
        See Also 
        -------- 
        io.formats.style.Styler : Helps style a DataFrame or Series according to the 
            data with HTML and CSS. 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.io.formats.style </span><span class="s2">import </span><span class="s1">Styler</span>

        <span class="s2">return </span><span class="s1">Styler(self)</span>

    <span class="s1">_shared_docs[</span>
        <span class="s4">&quot;items&quot;</span>
    <span class="s1">] = </span><span class="s4">r&quot;&quot;&quot; 
        Iterate over (column name, Series) pairs. 
 
        Iterates over the DataFrame columns, returning a tuple with 
        the column name and the content as a Series. 
 
        Yields 
        ------ 
        label : object 
            The column names for the DataFrame being iterated over. 
        content : Series 
            The column entries belonging to each label, as a Series. 
 
        See Also 
        -------- 
        DataFrame.iterrows : Iterate over DataFrame rows as 
            (index, Series) pairs. 
        DataFrame.itertuples : Iterate over DataFrame rows as namedtuples 
            of the values. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'], 
        ...                   'population': [1864, 22000, 80000]}, 
        ...                   index=['panda', 'polar', 'koala']) 
        &gt;&gt;&gt; df 
                species   population 
        panda   bear      1864 
        polar   bear      22000 
        koala   marsupial 80000 
        &gt;&gt;&gt; for label, content in df.items(): 
        ...     print(f'label: {label}') 
        ...     print(f'content: {content}', sep='\n') 
        ... 
        label: species 
        content: 
        panda         bear 
        polar         bear 
        koala    marsupial 
        Name: species, dtype: object 
        label: population 
        content: 
        panda     1864 
        polar    22000 
        koala    80000 
        Name: population, dtype: int64 
        &quot;&quot;&quot;</span>

    <span class="s1">@Appender(_shared_docs[</span><span class="s4">&quot;items&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">items(self) -&gt; Iterable[tuple[Hashable</span><span class="s2">, </span><span class="s1">Series]]:</span>
        <span class="s2">if </span><span class="s1">self.columns.is_unique </span><span class="s2">and </span><span class="s1">hasattr(self</span><span class="s2">, </span><span class="s4">&quot;_item_cache&quot;</span><span class="s1">):</span>
            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">self.columns:</span>
                <span class="s2">yield </span><span class="s1">k</span><span class="s2">, </span><span class="s1">self._get_item_cache(k)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">k </span><span class="s2">in </span><span class="s1">enumerate(self.columns):</span>
                <span class="s2">yield </span><span class="s1">k</span><span class="s2">, </span><span class="s1">self._ixs(i</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s1">@Appender(_shared_docs[</span><span class="s4">&quot;items&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">iteritems(self) -&gt; Iterable[tuple[Hashable</span><span class="s2">, </span><span class="s1">Series]]:</span>
        <span class="s2">yield from </span><span class="s1">self.items()</span>

    <span class="s2">def </span><span class="s1">iterrows(self) -&gt; Iterable[tuple[Hashable</span><span class="s2">, </span><span class="s1">Series]]:</span>
        <span class="s0">&quot;&quot;&quot; 
        Iterate over DataFrame rows as (index, Series) pairs. 
 
        Yields 
        ------ 
        index : label or tuple of label 
            The index of the row. A tuple for a `MultiIndex`. 
        data : Series 
            The data of the row as a Series. 
 
        See Also 
        -------- 
        DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values. 
        DataFrame.items : Iterate over (column name, Series) pairs. 
 
        Notes 
        ----- 
        1. Because ``iterrows`` returns a Series for each row, 
           it does **not** preserve dtypes across the rows (dtypes are 
           preserved across columns for DataFrames). For example, 
 
           &gt;&gt;&gt; df = pd.DataFrame([[1, 1.5]], columns=['int', 'float']) 
           &gt;&gt;&gt; row = next(df.iterrows())[1] 
           &gt;&gt;&gt; row 
           int      1.0 
           float    1.5 
           Name: 0, dtype: float64 
           &gt;&gt;&gt; print(row['int'].dtype) 
           float64 
           &gt;&gt;&gt; print(df['int'].dtype) 
           int64 
 
           To preserve dtypes while iterating over the rows, it is better 
           to use :meth:`itertuples` which returns namedtuples of the values 
           and which is generally faster than ``iterrows``. 
 
        2. You should **never modify** something you are iterating over. 
           This is not guaranteed to work in all cases. Depending on the 
           data types, the iterator returns a copy and not a view, and writing 
           to it will have no effect. 
        &quot;&quot;&quot;</span>
        <span class="s1">columns = self.columns</span>
        <span class="s1">klass = self._constructor_sliced</span>
        <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">zip(self.index</span><span class="s2">, </span><span class="s1">self.values):</span>
            <span class="s1">s = klass(v</span><span class="s2">, </span><span class="s1">index=columns</span><span class="s2">, </span><span class="s1">name=k)</span>
            <span class="s2">yield </span><span class="s1">k</span><span class="s2">, </span><span class="s1">s</span>

    <span class="s2">def </span><span class="s1">itertuples(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">index: bool = </span><span class="s2">True, </span><span class="s1">name: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s4">&quot;Pandas&quot;</span>
    <span class="s1">) -&gt; Iterable[tuple[Any</span><span class="s2">, </span><span class="s1">...]]:</span>
        <span class="s0">&quot;&quot;&quot; 
        Iterate over DataFrame rows as namedtuples. 
 
        Parameters 
        ---------- 
        index : bool, default True 
            If True, return the index as the first element of the tuple. 
        name : str or None, default &quot;Pandas&quot; 
            The name of the returned namedtuples or None to return regular 
            tuples. 
 
        Returns 
        ------- 
        iterator 
            An object to iterate over namedtuples for each row in the 
            DataFrame with the first field possibly being the index and 
            following fields being the column values. 
 
        See Also 
        -------- 
        DataFrame.iterrows : Iterate over DataFrame rows as (index, Series) 
            pairs. 
        DataFrame.items : Iterate over (column name, Series) pairs. 
 
        Notes 
        ----- 
        The column names will be renamed to positional names if they are 
        invalid Python identifiers, repeated, or start with an underscore. 
        On python versions &lt; 3.7 regular tuples are returned for DataFrames 
        with a large number of columns (&gt;254). 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]}, 
        ...                   index=['dog', 'hawk']) 
        &gt;&gt;&gt; df 
              num_legs  num_wings 
        dog          4          0 
        hawk         2          2 
        &gt;&gt;&gt; for row in df.itertuples(): 
        ...     print(row) 
        ... 
        Pandas(Index='dog', num_legs=4, num_wings=0) 
        Pandas(Index='hawk', num_legs=2, num_wings=2) 
 
        By setting the `index` parameter to False we can remove the index 
        as the first element of the tuple: 
 
        &gt;&gt;&gt; for row in df.itertuples(index=False): 
        ...     print(row) 
        ... 
        Pandas(num_legs=4, num_wings=0) 
        Pandas(num_legs=2, num_wings=2) 
 
        With the `name` parameter set we set a custom name for the yielded 
        namedtuples: 
 
        &gt;&gt;&gt; for row in df.itertuples(name='Animal'): 
        ...     print(row) 
        ... 
        Animal(Index='dog', num_legs=4, num_wings=0) 
        Animal(Index='hawk', num_legs=2, num_wings=2) 
        &quot;&quot;&quot;</span>
        <span class="s1">arrays = []</span>
        <span class="s1">fields = list(self.columns)</span>
        <span class="s2">if </span><span class="s1">index:</span>
            <span class="s1">arrays.append(self.index)</span>
            <span class="s1">fields.insert(</span><span class="s5">0</span><span class="s2">, </span><span class="s4">&quot;Index&quot;</span><span class="s1">)</span>

        <span class="s3"># use integer indexing because of possible duplicate column names</span>
        <span class="s1">arrays.extend(self.iloc[:</span><span class="s2">, </span><span class="s1">k] </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">range(len(self.columns)))</span>

        <span class="s2">if </span><span class="s1">name </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># https://github.com/python/mypy/issues/9046</span>
            <span class="s3"># error: namedtuple() expects a string literal as the first argument</span>
            <span class="s1">itertuple = collections.namedtuple(  </span><span class="s3"># type: ignore[misc]</span>
                <span class="s1">name</span><span class="s2">, </span><span class="s1">fields</span><span class="s2">, </span><span class="s1">rename=</span><span class="s2">True</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">map(itertuple._make</span><span class="s2">, </span><span class="s1">zip(*arrays))</span>

        <span class="s3"># fallback to regular tuples</span>
        <span class="s2">return </span><span class="s1">zip(*arrays)</span>

    <span class="s2">def </span><span class="s1">__len__(self) -&gt; int:</span>
        <span class="s0">&quot;&quot;&quot; 
        Returns length of info axis, but here we use the index. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">len(self.index)</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">dot(self</span><span class="s2">, </span><span class="s1">other: Series) -&gt; Series:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">dot(self</span><span class="s2">, </span><span class="s1">other: DataFrame | Index | ArrayLike) -&gt; DataFrame:</span>
        <span class="s1">...</span>

    <span class="s2">def </span><span class="s1">dot(self</span><span class="s2">, </span><span class="s1">other: AnyArrayLike | DataFrame) -&gt; DataFrame | Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute the matrix multiplication between the DataFrame and other. 
 
        This method computes the matrix product between the DataFrame and the 
        values of an other Series, DataFrame or a numpy array. 
 
        It can also be called using ``self @ other`` in Python &gt;= 3.5. 
 
        Parameters 
        ---------- 
        other : Series, DataFrame or array-like 
            The other object to compute the matrix product with. 
 
        Returns 
        ------- 
        Series or DataFrame 
            If other is a Series, return the matrix product between self and 
            other as a Series. If other is a DataFrame or a numpy.array, return 
            the matrix product of self and other in a DataFrame of a np.array. 
 
        See Also 
        -------- 
        Series.dot: Similar method for Series. 
 
        Notes 
        ----- 
        The dimensions of DataFrame and other must be compatible in order to 
        compute the matrix multiplication. In addition, the column names of 
        DataFrame and the index of other must contain the same values, as they 
        will be aligned prior to the multiplication. 
 
        The dot method for Series computes the inner product, instead of the 
        matrix product here. 
 
        Examples 
        -------- 
        Here we multiply a DataFrame with a Series. 
 
        &gt;&gt;&gt; df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]]) 
        &gt;&gt;&gt; s = pd.Series([1, 1, 2, 1]) 
        &gt;&gt;&gt; df.dot(s) 
        0    -4 
        1     5 
        dtype: int64 
 
        Here we multiply a DataFrame with another DataFrame. 
 
        &gt;&gt;&gt; other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]]) 
        &gt;&gt;&gt; df.dot(other) 
            0   1 
        0   1   4 
        1   2   2 
 
        Note that the dot method give the same result as @ 
 
        &gt;&gt;&gt; df @ other 
            0   1 
        0   1   4 
        1   2   2 
 
        The dot method works also if other is an np.array. 
 
        &gt;&gt;&gt; arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]]) 
        &gt;&gt;&gt; df.dot(arr) 
            0   1 
        0   1   4 
        1   2   2 
 
        Note how shuffling of the objects does not change the result. 
 
        &gt;&gt;&gt; s2 = s.reindex([1, 0, 2, 3]) 
        &gt;&gt;&gt; df.dot(s2) 
        0    -4 
        1     5 
        dtype: int64 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">(Series</span><span class="s2">, </span><span class="s1">DataFrame)):</span>
            <span class="s1">common = self.columns.union(other.index)</span>
            <span class="s2">if </span><span class="s1">len(common) &gt; len(self.columns) </span><span class="s2">or </span><span class="s1">len(common) &gt; len(other.index):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;matrices are not aligned&quot;</span><span class="s1">)</span>

            <span class="s1">left = self.reindex(columns=common</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s1">right = other.reindex(index=common</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s1">lvals = left.values</span>
            <span class="s1">rvals = right._values</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">left = self</span>
            <span class="s1">lvals = self.values</span>
            <span class="s1">rvals = np.asarray(other)</span>
            <span class="s2">if </span><span class="s1">lvals.shape[</span><span class="s5">1</span><span class="s1">] != rvals.shape[</span><span class="s5">0</span><span class="s1">]:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">f&quot;Dot product shape mismatch, </span><span class="s2">{</span><span class="s1">lvals.shape</span><span class="s2">} </span><span class="s4">vs </span><span class="s2">{</span><span class="s1">rvals.shape</span><span class="s2">}</span><span class="s4">&quot;</span>
                <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">return </span><span class="s1">self._constructor(</span>
                <span class="s1">np.dot(lvals</span><span class="s2">, </span><span class="s1">rvals)</span><span class="s2">, </span><span class="s1">index=left.index</span><span class="s2">, </span><span class="s1">columns=other.columns</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s2">return </span><span class="s1">self._constructor_sliced(np.dot(lvals</span><span class="s2">, </span><span class="s1">rvals)</span><span class="s2">, </span><span class="s1">index=left.index)</span>
        <span class="s2">elif </span><span class="s1">isinstance(rvals</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">Index)):</span>
            <span class="s1">result = np.dot(lvals</span><span class="s2">, </span><span class="s1">rvals)</span>
            <span class="s2">if </span><span class="s1">result.ndim == </span><span class="s5">2</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self._constructor(result</span><span class="s2">, </span><span class="s1">index=left.index)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self._constructor_sliced(result</span><span class="s2">, </span><span class="s1">index=left.index)</span>
        <span class="s2">else</span><span class="s1">:  </span><span class="s3"># pragma: no cover</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;unsupported type: </span><span class="s2">{</span><span class="s1">type(other)</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">__matmul__(self</span><span class="s2">, </span><span class="s1">other: Series) -&gt; Series:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">__matmul__(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">other: AnyArrayLike | DataFrame | Series</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s1">...</span>

    <span class="s2">def </span><span class="s1">__matmul__(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">other: AnyArrayLike | DataFrame | Series</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Matrix multiplication using binary `@` operator in Python&gt;=3.5. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.dot(other)</span>

    <span class="s2">def </span><span class="s1">__rmatmul__(self</span><span class="s2">, </span><span class="s1">other):</span>
        <span class="s0">&quot;&quot;&quot; 
        Matrix multiplication using binary `@` operator in Python&gt;=3.5. 
        &quot;&quot;&quot;</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.T.dot(np.transpose(other)).T</span>
        <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">err:</span>
            <span class="s2">if </span><span class="s4">&quot;shape mismatch&quot; </span><span class="s2">not in </span><span class="s1">str(err):</span>
                <span class="s2">raise</span>
            <span class="s3"># GH#21581 give exception message for original shapes</span>
            <span class="s1">msg = </span><span class="s4">f&quot;shapes </span><span class="s2">{</span><span class="s1">np.shape(other)</span><span class="s2">} </span><span class="s4">and </span><span class="s2">{</span><span class="s1">self.shape</span><span class="s2">} </span><span class="s4">not aligned&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg) </span><span class="s2">from </span><span class="s1">err</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># IO methods (to / from other formats)</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">from_dict(</span>
        <span class="s1">cls</span><span class="s2">,</span>
        <span class="s1">data</span><span class="s2">,</span>
        <span class="s1">orient: str = </span><span class="s4">&quot;columns&quot;</span><span class="s2">,</span>
        <span class="s1">dtype: Dtype | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">columns=</span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Construct DataFrame from dict of array-like or dicts. 
 
        Creates DataFrame object from dictionary by columns or by index 
        allowing dtype specification. 
 
        Parameters 
        ---------- 
        data : dict 
            Of the form {field : array-like} or {field : dict}. 
        orient : {'columns', 'index', 'tight'}, default 'columns' 
            The &quot;orientation&quot; of the data. If the keys of the passed dict 
            should be the columns of the resulting DataFrame, pass 'columns' 
            (default). Otherwise if the keys should be rows, pass 'index'. 
            If 'tight', assume a dict with keys ['index', 'columns', 'data', 
            'index_names', 'column_names']. 
 
            .. versionadded:: 1.4.0 
               'tight' as an allowed value for the ``orient`` argument 
 
        dtype : dtype, default None 
            Data type to force, otherwise infer. 
        columns : list, default None 
            Column labels to use when ``orient='index'``. Raises a ValueError 
            if used with ``orient='columns'`` or ``orient='tight'``. 
 
        Returns 
        ------- 
        DataFrame 
 
        See Also 
        -------- 
        DataFrame.from_records : DataFrame from structured ndarray, sequence 
            of tuples or dicts, or DataFrame. 
        DataFrame : DataFrame object creation using constructor. 
        DataFrame.to_dict : Convert the DataFrame to a dictionary. 
 
        Examples 
        -------- 
        By default the keys of the dict become the DataFrame columns: 
 
        &gt;&gt;&gt; data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']} 
        &gt;&gt;&gt; pd.DataFrame.from_dict(data) 
           col_1 col_2 
        0      3     a 
        1      2     b 
        2      1     c 
        3      0     d 
 
        Specify ``orient='index'`` to create the DataFrame using dictionary 
        keys as rows: 
 
        &gt;&gt;&gt; data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']} 
        &gt;&gt;&gt; pd.DataFrame.from_dict(data, orient='index') 
               0  1  2  3 
        row_1  3  2  1  0 
        row_2  a  b  c  d 
 
        When using the 'index' orientation, the column names can be 
        specified manually: 
 
        &gt;&gt;&gt; pd.DataFrame.from_dict(data, orient='index', 
        ...                        columns=['A', 'B', 'C', 'D']) 
               A  B  C  D 
        row_1  3  2  1  0 
        row_2  a  b  c  d 
 
        Specify ``orient='tight'`` to create the DataFrame using a 'tight' 
        format: 
 
        &gt;&gt;&gt; data = {'index': [('a', 'b'), ('a', 'c')], 
        ...         'columns': [('x', 1), ('y', 2)], 
        ...         'data': [[1, 3], [2, 4]], 
        ...         'index_names': ['n1', 'n2'], 
        ...         'column_names': ['z1', 'z2']} 
        &gt;&gt;&gt; pd.DataFrame.from_dict(data, orient='tight') 
        z1     x  y 
        z2     1  2 
        n1 n2 
        a  b   1  3 
           c   2  4 
        &quot;&quot;&quot;</span>
        <span class="s1">index = </span><span class="s2">None</span>
        <span class="s1">orient = orient.lower()</span>
        <span class="s2">if </span><span class="s1">orient == </span><span class="s4">&quot;index&quot;</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">len(data) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s3"># TODO speed up Series case</span>
                <span class="s2">if </span><span class="s1">isinstance(list(data.values())[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">(Series</span><span class="s2">, </span><span class="s1">dict)):</span>
                    <span class="s1">data = _from_nested_dict(data)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">data</span><span class="s2">, </span><span class="s1">index = list(data.values())</span><span class="s2">, </span><span class="s1">list(data.keys())</span>
        <span class="s2">elif </span><span class="s1">orient == </span><span class="s4">&quot;columns&quot; </span><span class="s2">or </span><span class="s1">orient == </span><span class="s4">&quot;tight&quot;</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">columns </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;cannot use columns parameter with orient='</span><span class="s2">{</span><span class="s1">orient</span><span class="s2">}</span><span class="s4">'&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:  </span><span class="s3"># pragma: no cover</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;only recognize index or columns for orient&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">orient != </span><span class="s4">&quot;tight&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">cls(data</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">realdata = data[</span><span class="s4">&quot;data&quot;</span><span class="s1">]</span>

            <span class="s2">def </span><span class="s1">create_index(indexlist</span><span class="s2">, </span><span class="s1">namelist):</span>
                <span class="s1">index: Index</span>
                <span class="s2">if </span><span class="s1">len(namelist) &gt; </span><span class="s5">1</span><span class="s1">:</span>
                    <span class="s1">index = MultiIndex.from_tuples(indexlist</span><span class="s2">, </span><span class="s1">names=namelist)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">index = Index(indexlist</span><span class="s2">, </span><span class="s1">name=namelist[</span><span class="s5">0</span><span class="s1">])</span>
                <span class="s2">return </span><span class="s1">index</span>

            <span class="s1">index = create_index(data[</span><span class="s4">&quot;index&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s1">data[</span><span class="s4">&quot;index_names&quot;</span><span class="s1">])</span>
            <span class="s1">columns = create_index(data[</span><span class="s4">&quot;columns&quot;</span><span class="s1">]</span><span class="s2">, </span><span class="s1">data[</span><span class="s4">&quot;column_names&quot;</span><span class="s1">])</span>
            <span class="s2">return </span><span class="s1">cls(realdata</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>

    <span class="s2">def </span><span class="s1">to_numpy(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">dtype: npt.DTypeLike | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">copy: bool = </span><span class="s2">False,</span>
        <span class="s1">na_value=lib.no_default</span><span class="s2">,</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot; 
        Convert the DataFrame to a NumPy array. 
 
        By default, the dtype of the returned array will be the common NumPy 
        dtype of all types in the DataFrame. For example, if the dtypes are 
        ``float16`` and ``float32``, the results dtype will be ``float32``. 
        This may require copying data and coercing values, which may be 
        expensive. 
 
        Parameters 
        ---------- 
        dtype : str or numpy.dtype, optional 
            The dtype to pass to :meth:`numpy.asarray`. 
        copy : bool, default False 
            Whether to ensure that the returned value is not a view on 
            another array. Note that ``copy=False`` does not *ensure* that 
            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that 
            a copy is made, even if not strictly necessary. 
        na_value : Any, optional 
            The value to use for missing values. The default value depends 
            on `dtype` and the dtypes of the DataFrame columns. 
 
            .. versionadded:: 1.1.0 
 
        Returns 
        ------- 
        numpy.ndarray 
 
        See Also 
        -------- 
        Series.to_numpy : Similar method for Series. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; pd.DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [3, 4]}).to_numpy() 
        array([[1, 3], 
               [2, 4]]) 
 
        With heterogeneous data, the lowest common type will have to 
        be used. 
 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [3.0, 4.5]}) 
        &gt;&gt;&gt; df.to_numpy() 
        array([[1. , 3. ], 
               [2. , 4.5]]) 
 
        For a mix of numeric and non-numeric types, the output array will 
        have object dtype. 
 
        &gt;&gt;&gt; df['C'] = pd.date_range('2000', periods=2) 
        &gt;&gt;&gt; df.to_numpy() 
        array([[1, 3.0, Timestamp('2000-01-01 00:00:00')], 
               [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object) 
        &quot;&quot;&quot;</span>
        <span class="s1">self._consolidate_inplace()</span>
        <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">dtype = np.dtype(dtype)</span>
        <span class="s1">result = self._mgr.as_array(dtype=dtype</span><span class="s2">, </span><span class="s1">copy=copy</span><span class="s2">, </span><span class="s1">na_value=na_value)</span>
        <span class="s2">if </span><span class="s1">result.dtype </span><span class="s2">is not </span><span class="s1">dtype:</span>
            <span class="s1">result = np.array(result</span><span class="s2">, </span><span class="s1">dtype=dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">to_dict(self</span><span class="s2">, </span><span class="s1">orient: str = </span><span class="s4">&quot;dict&quot;</span><span class="s2">, </span><span class="s1">into=dict):</span>
        <span class="s0">&quot;&quot;&quot; 
        Convert the DataFrame to a dictionary. 
 
        The type of the key-value pairs can be customized with the parameters 
        (see below). 
 
        Parameters 
        ---------- 
        orient : str {'dict', 'list', 'series', 'split', 'records', 'index'} 
            Determines the type of the values of the dictionary. 
 
            - 'dict' (default) : dict like {column -&gt; {index -&gt; value}} 
            - 'list' : dict like {column -&gt; [values]} 
            - 'series' : dict like {column -&gt; Series(values)} 
            - 'split' : dict like 
              {'index' -&gt; [index], 'columns' -&gt; [columns], 'data' -&gt; [values]} 
            - 'tight' : dict like 
              {'index' -&gt; [index], 'columns' -&gt; [columns], 'data' -&gt; [values], 
              'index_names' -&gt; [index.names], 'column_names' -&gt; [column.names]} 
            - 'records' : list like 
              [{column -&gt; value}, ... , {column -&gt; value}] 
            - 'index' : dict like {index -&gt; {column -&gt; value}} 
 
            Abbreviations are allowed. `s` indicates `series` and `sp` 
            indicates `split`. 
 
            .. versionadded:: 1.4.0 
                'tight' as an allowed value for the ``orient`` argument 
 
        into : class, default dict 
            The collections.abc.Mapping subclass used for all Mappings 
            in the return value.  Can be the actual class or an empty 
            instance of the mapping type you want.  If you want a 
            collections.defaultdict, you must pass it initialized. 
 
        Returns 
        ------- 
        dict, list or collections.abc.Mapping 
            Return a collections.abc.Mapping object representing the DataFrame. 
            The resulting transformation depends on the `orient` parameter. 
 
        See Also 
        -------- 
        DataFrame.from_dict: Create a DataFrame from a dictionary. 
        DataFrame.to_json: Convert a DataFrame to JSON format. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'col1': [1, 2], 
        ...                    'col2': [0.5, 0.75]}, 
        ...                   index=['row1', 'row2']) 
        &gt;&gt;&gt; df 
              col1  col2 
        row1     1  0.50 
        row2     2  0.75 
        &gt;&gt;&gt; df.to_dict() 
        {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}} 
 
        You can specify the return orientation. 
 
        &gt;&gt;&gt; df.to_dict('series') 
        {'col1': row1    1 
                 row2    2 
        Name: col1, dtype: int64, 
        'col2': row1    0.50 
                row2    0.75 
        Name: col2, dtype: float64} 
 
        &gt;&gt;&gt; df.to_dict('split') 
        {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'], 
         'data': [[1, 0.5], [2, 0.75]]} 
 
        &gt;&gt;&gt; df.to_dict('records') 
        [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}] 
 
        &gt;&gt;&gt; df.to_dict('index') 
        {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}} 
 
        &gt;&gt;&gt; df.to_dict('tight') 
        {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'], 
         'data': [[1, 0.5], [2, 0.75]], 'index_names': [None], 'column_names': [None]} 
 
        You can also specify the mapping type. 
 
        &gt;&gt;&gt; from collections import OrderedDict, defaultdict 
        &gt;&gt;&gt; df.to_dict(into=OrderedDict) 
        OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])), 
                     ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))]) 
 
        If you want a `defaultdict`, you need to initialize it: 
 
        &gt;&gt;&gt; dd = defaultdict(list) 
        &gt;&gt;&gt; df.to_dict('records', into=dd) 
        [defaultdict(&lt;class 'list'&gt;, {'col1': 1, 'col2': 0.5}), 
         defaultdict(&lt;class 'list'&gt;, {'col1': 2, 'col2': 0.75})] 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">self.columns.is_unique:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;DataFrame columns are not unique, some columns will be omitted.&quot;</span><span class="s2">,</span>
                <span class="s1">UserWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s3"># GH16122</span>
        <span class="s1">into_c = com.standardize_mapping(into)</span>

        <span class="s1">orient = orient.lower()</span>
        <span class="s3"># GH32515</span>
        <span class="s2">if </span><span class="s1">orient.startswith((</span><span class="s4">&quot;d&quot;</span><span class="s2">, </span><span class="s4">&quot;l&quot;</span><span class="s2">, </span><span class="s4">&quot;s&quot;</span><span class="s2">, </span><span class="s4">&quot;r&quot;</span><span class="s2">, </span><span class="s4">&quot;i&quot;</span><span class="s1">)) </span><span class="s2">and </span><span class="s1">orient </span><span class="s2">not in </span><span class="s1">{</span>
            <span class="s4">&quot;dict&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;list&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;series&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;split&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;records&quot;</span><span class="s2">,</span>
            <span class="s4">&quot;index&quot;</span><span class="s2">,</span>
        <span class="s1">}:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;Using short name for 'orient' is deprecated. Only the &quot;</span>
                <span class="s4">&quot;options: ('dict', list, 'series', 'split', 'records', 'index') &quot;</span>
                <span class="s4">&quot;will be used in a future version. Use one of the above &quot;</span>
                <span class="s4">&quot;to silence this warning.&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>

            <span class="s2">if </span><span class="s1">orient.startswith(</span><span class="s4">&quot;d&quot;</span><span class="s1">):</span>
                <span class="s1">orient = </span><span class="s4">&quot;dict&quot;</span>
            <span class="s2">elif </span><span class="s1">orient.startswith(</span><span class="s4">&quot;l&quot;</span><span class="s1">):</span>
                <span class="s1">orient = </span><span class="s4">&quot;list&quot;</span>
            <span class="s2">elif </span><span class="s1">orient.startswith(</span><span class="s4">&quot;sp&quot;</span><span class="s1">):</span>
                <span class="s1">orient = </span><span class="s4">&quot;split&quot;</span>
            <span class="s2">elif </span><span class="s1">orient.startswith(</span><span class="s4">&quot;s&quot;</span><span class="s1">):</span>
                <span class="s1">orient = </span><span class="s4">&quot;series&quot;</span>
            <span class="s2">elif </span><span class="s1">orient.startswith(</span><span class="s4">&quot;r&quot;</span><span class="s1">):</span>
                <span class="s1">orient = </span><span class="s4">&quot;records&quot;</span>
            <span class="s2">elif </span><span class="s1">orient.startswith(</span><span class="s4">&quot;i&quot;</span><span class="s1">):</span>
                <span class="s1">orient = </span><span class="s4">&quot;index&quot;</span>

        <span class="s2">if </span><span class="s1">orient == </span><span class="s4">&quot;dict&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">into_c((k</span><span class="s2">, </span><span class="s1">v.to_dict(into)) </span><span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.items())</span>

        <span class="s2">elif </span><span class="s1">orient == </span><span class="s4">&quot;list&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">into_c((k</span><span class="s2">, </span><span class="s1">v.tolist()) </span><span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.items())</span>

        <span class="s2">elif </span><span class="s1">orient == </span><span class="s4">&quot;split&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">into_c(</span>
                <span class="s1">(</span>
                    <span class="s1">(</span><span class="s4">&quot;index&quot;</span><span class="s2">, </span><span class="s1">self.index.tolist())</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s4">&quot;columns&quot;</span><span class="s2">, </span><span class="s1">self.columns.tolist())</span><span class="s2">,</span>
                    <span class="s1">(</span>
                        <span class="s4">&quot;data&quot;</span><span class="s2">,</span>
                        <span class="s1">[</span>
                            <span class="s1">list(map(maybe_box_native</span><span class="s2">, </span><span class="s1">t))</span>
                            <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">self.itertuples(index=</span><span class="s2">False, </span><span class="s1">name=</span><span class="s2">None</span><span class="s1">)</span>
                        <span class="s1">]</span><span class="s2">,</span>
                    <span class="s1">)</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">orient == </span><span class="s4">&quot;tight&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">into_c(</span>
                <span class="s1">(</span>
                    <span class="s1">(</span><span class="s4">&quot;index&quot;</span><span class="s2">, </span><span class="s1">self.index.tolist())</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s4">&quot;columns&quot;</span><span class="s2">, </span><span class="s1">self.columns.tolist())</span><span class="s2">,</span>
                    <span class="s1">(</span>
                        <span class="s4">&quot;data&quot;</span><span class="s2">,</span>
                        <span class="s1">[</span>
                            <span class="s1">list(map(maybe_box_native</span><span class="s2">, </span><span class="s1">t))</span>
                            <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">self.itertuples(index=</span><span class="s2">False, </span><span class="s1">name=</span><span class="s2">None</span><span class="s1">)</span>
                        <span class="s1">]</span><span class="s2">,</span>
                    <span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s4">&quot;index_names&quot;</span><span class="s2">, </span><span class="s1">list(self.index.names))</span><span class="s2">,</span>
                    <span class="s1">(</span><span class="s4">&quot;column_names&quot;</span><span class="s2">, </span><span class="s1">list(self.columns.names))</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">orient == </span><span class="s4">&quot;series&quot;</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">into_c((k</span><span class="s2">, </span><span class="s1">v) </span><span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.items())</span>

        <span class="s2">elif </span><span class="s1">orient == </span><span class="s4">&quot;records&quot;</span><span class="s1">:</span>
            <span class="s1">columns = self.columns.tolist()</span>
            <span class="s1">rows = (</span>
                <span class="s1">dict(zip(columns</span><span class="s2">, </span><span class="s1">row))</span>
                <span class="s2">for </span><span class="s1">row </span><span class="s2">in </span><span class="s1">self.itertuples(index=</span><span class="s2">False, </span><span class="s1">name=</span><span class="s2">None</span><span class="s1">)</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">[</span>
                <span class="s1">into_c((k</span><span class="s2">, </span><span class="s1">maybe_box_native(v)) </span><span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">row.items()) </span><span class="s2">for </span><span class="s1">row </span><span class="s2">in </span><span class="s1">rows</span>
            <span class="s1">]</span>

        <span class="s2">elif </span><span class="s1">orient == </span><span class="s4">&quot;index&quot;</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">self.index.is_unique:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;DataFrame index must be unique for orient='index'.&quot;</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">into_c(</span>
                <span class="s1">(t[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">dict(zip(self.columns</span><span class="s2">, </span><span class="s1">t[</span><span class="s5">1</span><span class="s1">:])))</span>
                <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">self.itertuples(name=</span><span class="s2">None</span><span class="s1">)</span>
            <span class="s1">)</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;orient '</span><span class="s2">{</span><span class="s1">orient</span><span class="s2">}</span><span class="s4">' not understood&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">to_gbq(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">destination_table: str</span><span class="s2">,</span>
        <span class="s1">project_id: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">chunksize: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">reauth: bool = </span><span class="s2">False,</span>
        <span class="s1">if_exists: str = </span><span class="s4">&quot;fail&quot;</span><span class="s2">,</span>
        <span class="s1">auth_local_webserver: bool = </span><span class="s2">False,</span>
        <span class="s1">table_schema: list[dict[str</span><span class="s2">, </span><span class="s1">str]] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">location: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">progress_bar: bool = </span><span class="s2">True,</span>
        <span class="s1">credentials=</span><span class="s2">None,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Write a DataFrame to a Google BigQuery table. 
 
        This function requires the `pandas-gbq package 
        &lt;https://pandas-gbq.readthedocs.io&gt;`__. 
 
        See the `How to authenticate with Google BigQuery 
        &lt;https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html&gt;`__ 
        guide for authentication instructions. 
 
        Parameters 
        ---------- 
        destination_table : str 
            Name of table to be written, in the form ``dataset.tablename``. 
        project_id : str, optional 
            Google BigQuery Account project ID. Optional when available from 
            the environment. 
        chunksize : int, optional 
            Number of rows to be inserted in each chunk from the dataframe. 
            Set to ``None`` to load the whole dataframe at once. 
        reauth : bool, default False 
            Force Google BigQuery to re-authenticate the user. This is useful 
            if multiple accounts are used. 
        if_exists : str, default 'fail' 
            Behavior when the destination table exists. Value can be one of: 
 
            ``'fail'`` 
                If table exists raise pandas_gbq.gbq.TableCreationError. 
            ``'replace'`` 
                If table exists, drop it, recreate it, and insert data. 
            ``'append'`` 
                If table exists, insert data. Create if does not exist. 
        auth_local_webserver : bool, default False 
            Use the `local webserver flow`_ instead of the `console flow`_ 
            when getting user credentials. 
 
            .. _local webserver flow: 
                https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server 
            .. _console flow: 
                https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console 
 
            *New in version 0.2.0 of pandas-gbq*. 
        table_schema : list of dicts, optional 
            List of BigQuery table fields to which according DataFrame 
            columns conform to, e.g. ``[{'name': 'col1', 'type': 
            'STRING'},...]``. If schema is not provided, it will be 
            generated according to dtypes of DataFrame columns. See 
            BigQuery API documentation on available names of a field. 
 
            *New in version 0.3.1 of pandas-gbq*. 
        location : str, optional 
            Location where the load job should run. See the `BigQuery locations 
            documentation 
            &lt;https://cloud.google.com/bigquery/docs/dataset-locations&gt;`__ for a 
            list of available locations. The location must match that of the 
            target dataset. 
 
            *New in version 0.5.0 of pandas-gbq*. 
        progress_bar : bool, default True 
            Use the library `tqdm` to show the progress bar for the upload, 
            chunk by chunk. 
 
            *New in version 0.5.0 of pandas-gbq*. 
        credentials : google.auth.credentials.Credentials, optional 
            Credentials for accessing Google APIs. Use this parameter to 
            override default credentials, such as to use Compute Engine 
            :class:`google.auth.compute_engine.Credentials` or Service 
            Account :class:`google.oauth2.service_account.Credentials` 
            directly. 
 
            *New in version 0.8.0 of pandas-gbq*. 
 
        See Also 
        -------- 
        pandas_gbq.to_gbq : This function in the pandas-gbq library. 
        read_gbq : Read a DataFrame from Google BigQuery. 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.io </span><span class="s2">import </span><span class="s1">gbq</span>

        <span class="s1">gbq.to_gbq(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">destination_table</span><span class="s2">,</span>
            <span class="s1">project_id=project_id</span><span class="s2">,</span>
            <span class="s1">chunksize=chunksize</span><span class="s2">,</span>
            <span class="s1">reauth=reauth</span><span class="s2">,</span>
            <span class="s1">if_exists=if_exists</span><span class="s2">,</span>
            <span class="s1">auth_local_webserver=auth_local_webserver</span><span class="s2">,</span>
            <span class="s1">table_schema=table_schema</span><span class="s2">,</span>
            <span class="s1">location=location</span><span class="s2">,</span>
            <span class="s1">progress_bar=progress_bar</span><span class="s2">,</span>
            <span class="s1">credentials=credentials</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">from_records(</span>
        <span class="s1">cls</span><span class="s2">,</span>
        <span class="s1">data</span><span class="s2">,</span>
        <span class="s1">index=</span><span class="s2">None,</span>
        <span class="s1">exclude=</span><span class="s2">None,</span>
        <span class="s1">columns=</span><span class="s2">None,</span>
        <span class="s1">coerce_float: bool = </span><span class="s2">False,</span>
        <span class="s1">nrows: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Convert structured or record ndarray to DataFrame. 
 
        Creates a DataFrame object from a structured ndarray, sequence of 
        tuples or dicts, or DataFrame. 
 
        Parameters 
        ---------- 
        data : structured ndarray, sequence of tuples or dicts, or DataFrame 
            Structured input data. 
        index : str, list of fields, array-like 
            Field of array to use as the index, alternately a specific set of 
            input labels to use. 
        exclude : sequence, default None 
            Columns or fields to exclude. 
        columns : sequence, default None 
            Column names to use. If the passed data do not have names 
            associated with them, this argument provides names for the 
            columns. Otherwise this argument indicates the order of the columns 
            in the result (any names not found in the data will become all-NA 
            columns). 
        coerce_float : bool, default False 
            Attempt to convert values of non-string, non-numeric objects (like 
            decimal.Decimal) to floating point, useful for SQL result sets. 
        nrows : int, default None 
            Number of rows to read if data is an iterator. 
 
        Returns 
        ------- 
        DataFrame 
 
        See Also 
        -------- 
        DataFrame.from_dict : DataFrame from dict of array-like or dicts. 
        DataFrame : DataFrame object creation using constructor. 
 
        Examples 
        -------- 
        Data can be provided as a structured ndarray: 
 
        &gt;&gt;&gt; data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')], 
        ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')]) 
        &gt;&gt;&gt; pd.DataFrame.from_records(data) 
           col_1 col_2 
        0      3     a 
        1      2     b 
        2      1     c 
        3      0     d 
 
        Data can be provided as a list of dicts: 
 
        &gt;&gt;&gt; data = [{'col_1': 3, 'col_2': 'a'}, 
        ...         {'col_1': 2, 'col_2': 'b'}, 
        ...         {'col_1': 1, 'col_2': 'c'}, 
        ...         {'col_1': 0, 'col_2': 'd'}] 
        &gt;&gt;&gt; pd.DataFrame.from_records(data) 
           col_1 col_2 
        0      3     a 
        1      2     b 
        2      1     c 
        3      0     d 
 
        Data can be provided as a list of tuples with corresponding columns: 
 
        &gt;&gt;&gt; data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')] 
        &gt;&gt;&gt; pd.DataFrame.from_records(data, columns=['col_1', 'col_2']) 
           col_1 col_2 
        0      3     a 
        1      2     b 
        2      1     c 
        3      0     d 
        &quot;&quot;&quot;</span>
        <span class="s1">result_index = </span><span class="s2">None</span>

        <span class="s3"># Make a copy of the input columns so we can modify it</span>
        <span class="s2">if </span><span class="s1">columns </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">columns = ensure_index(columns)</span>

        <span class="s2">def </span><span class="s1">maybe_reorder(</span>
            <span class="s1">arrays: list[ArrayLike]</span><span class="s2">, </span><span class="s1">arr_columns: Index</span><span class="s2">, </span><span class="s1">columns: Index</span><span class="s2">, </span><span class="s1">index</span>
        <span class="s1">) -&gt; tuple[list[ArrayLike]</span><span class="s2">, </span><span class="s1">Index</span><span class="s2">, </span><span class="s1">Index | </span><span class="s2">None</span><span class="s1">]:</span>
            <span class="s0">&quot;&quot;&quot; 
            If our desired 'columns' do not match the data's pre-existing 'arr_columns', 
            we re-order our arrays.  This is like a pre-emptive (cheap) reindex. 
            &quot;&quot;&quot;</span>
            <span class="s2">if </span><span class="s1">len(arrays):</span>
                <span class="s1">length = len(arrays[</span><span class="s5">0</span><span class="s1">])</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">length = </span><span class="s5">0</span>

            <span class="s1">result_index = </span><span class="s2">None</span>
            <span class="s2">if </span><span class="s1">len(arrays) == </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">index </span><span class="s2">is None and </span><span class="s1">length == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s3"># for backward compat use an object Index instead of RangeIndex</span>
                <span class="s1">result_index = Index([])</span>

            <span class="s1">arrays</span><span class="s2">, </span><span class="s1">arr_columns = reorder_arrays(arrays</span><span class="s2">, </span><span class="s1">arr_columns</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">length)</span>
            <span class="s2">return </span><span class="s1">arrays</span><span class="s2">, </span><span class="s1">arr_columns</span><span class="s2">, </span><span class="s1">result_index</span>

        <span class="s2">if </span><span class="s1">is_iterator(data):</span>
            <span class="s2">if </span><span class="s1">nrows == </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">cls()</span>

            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">first_row = next(data)</span>
            <span class="s2">except </span><span class="s1">StopIteration:</span>
                <span class="s2">return </span><span class="s1">cls(index=index</span><span class="s2">, </span><span class="s1">columns=columns)</span>

            <span class="s1">dtype = </span><span class="s2">None</span>
            <span class="s2">if </span><span class="s1">hasattr(first_row</span><span class="s2">, </span><span class="s4">&quot;dtype&quot;</span><span class="s1">) </span><span class="s2">and </span><span class="s1">first_row.dtype.names:</span>
                <span class="s1">dtype = first_row.dtype</span>

            <span class="s1">values = [first_row]</span>

            <span class="s2">if </span><span class="s1">nrows </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">values += data</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">values.extend(itertools.islice(data</span><span class="s2">, </span><span class="s1">nrows - </span><span class="s5">1</span><span class="s1">))</span>

            <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">data = np.array(values</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">data = values</span>

        <span class="s2">if </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s2">if </span><span class="s1">columns </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">columns = arr_columns = ensure_index(sorted(data))</span>
                <span class="s1">arrays = [data[k] </span><span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">columns]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">arrays = []</span>
                <span class="s1">arr_columns_list = []</span>
                <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">data.items():</span>
                    <span class="s2">if </span><span class="s1">k </span><span class="s2">in </span><span class="s1">columns:</span>
                        <span class="s1">arr_columns_list.append(k)</span>
                        <span class="s1">arrays.append(v)</span>

                <span class="s1">arr_columns = Index(arr_columns_list)</span>
                <span class="s1">arrays</span><span class="s2">, </span><span class="s1">arr_columns</span><span class="s2">, </span><span class="s1">result_index = maybe_reorder(</span>
                    <span class="s1">arrays</span><span class="s2">, </span><span class="s1">arr_columns</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">index</span>
                <span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">isinstance(data</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">DataFrame)):</span>
            <span class="s1">arrays</span><span class="s2">, </span><span class="s1">columns = to_arrays(data</span><span class="s2">, </span><span class="s1">columns)</span>
            <span class="s1">arr_columns = columns</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">arrays</span><span class="s2">, </span><span class="s1">arr_columns = to_arrays(data</span><span class="s2">, </span><span class="s1">columns)</span>
            <span class="s2">if </span><span class="s1">coerce_float:</span>
                <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">arr </span><span class="s2">in </span><span class="s1">enumerate(arrays):</span>
                    <span class="s2">if </span><span class="s1">arr.dtype == object:</span>
                        <span class="s3"># error: Argument 1 to &quot;maybe_convert_objects&quot; has</span>
                        <span class="s3"># incompatible type &quot;Union[ExtensionArray, ndarray]&quot;;</span>
                        <span class="s3"># expected &quot;ndarray&quot;</span>
                        <span class="s1">arrays[i] = lib.maybe_convert_objects(</span>
                            <span class="s1">arr</span><span class="s2">,  </span><span class="s3"># type: ignore[arg-type]</span>
                            <span class="s1">try_float=</span><span class="s2">True,</span>
                        <span class="s1">)</span>

            <span class="s1">arr_columns = ensure_index(arr_columns)</span>
            <span class="s2">if </span><span class="s1">columns </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">columns = arr_columns</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">arrays</span><span class="s2">, </span><span class="s1">arr_columns</span><span class="s2">, </span><span class="s1">result_index = maybe_reorder(</span>
                    <span class="s1">arrays</span><span class="s2">, </span><span class="s1">arr_columns</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">index</span>
                <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">exclude </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">exclude = set()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">exclude = set(exclude)</span>

        <span class="s2">if </span><span class="s1">index </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">isinstance(index</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">or not </span><span class="s1">hasattr(index</span><span class="s2">, </span><span class="s4">&quot;__iter__&quot;</span><span class="s1">):</span>
                <span class="s1">i = columns.get_loc(index)</span>
                <span class="s1">exclude.add(index)</span>
                <span class="s2">if </span><span class="s1">len(arrays) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                    <span class="s1">result_index = Index(arrays[i]</span><span class="s2">, </span><span class="s1">name=index)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">result_index = Index([]</span><span class="s2">, </span><span class="s1">name=index)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">index_data = [arrays[arr_columns.get_loc(field)] </span><span class="s2">for </span><span class="s1">field </span><span class="s2">in </span><span class="s1">index]</span>
                <span class="s2">except </span><span class="s1">(KeyError</span><span class="s2">, </span><span class="s1">TypeError):</span>
                    <span class="s3"># raised by get_loc, see GH#29258</span>
                    <span class="s1">result_index = index</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">result_index = ensure_index_from_sequences(index_data</span><span class="s2">, </span><span class="s1">names=index)</span>
                    <span class="s1">exclude.update(index)</span>

        <span class="s2">if </span><span class="s1">any(exclude):</span>
            <span class="s1">arr_exclude = [x </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">exclude </span><span class="s2">if </span><span class="s1">x </span><span class="s2">in </span><span class="s1">arr_columns]</span>
            <span class="s1">to_remove = [arr_columns.get_loc(col) </span><span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">arr_exclude]</span>
            <span class="s1">arrays = [v </span><span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">enumerate(arrays) </span><span class="s2">if </span><span class="s1">i </span><span class="s2">not in </span><span class="s1">to_remove]</span>

            <span class="s1">columns = columns.drop(exclude)</span>

        <span class="s1">manager = get_option(</span><span class="s4">&quot;mode.data_manager&quot;</span><span class="s1">)</span>
        <span class="s1">mgr = arrays_to_mgr(arrays</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">result_index</span><span class="s2">, </span><span class="s1">typ=manager)</span>

        <span class="s2">return </span><span class="s1">cls(mgr)</span>

    <span class="s2">def </span><span class="s1">to_records(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">index=</span><span class="s2">True, </span><span class="s1">column_dtypes=</span><span class="s2">None, </span><span class="s1">index_dtypes=</span><span class="s2">None</span>
    <span class="s1">) -&gt; np.recarray:</span>
        <span class="s0">&quot;&quot;&quot; 
        Convert DataFrame to a NumPy record array. 
 
        Index will be included as the first field of the record array if 
        requested. 
 
        Parameters 
        ---------- 
        index : bool, default True 
            Include index in resulting record array, stored in 'index' 
            field or using the index label, if set. 
        column_dtypes : str, type, dict, default None 
            If a string or type, the data type to store all columns. If 
            a dictionary, a mapping of column names and indices (zero-indexed) 
            to specific data types. 
        index_dtypes : str, type, dict, default None 
            If a string or type, the data type to store all index levels. If 
            a dictionary, a mapping of index level names and indices 
            (zero-indexed) to specific data types. 
 
            This mapping is applied only if `index=True`. 
 
        Returns 
        ------- 
        numpy.recarray 
            NumPy ndarray with the DataFrame labels as fields and each row 
            of the DataFrame as entries. 
 
        See Also 
        -------- 
        DataFrame.from_records: Convert structured or record ndarray 
            to DataFrame. 
        numpy.recarray: An ndarray that allows field access using 
            attributes, analogous to typed columns in a 
            spreadsheet. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]}, 
        ...                   index=['a', 'b']) 
        &gt;&gt;&gt; df 
           A     B 
        a  1  0.50 
        b  2  0.75 
        &gt;&gt;&gt; df.to_records() 
        rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)], 
                  dtype=[('index', 'O'), ('A', '&lt;i8'), ('B', '&lt;f8')]) 
 
        If the DataFrame index has no label then the recarray field name 
        is set to 'index'. If the index has a label then this is used as the 
        field name: 
 
        &gt;&gt;&gt; df.index = df.index.rename(&quot;I&quot;) 
        &gt;&gt;&gt; df.to_records() 
        rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)], 
                  dtype=[('I', 'O'), ('A', '&lt;i8'), ('B', '&lt;f8')]) 
 
        The index can be excluded from the record array: 
 
        &gt;&gt;&gt; df.to_records(index=False) 
        rec.array([(1, 0.5 ), (2, 0.75)], 
                  dtype=[('A', '&lt;i8'), ('B', '&lt;f8')]) 
 
        Data types can be specified for the columns: 
 
        &gt;&gt;&gt; df.to_records(column_dtypes={&quot;A&quot;: &quot;int32&quot;}) 
        rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)], 
                  dtype=[('I', 'O'), ('A', '&lt;i4'), ('B', '&lt;f8')]) 
 
        As well as for the index: 
 
        &gt;&gt;&gt; df.to_records(index_dtypes=&quot;&lt;S2&quot;) 
        rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)], 
                  dtype=[('I', 'S2'), ('A', '&lt;i8'), ('B', '&lt;f8')]) 
 
        &gt;&gt;&gt; index_dtypes = f&quot;&lt;S{df.index.str.len().max()}&quot; 
        &gt;&gt;&gt; df.to_records(index_dtypes=index_dtypes) 
        rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)], 
                  dtype=[('I', 'S1'), ('A', '&lt;i8'), ('B', '&lt;f8')]) 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">index:</span>
            <span class="s2">if </span><span class="s1">isinstance(self.index</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                <span class="s3"># array of tuples to numpy cols. copy copy copy</span>
                <span class="s1">ix_vals = list(map(np.array</span><span class="s2">, </span><span class="s1">zip(*self.index._values)))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># error: List item 0 has incompatible type &quot;ArrayLike&quot;; expected</span>
                <span class="s3"># &quot;ndarray&quot;</span>
                <span class="s1">ix_vals = [self.index.values]  </span><span class="s3"># type: ignore[list-item]</span>

            <span class="s1">arrays = ix_vals + [</span>
                <span class="s1">np.asarray(self.iloc[:</span><span class="s2">, </span><span class="s1">i]) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(self.columns))</span>
            <span class="s1">]</span>

            <span class="s1">index_names = list(self.index.names)</span>

            <span class="s2">if </span><span class="s1">isinstance(self.index</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                <span class="s1">index_names = com.fill_missing_names(index_names)</span>
            <span class="s2">elif </span><span class="s1">index_names[</span><span class="s5">0</span><span class="s1">] </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">index_names = [</span><span class="s4">&quot;index&quot;</span><span class="s1">]</span>

            <span class="s1">names = [str(name) </span><span class="s2">for </span><span class="s1">name </span><span class="s2">in </span><span class="s1">itertools.chain(index_names</span><span class="s2">, </span><span class="s1">self.columns)]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">arrays = [np.asarray(self.iloc[:</span><span class="s2">, </span><span class="s1">i]) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(self.columns))]</span>
            <span class="s1">names = [str(c) </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">self.columns]</span>
            <span class="s1">index_names = []</span>

        <span class="s1">index_len = len(index_names)</span>
        <span class="s1">formats = []</span>

        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">enumerate(arrays):</span>
            <span class="s1">index = i</span>

            <span class="s3"># When the names and arrays are collected, we</span>
            <span class="s3"># first collect those in the DataFrame's index,</span>
            <span class="s3"># followed by those in its columns.</span>
            <span class="s3">#</span>
            <span class="s3"># Thus, the total length of the array is:</span>
            <span class="s3"># len(index_names) + len(DataFrame.columns).</span>
            <span class="s3">#</span>
            <span class="s3"># This check allows us to see whether we are</span>
            <span class="s3"># handling a name / array in the index or column.</span>
            <span class="s2">if </span><span class="s1">index &lt; index_len:</span>
                <span class="s1">dtype_mapping = index_dtypes</span>
                <span class="s1">name = index_names[index]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">index -= index_len</span>
                <span class="s1">dtype_mapping = column_dtypes</span>
                <span class="s1">name = self.columns[index]</span>

            <span class="s3"># We have a dictionary, so we get the data type</span>
            <span class="s3"># associated with the index or column (which can</span>
            <span class="s3"># be denoted by its name in the DataFrame or its</span>
            <span class="s3"># position in DataFrame's array of indices or</span>
            <span class="s3"># columns, whichever is applicable.</span>
            <span class="s2">if </span><span class="s1">is_dict_like(dtype_mapping):</span>
                <span class="s2">if </span><span class="s1">name </span><span class="s2">in </span><span class="s1">dtype_mapping:</span>
                    <span class="s1">dtype_mapping = dtype_mapping[name]</span>
                <span class="s2">elif </span><span class="s1">index </span><span class="s2">in </span><span class="s1">dtype_mapping:</span>
                    <span class="s1">dtype_mapping = dtype_mapping[index]</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">dtype_mapping = </span><span class="s2">None</span>

            <span class="s3"># If no mapping can be found, use the array's</span>
            <span class="s3"># dtype attribute for formatting.</span>
            <span class="s3">#</span>
            <span class="s3"># A valid dtype must either be a type or</span>
            <span class="s3"># string naming a type.</span>
            <span class="s2">if </span><span class="s1">dtype_mapping </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">formats.append(v.dtype)</span>
            <span class="s2">elif </span><span class="s1">isinstance(dtype_mapping</span><span class="s2">, </span><span class="s1">(type</span><span class="s2">, </span><span class="s1">np.dtype</span><span class="s2">, </span><span class="s1">str)):</span>
                <span class="s3"># Argument 1 to &quot;append&quot; of &quot;list&quot; has incompatible type</span>
                <span class="s3"># &quot;Union[type, dtype[Any], str]&quot;; expected &quot;dtype[_SCT]&quot;  [arg-type]</span>
                <span class="s1">formats.append(dtype_mapping)  </span><span class="s3"># type: ignore[arg-type]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">element = </span><span class="s4">&quot;row&quot; </span><span class="s2">if </span><span class="s1">i &lt; index_len </span><span class="s2">else </span><span class="s4">&quot;column&quot;</span>
                <span class="s1">msg = </span><span class="s4">f&quot;Invalid dtype </span><span class="s2">{</span><span class="s1">dtype_mapping</span><span class="s2">} </span><span class="s4">specified for </span><span class="s2">{</span><span class="s1">element</span><span class="s2">} {</span><span class="s1">name</span><span class="s2">}</span><span class="s4">&quot;</span>
                <span class="s2">raise </span><span class="s1">ValueError(msg)</span>

        <span class="s2">return </span><span class="s1">np.rec.fromarrays(arrays</span><span class="s2">, </span><span class="s1">dtype={</span><span class="s4">&quot;names&quot;</span><span class="s1">: names</span><span class="s2">, </span><span class="s4">&quot;formats&quot;</span><span class="s1">: formats})</span>

    <span class="s1">@classmethod</span>
    <span class="s2">def </span><span class="s1">_from_arrays(</span>
        <span class="s1">cls</span><span class="s2">,</span>
        <span class="s1">arrays</span><span class="s2">,</span>
        <span class="s1">columns</span><span class="s2">,</span>
        <span class="s1">index</span><span class="s2">,</span>
        <span class="s1">dtype: Dtype | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">verify_integrity: bool = </span><span class="s2">True,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Create DataFrame from a list of arrays corresponding to the columns. 
 
        Parameters 
        ---------- 
        arrays : list-like of arrays 
            Each array in the list corresponds to one column, in order. 
        columns : list-like, Index 
            The column names for the resulting DataFrame. 
        index : list-like, Index 
            The rows labels for the resulting DataFrame. 
        dtype : dtype, optional 
            Optional dtype to enforce for all arrays. 
        verify_integrity : bool, default True 
            Validate and homogenize all input. If set to False, it is assumed 
            that all elements of `arrays` are actual arrays how they will be 
            stored in a block (numpy ndarray or ExtensionArray), have the same 
            length as and are aligned with the index, and that `columns` and 
            `index` are ensured to be an Index object. 
 
        Returns 
        ------- 
        DataFrame 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">dtype </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">dtype = pandas_dtype(dtype)</span>

        <span class="s1">manager = get_option(</span><span class="s4">&quot;mode.data_manager&quot;</span><span class="s1">)</span>
        <span class="s1">columns = ensure_index(columns)</span>
        <span class="s2">if </span><span class="s1">len(columns) != len(arrays):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;len(columns) must match len(arrays)&quot;</span><span class="s1">)</span>
        <span class="s1">mgr = arrays_to_mgr(</span>
            <span class="s1">arrays</span><span class="s2">,</span>
            <span class="s1">columns</span><span class="s2">,</span>
            <span class="s1">index</span><span class="s2">,</span>
            <span class="s1">dtype=dtype</span><span class="s2">,</span>
            <span class="s1">verify_integrity=verify_integrity</span><span class="s2">,</span>
            <span class="s1">typ=manager</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">cls(mgr)</span>

    <span class="s1">@doc(</span>
        <span class="s1">storage_options=_shared_docs[</span><span class="s4">&quot;storage_options&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">compression_options=_shared_docs[</span><span class="s4">&quot;compression_options&quot;</span><span class="s1">] % </span><span class="s4">&quot;path&quot;</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">@deprecate_kwarg(old_arg_name=</span><span class="s4">&quot;fname&quot;</span><span class="s2">, </span><span class="s1">new_arg_name=</span><span class="s4">&quot;path&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">to_stata(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">path: FilePath | WriteBuffer[bytes]</span><span class="s2">,</span>
        <span class="s1">convert_dates: dict[Hashable</span><span class="s2">, </span><span class="s1">str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">write_index: bool = </span><span class="s2">True,</span>
        <span class="s1">byteorder: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">time_stamp: datetime.datetime | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">data_label: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">variable_labels: dict[Hashable</span><span class="s2">, </span><span class="s1">str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">version: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s5">114</span><span class="s2">,</span>
        <span class="s1">convert_strl: Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">compression: CompressionOptions = </span><span class="s4">&quot;infer&quot;</span><span class="s2">,</span>
        <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">value_labels: dict[Hashable</span><span class="s2">, </span><span class="s1">dict[float | int</span><span class="s2">, </span><span class="s1">str]] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Export DataFrame object to Stata dta format. 
 
        Writes the DataFrame to a Stata dataset file. 
        &quot;dta&quot; files contain a Stata dataset. 
 
        Parameters 
        ---------- 
        path : str, path object, or buffer 
            String, path object (implementing ``os.PathLike[str]``), or file-like 
            object implementing a binary ``write()`` function. 
 
            .. versionchanged:: 1.0.0 
 
            Previously this was &quot;fname&quot; 
 
        convert_dates : dict 
            Dictionary mapping columns containing datetime types to stata 
            internal format to use when writing the dates. Options are 'tc', 
            'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer 
            or a name. Datetime columns that do not have a conversion type 
            specified will be converted to 'tc'. Raises NotImplementedError if 
            a datetime column has timezone information. 
        write_index : bool 
            Write the index to Stata dataset. 
        byteorder : str 
            Can be &quot;&gt;&quot;, &quot;&lt;&quot;, &quot;little&quot;, or &quot;big&quot;. default is `sys.byteorder`. 
        time_stamp : datetime 
            A datetime to use as file creation date.  Default is the current 
            time. 
        data_label : str, optional 
            A label for the data set.  Must be 80 characters or smaller. 
        variable_labels : dict 
            Dictionary containing columns as keys and variable labels as 
            values. Each label must be 80 characters or smaller. 
        version : {{114, 117, 118, 119, None}}, default 114 
            Version to use in the output dta file. Set to None to let pandas 
            decide between 118 or 119 formats depending on the number of 
            columns in the frame. Version 114 can be read by Stata 10 and 
            later. Version 117 can be read by Stata 13 or later. Version 118 
            is supported in Stata 14 and later. Version 119 is supported in 
            Stata 15 and later. Version 114 limits string variables to 244 
            characters or fewer while versions 117 and later allow strings 
            with lengths up to 2,000,000 characters. Versions 118 and 119 
            support Unicode characters, and version 119 supports more than 
            32,767 variables. 
 
            Version 119 should usually only be used when the number of 
            variables exceeds the capacity of dta format 118. Exporting 
            smaller datasets in format 119 may have unintended consequences, 
            and, as of November 2020, Stata SE cannot read version 119 files. 
 
            .. versionchanged:: 1.0.0 
 
                Added support for formats 118 and 119. 
 
        convert_strl : list, optional 
            List of column names to convert to string columns to Stata StrL 
            format. Only available if version is 117.  Storing strings in the 
            StrL format can produce smaller dta files if strings have more than 
            8 characters and values are repeated. 
        {compression_options} 
 
            .. versionadded:: 1.1.0 
 
            .. versionchanged:: 1.4.0 Zstandard support. 
 
        {storage_options} 
 
            .. versionadded:: 1.2.0 
 
        value_labels : dict of dicts 
            Dictionary containing columns as keys and dictionaries of column value 
            to labels as values. Labels for a single variable must be 32,000 
            characters or smaller. 
 
            .. versionadded:: 1.4.0 
 
        Raises 
        ------ 
        NotImplementedError 
            * If datetimes contain timezone information 
            * Column dtype is not representable in Stata 
        ValueError 
            * Columns listed in convert_dates are neither datetime64[ns] 
              or datetime.datetime 
            * Column listed in convert_dates is not in DataFrame 
            * Categorical label contains more than 32,000 characters 
 
        See Also 
        -------- 
        read_stata : Import Stata data files. 
        io.stata.StataWriter : Low-level writer for Stata data files. 
        io.stata.StataWriter117 : Low-level writer for version 117 files. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({{'animal': ['falcon', 'parrot', 'falcon', 
        ...                               'parrot'], 
        ...                    'speed': [350, 18, 361, 15]}}) 
        &gt;&gt;&gt; df.to_stata('animals.dta')  # doctest: +SKIP 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">version </span><span class="s2">not in </span><span class="s1">(</span><span class="s5">114</span><span class="s2">, </span><span class="s5">117</span><span class="s2">, </span><span class="s5">118</span><span class="s2">, </span><span class="s5">119</span><span class="s2">, None</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Only formats 114, 117, 118 and 119 are supported.&quot;</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">version == </span><span class="s5">114</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">convert_strl </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;strl is not supported in format 114&quot;</span><span class="s1">)</span>
            <span class="s2">from </span><span class="s1">pandas.io.stata </span><span class="s2">import </span><span class="s1">StataWriter </span><span class="s2">as </span><span class="s1">statawriter</span>
        <span class="s2">elif </span><span class="s1">version == </span><span class="s5">117</span><span class="s1">:</span>
            <span class="s3"># mypy: Name 'statawriter' already defined (possibly by an import)</span>
            <span class="s2">from </span><span class="s1">pandas.io.stata </span><span class="s2">import </span><span class="s1">(  </span><span class="s3"># type: ignore[no-redef]</span>
                <span class="s1">StataWriter117 </span><span class="s2">as </span><span class="s1">statawriter</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:  </span><span class="s3"># versions 118 and 119</span>
            <span class="s3"># mypy: Name 'statawriter' already defined (possibly by an import)</span>
            <span class="s2">from </span><span class="s1">pandas.io.stata </span><span class="s2">import </span><span class="s1">(  </span><span class="s3"># type: ignore[no-redef]</span>
                <span class="s1">StataWriterUTF8 </span><span class="s2">as </span><span class="s1">statawriter</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s1">kwargs: dict[str</span><span class="s2">, </span><span class="s1">Any] = {}</span>
        <span class="s2">if </span><span class="s1">version </span><span class="s2">is None or </span><span class="s1">version &gt;= </span><span class="s5">117</span><span class="s1">:</span>
            <span class="s3"># strl conversion is only supported &gt;= 117</span>
            <span class="s1">kwargs[</span><span class="s4">&quot;convert_strl&quot;</span><span class="s1">] = convert_strl</span>
        <span class="s2">if </span><span class="s1">version </span><span class="s2">is None or </span><span class="s1">version &gt;= </span><span class="s5">118</span><span class="s1">:</span>
            <span class="s3"># Specifying the version is only supported for UTF8 (118 or 119)</span>
            <span class="s1">kwargs[</span><span class="s4">&quot;version&quot;</span><span class="s1">] = version</span>

        <span class="s1">writer = statawriter(</span>
            <span class="s1">path</span><span class="s2">,</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">convert_dates=convert_dates</span><span class="s2">,</span>
            <span class="s1">byteorder=byteorder</span><span class="s2">,</span>
            <span class="s1">time_stamp=time_stamp</span><span class="s2">,</span>
            <span class="s1">data_label=data_label</span><span class="s2">,</span>
            <span class="s1">write_index=write_index</span><span class="s2">,</span>
            <span class="s1">variable_labels=variable_labels</span><span class="s2">,</span>
            <span class="s1">compression=compression</span><span class="s2">,</span>
            <span class="s1">storage_options=storage_options</span><span class="s2">,</span>
            <span class="s1">value_labels=value_labels</span><span class="s2">,</span>
            <span class="s1">**kwargs</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s1">writer.write_file()</span>

    <span class="s1">@deprecate_kwarg(old_arg_name=</span><span class="s4">&quot;fname&quot;</span><span class="s2">, </span><span class="s1">new_arg_name=</span><span class="s4">&quot;path&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">to_feather(self</span><span class="s2">, </span><span class="s1">path: FilePath | WriteBuffer[bytes]</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Write a DataFrame to the binary Feather format. 
 
        Parameters 
        ---------- 
        path : str, path object, file-like object 
            String, path object (implementing ``os.PathLike[str]``), or file-like 
            object implementing a binary ``write()`` function. If a string or a path, 
            it will be used as Root Directory path when writing a partitioned dataset. 
        **kwargs : 
            Additional keywords passed to :func:`pyarrow.feather.write_feather`. 
            Starting with pyarrow 0.17, this includes the `compression`, 
            `compression_level`, `chunksize` and `version` keywords. 
 
            .. versionadded:: 1.1.0 
 
        Notes 
        ----- 
        This function writes the dataframe as a `feather file 
        &lt;https://arrow.apache.org/docs/python/feather.html&gt;`_. Requires a default 
        index. For saving the DataFrame with your custom index use a method that 
        supports custom indices e.g. `to_parquet`. 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.io.feather_format </span><span class="s2">import </span><span class="s1">to_feather</span>

        <span class="s1">to_feather(self</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s1">@doc(</span>
        <span class="s1">Series.to_markdown</span><span class="s2">,</span>
        <span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">storage_options=_shared_docs[</span><span class="s4">&quot;storage_options&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">examples=</span><span class="s4">&quot;&quot;&quot;Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame( 
        ...     data={&quot;animal_1&quot;: [&quot;elk&quot;, &quot;pig&quot;], &quot;animal_2&quot;: [&quot;dog&quot;, &quot;quetzal&quot;]} 
        ... ) 
        &gt;&gt;&gt; print(df.to_markdown()) 
        |    | animal_1   | animal_2   | 
        |---:|:-----------|:-----------| 
        |  0 | elk        | dog        | 
        |  1 | pig        | quetzal    | 
 
        Output markdown with a tabulate option. 
 
        &gt;&gt;&gt; print(df.to_markdown(tablefmt=&quot;grid&quot;)) 
        +----+------------+------------+ 
        |    | animal_1   | animal_2   | 
        +====+============+============+ 
        |  0 | elk        | dog        | 
        +----+------------+------------+ 
        |  1 | pig        | quetzal    | 
        +----+------------+------------+&quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">to_markdown(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">buf: IO[str] | str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">mode: str = </span><span class="s4">&quot;wt&quot;</span><span class="s2">,</span>
        <span class="s1">index: bool = </span><span class="s2">True,</span>
        <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; str | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s4">&quot;showindex&quot; </span><span class="s2">in </span><span class="s1">kwargs:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;'showindex' is deprecated. Only 'index' will be used &quot;</span>
                <span class="s4">&quot;in a future version. Use 'index' to silence this warning.&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s1">kwargs.setdefault(</span><span class="s4">&quot;headers&quot;</span><span class="s2">, </span><span class="s4">&quot;keys&quot;</span><span class="s1">)</span>
        <span class="s1">kwargs.setdefault(</span><span class="s4">&quot;tablefmt&quot;</span><span class="s2">, </span><span class="s4">&quot;pipe&quot;</span><span class="s1">)</span>
        <span class="s1">kwargs.setdefault(</span><span class="s4">&quot;showindex&quot;</span><span class="s2">, </span><span class="s1">index)</span>
        <span class="s1">tabulate = import_optional_dependency(</span><span class="s4">&quot;tabulate&quot;</span><span class="s1">)</span>
        <span class="s1">result = tabulate.tabulate(self</span><span class="s2">, </span><span class="s1">**kwargs)</span>
        <span class="s2">if </span><span class="s1">buf </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s2">with </span><span class="s1">get_handle(buf</span><span class="s2">, </span><span class="s1">mode</span><span class="s2">, </span><span class="s1">storage_options=storage_options) </span><span class="s2">as </span><span class="s1">handles:</span>
            <span class="s1">handles.handle.write(result)</span>
        <span class="s2">return None</span>

    <span class="s1">@doc(storage_options=_shared_docs[</span><span class="s4">&quot;storage_options&quot;</span><span class="s1">])</span>
    <span class="s1">@deprecate_kwarg(old_arg_name=</span><span class="s4">&quot;fname&quot;</span><span class="s2">, </span><span class="s1">new_arg_name=</span><span class="s4">&quot;path&quot;</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">to_parquet(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">path: FilePath | WriteBuffer[bytes] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">engine: str = </span><span class="s4">&quot;auto&quot;</span><span class="s2">,</span>
        <span class="s1">compression: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s4">&quot;snappy&quot;</span><span class="s2">,</span>
        <span class="s1">index: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">partition_cols: list[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; bytes | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Write a DataFrame to the binary parquet format. 
 
        This function writes the dataframe as a `parquet file 
        &lt;https://parquet.apache.org/&gt;`_. You can choose different parquet 
        backends, and have the option of compression. See 
        :ref:`the user guide &lt;io.parquet&gt;` for more details. 
 
        Parameters 
        ---------- 
        path : str, path object, file-like object, or None, default None 
            String, path object (implementing ``os.PathLike[str]``), or file-like 
            object implementing a binary ``write()`` function. If None, the result is 
            returned as bytes. If a string or path, it will be used as Root Directory 
            path when writing a partitioned dataset. 
 
            .. versionchanged:: 1.2.0 
 
            Previously this was &quot;fname&quot; 
 
        engine : {{'auto', 'pyarrow', 'fastparquet'}}, default 'auto' 
            Parquet library to use. If 'auto', then the option 
            ``io.parquet.engine`` is used. The default ``io.parquet.engine`` 
            behavior is to try 'pyarrow', falling back to 'fastparquet' if 
            'pyarrow' is unavailable. 
        compression : {{'snappy', 'gzip', 'brotli', None}}, default 'snappy' 
            Name of the compression to use. Use ``None`` for no compression. 
        index : bool, default None 
            If ``True``, include the dataframe's index(es) in the file output. 
            If ``False``, they will not be written to the file. 
            If ``None``, similar to ``True`` the dataframe's index(es) 
            will be saved. However, instead of being saved as values, 
            the RangeIndex will be stored as a range in the metadata so it 
            doesn't require much space and is faster. Other indexes will 
            be included as columns in the file output. 
        partition_cols : list, optional, default None 
            Column names by which to partition the dataset. 
            Columns are partitioned in the order they are given. 
            Must be None if path is not a string. 
        {storage_options} 
 
            .. versionadded:: 1.2.0 
 
        **kwargs 
            Additional arguments passed to the parquet library. See 
            :ref:`pandas io &lt;io.parquet&gt;` for more details. 
 
        Returns 
        ------- 
        bytes if no path argument is provided else None 
 
        See Also 
        -------- 
        read_parquet : Read a parquet file. 
        DataFrame.to_csv : Write a csv file. 
        DataFrame.to_sql : Write to a sql table. 
        DataFrame.to_hdf : Write to hdf. 
 
        Notes 
        ----- 
        This function requires either the `fastparquet 
        &lt;https://pypi.org/project/fastparquet&gt;`_ or `pyarrow 
        &lt;https://arrow.apache.org/docs/python/&gt;`_ library. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame(data={{'col1': [1, 2], 'col2': [3, 4]}}) 
        &gt;&gt;&gt; df.to_parquet('df.parquet.gzip', 
        ...               compression='gzip')  # doctest: +SKIP 
        &gt;&gt;&gt; pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP 
           col1  col2 
        0     1     3 
        1     2     4 
 
        If you want to get a buffer to the parquet content you can use a io.BytesIO 
        object, as long as you don't use partition_cols, which creates multiple files. 
 
        &gt;&gt;&gt; import io 
        &gt;&gt;&gt; f = io.BytesIO() 
        &gt;&gt;&gt; df.to_parquet(f) 
        &gt;&gt;&gt; f.seek(0) 
        0 
        &gt;&gt;&gt; content = f.read() 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.io.parquet </span><span class="s2">import </span><span class="s1">to_parquet</span>

        <span class="s2">return </span><span class="s1">to_parquet(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">path</span><span class="s2">,</span>
            <span class="s1">engine</span><span class="s2">,</span>
            <span class="s1">compression=compression</span><span class="s2">,</span>
            <span class="s1">index=index</span><span class="s2">,</span>
            <span class="s1">partition_cols=partition_cols</span><span class="s2">,</span>
            <span class="s1">storage_options=storage_options</span><span class="s2">,</span>
            <span class="s1">**kwargs</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@Substitution(</span>
        <span class="s1">header_type=</span><span class="s4">&quot;bool&quot;</span><span class="s2">,</span>
        <span class="s1">header=</span><span class="s4">&quot;Whether to print column labels, default True&quot;</span><span class="s2">,</span>
        <span class="s1">col_space_type=</span><span class="s4">&quot;str or int, list or dict of int or str&quot;</span><span class="s2">,</span>
        <span class="s1">col_space=</span><span class="s4">&quot;The minimum width of each column in CSS length &quot;</span>
        <span class="s4">&quot;units.  An int is assumed to be px units.</span><span class="s2">\n\n</span><span class="s4">&quot;</span>
        <span class="s4">&quot;            .. versionadded:: 0.25.0</span><span class="s2">\n</span><span class="s4">&quot;</span>
        <span class="s4">&quot;                Ability to use str&quot;</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">@Substitution(shared_params=fmt.common_docstring</span><span class="s2">, </span><span class="s1">returns=fmt.return_docstring)</span>
    <span class="s2">def </span><span class="s1">to_html(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">buf: FilePath | WriteBuffer[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">columns: Sequence[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">col_space: ColspaceArgType | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">header: bool | Sequence[str] = </span><span class="s2">True,</span>
        <span class="s1">index: bool = </span><span class="s2">True,</span>
        <span class="s1">na_rep: str = </span><span class="s4">&quot;NaN&quot;</span><span class="s2">,</span>
        <span class="s1">formatters: FormattersType | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">float_format: FloatFormatType | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">sparsify: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">index_names: bool = </span><span class="s2">True,</span>
        <span class="s1">justify: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">max_rows: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">max_cols: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">show_dimensions: bool | str = </span><span class="s2">False,</span>
        <span class="s1">decimal: str = </span><span class="s4">&quot;.&quot;</span><span class="s2">,</span>
        <span class="s1">bold_rows: bool = </span><span class="s2">True,</span>
        <span class="s1">classes: str | list | tuple | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">escape: bool = </span><span class="s2">True,</span>
        <span class="s1">notebook: bool = </span><span class="s2">False,</span>
        <span class="s1">border: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">table_id: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">render_links: bool = </span><span class="s2">False,</span>
        <span class="s1">encoding: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Render a DataFrame as an HTML table. 
        %(shared_params)s 
        bold_rows : bool, default True 
            Make the row labels bold in the output. 
        classes : str or list or tuple, default None 
            CSS class(es) to apply to the resulting html table. 
        escape : bool, default True 
            Convert the characters &lt;, &gt;, and &amp; to HTML-safe sequences. 
        notebook : {True, False}, default False 
            Whether the generated HTML is for IPython Notebook. 
        border : int 
            A ``border=border`` attribute is included in the opening 
            `&lt;table&gt;` tag. Default ``pd.options.display.html.border``. 
        table_id : str, optional 
            A css id is included in the opening `&lt;table&gt;` tag if specified. 
        render_links : bool, default False 
            Convert URLs to HTML links. 
        encoding : str, default &quot;utf-8&quot; 
            Set character encoding. 
 
            .. versionadded:: 1.0 
        %(returns)s 
        See Also 
        -------- 
        to_string : Convert DataFrame to a string. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">justify </span><span class="s2">is not None and </span><span class="s1">justify </span><span class="s2">not in </span><span class="s1">fmt._VALID_JUSTIFY_PARAMETERS:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Invalid value for justify parameter&quot;</span><span class="s1">)</span>

        <span class="s1">formatter = fmt.DataFrameFormatter(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">columns=columns</span><span class="s2">,</span>
            <span class="s1">col_space=col_space</span><span class="s2">,</span>
            <span class="s1">na_rep=na_rep</span><span class="s2">,</span>
            <span class="s1">header=header</span><span class="s2">,</span>
            <span class="s1">index=index</span><span class="s2">,</span>
            <span class="s1">formatters=formatters</span><span class="s2">,</span>
            <span class="s1">float_format=float_format</span><span class="s2">,</span>
            <span class="s1">bold_rows=bold_rows</span><span class="s2">,</span>
            <span class="s1">sparsify=sparsify</span><span class="s2">,</span>
            <span class="s1">justify=justify</span><span class="s2">,</span>
            <span class="s1">index_names=index_names</span><span class="s2">,</span>
            <span class="s1">escape=escape</span><span class="s2">,</span>
            <span class="s1">decimal=decimal</span><span class="s2">,</span>
            <span class="s1">max_rows=max_rows</span><span class="s2">,</span>
            <span class="s1">max_cols=max_cols</span><span class="s2">,</span>
            <span class="s1">show_dimensions=show_dimensions</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s3"># TODO: a generic formatter wld b in DataFrameFormatter</span>
        <span class="s2">return </span><span class="s1">fmt.DataFrameRenderer(formatter).to_html(</span>
            <span class="s1">buf=buf</span><span class="s2">,</span>
            <span class="s1">classes=classes</span><span class="s2">,</span>
            <span class="s1">notebook=notebook</span><span class="s2">,</span>
            <span class="s1">border=border</span><span class="s2">,</span>
            <span class="s1">encoding=encoding</span><span class="s2">,</span>
            <span class="s1">table_id=table_id</span><span class="s2">,</span>
            <span class="s1">render_links=render_links</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@doc(</span>
        <span class="s1">storage_options=_shared_docs[</span><span class="s4">&quot;storage_options&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">compression_options=_shared_docs[</span><span class="s4">&quot;compression_options&quot;</span><span class="s1">] % </span><span class="s4">&quot;path_or_buffer&quot;</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">to_xml(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">path_or_buffer: FilePath | WriteBuffer[bytes] | WriteBuffer[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">index: bool = </span><span class="s2">True,</span>
        <span class="s1">root_name: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s4">&quot;data&quot;</span><span class="s2">,</span>
        <span class="s1">row_name: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s4">&quot;row&quot;</span><span class="s2">,</span>
        <span class="s1">na_rep: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">attr_cols: list[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">elem_cols: list[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">namespaces: dict[str | </span><span class="s2">None, </span><span class="s1">str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">prefix: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">encoding: str = </span><span class="s4">&quot;utf-8&quot;</span><span class="s2">,</span>
        <span class="s1">xml_declaration: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">True,</span>
        <span class="s1">pretty_print: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">True,</span>
        <span class="s1">parser: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s4">&quot;lxml&quot;</span><span class="s2">,</span>
        <span class="s1">stylesheet: FilePath | ReadBuffer[str] | ReadBuffer[bytes] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">compression: CompressionOptions = </span><span class="s4">&quot;infer&quot;</span><span class="s2">,</span>
        <span class="s1">storage_options: StorageOptions = </span><span class="s2">None,</span>
    <span class="s1">) -&gt; str | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Render a DataFrame to an XML document. 
 
        .. versionadded:: 1.3.0 
 
        Parameters 
        ---------- 
        path_or_buffer : str, path object, file-like object, or None, default None 
            String, path object (implementing ``os.PathLike[str]``), or file-like 
            object implementing a ``write()`` function. If None, the result is returned 
            as a string. 
        index : bool, default True 
            Whether to include index in XML document. 
        root_name : str, default 'data' 
            The name of root element in XML document. 
        row_name : str, default 'row' 
            The name of row element in XML document. 
        na_rep : str, optional 
            Missing data representation. 
        attr_cols : list-like, optional 
            List of columns to write as attributes in row element. 
            Hierarchical columns will be flattened with underscore 
            delimiting the different levels. 
        elem_cols : list-like, optional 
            List of columns to write as children in row element. By default, 
            all columns output as children of row element. Hierarchical 
            columns will be flattened with underscore delimiting the 
            different levels. 
        namespaces : dict, optional 
            All namespaces to be defined in root element. Keys of dict 
            should be prefix names and values of dict corresponding URIs. 
            Default namespaces should be given empty string key. For 
            example, :: 
 
                namespaces = {{&quot;&quot;: &quot;https://example.com&quot;}} 
 
        prefix : str, optional 
            Namespace prefix to be used for every element and/or attribute 
            in document. This should be one of the keys in ``namespaces`` 
            dict. 
        encoding : str, default 'utf-8' 
            Encoding of the resulting document. 
        xml_declaration : bool, default True 
            Whether to include the XML declaration at start of document. 
        pretty_print : bool, default True 
            Whether output should be pretty printed with indentation and 
            line breaks. 
        parser : {{'lxml','etree'}}, default 'lxml' 
            Parser module to use for building of tree. Only 'lxml' and 
            'etree' are supported. With 'lxml', the ability to use XSLT 
            stylesheet is supported. 
        stylesheet : str, path object or file-like object, optional 
            A URL, file-like object, or a raw string containing an XSLT 
            script used to transform the raw XML output. Script should use 
            layout of elements and attributes from original output. This 
            argument requires ``lxml`` to be installed. Only XSLT 1.0 
            scripts and not later versions is currently supported. 
        {compression_options} 
 
            .. versionchanged:: 1.4.0 Zstandard support. 
 
        {storage_options} 
 
        Returns 
        ------- 
        None or str 
            If ``io`` is None, returns the resulting XML format as a 
            string. Otherwise returns None. 
 
        See Also 
        -------- 
        to_json : Convert the pandas object to a JSON string. 
        to_html : Convert DataFrame to a html. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({{'shape': ['square', 'circle', 'triangle'], 
        ...                    'degrees': [360, 360, 180], 
        ...                    'sides': [4, np.nan, 3]}}) 
 
        &gt;&gt;&gt; df.to_xml()  # doctest: +SKIP 
        &lt;?xml version='1.0' encoding='utf-8'?&gt; 
        &lt;data&gt; 
          &lt;row&gt; 
            &lt;index&gt;0&lt;/index&gt; 
            &lt;shape&gt;square&lt;/shape&gt; 
            &lt;degrees&gt;360&lt;/degrees&gt; 
            &lt;sides&gt;4.0&lt;/sides&gt; 
          &lt;/row&gt; 
          &lt;row&gt; 
            &lt;index&gt;1&lt;/index&gt; 
            &lt;shape&gt;circle&lt;/shape&gt; 
            &lt;degrees&gt;360&lt;/degrees&gt; 
            &lt;sides/&gt; 
          &lt;/row&gt; 
          &lt;row&gt; 
            &lt;index&gt;2&lt;/index&gt; 
            &lt;shape&gt;triangle&lt;/shape&gt; 
            &lt;degrees&gt;180&lt;/degrees&gt; 
            &lt;sides&gt;3.0&lt;/sides&gt; 
          &lt;/row&gt; 
        &lt;/data&gt; 
 
        &gt;&gt;&gt; df.to_xml(attr_cols=[ 
        ...           'index', 'shape', 'degrees', 'sides' 
        ...           ])  # doctest: +SKIP 
        &lt;?xml version='1.0' encoding='utf-8'?&gt; 
        &lt;data&gt; 
          &lt;row index=&quot;0&quot; shape=&quot;square&quot; degrees=&quot;360&quot; sides=&quot;4.0&quot;/&gt; 
          &lt;row index=&quot;1&quot; shape=&quot;circle&quot; degrees=&quot;360&quot;/&gt; 
          &lt;row index=&quot;2&quot; shape=&quot;triangle&quot; degrees=&quot;180&quot; sides=&quot;3.0&quot;/&gt; 
        &lt;/data&gt; 
 
        &gt;&gt;&gt; df.to_xml(namespaces={{&quot;doc&quot;: &quot;https://example.com&quot;}}, 
        ...           prefix=&quot;doc&quot;)  # doctest: +SKIP 
        &lt;?xml version='1.0' encoding='utf-8'?&gt; 
        &lt;doc:data xmlns:doc=&quot;https://example.com&quot;&gt; 
          &lt;doc:row&gt; 
            &lt;doc:index&gt;0&lt;/doc:index&gt; 
            &lt;doc:shape&gt;square&lt;/doc:shape&gt; 
            &lt;doc:degrees&gt;360&lt;/doc:degrees&gt; 
            &lt;doc:sides&gt;4.0&lt;/doc:sides&gt; 
          &lt;/doc:row&gt; 
          &lt;doc:row&gt; 
            &lt;doc:index&gt;1&lt;/doc:index&gt; 
            &lt;doc:shape&gt;circle&lt;/doc:shape&gt; 
            &lt;doc:degrees&gt;360&lt;/doc:degrees&gt; 
            &lt;doc:sides/&gt; 
          &lt;/doc:row&gt; 
          &lt;doc:row&gt; 
            &lt;doc:index&gt;2&lt;/doc:index&gt; 
            &lt;doc:shape&gt;triangle&lt;/doc:shape&gt; 
            &lt;doc:degrees&gt;180&lt;/doc:degrees&gt; 
            &lt;doc:sides&gt;3.0&lt;/doc:sides&gt; 
          &lt;/doc:row&gt; 
        &lt;/doc:data&gt; 
        &quot;&quot;&quot;</span>

        <span class="s2">from </span><span class="s1">pandas.io.formats.xml </span><span class="s2">import </span><span class="s1">(</span>
            <span class="s1">EtreeXMLFormatter</span><span class="s2">,</span>
            <span class="s1">LxmlXMLFormatter</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s1">lxml = import_optional_dependency(</span><span class="s4">&quot;lxml.etree&quot;</span><span class="s2">, </span><span class="s1">errors=</span><span class="s4">&quot;ignore&quot;</span><span class="s1">)</span>

        <span class="s1">TreeBuilder: type[EtreeXMLFormatter] | type[LxmlXMLFormatter]</span>

        <span class="s2">if </span><span class="s1">parser == </span><span class="s4">&quot;lxml&quot;</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">lxml </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">TreeBuilder = LxmlXMLFormatter</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ImportError(</span>
                    <span class="s4">&quot;lxml not found, please install or use the etree parser.&quot;</span>
                <span class="s1">)</span>

        <span class="s2">elif </span><span class="s1">parser == </span><span class="s4">&quot;etree&quot;</span><span class="s1">:</span>
            <span class="s1">TreeBuilder = EtreeXMLFormatter</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Values for parser can only be lxml or etree.&quot;</span><span class="s1">)</span>

        <span class="s1">xml_formatter = TreeBuilder(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">path_or_buffer=path_or_buffer</span><span class="s2">,</span>
            <span class="s1">index=index</span><span class="s2">,</span>
            <span class="s1">root_name=root_name</span><span class="s2">,</span>
            <span class="s1">row_name=row_name</span><span class="s2">,</span>
            <span class="s1">na_rep=na_rep</span><span class="s2">,</span>
            <span class="s1">attr_cols=attr_cols</span><span class="s2">,</span>
            <span class="s1">elem_cols=elem_cols</span><span class="s2">,</span>
            <span class="s1">namespaces=namespaces</span><span class="s2">,</span>
            <span class="s1">prefix=prefix</span><span class="s2">,</span>
            <span class="s1">encoding=encoding</span><span class="s2">,</span>
            <span class="s1">xml_declaration=xml_declaration</span><span class="s2">,</span>
            <span class="s1">pretty_print=pretty_print</span><span class="s2">,</span>
            <span class="s1">stylesheet=stylesheet</span><span class="s2">,</span>
            <span class="s1">compression=compression</span><span class="s2">,</span>
            <span class="s1">storage_options=storage_options</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">xml_formatter.write_output()</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s1">@doc(INFO_DOCSTRING</span><span class="s2">, </span><span class="s1">**frame_sub_kwargs)</span>
    <span class="s2">def </span><span class="s1">info(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">verbose: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">buf: WriteBuffer[str] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">max_cols: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">memory_usage: bool | str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">show_counts: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">null_counts: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">null_counts </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">show_counts </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;null_counts used with show_counts. Use show_counts.&quot;</span><span class="s1">)</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;null_counts is deprecated. Use show_counts instead&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">show_counts = null_counts</span>
        <span class="s1">info = DataFrameInfo(</span>
            <span class="s1">data=self</span><span class="s2">,</span>
            <span class="s1">memory_usage=memory_usage</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s1">info.render(</span>
            <span class="s1">buf=buf</span><span class="s2">,</span>
            <span class="s1">max_cols=max_cols</span><span class="s2">,</span>
            <span class="s1">verbose=verbose</span><span class="s2">,</span>
            <span class="s1">show_counts=show_counts</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">memory_usage(self</span><span class="s2">, </span><span class="s1">index: bool = </span><span class="s2">True, </span><span class="s1">deep: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the memory usage of each column in bytes. 
 
        The memory usage can optionally include the contribution of 
        the index and elements of `object` dtype. 
 
        This value is displayed in `DataFrame.info` by default. This can be 
        suppressed by setting ``pandas.options.display.memory_usage`` to False. 
 
        Parameters 
        ---------- 
        index : bool, default True 
            Specifies whether to include the memory usage of the DataFrame's 
            index in returned Series. If ``index=True``, the memory usage of 
            the index is the first item in the output. 
        deep : bool, default False 
            If True, introspect the data deeply by interrogating 
            `object` dtypes for system-level memory consumption, and include 
            it in the returned values. 
 
        Returns 
        ------- 
        Series 
            A Series whose index is the original column names and whose values 
            is the memory usage of each column in bytes. 
 
        See Also 
        -------- 
        numpy.ndarray.nbytes : Total bytes consumed by the elements of an 
            ndarray. 
        Series.memory_usage : Bytes consumed by a Series. 
        Categorical : Memory-efficient array for string values with 
            many repeated values. 
        DataFrame.info : Concise summary of a DataFrame. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; dtypes = ['int64', 'float64', 'complex128', 'object', 'bool'] 
        &gt;&gt;&gt; data = dict([(t, np.ones(shape=5000, dtype=int).astype(t)) 
        ...              for t in dtypes]) 
        &gt;&gt;&gt; df = pd.DataFrame(data) 
        &gt;&gt;&gt; df.head() 
           int64  float64            complex128  object  bool 
        0      1      1.0              1.0+0.0j       1  True 
        1      1      1.0              1.0+0.0j       1  True 
        2      1      1.0              1.0+0.0j       1  True 
        3      1      1.0              1.0+0.0j       1  True 
        4      1      1.0              1.0+0.0j       1  True 
 
        &gt;&gt;&gt; df.memory_usage() 
        Index           128 
        int64         40000 
        float64       40000 
        complex128    80000 
        object        40000 
        bool           5000 
        dtype: int64 
 
        &gt;&gt;&gt; df.memory_usage(index=False) 
        int64         40000 
        float64       40000 
        complex128    80000 
        object        40000 
        bool           5000 
        dtype: int64 
 
        The memory footprint of `object` dtype columns is ignored by default: 
 
        &gt;&gt;&gt; df.memory_usage(deep=True) 
        Index            128 
        int64          40000 
        float64        40000 
        complex128     80000 
        object        180000 
        bool            5000 
        dtype: int64 
 
        Use a Categorical for efficient storage of an object-dtype column with 
        many repeated values. 
 
        &gt;&gt;&gt; df['object'].astype('category').memory_usage(deep=True) 
        5244 
        &quot;&quot;&quot;</span>
        <span class="s1">result = self._constructor_sliced(</span>
            <span class="s1">[c.memory_usage(index=</span><span class="s2">False, </span><span class="s1">deep=deep) </span><span class="s2">for </span><span class="s1">col</span><span class="s2">, </span><span class="s1">c </span><span class="s2">in </span><span class="s1">self.items()]</span><span class="s2">,</span>
            <span class="s1">index=self.columns</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">index:</span>
            <span class="s1">index_memory_usage = self._constructor_sliced(</span>
                <span class="s1">self.index.memory_usage(deep=deep)</span><span class="s2">, </span><span class="s1">index=[</span><span class="s4">&quot;Index&quot;</span><span class="s1">]</span>
            <span class="s1">)</span>
            <span class="s1">result = index_memory_usage._append(result)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">transpose(self</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">copy: bool = </span><span class="s2">False</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Transpose index and columns. 
 
        Reflect the DataFrame over its main diagonal by writing rows as columns 
        and vice-versa. The property :attr:`.T` is an accessor to the method 
        :meth:`transpose`. 
 
        Parameters 
        ---------- 
        *args : tuple, optional 
            Accepted for compatibility with NumPy. 
        copy : bool, default False 
            Whether to copy the data after transposing, even for DataFrames 
            with a single dtype. 
 
            Note that a copy is always required for mixed dtype DataFrames, 
            or for DataFrames with any extension types. 
 
        Returns 
        ------- 
        DataFrame 
            The transposed DataFrame. 
 
        See Also 
        -------- 
        numpy.transpose : Permute the dimensions of a given array. 
 
        Notes 
        ----- 
        Transposing a DataFrame with mixed dtypes will result in a homogeneous 
        DataFrame with the `object` dtype. In such a case, a copy of the data 
        is always made. 
 
        Examples 
        -------- 
        **Square DataFrame with homogeneous dtype** 
 
        &gt;&gt;&gt; d1 = {'col1': [1, 2], 'col2': [3, 4]} 
        &gt;&gt;&gt; df1 = pd.DataFrame(data=d1) 
        &gt;&gt;&gt; df1 
           col1  col2 
        0     1     3 
        1     2     4 
 
        &gt;&gt;&gt; df1_transposed = df1.T # or df1.transpose() 
        &gt;&gt;&gt; df1_transposed 
              0  1 
        col1  1  2 
        col2  3  4 
 
        When the dtype is homogeneous in the original DataFrame, we get a 
        transposed DataFrame with the same dtype: 
 
        &gt;&gt;&gt; df1.dtypes 
        col1    int64 
        col2    int64 
        dtype: object 
        &gt;&gt;&gt; df1_transposed.dtypes 
        0    int64 
        1    int64 
        dtype: object 
 
        **Non-square DataFrame with mixed dtypes** 
 
        &gt;&gt;&gt; d2 = {'name': ['Alice', 'Bob'], 
        ...       'score': [9.5, 8], 
        ...       'employed': [False, True], 
        ...       'kids': [0, 0]} 
        &gt;&gt;&gt; df2 = pd.DataFrame(data=d2) 
        &gt;&gt;&gt; df2 
            name  score  employed  kids 
        0  Alice    9.5     False     0 
        1    Bob    8.0      True     0 
 
        &gt;&gt;&gt; df2_transposed = df2.T # or df2.transpose() 
        &gt;&gt;&gt; df2_transposed 
                      0     1 
        name      Alice   Bob 
        score       9.5   8.0 
        employed  False  True 
        kids          0     0 
 
        When the DataFrame has mixed dtypes, we get a transposed DataFrame with 
        the `object` dtype: 
 
        &gt;&gt;&gt; df2.dtypes 
        name         object 
        score       float64 
        employed       bool 
        kids          int64 
        dtype: object 
        &gt;&gt;&gt; df2_transposed.dtypes 
        0    object 
        1    object 
        dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s1">nv.validate_transpose(args</span><span class="s2">, </span><span class="s1">{})</span>
        <span class="s3"># construct the args</span>

        <span class="s1">dtypes = list(self.dtypes)</span>

        <span class="s2">if </span><span class="s1">self._can_fast_transpose:</span>
            <span class="s3"># Note: tests pass without this, but this improves perf quite a bit.</span>
            <span class="s1">new_vals = self._values.T</span>
            <span class="s2">if </span><span class="s1">copy:</span>
                <span class="s1">new_vals = new_vals.copy()</span>

            <span class="s1">result = self._constructor(new_vals</span><span class="s2">, </span><span class="s1">index=self.columns</span><span class="s2">, </span><span class="s1">columns=self.index)</span>

        <span class="s2">elif </span><span class="s1">(</span>
            <span class="s1">self._is_homogeneous_type </span><span class="s2">and </span><span class="s1">dtypes </span><span class="s2">and </span><span class="s1">is_extension_array_dtype(dtypes[</span><span class="s5">0</span><span class="s1">])</span>
        <span class="s1">):</span>
            <span class="s3"># We have EAs with the same dtype. We can preserve that dtype in transpose.</span>
            <span class="s1">dtype = dtypes[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">arr_type = dtype.construct_array_type()</span>
            <span class="s1">values = self.values</span>

            <span class="s1">new_values = [arr_type._from_sequence(row</span><span class="s2">, </span><span class="s1">dtype=dtype) </span><span class="s2">for </span><span class="s1">row </span><span class="s2">in </span><span class="s1">values]</span>
            <span class="s1">result = type(self)._from_arrays(</span>
                <span class="s1">new_values</span><span class="s2">, </span><span class="s1">index=self.columns</span><span class="s2">, </span><span class="s1">columns=self.index</span>
            <span class="s1">)</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">new_arr = self.values.T</span>
            <span class="s2">if </span><span class="s1">copy:</span>
                <span class="s1">new_arr = new_arr.copy()</span>
            <span class="s1">result = self._constructor(new_arr</span><span class="s2">, </span><span class="s1">index=self.columns</span><span class="s2">, </span><span class="s1">columns=self.index)</span>

        <span class="s2">return </span><span class="s1">result.__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;transpose&quot;</span><span class="s1">)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">T(self) -&gt; DataFrame:</span>
        <span class="s2">return </span><span class="s1">self.transpose()</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Indexing Methods</span>

    <span class="s2">def </span><span class="s1">_ixs(self</span><span class="s2">, </span><span class="s1">i: int</span><span class="s2">, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Parameters 
        ---------- 
        i : int 
        axis : int 
 
        Notes 
        ----- 
        If slice passed, the resulting data will be a view. 
        &quot;&quot;&quot;</span>
        <span class="s3"># irow</span>
        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">new_values = self._mgr.fast_xs(i)</span>

            <span class="s3"># if we are a copy, mark as such</span>
            <span class="s1">copy = isinstance(new_values</span><span class="s2">, </span><span class="s1">np.ndarray) </span><span class="s2">and </span><span class="s1">new_values.base </span><span class="s2">is None</span>
            <span class="s1">result = self._constructor_sliced(</span>
                <span class="s1">new_values</span><span class="s2">,</span>
                <span class="s1">index=self.columns</span><span class="s2">,</span>
                <span class="s1">name=self.index[i]</span><span class="s2">,</span>
                <span class="s1">dtype=new_values.dtype</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">result._set_is_copy(self</span><span class="s2">, </span><span class="s1">copy=copy)</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s3"># icol</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">label = self.columns[i]</span>

            <span class="s1">col_mgr = self._mgr.iget(i)</span>
            <span class="s1">result = self._box_col_values(col_mgr</span><span class="s2">, </span><span class="s1">i)</span>

            <span class="s3"># this is a cached value, mark it so</span>
            <span class="s1">result._set_as_cached(label</span><span class="s2">, </span><span class="s1">self)</span>
            <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_get_column_array(self</span><span class="s2">, </span><span class="s1">i: int) -&gt; ArrayLike:</span>
        <span class="s0">&quot;&quot;&quot; 
        Get the values of the i'th column (ndarray or ExtensionArray, as stored 
        in the Block) 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._mgr.iget_values(i)</span>

    <span class="s2">def </span><span class="s1">_iter_column_arrays(self) -&gt; Iterator[ArrayLike]:</span>
        <span class="s0">&quot;&quot;&quot; 
        Iterate over the arrays of all columns in order. 
        This returns the values as stored in the Block (ndarray or ExtensionArray). 
        &quot;&quot;&quot;</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(self.columns)):</span>
            <span class="s2">yield </span><span class="s1">self._get_column_array(i)</span>

    <span class="s2">def </span><span class="s1">__getitem__(self</span><span class="s2">, </span><span class="s1">key):</span>
        <span class="s1">check_deprecated_indexers(key)</span>
        <span class="s1">key = lib.item_from_zerodim(key)</span>
        <span class="s1">key = com.apply_if_callable(key</span><span class="s2">, </span><span class="s1">self)</span>

        <span class="s2">if </span><span class="s1">is_hashable(key) </span><span class="s2">and not </span><span class="s1">is_iterator(key):</span>
            <span class="s3"># is_iterator to exclude generator e.g. test_getitem_listlike</span>
            <span class="s3"># shortcut if the key is in columns</span>
            <span class="s2">if </span><span class="s1">self.columns.is_unique </span><span class="s2">and </span><span class="s1">key </span><span class="s2">in </span><span class="s1">self.columns:</span>
                <span class="s2">if </span><span class="s1">isinstance(self.columns</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                    <span class="s2">return </span><span class="s1">self._getitem_multilevel(key)</span>
                <span class="s2">return </span><span class="s1">self._get_item_cache(key)</span>

        <span class="s3"># Do we have a slicer (on rows)?</span>
        <span class="s1">indexer = convert_to_index_sliceable(self</span><span class="s2">, </span><span class="s1">key)</span>
        <span class="s2">if </span><span class="s1">indexer </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">isinstance(indexer</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
                <span class="s1">indexer = lib.maybe_indices_to_slice(</span>
                    <span class="s1">indexer.astype(np.intp</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span><span class="s2">, </span><span class="s1">len(self)</span>
                <span class="s1">)</span>
                <span class="s2">if </span><span class="s1">isinstance(indexer</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
                    <span class="s3"># GH#43223 If we can not convert, use take</span>
                    <span class="s2">return </span><span class="s1">self.take(indexer</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>
            <span class="s3"># either we have a slice or we have a string that can be converted</span>
            <span class="s3">#  to a slice for partial-string date indexing</span>
            <span class="s2">return </span><span class="s1">self._slice(indexer</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>

        <span class="s3"># Do we have a (boolean) DataFrame?</span>
        <span class="s2">if </span><span class="s1">isinstance(key</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">return </span><span class="s1">self.where(key)</span>

        <span class="s3"># Do we have a (boolean) 1d indexer?</span>
        <span class="s2">if </span><span class="s1">com.is_bool_indexer(key):</span>
            <span class="s2">return </span><span class="s1">self._getitem_bool_array(key)</span>

        <span class="s3"># We are left with two options: a single key, and a collection of keys,</span>
        <span class="s3"># We interpret tuples as collections only for non-MultiIndex</span>
        <span class="s1">is_single_key = isinstance(key</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">or not </span><span class="s1">is_list_like(key)</span>

        <span class="s2">if </span><span class="s1">is_single_key:</span>
            <span class="s2">if </span><span class="s1">self.columns.nlevels &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">self._getitem_multilevel(key)</span>
            <span class="s1">indexer = self.columns.get_loc(key)</span>
            <span class="s2">if </span><span class="s1">is_integer(indexer):</span>
                <span class="s1">indexer = [indexer]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">is_iterator(key):</span>
                <span class="s1">key = list(key)</span>
            <span class="s1">indexer = self.columns._get_indexer_strict(key</span><span class="s2">, </span><span class="s4">&quot;columns&quot;</span><span class="s1">)[</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s3"># take() does not accept boolean indexers</span>
        <span class="s2">if </span><span class="s1">getattr(indexer</span><span class="s2">, </span><span class="s4">&quot;dtype&quot;</span><span class="s2">, None</span><span class="s1">) == bool:</span>
            <span class="s1">indexer = np.where(indexer)[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">data = self._take_with_is_copy(indexer</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">is_single_key:</span>
            <span class="s3"># What does looking for a single key in a non-unique index return?</span>
            <span class="s3"># The behavior is inconsistent. It returns a Series, except when</span>
            <span class="s3"># - the key itself is repeated (test on data.shape, #9519), or</span>
            <span class="s3"># - we have a MultiIndex on columns (test on self.columns, #21309)</span>
            <span class="s2">if </span><span class="s1">data.shape[</span><span class="s5">1</span><span class="s1">] == </span><span class="s5">1 </span><span class="s2">and not </span><span class="s1">isinstance(self.columns</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                <span class="s3"># GH#26490 using data[key] can cause RecursionError</span>
                <span class="s2">return </span><span class="s1">data._get_item_cache(key)</span>

        <span class="s2">return </span><span class="s1">data</span>

    <span class="s2">def </span><span class="s1">_getitem_bool_array(self</span><span class="s2">, </span><span class="s1">key):</span>
        <span class="s3"># also raises Exception if object array with NA values</span>
        <span class="s3"># warning here just in case -- previously __setitem__ was</span>
        <span class="s3"># reindexing but __getitem__ was not; it seems more reasonable to</span>
        <span class="s3"># go with the __setitem__ behavior since that is more consistent</span>
        <span class="s3"># with all other indexing behavior</span>
        <span class="s2">if </span><span class="s1">isinstance(key</span><span class="s2">, </span><span class="s1">Series) </span><span class="s2">and not </span><span class="s1">key.index.equals(self.index):</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;Boolean Series key will be reindexed to match DataFrame index.&quot;</span><span class="s2">,</span>
                <span class="s1">UserWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">len(key) != len(self.index):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">f&quot;Item wrong length </span><span class="s2">{</span><span class="s1">len(key)</span><span class="s2">} </span><span class="s4">instead of </span><span class="s2">{</span><span class="s1">len(self.index)</span><span class="s2">}</span><span class="s4">.&quot;</span>
            <span class="s1">)</span>

        <span class="s3"># check_bool_indexer will throw exception if Series key cannot</span>
        <span class="s3"># be reindexed to match DataFrame rows</span>
        <span class="s1">key = check_bool_indexer(self.index</span><span class="s2">, </span><span class="s1">key)</span>
        <span class="s1">indexer = key.nonzero()[</span><span class="s5">0</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">self._take_with_is_copy(indexer</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_getitem_multilevel(self</span><span class="s2">, </span><span class="s1">key):</span>
        <span class="s3"># self.columns is a MultiIndex</span>
        <span class="s1">loc = self.columns.get_loc(key)</span>
        <span class="s2">if </span><span class="s1">isinstance(loc</span><span class="s2">, </span><span class="s1">(slice</span><span class="s2">, </span><span class="s1">np.ndarray)):</span>
            <span class="s1">new_columns = self.columns[loc]</span>
            <span class="s1">result_columns = maybe_droplevels(new_columns</span><span class="s2">, </span><span class="s1">key)</span>
            <span class="s2">if </span><span class="s1">self._is_mixed_type:</span>
                <span class="s1">result = self.reindex(columns=new_columns)</span>
                <span class="s1">result.columns = result_columns</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">new_values = self.values[:</span><span class="s2">, </span><span class="s1">loc]</span>
                <span class="s1">result = self._constructor(</span>
                    <span class="s1">new_values</span><span class="s2">, </span><span class="s1">index=self.index</span><span class="s2">, </span><span class="s1">columns=result_columns</span>
                <span class="s1">)</span>
                <span class="s1">result = result.__finalize__(self)</span>

            <span class="s3"># If there is only one column being returned, and its name is</span>
            <span class="s3"># either an empty string, or a tuple with an empty string as its</span>
            <span class="s3"># first element, then treat the empty string as a placeholder</span>
            <span class="s3"># and return the column as if the user had provided that empty</span>
            <span class="s3"># string in the key. If the result is a Series, exclude the</span>
            <span class="s3"># implied empty string from its name.</span>
            <span class="s2">if </span><span class="s1">len(result.columns) == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">top = result.columns[</span><span class="s5">0</span><span class="s1">]</span>
                <span class="s2">if </span><span class="s1">isinstance(top</span><span class="s2">, </span><span class="s1">tuple):</span>
                    <span class="s1">top = top[</span><span class="s5">0</span><span class="s1">]</span>
                <span class="s2">if </span><span class="s1">top == </span><span class="s4">&quot;&quot;</span><span class="s1">:</span>
                    <span class="s1">result = result[</span><span class="s4">&quot;&quot;</span><span class="s1">]</span>
                    <span class="s2">if </span><span class="s1">isinstance(result</span><span class="s2">, </span><span class="s1">Series):</span>
                        <span class="s1">result = self._constructor_sliced(</span>
                            <span class="s1">result</span><span class="s2">, </span><span class="s1">index=self.index</span><span class="s2">, </span><span class="s1">name=key</span>
                        <span class="s1">)</span>

            <span class="s1">result._set_is_copy(self)</span>
            <span class="s2">return </span><span class="s1">result</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># loc is neither a slice nor ndarray, so must be an int</span>
            <span class="s2">return </span><span class="s1">self._ixs(loc</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_value(self</span><span class="s2">, </span><span class="s1">index</span><span class="s2">, </span><span class="s1">col</span><span class="s2">, </span><span class="s1">takeable: bool = </span><span class="s2">False</span><span class="s1">) -&gt; Scalar:</span>
        <span class="s0">&quot;&quot;&quot; 
        Quickly retrieve single value at passed column and index. 
 
        Parameters 
        ---------- 
        index : row label 
        col : column label 
        takeable : interpret the index/col as indexers, default False 
 
        Returns 
        ------- 
        scalar 
 
        Notes 
        ----- 
        Assumes that both `self.index._index_as_unique` and 
        `self.columns._index_as_unique`; Caller is responsible for checking. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">takeable:</span>
            <span class="s1">series = self._ixs(col</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">series._values[index]</span>

        <span class="s1">series = self._get_item_cache(col)</span>
        <span class="s1">engine = self.index._engine</span>

        <span class="s2">if not </span><span class="s1">isinstance(self.index</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
            <span class="s3"># CategoricalIndex: Trying to use the engine fastpath may give incorrect</span>
            <span class="s3">#  results if our categories are integers that dont match our codes</span>
            <span class="s3"># IntervalIndex: IntervalTree has no get_loc</span>
            <span class="s1">row = self.index.get_loc(index)</span>
            <span class="s2">return </span><span class="s1">series._values[row]</span>

        <span class="s3"># For MultiIndex going through engine effectively restricts us to</span>
        <span class="s3">#  same-length tuples; see test_get_set_value_no_partial_indexing</span>
        <span class="s1">loc = engine.get_loc(index)</span>
        <span class="s2">return </span><span class="s1">series._values[loc]</span>

    <span class="s2">def </span><span class="s1">__setitem__(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s1">key = com.apply_if_callable(key</span><span class="s2">, </span><span class="s1">self)</span>

        <span class="s3"># see if we can slice the rows</span>
        <span class="s1">indexer = convert_to_index_sliceable(self</span><span class="s2">, </span><span class="s1">key)</span>
        <span class="s2">if </span><span class="s1">indexer </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># either we have a slice or we have a string that can be converted</span>
            <span class="s3">#  to a slice for partial-string date indexing</span>
            <span class="s2">return </span><span class="s1">self._setitem_slice(indexer</span><span class="s2">, </span><span class="s1">value)</span>

        <span class="s2">if </span><span class="s1">isinstance(key</span><span class="s2">, </span><span class="s1">DataFrame) </span><span class="s2">or </span><span class="s1">getattr(key</span><span class="s2">, </span><span class="s4">&quot;ndim&quot;</span><span class="s2">, None</span><span class="s1">) == </span><span class="s5">2</span><span class="s1">:</span>
            <span class="s1">self._setitem_frame(key</span><span class="s2">, </span><span class="s1">value)</span>
        <span class="s2">elif </span><span class="s1">isinstance(key</span><span class="s2">, </span><span class="s1">(Series</span><span class="s2">, </span><span class="s1">np.ndarray</span><span class="s2">, </span><span class="s1">list</span><span class="s2">, </span><span class="s1">Index)):</span>
            <span class="s1">self._setitem_array(key</span><span class="s2">, </span><span class="s1">value)</span>
        <span class="s2">elif </span><span class="s1">isinstance(value</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s1">self._set_item_frame_value(key</span><span class="s2">, </span><span class="s1">value)</span>
        <span class="s2">elif </span><span class="s1">(</span>
            <span class="s1">is_list_like(value)</span>
            <span class="s2">and not </span><span class="s1">self.columns.is_unique</span>
            <span class="s2">and </span><span class="s5">1 </span><span class="s1">&lt; len(self.columns.get_indexer_for([key])) == len(value)</span>
        <span class="s1">):</span>
            <span class="s3"># Column to set is duplicated</span>
            <span class="s1">self._setitem_array([key]</span><span class="s2">, </span><span class="s1">value)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># set column</span>
            <span class="s1">self._set_item(key</span><span class="s2">, </span><span class="s1">value)</span>

    <span class="s2">def </span><span class="s1">_setitem_slice(self</span><span class="s2">, </span><span class="s1">key: slice</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s3"># NB: we can't just use self.loc[key] = value because that</span>
        <span class="s3">#  operates on labels and we need to operate positional for</span>
        <span class="s3">#  backwards-compat, xref GH#31469</span>
        <span class="s1">self._check_setitem_copy()</span>
        <span class="s1">self.iloc[key] = value</span>

    <span class="s2">def </span><span class="s1">_setitem_array(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s3"># also raises Exception if object array with NA values</span>
        <span class="s2">if </span><span class="s1">com.is_bool_indexer(key):</span>
            <span class="s3"># bool indexer is indexing along rows</span>
            <span class="s2">if </span><span class="s1">len(key) != len(self.index):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">f&quot;Item wrong length </span><span class="s2">{</span><span class="s1">len(key)</span><span class="s2">} </span><span class="s4">instead of </span><span class="s2">{</span><span class="s1">len(self.index)</span><span class="s2">}</span><span class="s4">!&quot;</span>
                <span class="s1">)</span>
            <span class="s1">key = check_bool_indexer(self.index</span><span class="s2">, </span><span class="s1">key)</span>
            <span class="s1">indexer = key.nonzero()[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">self._check_setitem_copy()</span>
            <span class="s2">if </span><span class="s1">isinstance(value</span><span class="s2">, </span><span class="s1">DataFrame):</span>
                <span class="s3"># GH#39931 reindex since iloc does not align</span>
                <span class="s1">value = value.reindex(self.index.take(indexer))</span>
            <span class="s1">self.iloc[indexer] = value</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># Note: unlike self.iloc[:, indexer] = value, this will</span>
            <span class="s3">#  never try to overwrite values inplace</span>

            <span class="s2">if </span><span class="s1">isinstance(value</span><span class="s2">, </span><span class="s1">DataFrame):</span>
                <span class="s1">check_key_length(self.columns</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value)</span>
                <span class="s2">for </span><span class="s1">k1</span><span class="s2">, </span><span class="s1">k2 </span><span class="s2">in </span><span class="s1">zip(key</span><span class="s2">, </span><span class="s1">value.columns):</span>
                    <span class="s1">self[k1] = value[k2]</span>

            <span class="s2">elif not </span><span class="s1">is_list_like(value):</span>
                <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">key:</span>
                    <span class="s1">self[col] = value</span>

            <span class="s2">elif </span><span class="s1">isinstance(value</span><span class="s2">, </span><span class="s1">np.ndarray) </span><span class="s2">and </span><span class="s1">value.ndim == </span><span class="s5">2</span><span class="s1">:</span>
                <span class="s1">self._iset_not_inplace(key</span><span class="s2">, </span><span class="s1">value)</span>

            <span class="s2">elif </span><span class="s1">np.ndim(value) &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s3"># list of lists</span>
                <span class="s1">value = DataFrame(value).values</span>
                <span class="s2">return </span><span class="s1">self._setitem_array(key</span><span class="s2">, </span><span class="s1">value)</span>

            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">self._iset_not_inplace(key</span><span class="s2">, </span><span class="s1">value)</span>

    <span class="s2">def </span><span class="s1">_iset_not_inplace(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s3"># GH#39510 when setting with df[key] = obj with a list-like key and</span>
        <span class="s3">#  list-like value, we iterate over those listlikes and set columns</span>
        <span class="s3">#  one at a time.  This is different from dispatching to</span>
        <span class="s3">#  `self.loc[:, key]= value`  because loc.__setitem__ may overwrite</span>
        <span class="s3">#  data inplace, whereas this will insert new arrays.</span>

        <span class="s2">def </span><span class="s1">igetitem(obj</span><span class="s2">, </span><span class="s1">i: int):</span>
            <span class="s3"># Note: we catch DataFrame obj before getting here, but</span>
            <span class="s3">#  hypothetically would return obj.iloc[:, i]</span>
            <span class="s2">if </span><span class="s1">isinstance(obj</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
                <span class="s2">return </span><span class="s1">obj[...</span><span class="s2">, </span><span class="s1">i]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">obj[i]</span>

        <span class="s2">if </span><span class="s1">self.columns.is_unique:</span>
            <span class="s2">if </span><span class="s1">np.shape(value)[-</span><span class="s5">1</span><span class="s1">] != len(key):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Columns must be same length as key&quot;</span><span class="s1">)</span>

            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">col </span><span class="s2">in </span><span class="s1">enumerate(key):</span>
                <span class="s1">self[col] = igetitem(value</span><span class="s2">, </span><span class="s1">i)</span>

        <span class="s2">else</span><span class="s1">:</span>

            <span class="s1">ilocs = self.columns.get_indexer_non_unique(key)[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s2">if </span><span class="s1">(ilocs &lt; </span><span class="s5">0</span><span class="s1">).any():</span>
                <span class="s3"># key entries not in self.columns</span>
                <span class="s2">raise </span><span class="s1">NotImplementedError</span>

            <span class="s2">if </span><span class="s1">np.shape(value)[-</span><span class="s5">1</span><span class="s1">] != len(ilocs):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Columns must be same length as key&quot;</span><span class="s1">)</span>

            <span class="s2">assert </span><span class="s1">np.ndim(value) &lt;= </span><span class="s5">2</span>

            <span class="s1">orig_columns = self.columns</span>

            <span class="s3"># Using self.iloc[:, i] = ... may set values inplace, which</span>
            <span class="s3">#  by convention we do not do in __setitem__</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">self.columns = Index(range(len(self.columns)))</span>
                <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">iloc </span><span class="s2">in </span><span class="s1">enumerate(ilocs):</span>
                    <span class="s1">self[iloc] = igetitem(value</span><span class="s2">, </span><span class="s1">i)</span>
            <span class="s2">finally</span><span class="s1">:</span>
                <span class="s1">self.columns = orig_columns</span>

    <span class="s2">def </span><span class="s1">_setitem_frame(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s3"># support boolean setting with DataFrame input, e.g.</span>
        <span class="s3"># df[df &gt; df2] = 0</span>
        <span class="s2">if </span><span class="s1">isinstance(key</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
            <span class="s2">if </span><span class="s1">key.shape != self.shape:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Array conditional must be same shape as self&quot;</span><span class="s1">)</span>
            <span class="s1">key = self._constructor(key</span><span class="s2">, </span><span class="s1">**self._construct_axes_dict())</span>

        <span class="s2">if </span><span class="s1">key.size </span><span class="s2">and not </span><span class="s1">is_bool_dtype(key.values):</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span>
                <span class="s4">&quot;Must pass DataFrame or 2-d ndarray with boolean values only&quot;</span>
            <span class="s1">)</span>

        <span class="s1">self._check_inplace_setting(value)</span>
        <span class="s1">self._check_setitem_copy()</span>
        <span class="s1">self._where(-key</span><span class="s2">, </span><span class="s1">value</span><span class="s2">, </span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_set_item_frame_value(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value: DataFrame) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">self._ensure_valid_index(value)</span>

        <span class="s3"># align columns</span>
        <span class="s2">if </span><span class="s1">key </span><span class="s2">in </span><span class="s1">self.columns:</span>
            <span class="s1">loc = self.columns.get_loc(key)</span>
            <span class="s1">cols = self.columns[loc]</span>
            <span class="s1">len_cols = </span><span class="s5">1 </span><span class="s2">if </span><span class="s1">is_scalar(cols) </span><span class="s2">else </span><span class="s1">len(cols)</span>
            <span class="s2">if </span><span class="s1">len_cols != len(value.columns):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Columns must be same length as key&quot;</span><span class="s1">)</span>

            <span class="s3"># align right-hand-side columns if self.columns</span>
            <span class="s3"># is multi-index and self[key] is a sub-frame</span>
            <span class="s2">if </span><span class="s1">isinstance(self.columns</span><span class="s2">, </span><span class="s1">MultiIndex) </span><span class="s2">and </span><span class="s1">isinstance(</span>
                <span class="s1">loc</span><span class="s2">, </span><span class="s1">(slice</span><span class="s2">, </span><span class="s1">Series</span><span class="s2">, </span><span class="s1">np.ndarray</span><span class="s2">, </span><span class="s1">Index)</span>
            <span class="s1">):</span>
                <span class="s1">cols = maybe_droplevels(cols</span><span class="s2">, </span><span class="s1">key)</span>
                <span class="s2">if </span><span class="s1">len(cols) </span><span class="s2">and not </span><span class="s1">cols.equals(value.columns):</span>
                    <span class="s1">value = value.reindex(cols</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

        <span class="s3"># now align rows</span>
        <span class="s1">arraylike = _reindex_for_setitem(value</span><span class="s2">, </span><span class="s1">self.index)</span>
        <span class="s1">self._set_item_mgr(key</span><span class="s2">, </span><span class="s1">arraylike)</span>

    <span class="s2">def </span><span class="s1">_iset_item_mgr(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">loc: int | slice | np.ndarray</span><span class="s2">, </span><span class="s1">value</span><span class="s2">, </span><span class="s1">inplace: bool = </span><span class="s2">False</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s3"># when called from _set_item_mgr loc can be anything returned from get_loc</span>
        <span class="s1">self._mgr.iset(loc</span><span class="s2">, </span><span class="s1">value</span><span class="s2">, </span><span class="s1">inplace=inplace)</span>
        <span class="s1">self._clear_item_cache()</span>

    <span class="s2">def </span><span class="s1">_set_item_mgr(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value: ArrayLike) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">loc = self._info_axis.get_loc(key)</span>
        <span class="s2">except </span><span class="s1">KeyError:</span>
            <span class="s3"># This item wasn't present, just insert at end</span>
            <span class="s1">self._mgr.insert(len(self._info_axis)</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self._iset_item_mgr(loc</span><span class="s2">, </span><span class="s1">value)</span>

        <span class="s3"># check if we are modifying a copy</span>
        <span class="s3"># try to set first as we want an invalid</span>
        <span class="s3"># value exception to occur first</span>
        <span class="s2">if </span><span class="s1">len(self):</span>
            <span class="s1">self._check_setitem_copy()</span>

    <span class="s2">def </span><span class="s1">_iset_item(self</span><span class="s2">, </span><span class="s1">loc: int</span><span class="s2">, </span><span class="s1">value) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">arraylike = self._sanitize_column(value)</span>
        <span class="s1">self._iset_item_mgr(loc</span><span class="s2">, </span><span class="s1">arraylike</span><span class="s2">, </span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s3"># check if we are modifying a copy</span>
        <span class="s3"># try to set first as we want an invalid</span>
        <span class="s3"># value exception to occur first</span>
        <span class="s2">if </span><span class="s1">len(self):</span>
            <span class="s1">self._check_setitem_copy()</span>

    <span class="s2">def </span><span class="s1">_set_item(self</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Add series to DataFrame in specified column. 
 
        If series is a numpy-array (not a Series/TimeSeries), it must be the 
        same length as the DataFrames index or an error will be thrown. 
 
        Series/TimeSeries will be conformed to the DataFrames index to 
        ensure homogeneity. 
        &quot;&quot;&quot;</span>
        <span class="s1">value = self._sanitize_column(value)</span>

        <span class="s2">if </span><span class="s1">(</span>
            <span class="s1">key </span><span class="s2">in </span><span class="s1">self.columns</span>
            <span class="s2">and </span><span class="s1">value.ndim == </span><span class="s5">1</span>
            <span class="s2">and not </span><span class="s1">is_extension_array_dtype(value)</span>
        <span class="s1">):</span>
            <span class="s3"># broadcast across multiple columns if necessary</span>
            <span class="s2">if not </span><span class="s1">self.columns.is_unique </span><span class="s2">or </span><span class="s1">isinstance(self.columns</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                <span class="s1">existing_piece = self[key]</span>
                <span class="s2">if </span><span class="s1">isinstance(existing_piece</span><span class="s2">, </span><span class="s1">DataFrame):</span>
                    <span class="s1">value = np.tile(value</span><span class="s2">, </span><span class="s1">(len(existing_piece.columns)</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)).T</span>

        <span class="s1">self._set_item_mgr(key</span><span class="s2">, </span><span class="s1">value)</span>

    <span class="s2">def </span><span class="s1">_set_value(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">index: IndexLabel</span><span class="s2">, </span><span class="s1">col</span><span class="s2">, </span><span class="s1">value: Scalar</span><span class="s2">, </span><span class="s1">takeable: bool = </span><span class="s2">False</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Put single value at passed column and index. 
 
        Parameters 
        ---------- 
        index : Label 
            row label 
        col : Label 
            column label 
        value : scalar 
        takeable : bool, default False 
            Sets whether or not index/col interpreted as indexers 
        &quot;&quot;&quot;</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">takeable:</span>
                <span class="s1">series = self._ixs(col</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
                <span class="s1">series._set_value(index</span><span class="s2">, </span><span class="s1">value</span><span class="s2">, </span><span class="s1">takeable=</span><span class="s2">True</span><span class="s1">)</span>
                <span class="s2">return</span>

            <span class="s1">series = self._get_item_cache(col)</span>
            <span class="s1">loc = self.index.get_loc(index)</span>
            <span class="s1">dtype = series.dtype</span>
            <span class="s2">if </span><span class="s1">isinstance(dtype</span><span class="s2">, </span><span class="s1">np.dtype) </span><span class="s2">and </span><span class="s1">dtype.kind </span><span class="s2">not in </span><span class="s1">[</span><span class="s4">&quot;m&quot;</span><span class="s2">, </span><span class="s4">&quot;M&quot;</span><span class="s1">]:</span>
                <span class="s3"># otherwise we have EA values, and this check will be done</span>
                <span class="s3">#  via setitem_inplace</span>
                <span class="s2">if not </span><span class="s1">can_hold_element(series._values</span><span class="s2">, </span><span class="s1">value):</span>
                    <span class="s3"># We'll go through loc and end up casting.</span>
                    <span class="s2">raise </span><span class="s1">TypeError</span>

            <span class="s1">series._mgr.setitem_inplace(loc</span><span class="s2">, </span><span class="s1">value)</span>
            <span class="s3"># Note: trying to use series._set_value breaks tests in</span>
            <span class="s3">#  tests.frame.indexing.test_indexing and tests.indexing.test_partial</span>
        <span class="s2">except </span><span class="s1">(KeyError</span><span class="s2">, </span><span class="s1">TypeError):</span>
            <span class="s3"># set using a non-recursive method &amp; reset the cache</span>
            <span class="s2">if </span><span class="s1">takeable:</span>
                <span class="s1">self.iloc[index</span><span class="s2">, </span><span class="s1">col] = value</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">self.loc[index</span><span class="s2">, </span><span class="s1">col] = value</span>
            <span class="s1">self._item_cache.pop(col</span><span class="s2">, None</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_ensure_valid_index(self</span><span class="s2">, </span><span class="s1">value) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Ensure that if we don't have an index, that we can create one from the 
        passed value. 
        &quot;&quot;&quot;</span>
        <span class="s3"># GH5632, make sure that we are a Series convertible</span>
        <span class="s2">if not </span><span class="s1">len(self.index) </span><span class="s2">and </span><span class="s1">is_list_like(value) </span><span class="s2">and </span><span class="s1">len(value):</span>
            <span class="s2">if not </span><span class="s1">isinstance(value</span><span class="s2">, </span><span class="s1">DataFrame):</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">value = Series(value)</span>
                <span class="s2">except </span><span class="s1">(ValueError</span><span class="s2">, </span><span class="s1">NotImplementedError</span><span class="s2">, </span><span class="s1">TypeError) </span><span class="s2">as </span><span class="s1">err:</span>
                    <span class="s2">raise </span><span class="s1">ValueError(</span>
                        <span class="s4">&quot;Cannot set a frame with no defined index &quot;</span>
                        <span class="s4">&quot;and a value that cannot be converted to a Series&quot;</span>
                    <span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>

            <span class="s3"># GH31368 preserve name of index</span>
            <span class="s1">index_copy = value.index.copy()</span>
            <span class="s2">if </span><span class="s1">self.index.name </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">index_copy.name = self.index.name</span>

            <span class="s1">self._mgr = self._mgr.reindex_axis(index_copy</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">fill_value=np.nan)</span>

    <span class="s2">def </span><span class="s1">_box_col_values(self</span><span class="s2">, </span><span class="s1">values: SingleDataManager</span><span class="s2">, </span><span class="s1">loc: int) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Provide boxed values for a column. 
        &quot;&quot;&quot;</span>
        <span class="s3"># Lookup in columns so that if e.g. a str datetime was passed</span>
        <span class="s3">#  we attach the Timestamp object as the name.</span>
        <span class="s1">name = self.columns[loc]</span>
        <span class="s1">klass = self._constructor_sliced</span>
        <span class="s3"># We get index=self.index bc values is a SingleDataManager</span>
        <span class="s2">return </span><span class="s1">klass(values</span><span class="s2">, </span><span class="s1">name=name</span><span class="s2">, </span><span class="s1">fastpath=</span><span class="s2">True</span><span class="s1">).__finalize__(self)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Lookup Caching</span>

    <span class="s2">def </span><span class="s1">_clear_item_cache(self) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">self._item_cache.clear()</span>

    <span class="s2">def </span><span class="s1">_get_item_cache(self</span><span class="s2">, </span><span class="s1">item: Hashable) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot;Return the cached item, item represents a label indexer.&quot;&quot;&quot;</span>
        <span class="s1">cache = self._item_cache</span>
        <span class="s1">res = cache.get(item)</span>
        <span class="s2">if </span><span class="s1">res </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s3"># All places that call _get_item_cache have unique columns,</span>
            <span class="s3">#  pending resolution of GH#33047</span>

            <span class="s1">loc = self.columns.get_loc(item)</span>
            <span class="s1">res = self._ixs(loc</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>

            <span class="s1">cache[item] = res</span>

            <span class="s3"># for a chain</span>
            <span class="s1">res._is_copy = self._is_copy</span>
        <span class="s2">return </span><span class="s1">res</span>

    <span class="s2">def </span><span class="s1">_reset_cacher(self) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s3"># no-op for DataFrame</span>
        <span class="s2">pass</span>

    <span class="s2">def </span><span class="s1">_maybe_cache_changed(self</span><span class="s2">, </span><span class="s1">item</span><span class="s2">, </span><span class="s1">value: Series</span><span class="s2">, </span><span class="s1">inplace: bool) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        The object has called back to us saying maybe it has changed. 
        &quot;&quot;&quot;</span>
        <span class="s1">loc = self._info_axis.get_loc(item)</span>
        <span class="s1">arraylike = value._values</span>
        <span class="s1">self._mgr.iset(loc</span><span class="s2">, </span><span class="s1">arraylike</span><span class="s2">, </span><span class="s1">inplace=inplace)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Unsorted</span>

    <span class="s2">def </span><span class="s1">query(self</span><span class="s2">, </span><span class="s1">expr: str</span><span class="s2">, </span><span class="s1">inplace: bool = </span><span class="s2">False, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Query the columns of a DataFrame with a boolean expression. 
 
        Parameters 
        ---------- 
        expr : str 
            The query string to evaluate. 
 
            You can refer to variables 
            in the environment by prefixing them with an '@' character like 
            ``@a + b``. 
 
            You can refer to column names that are not valid Python variable names 
            by surrounding them in backticks. Thus, column names containing spaces 
            or punctuations (besides underscores) or starting with digits must be 
            surrounded by backticks. (For example, a column named &quot;Area (cm^2)&quot; would 
            be referenced as ```Area (cm^2)```). Column names which are Python keywords 
            (like &quot;list&quot;, &quot;for&quot;, &quot;import&quot;, etc) cannot be used. 
 
            For example, if one of your columns is called ``a a`` and you want 
            to sum it with ``b``, your query should be ```a a` + b``. 
 
            .. versionadded:: 0.25.0 
                Backtick quoting introduced. 
 
            .. versionadded:: 1.0.0 
                Expanding functionality of backtick quoting for more than only spaces. 
 
        inplace : bool 
            Whether the query should modify the data in place or return 
            a modified copy. 
        **kwargs 
            See the documentation for :func:`eval` for complete details 
            on the keyword arguments accepted by :meth:`DataFrame.query`. 
 
        Returns 
        ------- 
        DataFrame or None 
            DataFrame resulting from the provided query expression or 
            None if ``inplace=True``. 
 
        See Also 
        -------- 
        eval : Evaluate a string describing operations on 
            DataFrame columns. 
        DataFrame.eval : Evaluate a string describing operations on 
            DataFrame columns. 
 
        Notes 
        ----- 
        The result of the evaluation of this expression is first passed to 
        :attr:`DataFrame.loc` and if that fails because of a 
        multidimensional key (e.g., a DataFrame) then the result will be passed 
        to :meth:`DataFrame.__getitem__`. 
 
        This method uses the top-level :func:`eval` function to 
        evaluate the passed query. 
 
        The :meth:`~pandas.DataFrame.query` method uses a slightly 
        modified Python syntax by default. For example, the ``&amp;`` and ``|`` 
        (bitwise) operators have the precedence of their boolean cousins, 
        :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python, 
        however the semantics are different. 
 
        You can change the semantics of the expression by passing the keyword 
        argument ``parser='python'``. This enforces the same semantics as 
        evaluation in Python space. Likewise, you can pass ``engine='python'`` 
        to evaluate an expression using Python itself as a backend. This is not 
        recommended as it is inefficient compared to using ``numexpr`` as the 
        engine. 
 
        The :attr:`DataFrame.index` and 
        :attr:`DataFrame.columns` attributes of the 
        :class:`~pandas.DataFrame` instance are placed in the query namespace 
        by default, which allows you to treat both the index and columns of the 
        frame as a column in the frame. 
        The identifier ``index`` is used for the frame index; you can also 
        use the name of the index to identify it in a query. Please note that 
        Python keywords may not be used as identifiers. 
 
        For further details and examples see the ``query`` documentation in 
        :ref:`indexing &lt;indexing.query&gt;`. 
 
        *Backtick quoted variables* 
 
        Backtick quoted variables are parsed as literal Python code and 
        are converted internally to a Python valid identifier. 
        This can lead to the following problems. 
 
        During parsing a number of disallowed characters inside the backtick 
        quoted string are replaced by strings that are allowed as a Python identifier. 
        These characters include all operators in Python, the space character, the 
        question mark, the exclamation mark, the dollar sign, and the euro sign. 
        For other characters that fall outside the ASCII range (U+0001..U+007F) 
        and those that are not further specified in PEP 3131, 
        the query parser will raise an error. 
        This excludes whitespace different than the space character, 
        but also the hashtag (as it is used for comments) and the backtick 
        itself (backtick can also not be escaped). 
 
        In a special case, quotes that make a pair around a backtick can 
        confuse the parser. 
        For example, ```it's` &gt; `that's``` will raise an error, 
        as it forms a quoted string (``'s &gt; `that'``) with a backtick inside. 
 
        See also the Python documentation about lexical analysis 
        (https://docs.python.org/3/reference/lexical_analysis.html) 
        in combination with the source code in :mod:`pandas.core.computation.parsing`. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A': range(1, 6), 
        ...                    'B': range(10, 0, -2), 
        ...                    'C C': range(10, 5, -1)}) 
        &gt;&gt;&gt; df 
           A   B  C C 
        0  1  10   10 
        1  2   8    9 
        2  3   6    8 
        3  4   4    7 
        4  5   2    6 
        &gt;&gt;&gt; df.query('A &gt; B') 
           A  B  C C 
        4  5  2    6 
 
        The previous expression is equivalent to 
 
        &gt;&gt;&gt; df[df.A &gt; df.B] 
           A  B  C C 
        4  5  2    6 
 
        For columns with spaces in their name, you can use backtick quoting. 
 
        &gt;&gt;&gt; df.query('B == `C C`') 
           A   B  C C 
        0  1  10   10 
 
        The previous expression is equivalent to 
 
        &gt;&gt;&gt; df[df.B == df['C C']] 
           A   B  C C 
        0  1  10   10 
        &quot;&quot;&quot;</span>
        <span class="s1">inplace = validate_bool_kwarg(inplace</span><span class="s2">, </span><span class="s4">&quot;inplace&quot;</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">isinstance(expr</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">msg = </span><span class="s4">f&quot;expr must be a string to be evaluated, </span><span class="s2">{</span><span class="s1">type(expr)</span><span class="s2">} </span><span class="s4">given&quot;</span>
            <span class="s2">raise </span><span class="s1">ValueError(msg)</span>
        <span class="s1">kwargs[</span><span class="s4">&quot;level&quot;</span><span class="s1">] = kwargs.pop(</span><span class="s4">&quot;level&quot;</span><span class="s2">, </span><span class="s5">0</span><span class="s1">) + </span><span class="s5">1</span>
        <span class="s1">kwargs[</span><span class="s4">&quot;target&quot;</span><span class="s1">] = </span><span class="s2">None</span>
        <span class="s1">res = self.eval(expr</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">result = self.loc[res]</span>
        <span class="s2">except </span><span class="s1">ValueError:</span>
            <span class="s3"># when res is multi-dimensional loc raises, but this is sometimes a</span>
            <span class="s3"># valid query</span>
            <span class="s1">result = self[res]</span>

        <span class="s2">if </span><span class="s1">inplace:</span>
            <span class="s1">self._update_inplace(result)</span>
            <span class="s2">return None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">eval(self</span><span class="s2">, </span><span class="s1">expr: str</span><span class="s2">, </span><span class="s1">inplace: bool = </span><span class="s2">False, </span><span class="s1">**kwargs):</span>
        <span class="s0">&quot;&quot;&quot; 
        Evaluate a string describing operations on DataFrame columns. 
 
        Operates on columns only, not specific rows or elements.  This allows 
        `eval` to run arbitrary code, which can make you vulnerable to code 
        injection if you pass user input to this function. 
 
        Parameters 
        ---------- 
        expr : str 
            The expression string to evaluate. 
        inplace : bool, default False 
            If the expression contains an assignment, whether to perform the 
            operation inplace and mutate the existing DataFrame. Otherwise, 
            a new DataFrame is returned. 
        **kwargs 
            See the documentation for :func:`eval` for complete details 
            on the keyword arguments accepted by 
            :meth:`~pandas.DataFrame.query`. 
 
        Returns 
        ------- 
        ndarray, scalar, pandas object, or None 
            The result of the evaluation or None if ``inplace=True``. 
 
        See Also 
        -------- 
        DataFrame.query : Evaluates a boolean expression to query the columns 
            of a frame. 
        DataFrame.assign : Can evaluate an expression or function to create new 
            values for a column. 
        eval : Evaluate a Python expression as a string using various 
            backends. 
 
        Notes 
        ----- 
        For more details see the API documentation for :func:`~eval`. 
        For detailed examples see :ref:`enhancing performance with eval 
        &lt;enhancingperf.eval&gt;`. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)}) 
        &gt;&gt;&gt; df 
           A   B 
        0  1  10 
        1  2   8 
        2  3   6 
        3  4   4 
        4  5   2 
        &gt;&gt;&gt; df.eval('A + B') 
        0    11 
        1    10 
        2     9 
        3     8 
        4     7 
        dtype: int64 
 
        Assignment is allowed though by default the original DataFrame is not 
        modified. 
 
        &gt;&gt;&gt; df.eval('C = A + B') 
           A   B   C 
        0  1  10  11 
        1  2   8  10 
        2  3   6   9 
        3  4   4   8 
        4  5   2   7 
        &gt;&gt;&gt; df 
           A   B 
        0  1  10 
        1  2   8 
        2  3   6 
        3  4   4 
        4  5   2 
 
        Use ``inplace=True`` to modify the original DataFrame. 
 
        &gt;&gt;&gt; df.eval('C = A + B', inplace=True) 
        &gt;&gt;&gt; df 
           A   B   C 
        0  1  10  11 
        1  2   8  10 
        2  3   6   9 
        3  4   4   8 
        4  5   2   7 
 
        Multiple columns can be assigned to using multi-line expressions: 
 
        &gt;&gt;&gt; df.eval( 
        ...     ''' 
        ... C = A + B 
        ... D = A - B 
        ... ''' 
        ... ) 
           A   B   C  D 
        0  1  10  11 -9 
        1  2   8  10 -6 
        2  3   6   9 -3 
        3  4   4   8  0 
        4  5   2   7  3 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.core.computation.eval </span><span class="s2">import </span><span class="s1">eval </span><span class="s2">as </span><span class="s1">_eval</span>

        <span class="s1">inplace = validate_bool_kwarg(inplace</span><span class="s2">, </span><span class="s4">&quot;inplace&quot;</span><span class="s1">)</span>
        <span class="s1">kwargs[</span><span class="s4">&quot;level&quot;</span><span class="s1">] = kwargs.pop(</span><span class="s4">&quot;level&quot;</span><span class="s2">, </span><span class="s5">0</span><span class="s1">) + </span><span class="s5">1</span>
        <span class="s1">index_resolvers = self._get_index_resolvers()</span>
        <span class="s1">column_resolvers = self._get_cleaned_column_resolvers()</span>
        <span class="s1">resolvers = column_resolvers</span><span class="s2">, </span><span class="s1">index_resolvers</span>
        <span class="s2">if </span><span class="s4">&quot;target&quot; </span><span class="s2">not in </span><span class="s1">kwargs:</span>
            <span class="s1">kwargs[</span><span class="s4">&quot;target&quot;</span><span class="s1">] = self</span>
        <span class="s1">kwargs[</span><span class="s4">&quot;resolvers&quot;</span><span class="s1">] = tuple(kwargs.get(</span><span class="s4">&quot;resolvers&quot;</span><span class="s2">, </span><span class="s1">())) + resolvers</span>

        <span class="s2">return </span><span class="s1">_eval(expr</span><span class="s2">, </span><span class="s1">inplace=inplace</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s2">def </span><span class="s1">select_dtypes(self</span><span class="s2">, </span><span class="s1">include=</span><span class="s2">None, </span><span class="s1">exclude=</span><span class="s2">None</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a subset of the DataFrame's columns based on the column dtypes. 
 
        Parameters 
        ---------- 
        include, exclude : scalar or list-like 
            A selection of dtypes or strings to be included/excluded. At least 
            one of these parameters must be supplied. 
 
        Returns 
        ------- 
        DataFrame 
            The subset of the frame including the dtypes in ``include`` and 
            excluding the dtypes in ``exclude``. 
 
        Raises 
        ------ 
        ValueError 
            * If both of ``include`` and ``exclude`` are empty 
            * If ``include`` and ``exclude`` have overlapping elements 
            * If any kind of string dtype is passed in. 
 
        See Also 
        -------- 
        DataFrame.dtypes: Return Series with the data type of each column. 
 
        Notes 
        ----- 
        * To select all *numeric* types, use ``np.number`` or ``'number'`` 
        * To select strings you must use the ``object`` dtype, but note that 
          this will return *all* object dtype columns 
        * See the `numpy dtype hierarchy 
          &lt;https://numpy.org/doc/stable/reference/arrays.scalars.html&gt;`__ 
        * To select datetimes, use ``np.datetime64``, ``'datetime'`` or 
          ``'datetime64'`` 
        * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or 
          ``'timedelta64'`` 
        * To select Pandas categorical dtypes, use ``'category'`` 
        * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in 
          0.20.0) or ``'datetime64[ns, tz]'`` 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'a': [1, 2] * 3, 
        ...                    'b': [True, False] * 3, 
        ...                    'c': [1.0, 2.0] * 3}) 
        &gt;&gt;&gt; df 
                a      b  c 
        0       1   True  1.0 
        1       2  False  2.0 
        2       1   True  1.0 
        3       2  False  2.0 
        4       1   True  1.0 
        5       2  False  2.0 
 
        &gt;&gt;&gt; df.select_dtypes(include='bool') 
           b 
        0  True 
        1  False 
        2  True 
        3  False 
        4  True 
        5  False 
 
        &gt;&gt;&gt; df.select_dtypes(include=['float64']) 
           c 
        0  1.0 
        1  2.0 
        2  1.0 
        3  2.0 
        4  1.0 
        5  2.0 
 
        &gt;&gt;&gt; df.select_dtypes(exclude=['int64']) 
               b    c 
        0   True  1.0 
        1  False  2.0 
        2   True  1.0 
        3  False  2.0 
        4   True  1.0 
        5  False  2.0 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">is_list_like(include):</span>
            <span class="s1">include = (include</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if </span><span class="s1">include </span><span class="s2">is not None else </span><span class="s1">()</span>
        <span class="s2">if not </span><span class="s1">is_list_like(exclude):</span>
            <span class="s1">exclude = (exclude</span><span class="s2">,</span><span class="s1">) </span><span class="s2">if </span><span class="s1">exclude </span><span class="s2">is not None else </span><span class="s1">()</span>

        <span class="s1">selection = (frozenset(include)</span><span class="s2">, </span><span class="s1">frozenset(exclude))</span>

        <span class="s2">if not </span><span class="s1">any(selection):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;at least one of include or exclude must be nonempty&quot;</span><span class="s1">)</span>

        <span class="s3"># convert the myriad valid dtypes object to a single representation</span>
        <span class="s2">def </span><span class="s1">check_int_infer_dtype(dtypes):</span>
            <span class="s1">converted_dtypes: list[type] = []</span>
            <span class="s2">for </span><span class="s1">dtype </span><span class="s2">in </span><span class="s1">dtypes:</span>
                <span class="s3"># Numpy maps int to different types (int32, in64) on Windows and Linux</span>
                <span class="s3"># see https://github.com/numpy/numpy/issues/9464</span>
                <span class="s2">if </span><span class="s1">(isinstance(dtype</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">and </span><span class="s1">dtype == </span><span class="s4">&quot;int&quot;</span><span class="s1">) </span><span class="s2">or </span><span class="s1">(dtype </span><span class="s2">is </span><span class="s1">int):</span>
                    <span class="s1">converted_dtypes.append(np.int32)</span>
                    <span class="s1">converted_dtypes.append(np.int64)</span>
                <span class="s2">elif </span><span class="s1">dtype == </span><span class="s4">&quot;float&quot; </span><span class="s2">or </span><span class="s1">dtype </span><span class="s2">is </span><span class="s1">float:</span>
                    <span class="s3"># GH#42452 : np.dtype(&quot;float&quot;) coerces to np.float64 from Numpy 1.20</span>
                    <span class="s1">converted_dtypes.extend([np.float64</span><span class="s2">, </span><span class="s1">np.float32])</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">converted_dtypes.append(infer_dtype_from_object(dtype))</span>
            <span class="s2">return </span><span class="s1">frozenset(converted_dtypes)</span>

        <span class="s1">include = check_int_infer_dtype(include)</span>
        <span class="s1">exclude = check_int_infer_dtype(exclude)</span>

        <span class="s2">for </span><span class="s1">dtypes </span><span class="s2">in </span><span class="s1">(include</span><span class="s2">, </span><span class="s1">exclude):</span>
            <span class="s1">invalidate_string_dtypes(dtypes)</span>

        <span class="s3"># can't both include AND exclude!</span>
        <span class="s2">if not </span><span class="s1">include.isdisjoint(exclude):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;include and exclude overlap on </span><span class="s2">{</span><span class="s1">(include &amp; exclude)</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

        <span class="s2">def </span><span class="s1">dtype_predicate(dtype: DtypeObj</span><span class="s2">, </span><span class="s1">dtypes_set) -&gt; bool:</span>
            <span class="s2">return </span><span class="s1">issubclass(dtype.type</span><span class="s2">, </span><span class="s1">tuple(dtypes_set)) </span><span class="s2">or </span><span class="s1">(</span>
                <span class="s1">np.number </span><span class="s2">in </span><span class="s1">dtypes_set </span><span class="s2">and </span><span class="s1">getattr(dtype</span><span class="s2">, </span><span class="s4">&quot;_is_numeric&quot;</span><span class="s2">, False</span><span class="s1">)</span>
            <span class="s1">)</span>

        <span class="s2">def </span><span class="s1">predicate(arr: ArrayLike) -&gt; bool:</span>
            <span class="s1">dtype = arr.dtype</span>
            <span class="s2">if </span><span class="s1">include:</span>
                <span class="s2">if not </span><span class="s1">dtype_predicate(dtype</span><span class="s2">, </span><span class="s1">include):</span>
                    <span class="s2">return False</span>

            <span class="s2">if </span><span class="s1">exclude:</span>
                <span class="s2">if </span><span class="s1">dtype_predicate(dtype</span><span class="s2">, </span><span class="s1">exclude):</span>
                    <span class="s2">return False</span>

            <span class="s2">return True</span>

        <span class="s1">mgr = self._mgr._get_data_subset(predicate)</span>
        <span class="s2">return </span><span class="s1">type(self)(mgr).__finalize__(self)</span>

    <span class="s2">def </span><span class="s1">insert(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">loc: int</span><span class="s2">,</span>
        <span class="s1">column: Hashable</span><span class="s2">,</span>
        <span class="s1">value: Scalar | AnyArrayLike</span><span class="s2">,</span>
        <span class="s1">allow_duplicates: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Insert column into DataFrame at specified location. 
 
        Raises a ValueError if `column` is already contained in the DataFrame, 
        unless `allow_duplicates` is set to True. 
 
        Parameters 
        ---------- 
        loc : int 
            Insertion index. Must verify 0 &lt;= loc &lt;= len(columns). 
        column : str, number, or hashable object 
            Label of the inserted column. 
        value : Scalar, Series, or array-like 
        allow_duplicates : bool, optional default False 
 
        See Also 
        -------- 
        Index.insert : Insert new item by index. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]}) 
        &gt;&gt;&gt; df 
           col1  col2 
        0     1     3 
        1     2     4 
        &gt;&gt;&gt; df.insert(1, &quot;newcol&quot;, [99, 99]) 
        &gt;&gt;&gt; df 
           col1  newcol  col2 
        0     1      99     3 
        1     2      99     4 
        &gt;&gt;&gt; df.insert(0, &quot;col1&quot;, [100, 100], allow_duplicates=True) 
        &gt;&gt;&gt; df 
           col1  col1  newcol  col2 
        0   100     1      99     3 
        1   100     2      99     4 
 
        Notice that pandas uses index alignment in case of `value` from type `Series`: 
 
        &gt;&gt;&gt; df.insert(0, &quot;col0&quot;, pd.Series([5, 6], index=[1, 2])) 
        &gt;&gt;&gt; df 
           col0  col1  col1  newcol  col2 
        0   NaN   100     1      99     3 
        1   5.0   100     2      99     4 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">allow_duplicates </span><span class="s2">and not </span><span class="s1">self.flags.allows_duplicate_labels:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;Cannot specify 'allow_duplicates=True' when &quot;</span>
                <span class="s4">&quot;'self.flags.allows_duplicate_labels' is False.&quot;</span>
            <span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">allow_duplicates </span><span class="s2">and </span><span class="s1">column </span><span class="s2">in </span><span class="s1">self.columns:</span>
            <span class="s3"># Should this be a different kind of error??</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;cannot insert </span><span class="s2">{</span><span class="s1">column</span><span class="s2">}</span><span class="s4">, already exists&quot;</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">isinstance(loc</span><span class="s2">, </span><span class="s1">int):</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;loc must be int&quot;</span><span class="s1">)</span>

        <span class="s1">value = self._sanitize_column(value)</span>
        <span class="s1">self._mgr.insert(loc</span><span class="s2">, </span><span class="s1">column</span><span class="s2">, </span><span class="s1">value)</span>

    <span class="s2">def </span><span class="s1">assign(self</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; DataFrame:</span>
        <span class="s0">r&quot;&quot;&quot; 
        Assign new columns to a DataFrame. 
 
        Returns a new object with all original columns in addition to new ones. 
        Existing columns that are re-assigned will be overwritten. 
 
        Parameters 
        ---------- 
        **kwargs : dict of {str: callable or Series} 
            The column names are keywords. If the values are 
            callable, they are computed on the DataFrame and 
            assigned to the new columns. The callable must not 
            change input DataFrame (though pandas doesn't check it). 
            If the values are not callable, (e.g. a Series, scalar, or array), 
            they are simply assigned. 
 
        Returns 
        ------- 
        DataFrame 
            A new DataFrame with the new columns in addition to 
            all the existing columns. 
 
        Notes 
        ----- 
        Assigning multiple columns within the same ``assign`` is possible. 
        Later items in '\*\*kwargs' may refer to newly created or modified 
        columns in 'df'; items are computed and assigned into 'df' in order. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'temp_c': [17.0, 25.0]}, 
        ...                   index=['Portland', 'Berkeley']) 
        &gt;&gt;&gt; df 
                  temp_c 
        Portland    17.0 
        Berkeley    25.0 
 
        Where the value is a callable, evaluated on `df`: 
 
        &gt;&gt;&gt; df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32) 
                  temp_c  temp_f 
        Portland    17.0    62.6 
        Berkeley    25.0    77.0 
 
        Alternatively, the same behavior can be achieved by directly 
        referencing an existing Series or sequence: 
 
        &gt;&gt;&gt; df.assign(temp_f=df['temp_c'] * 9 / 5 + 32) 
                  temp_c  temp_f 
        Portland    17.0    62.6 
        Berkeley    25.0    77.0 
 
        You can create multiple columns within the same assign where one 
        of the columns depends on another one defined within the same assign: 
 
        &gt;&gt;&gt; df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32, 
        ...           temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9) 
                  temp_c  temp_f  temp_k 
        Portland    17.0    62.6  290.15 
        Berkeley    25.0    77.0  298.15 
        &quot;&quot;&quot;</span>
        <span class="s1">data = self.copy()</span>

        <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">kwargs.items():</span>
            <span class="s1">data[k] = com.apply_if_callable(v</span><span class="s2">, </span><span class="s1">data)</span>
        <span class="s2">return </span><span class="s1">data</span>

    <span class="s2">def </span><span class="s1">_sanitize_column(self</span><span class="s2">, </span><span class="s1">value) -&gt; ArrayLike:</span>
        <span class="s0">&quot;&quot;&quot; 
        Ensures new columns (which go into the BlockManager as new blocks) are 
        always copied and converted into an array. 
 
        Parameters 
        ---------- 
        value : scalar, Series, or array-like 
 
        Returns 
        ------- 
        numpy.ndarray or ExtensionArray 
        &quot;&quot;&quot;</span>
        <span class="s1">self._ensure_valid_index(value)</span>

        <span class="s3"># We should never get here with DataFrame value</span>
        <span class="s2">if </span><span class="s1">isinstance(value</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s2">return </span><span class="s1">_reindex_for_setitem(value</span><span class="s2">, </span><span class="s1">self.index)</span>

        <span class="s2">if </span><span class="s1">is_list_like(value):</span>
            <span class="s1">com.require_length_match(value</span><span class="s2">, </span><span class="s1">self.index)</span>
        <span class="s2">return </span><span class="s1">sanitize_array(value</span><span class="s2">, </span><span class="s1">self.index</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">True, </span><span class="s1">allow_2d=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_series(self):</span>
        <span class="s2">return </span><span class="s1">{</span>
            <span class="s1">item: Series(</span>
                <span class="s1">self._mgr.iget(idx)</span><span class="s2">, </span><span class="s1">index=self.index</span><span class="s2">, </span><span class="s1">name=item</span><span class="s2">, </span><span class="s1">fastpath=</span><span class="s2">True</span>
            <span class="s1">)</span>
            <span class="s2">for </span><span class="s1">idx</span><span class="s2">, </span><span class="s1">item </span><span class="s2">in </span><span class="s1">enumerate(self.columns)</span>
        <span class="s1">}</span>

    <span class="s2">def </span><span class="s1">lookup(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">row_labels: Sequence[IndexLabel]</span><span class="s2">, </span><span class="s1">col_labels: Sequence[IndexLabel]</span>
    <span class="s1">) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot; 
        Label-based &quot;fancy indexing&quot; function for DataFrame. 
        Given equal-length arrays of row and column labels, return an 
        array of the values corresponding to each (row, col) pair. 
 
        .. deprecated:: 1.2.0 
            DataFrame.lookup is deprecated, 
            use DataFrame.melt and DataFrame.loc instead. 
            For further details see 
            :ref:`Looking up values by index/column labels &lt;indexing.lookup&gt;`. 
 
        Parameters 
        ---------- 
        row_labels : sequence 
            The row labels to use for lookup. 
        col_labels : sequence 
            The column labels to use for lookup. 
 
        Returns 
        ------- 
        numpy.ndarray 
            The found values. 
        &quot;&quot;&quot;</span>
        <span class="s1">msg = (</span>
            <span class="s4">&quot;The 'lookup' method is deprecated and will be &quot;</span>
            <span class="s4">&quot;removed in a future version. &quot;</span>
            <span class="s4">&quot;You can use DataFrame.melt and DataFrame.loc &quot;</span>
            <span class="s4">&quot;as a substitute.&quot;</span>
        <span class="s1">)</span>
        <span class="s1">warnings.warn(msg</span><span class="s2">, </span><span class="s1">FutureWarning</span><span class="s2">, </span><span class="s1">stacklevel=find_stack_level())</span>

        <span class="s1">n = len(row_labels)</span>
        <span class="s2">if </span><span class="s1">n != len(col_labels):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Row labels must have same size as column labels&quot;</span><span class="s1">)</span>
        <span class="s2">if not </span><span class="s1">(self.index.is_unique </span><span class="s2">and </span><span class="s1">self.columns.is_unique):</span>
            <span class="s3"># GH#33041</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;DataFrame.lookup requires unique index and columns&quot;</span><span class="s1">)</span>

        <span class="s1">thresh = </span><span class="s5">1000</span>
        <span class="s2">if not </span><span class="s1">self._is_mixed_type </span><span class="s2">or </span><span class="s1">n &gt; thresh:</span>
            <span class="s1">values = self.values</span>
            <span class="s1">ridx = self.index.get_indexer(row_labels)</span>
            <span class="s1">cidx = self.columns.get_indexer(col_labels)</span>
            <span class="s2">if </span><span class="s1">(ridx == -</span><span class="s5">1</span><span class="s1">).any():</span>
                <span class="s2">raise </span><span class="s1">KeyError(</span><span class="s4">&quot;One or more row labels was not found&quot;</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">(cidx == -</span><span class="s5">1</span><span class="s1">).any():</span>
                <span class="s2">raise </span><span class="s1">KeyError(</span><span class="s4">&quot;One or more column labels was not found&quot;</span><span class="s1">)</span>
            <span class="s1">flat_index = ridx * len(self.columns) + cidx</span>
            <span class="s1">result = values.flat[flat_index]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = np.empty(n</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;O&quot;</span><span class="s1">)</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">(r</span><span class="s2">, </span><span class="s1">c) </span><span class="s2">in </span><span class="s1">enumerate(zip(row_labels</span><span class="s2">, </span><span class="s1">col_labels)):</span>
                <span class="s1">result[i] = self._get_value(r</span><span class="s2">, </span><span class="s1">c)</span>

        <span class="s2">if </span><span class="s1">is_object_dtype(result):</span>
            <span class="s1">result = lib.maybe_convert_objects(result)</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Reindexing and alignment</span>

    <span class="s2">def </span><span class="s1">_reindex_axes(self</span><span class="s2">, </span><span class="s1">axes</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">limit</span><span class="s2">, </span><span class="s1">tolerance</span><span class="s2">, </span><span class="s1">method</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">, </span><span class="s1">copy):</span>
        <span class="s1">frame = self</span>

        <span class="s1">columns = axes[</span><span class="s4">&quot;columns&quot;</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">columns </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">frame = frame._reindex_columns(</span>
                <span class="s1">columns</span><span class="s2">, </span><span class="s1">method</span><span class="s2">, </span><span class="s1">copy</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">, </span><span class="s1">limit</span><span class="s2">, </span><span class="s1">tolerance</span>
            <span class="s1">)</span>

        <span class="s1">index = axes[</span><span class="s4">&quot;index&quot;</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">index </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">frame = frame._reindex_index(</span>
                <span class="s1">index</span><span class="s2">, </span><span class="s1">method</span><span class="s2">, </span><span class="s1">copy</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">fill_value</span><span class="s2">, </span><span class="s1">limit</span><span class="s2">, </span><span class="s1">tolerance</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">frame</span>

    <span class="s2">def </span><span class="s1">_reindex_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">new_index</span><span class="s2">,</span>
        <span class="s1">method</span><span class="s2">,</span>
        <span class="s1">copy: bool</span><span class="s2">,</span>
        <span class="s1">level: Level</span><span class="s2">,</span>
        <span class="s1">fill_value=np.nan</span><span class="s2">,</span>
        <span class="s1">limit=</span><span class="s2">None,</span>
        <span class="s1">tolerance=</span><span class="s2">None,</span>
    <span class="s1">):</span>
        <span class="s1">new_index</span><span class="s2">, </span><span class="s1">indexer = self.index.reindex(</span>
            <span class="s1">new_index</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">, </span><span class="s1">level=level</span><span class="s2">, </span><span class="s1">limit=limit</span><span class="s2">, </span><span class="s1">tolerance=tolerance</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._reindex_with_indexers(</span>
            <span class="s1">{</span><span class="s5">0</span><span class="s1">: [new_index</span><span class="s2">, </span><span class="s1">indexer]}</span><span class="s2">,</span>
            <span class="s1">copy=copy</span><span class="s2">,</span>
            <span class="s1">fill_value=fill_value</span><span class="s2">,</span>
            <span class="s1">allow_dups=</span><span class="s2">False,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_reindex_columns(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">new_columns</span><span class="s2">,</span>
        <span class="s1">method</span><span class="s2">,</span>
        <span class="s1">copy: bool</span><span class="s2">,</span>
        <span class="s1">level: Level</span><span class="s2">,</span>
        <span class="s1">fill_value=</span><span class="s2">None,</span>
        <span class="s1">limit=</span><span class="s2">None,</span>
        <span class="s1">tolerance=</span><span class="s2">None,</span>
    <span class="s1">):</span>
        <span class="s1">new_columns</span><span class="s2">, </span><span class="s1">indexer = self.columns.reindex(</span>
            <span class="s1">new_columns</span><span class="s2">, </span><span class="s1">method=method</span><span class="s2">, </span><span class="s1">level=level</span><span class="s2">, </span><span class="s1">limit=limit</span><span class="s2">, </span><span class="s1">tolerance=tolerance</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self._reindex_with_indexers(</span>
            <span class="s1">{</span><span class="s5">1</span><span class="s1">: [new_columns</span><span class="s2">, </span><span class="s1">indexer]}</span><span class="s2">,</span>
            <span class="s1">copy=copy</span><span class="s2">,</span>
            <span class="s1">fill_value=fill_value</span><span class="s2">,</span>
            <span class="s1">allow_dups=</span><span class="s2">False,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_reindex_multi(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">axes: dict[str</span><span class="s2">, </span><span class="s1">Index]</span><span class="s2">, </span><span class="s1">copy: bool</span><span class="s2">, </span><span class="s1">fill_value</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        We are guaranteed non-Nones in the axes. 
        &quot;&quot;&quot;</span>

        <span class="s1">new_index</span><span class="s2">, </span><span class="s1">row_indexer = self.index.reindex(axes[</span><span class="s4">&quot;index&quot;</span><span class="s1">])</span>
        <span class="s1">new_columns</span><span class="s2">, </span><span class="s1">col_indexer = self.columns.reindex(axes[</span><span class="s4">&quot;columns&quot;</span><span class="s1">])</span>

        <span class="s2">if </span><span class="s1">row_indexer </span><span class="s2">is not None and </span><span class="s1">col_indexer </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># Fastpath. By doing two 'take's at once we avoid making an</span>
            <span class="s3">#  unnecessary copy.</span>
            <span class="s3"># We only get here with `not self._is_mixed_type`, which (almost)</span>
            <span class="s3">#  ensures that self.values is cheap. It may be worth making this</span>
            <span class="s3">#  condition more specific.</span>
            <span class="s1">indexer = row_indexer</span><span class="s2">, </span><span class="s1">col_indexer</span>
            <span class="s1">new_values = take_2d_multi(self.values</span><span class="s2">, </span><span class="s1">indexer</span><span class="s2">, </span><span class="s1">fill_value=fill_value)</span>
            <span class="s2">return </span><span class="s1">self._constructor(new_values</span><span class="s2">, </span><span class="s1">index=new_index</span><span class="s2">, </span><span class="s1">columns=new_columns)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._reindex_with_indexers(</span>
                <span class="s1">{</span><span class="s5">0</span><span class="s1">: [new_index</span><span class="s2">, </span><span class="s1">row_indexer]</span><span class="s2">, </span><span class="s5">1</span><span class="s1">: [new_columns</span><span class="s2">, </span><span class="s1">col_indexer]}</span><span class="s2">,</span>
                <span class="s1">copy=copy</span><span class="s2">,</span>
                <span class="s1">fill_value=fill_value</span><span class="s2">,</span>
            <span class="s1">)</span>

    <span class="s1">@doc(NDFrame.align</span><span class="s2">, </span><span class="s1">**_shared_doc_kwargs)</span>
    <span class="s2">def </span><span class="s1">align(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other</span><span class="s2">,</span>
        <span class="s1">join: str = </span><span class="s4">&quot;outer&quot;</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">level: Level | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">copy: bool = </span><span class="s2">True,</span>
        <span class="s1">fill_value=</span><span class="s2">None,</span>
        <span class="s1">method: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">limit=</span><span class="s2">None,</span>
        <span class="s1">fill_axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">broadcast_axis: Axis | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">return </span><span class="s1">super().align(</span>
            <span class="s1">other</span><span class="s2">,</span>
            <span class="s1">join=join</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">level=level</span><span class="s2">,</span>
            <span class="s1">copy=copy</span><span class="s2">,</span>
            <span class="s1">fill_value=fill_value</span><span class="s2">,</span>
            <span class="s1">method=method</span><span class="s2">,</span>
            <span class="s1">limit=limit</span><span class="s2">,</span>
            <span class="s1">fill_axis=fill_axis</span><span class="s2">,</span>
            <span class="s1">broadcast_axis=broadcast_axis</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">set_axis(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">labels</span><span class="s2">, </span><span class="s1">axis: Axis = ...</span><span class="s2">, </span><span class="s1">inplace: Literal[</span><span class="s2">False</span><span class="s1">] = ...</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">set_axis(self</span><span class="s2">, </span><span class="s1">labels</span><span class="s2">, </span><span class="s1">axis: Axis</span><span class="s2">, </span><span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">set_axis(self</span><span class="s2">, </span><span class="s1">labels</span><span class="s2">, </span><span class="s1">*</span><span class="s2">, </span><span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">set_axis(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">labels</span><span class="s2">, </span><span class="s1">axis: Axis = ...</span><span class="s2">, </span><span class="s1">inplace: bool = ...</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;labels&quot;</span><span class="s1">])</span>
    <span class="s1">@Appender(</span>
        <span class="s4">&quot;&quot;&quot; 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2, 3], &quot;B&quot;: [4, 5, 6]}) 
 
        Change the row labels. 
 
        &gt;&gt;&gt; df.set_axis(['a', 'b', 'c'], axis='index') 
           A  B 
        a  1  4 
        b  2  5 
        c  3  6 
 
        Change the column labels. 
 
        &gt;&gt;&gt; df.set_axis(['I', 'II'], axis='columns') 
           I  II 
        0  1   4 
        1  2   5 
        2  3   6 
 
        Now, update the labels inplace. 
 
        &gt;&gt;&gt; df.set_axis(['i', 'ii'], axis='columns', inplace=True) 
        &gt;&gt;&gt; df 
           i  ii 
        0  1   4 
        1  2   5 
        2  3   6 
        &quot;&quot;&quot;</span>
    <span class="s1">)</span>
    <span class="s1">@Substitution(</span>
        <span class="s1">**_shared_doc_kwargs</span><span class="s2">,</span>
        <span class="s1">extended_summary_sub=</span><span class="s4">&quot; column or&quot;</span><span class="s2">,</span>
        <span class="s1">axis_description_sub=</span><span class="s4">&quot;, and 1 identifies the columns&quot;</span><span class="s2">,</span>
        <span class="s1">see_also_sub=</span><span class="s4">&quot; or columns&quot;</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">@Appender(NDFrame.set_axis.__doc__)</span>
    <span class="s2">def </span><span class="s1">set_axis(self</span><span class="s2">, </span><span class="s1">labels</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">inplace: bool = </span><span class="s2">False</span><span class="s1">):</span>
        <span class="s2">return </span><span class="s1">super().set_axis(labels</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">inplace=inplace)</span>

    <span class="s1">@Substitution(**_shared_doc_kwargs)</span>
    <span class="s1">@Appender(NDFrame.reindex.__doc__)</span>
    <span class="s1">@rewrite_axis_style_signature(</span>
        <span class="s4">&quot;labels&quot;</span><span class="s2">,</span>
        <span class="s1">[</span>
            <span class="s1">(</span><span class="s4">&quot;method&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s4">&quot;copy&quot;</span><span class="s2">, True</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s4">&quot;level&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s4">&quot;fill_value&quot;</span><span class="s2">, </span><span class="s1">np.nan)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s4">&quot;limit&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">(</span><span class="s4">&quot;tolerance&quot;</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">]</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">reindex(self</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs) -&gt; DataFrame:</span>
        <span class="s1">axes = validate_axis_style_args(self</span><span class="s2">, </span><span class="s1">args</span><span class="s2">, </span><span class="s1">kwargs</span><span class="s2">, </span><span class="s4">&quot;labels&quot;</span><span class="s2">, </span><span class="s4">&quot;reindex&quot;</span><span class="s1">)</span>
        <span class="s1">kwargs.update(axes)</span>
        <span class="s3"># Pop these, since the values are in `kwargs` under different names</span>
        <span class="s1">kwargs.pop(</span><span class="s4">&quot;axis&quot;</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">kwargs.pop(</span><span class="s4">&quot;labels&quot;</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">super().reindex(**kwargs)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;labels&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">drop(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">labels=</span><span class="s2">None,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">index=</span><span class="s2">None,</span>
        <span class="s1">columns=</span><span class="s2">None,</span>
        <span class="s1">level: Level | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">errors: str = </span><span class="s4">&quot;raise&quot;</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Drop specified labels from rows or columns. 
 
        Remove rows or columns by specifying label names and corresponding 
        axis, or by specifying directly index or column names. When using a 
        multi-index, labels on different levels can be removed by specifying 
        the level. See the `user guide &lt;advanced.shown_levels&gt;` 
        for more information about the now unused levels. 
 
        Parameters 
        ---------- 
        labels : single label or list-like 
            Index or column labels to drop. A tuple will be used as a single 
            label and not treated as a list-like. 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            Whether to drop labels from the index (0 or 'index') or 
            columns (1 or 'columns'). 
        index : single label or list-like 
            Alternative to specifying axis (``labels, axis=0`` 
            is equivalent to ``index=labels``). 
        columns : single label or list-like 
            Alternative to specifying axis (``labels, axis=1`` 
            is equivalent to ``columns=labels``). 
        level : int or level name, optional 
            For MultiIndex, level from which the labels will be removed. 
        inplace : bool, default False 
            If False, return a copy. Otherwise, do operation 
            inplace and return None. 
        errors : {'ignore', 'raise'}, default 'raise' 
            If 'ignore', suppress error and only existing labels are 
            dropped. 
 
        Returns 
        ------- 
        DataFrame or None 
            DataFrame without the removed index or column labels or 
            None if ``inplace=True``. 
 
        Raises 
        ------ 
        KeyError 
            If any of the labels is not found in the selected axis. 
 
        See Also 
        -------- 
        DataFrame.loc : Label-location based indexer for selection by label. 
        DataFrame.dropna : Return DataFrame with labels on given axis omitted 
            where (all or any) data are missing. 
        DataFrame.drop_duplicates : Return DataFrame with duplicate rows 
            removed, optionally only considering certain columns. 
        Series.drop : Return Series with specified index labels removed. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame(np.arange(12).reshape(3, 4), 
        ...                   columns=['A', 'B', 'C', 'D']) 
        &gt;&gt;&gt; df 
           A  B   C   D 
        0  0  1   2   3 
        1  4  5   6   7 
        2  8  9  10  11 
 
        Drop columns 
 
        &gt;&gt;&gt; df.drop(['B', 'C'], axis=1) 
           A   D 
        0  0   3 
        1  4   7 
        2  8  11 
 
        &gt;&gt;&gt; df.drop(columns=['B', 'C']) 
           A   D 
        0  0   3 
        1  4   7 
        2  8  11 
 
        Drop a row by index 
 
        &gt;&gt;&gt; df.drop([0, 1]) 
           A  B   C   D 
        2  8  9  10  11 
 
        Drop columns and/or rows of MultiIndex DataFrame 
 
        &gt;&gt;&gt; midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'], 
        ...                              ['speed', 'weight', 'length']], 
        ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2], 
        ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]]) 
        &gt;&gt;&gt; df = pd.DataFrame(index=midx, columns=['big', 'small'], 
        ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20], 
        ...                         [250, 150], [1.5, 0.8], [320, 250], 
        ...                         [1, 0.8], [0.3, 0.2]]) 
        &gt;&gt;&gt; df 
                        big     small 
        lama    speed   45.0    30.0 
                weight  200.0   100.0 
                length  1.5     1.0 
        cow     speed   30.0    20.0 
                weight  250.0   150.0 
                length  1.5     0.8 
        falcon  speed   320.0   250.0 
                weight  1.0     0.8 
                length  0.3     0.2 
 
        Drop a specific index combination from the MultiIndex 
        DataFrame, i.e., drop the combination ``'falcon'`` and 
        ``'weight'``, which deletes only the corresponding row 
 
        &gt;&gt;&gt; df.drop(index=('falcon', 'weight')) 
                        big     small 
        lama    speed   45.0    30.0 
                weight  200.0   100.0 
                length  1.5     1.0 
        cow     speed   30.0    20.0 
                weight  250.0   150.0 
                length  1.5     0.8 
        falcon  speed   320.0   250.0 
                length  0.3     0.2 
 
        &gt;&gt;&gt; df.drop(index='cow', columns='small') 
                        big 
        lama    speed   45.0 
                weight  200.0 
                length  1.5 
        falcon  speed   320.0 
                weight  1.0 
                length  0.3 
 
        &gt;&gt;&gt; df.drop(index='length', level=1) 
                        big     small 
        lama    speed   45.0    30.0 
                weight  200.0   100.0 
        cow     speed   30.0    20.0 
                weight  250.0   150.0 
        falcon  speed   320.0   250.0 
                weight  1.0     0.8 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">super().drop(</span>
            <span class="s1">labels=labels</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">index=index</span><span class="s2">,</span>
            <span class="s1">columns=columns</span><span class="s2">,</span>
            <span class="s1">level=level</span><span class="s2">,</span>
            <span class="s1">inplace=inplace</span><span class="s2">,</span>
            <span class="s1">errors=errors</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">rename(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">mapper: Renamer | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">index: Renamer | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">columns: Renamer | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">copy: bool = </span><span class="s2">True,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">level: Level | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">errors: str = </span><span class="s4">&quot;ignore&quot;</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Alter axes labels. 
 
        Function / dict values must be unique (1-to-1). Labels not contained in 
        a dict / Series will be left as-is. Extra labels listed don't throw an 
        error. 
 
        See the :ref:`user guide &lt;basics.rename&gt;` for more. 
 
        Parameters 
        ---------- 
        mapper : dict-like or function 
            Dict-like or function transformations to apply to 
            that axis' values. Use either ``mapper`` and ``axis`` to 
            specify the axis to target with ``mapper``, or ``index`` and 
            ``columns``. 
        index : dict-like or function 
            Alternative to specifying axis (``mapper, axis=0`` 
            is equivalent to ``index=mapper``). 
        columns : dict-like or function 
            Alternative to specifying axis (``mapper, axis=1`` 
            is equivalent to ``columns=mapper``). 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            Axis to target with ``mapper``. Can be either the axis name 
            ('index', 'columns') or number (0, 1). The default is 'index'. 
        copy : bool, default True 
            Also copy underlying data. 
        inplace : bool, default False 
            Whether to return a new DataFrame. If True then value of copy is 
            ignored. 
        level : int or level name, default None 
            In case of a MultiIndex, only rename labels in the specified 
            level. 
        errors : {'ignore', 'raise'}, default 'ignore' 
            If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`, 
            or `columns` contains labels that are not present in the Index 
            being transformed. 
            If 'ignore', existing keys will be renamed and extra keys will be 
            ignored. 
 
        Returns 
        ------- 
        DataFrame or None 
            DataFrame with the renamed axis labels or None if ``inplace=True``. 
 
        Raises 
        ------ 
        KeyError 
            If any of the labels is not found in the selected axis and 
            &quot;errors='raise'&quot;. 
 
        See Also 
        -------- 
        DataFrame.rename_axis : Set the name of the axis. 
 
        Examples 
        -------- 
        ``DataFrame.rename`` supports two calling conventions 
 
        * ``(index=index_mapper, columns=columns_mapper, ...)`` 
        * ``(mapper, axis={'index', 'columns'}, ...)`` 
 
        We *highly* recommend using keyword arguments to clarify your 
        intent. 
 
        Rename columns using a mapping: 
 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2, 3], &quot;B&quot;: [4, 5, 6]}) 
        &gt;&gt;&gt; df.rename(columns={&quot;A&quot;: &quot;a&quot;, &quot;B&quot;: &quot;c&quot;}) 
           a  c 
        0  1  4 
        1  2  5 
        2  3  6 
 
        Rename index using a mapping: 
 
        &gt;&gt;&gt; df.rename(index={0: &quot;x&quot;, 1: &quot;y&quot;, 2: &quot;z&quot;}) 
           A  B 
        x  1  4 
        y  2  5 
        z  3  6 
 
        Cast index labels to a different type: 
 
        &gt;&gt;&gt; df.index 
        RangeIndex(start=0, stop=3, step=1) 
        &gt;&gt;&gt; df.rename(index=str).index 
        Index(['0', '1', '2'], dtype='object') 
 
        &gt;&gt;&gt; df.rename(columns={&quot;A&quot;: &quot;a&quot;, &quot;B&quot;: &quot;b&quot;, &quot;C&quot;: &quot;c&quot;}, errors=&quot;raise&quot;) 
        Traceback (most recent call last): 
        KeyError: ['C'] not found in axis 
 
        Using axis-style parameters: 
 
        &gt;&gt;&gt; df.rename(str.lower, axis='columns') 
           a  b 
        0  1  4 
        1  2  5 
        2  3  6 
 
        &gt;&gt;&gt; df.rename({1: 2, 2: 4}, axis='index') 
           A  B 
        0  1  4 
        2  2  5 
        4  3  6 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">super()._rename(</span>
            <span class="s1">mapper=mapper</span><span class="s2">,</span>
            <span class="s1">index=index</span><span class="s2">,</span>
            <span class="s1">columns=columns</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">copy=copy</span><span class="s2">,</span>
            <span class="s1">inplace=inplace</span><span class="s2">,</span>
            <span class="s1">level=level</span><span class="s2">,</span>
            <span class="s1">errors=errors</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value=...</span><span class="s2">,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">False</span><span class="s1">] = ...</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value</span><span class="s2">,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value</span><span class="s2">,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value=...</span><span class="s2">,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">inplace: bool = ...</span><span class="s2">,</span>
        <span class="s1">limit=...</span><span class="s2">,</span>
        <span class="s1">downcast=...</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;value&quot;</span><span class="s1">])</span>
    <span class="s1">@doc(NDFrame.fillna</span><span class="s2">, </span><span class="s1">**_shared_doc_kwargs)</span>
    <span class="s2">def </span><span class="s1">fillna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">value: object | ArrayLike | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">method: FillnaOptions | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">limit=</span><span class="s2">None,</span>
        <span class="s1">downcast=</span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">super().fillna(</span>
            <span class="s1">value=value</span><span class="s2">,</span>
            <span class="s1">method=method</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">inplace=inplace</span><span class="s2">,</span>
            <span class="s1">limit=limit</span><span class="s2">,</span>
            <span class="s1">downcast=downcast</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">pop(self</span><span class="s2">, </span><span class="s1">item: Hashable) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return item and drop from frame. Raise KeyError if not found. 
 
        Parameters 
        ---------- 
        item : label 
            Label of column to be popped. 
 
        Returns 
        ------- 
        Series 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([('falcon', 'bird', 389.0), 
        ...                    ('parrot', 'bird', 24.0), 
        ...                    ('lion', 'mammal', 80.5), 
        ...                    ('monkey', 'mammal', np.nan)], 
        ...                   columns=('name', 'class', 'max_speed')) 
        &gt;&gt;&gt; df 
             name   class  max_speed 
        0  falcon    bird      389.0 
        1  parrot    bird       24.0 
        2    lion  mammal       80.5 
        3  monkey  mammal        NaN 
 
        &gt;&gt;&gt; df.pop('class') 
        0      bird 
        1      bird 
        2    mammal 
        3    mammal 
        Name: class, dtype: object 
 
        &gt;&gt;&gt; df 
             name  max_speed 
        0  falcon      389.0 
        1  parrot       24.0 
        2    lion       80.5 
        3  monkey        NaN 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">super().pop(item=item)</span>

    <span class="s1">@doc(NDFrame.replace</span><span class="s2">, </span><span class="s1">**_shared_doc_kwargs)</span>
    <span class="s2">def </span><span class="s1">replace(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">to_replace=</span><span class="s2">None,</span>
        <span class="s1">value=lib.no_default</span><span class="s2">,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">limit=</span><span class="s2">None,</span>
        <span class="s1">regex: bool = </span><span class="s2">False,</span>
        <span class="s1">method: str | lib.NoDefault = lib.no_default</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s2">return </span><span class="s1">super().replace(</span>
            <span class="s1">to_replace=to_replace</span><span class="s2">,</span>
            <span class="s1">value=value</span><span class="s2">,</span>
            <span class="s1">inplace=inplace</span><span class="s2">,</span>
            <span class="s1">limit=limit</span><span class="s2">,</span>
            <span class="s1">regex=regex</span><span class="s2">,</span>
            <span class="s1">method=method</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_replace_columnwise(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">mapping: dict[Hashable</span><span class="s2">, </span><span class="s1">tuple[Any</span><span class="s2">, </span><span class="s1">Any]]</span><span class="s2">, </span><span class="s1">inplace: bool</span><span class="s2">, </span><span class="s1">regex</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Dispatch to Series.replace column-wise. 
 
        Parameters 
        ---------- 
        mapping : dict 
            of the form {col: (target, value)} 
        inplace : bool 
        regex : bool or same types as `to_replace` in DataFrame.replace 
 
        Returns 
        ------- 
        DataFrame or None 
        &quot;&quot;&quot;</span>
        <span class="s3"># Operate column-wise</span>
        <span class="s1">res = self </span><span class="s2">if </span><span class="s1">inplace </span><span class="s2">else </span><span class="s1">self.copy()</span>
        <span class="s1">ax = self.columns</span>

        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(len(ax)):</span>
            <span class="s2">if </span><span class="s1">ax[i] </span><span class="s2">in </span><span class="s1">mapping:</span>
                <span class="s1">ser = self.iloc[:</span><span class="s2">, </span><span class="s1">i]</span>

                <span class="s1">target</span><span class="s2">, </span><span class="s1">value = mapping[ax[i]]</span>
                <span class="s1">newobj = ser.replace(target</span><span class="s2">, </span><span class="s1">value</span><span class="s2">, </span><span class="s1">regex=regex)</span>

                <span class="s1">res.iloc[:</span><span class="s2">, </span><span class="s1">i] = newobj</span>

        <span class="s2">if </span><span class="s1">inplace:</span>
            <span class="s2">return</span>
        <span class="s2">return </span><span class="s1">res.__finalize__(self)</span>

    <span class="s1">@doc(NDFrame.shift</span><span class="s2">, </span><span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">shift(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">periods=</span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">freq: Frequency | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">fill_value=lib.no_default</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>

        <span class="s1">ncols = len(self.columns)</span>
        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">1 </span><span class="s2">and </span><span class="s1">periods != </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">fill_value </span><span class="s2">is </span><span class="s1">lib.no_default </span><span class="s2">and </span><span class="s1">ncols &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># We will infer fill_value to match the closest column</span>

            <span class="s3"># Use a column that we know is valid for our column's dtype GH#38434</span>
            <span class="s1">label = self.columns[</span><span class="s5">0</span><span class="s1">]</span>

            <span class="s2">if </span><span class="s1">periods &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">result = self.iloc[:</span><span class="s2">, </span><span class="s1">:-periods]</span>
                <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">range(min(ncols</span><span class="s2">, </span><span class="s1">abs(periods))):</span>
                    <span class="s3"># TODO(EA2D): doing this in a loop unnecessary with 2D EAs</span>
                    <span class="s3"># Define filler inside loop so we get a copy</span>
                    <span class="s1">filler = self.iloc[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">].shift(len(self))</span>
                    <span class="s1">result.insert(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">label</span><span class="s2">, </span><span class="s1">filler</span><span class="s2">, </span><span class="s1">allow_duplicates=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">result = self.iloc[:</span><span class="s2">, </span><span class="s1">-periods:]</span>
                <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">range(min(ncols</span><span class="s2">, </span><span class="s1">abs(periods))):</span>
                    <span class="s3"># Define filler inside loop so we get a copy</span>
                    <span class="s1">filler = self.iloc[:</span><span class="s2">, </span><span class="s1">-</span><span class="s5">1</span><span class="s1">].shift(len(self))</span>
                    <span class="s1">result.insert(</span>
                        <span class="s1">len(result.columns)</span><span class="s2">, </span><span class="s1">label</span><span class="s2">, </span><span class="s1">filler</span><span class="s2">, </span><span class="s1">allow_duplicates=</span><span class="s2">True</span>
                    <span class="s1">)</span>

            <span class="s1">result.columns = self.columns.copy()</span>
            <span class="s2">return </span><span class="s1">result</span>

        <span class="s2">return </span><span class="s1">super().shift(</span>
            <span class="s1">periods=periods</span><span class="s2">, </span><span class="s1">freq=freq</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">fill_value=fill_value</span>
        <span class="s1">)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;keys&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">set_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">keys</span><span class="s2">,</span>
        <span class="s1">drop: bool = </span><span class="s2">True,</span>
        <span class="s1">append: bool = </span><span class="s2">False,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">verify_integrity: bool = </span><span class="s2">False,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Set the DataFrame index using existing columns. 
 
        Set the DataFrame index (row labels) using one or more existing 
        columns or arrays (of the correct length). The index can replace the 
        existing index or expand on it. 
 
        Parameters 
        ---------- 
        keys : label or array-like or list of labels/arrays 
            This parameter can be either a single column key, a single array of 
            the same length as the calling DataFrame, or a list containing an 
            arbitrary combination of column keys and arrays. Here, &quot;array&quot; 
            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and 
            instances of :class:`~collections.abc.Iterator`. 
        drop : bool, default True 
            Delete columns to be used as the new index. 
        append : bool, default False 
            Whether to append columns to existing index. 
        inplace : bool, default False 
            If True, modifies the DataFrame in place (do not create a new object). 
        verify_integrity : bool, default False 
            Check the new index for duplicates. Otherwise defer the check until 
            necessary. Setting to False will improve the performance of this 
            method. 
 
        Returns 
        ------- 
        DataFrame or None 
            Changed row labels or None if ``inplace=True``. 
 
        See Also 
        -------- 
        DataFrame.reset_index : Opposite of set_index. 
        DataFrame.reindex : Change to new indices or expand indices. 
        DataFrame.reindex_like : Change to same indices as other DataFrame. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'month': [1, 4, 7, 10], 
        ...                    'year': [2012, 2014, 2013, 2014], 
        ...                    'sale': [55, 40, 84, 31]}) 
        &gt;&gt;&gt; df 
           month  year  sale 
        0      1  2012    55 
        1      4  2014    40 
        2      7  2013    84 
        3     10  2014    31 
 
        Set the index to become the 'month' column: 
 
        &gt;&gt;&gt; df.set_index('month') 
               year  sale 
        month 
        1      2012    55 
        4      2014    40 
        7      2013    84 
        10     2014    31 
 
        Create a MultiIndex using columns 'year' and 'month': 
 
        &gt;&gt;&gt; df.set_index(['year', 'month']) 
                    sale 
        year  month 
        2012  1     55 
        2014  4     40 
        2013  7     84 
        2014  10    31 
 
        Create a MultiIndex using an Index and a column: 
 
        &gt;&gt;&gt; df.set_index([pd.Index([1, 2, 3, 4]), 'year']) 
                 month  sale 
           year 
        1  2012  1      55 
        2  2014  4      40 
        3  2013  7      84 
        4  2014  10     31 
 
        Create a MultiIndex using two Series: 
 
        &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4]) 
        &gt;&gt;&gt; df.set_index([s, s**2]) 
              month  year  sale 
        1 1       1  2012    55 
        2 4       4  2014    40 
        3 9       7  2013    84 
        4 16     10  2014    31 
        &quot;&quot;&quot;</span>
        <span class="s1">inplace = validate_bool_kwarg(inplace</span><span class="s2">, </span><span class="s4">&quot;inplace&quot;</span><span class="s1">)</span>
        <span class="s1">self._check_inplace_and_allows_duplicate_labels(inplace)</span>
        <span class="s2">if not </span><span class="s1">isinstance(keys</span><span class="s2">, </span><span class="s1">list):</span>
            <span class="s1">keys = [keys]</span>

        <span class="s1">err_msg = (</span>
            <span class="s4">'The parameter &quot;keys&quot; may be a column key, one-dimensional '</span>
            <span class="s4">&quot;array, or a list containing only valid column keys and &quot;</span>
            <span class="s4">&quot;one-dimensional arrays.&quot;</span>
        <span class="s1">)</span>

        <span class="s1">missing: list[Hashable] = []</span>
        <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">keys:</span>
            <span class="s2">if </span><span class="s1">isinstance(col</span><span class="s2">, </span><span class="s1">(Index</span><span class="s2">, </span><span class="s1">Series</span><span class="s2">, </span><span class="s1">np.ndarray</span><span class="s2">, </span><span class="s1">list</span><span class="s2">, </span><span class="s1">abc.Iterator)):</span>
                <span class="s3"># arrays are fine as long as they are one-dimensional</span>
                <span class="s3"># iterators get converted to list below</span>
                <span class="s2">if </span><span class="s1">getattr(col</span><span class="s2">, </span><span class="s4">&quot;ndim&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) != </span><span class="s5">1</span><span class="s1">:</span>
                    <span class="s2">raise </span><span class="s1">ValueError(err_msg)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># everything else gets tried as a key; see GH 24969</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">found = col </span><span class="s2">in </span><span class="s1">self.columns</span>
                <span class="s2">except </span><span class="s1">TypeError </span><span class="s2">as </span><span class="s1">err:</span>
                    <span class="s2">raise </span><span class="s1">TypeError(</span>
                        <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">err_msg</span><span class="s2">}</span><span class="s4">. Received column of type </span><span class="s2">{</span><span class="s1">type(col)</span><span class="s2">}</span><span class="s4">&quot;</span>
                    <span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s2">if not </span><span class="s1">found:</span>
                        <span class="s1">missing.append(col)</span>

        <span class="s2">if </span><span class="s1">missing:</span>
            <span class="s2">raise </span><span class="s1">KeyError(</span><span class="s4">f&quot;None of </span><span class="s2">{</span><span class="s1">missing</span><span class="s2">} </span><span class="s4">are in the columns&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">inplace:</span>
            <span class="s1">frame = self</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">frame = self.copy()</span>

        <span class="s1">arrays = []</span>
        <span class="s1">names: list[Hashable] = []</span>
        <span class="s2">if </span><span class="s1">append:</span>
            <span class="s1">names = list(self.index.names)</span>
            <span class="s2">if </span><span class="s1">isinstance(self.index</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.index.nlevels):</span>
                    <span class="s1">arrays.append(self.index._get_level_values(i))</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">arrays.append(self.index)</span>

        <span class="s1">to_remove: list[Hashable] = []</span>
        <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">keys:</span>
            <span class="s2">if </span><span class="s1">isinstance(col</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                <span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">range(col.nlevels):</span>
                    <span class="s1">arrays.append(col._get_level_values(n))</span>
                <span class="s1">names.extend(col.names)</span>
            <span class="s2">elif </span><span class="s1">isinstance(col</span><span class="s2">, </span><span class="s1">(Index</span><span class="s2">, </span><span class="s1">Series)):</span>
                <span class="s3"># if Index then not MultiIndex (treated above)</span>

                <span class="s3"># error: Argument 1 to &quot;append&quot; of &quot;list&quot; has incompatible type</span>
                <span class="s3">#  &quot;Union[Index, Series]&quot;; expected &quot;Index&quot;</span>
                <span class="s1">arrays.append(col)  </span><span class="s3"># type:ignore[arg-type]</span>
                <span class="s1">names.append(col.name)</span>
            <span class="s2">elif </span><span class="s1">isinstance(col</span><span class="s2">, </span><span class="s1">(list</span><span class="s2">, </span><span class="s1">np.ndarray)):</span>
                <span class="s3"># error: Argument 1 to &quot;append&quot; of &quot;list&quot; has incompatible type</span>
                <span class="s3"># &quot;Union[List[Any], ndarray]&quot;; expected &quot;Index&quot;</span>
                <span class="s1">arrays.append(col)  </span><span class="s3"># type: ignore[arg-type]</span>
                <span class="s1">names.append(</span><span class="s2">None</span><span class="s1">)</span>
            <span class="s2">elif </span><span class="s1">isinstance(col</span><span class="s2">, </span><span class="s1">abc.Iterator):</span>
                <span class="s3"># error: Argument 1 to &quot;append&quot; of &quot;list&quot; has incompatible type</span>
                <span class="s3"># &quot;List[Any]&quot;; expected &quot;Index&quot;</span>
                <span class="s1">arrays.append(list(col))  </span><span class="s3"># type: ignore[arg-type]</span>
                <span class="s1">names.append(</span><span class="s2">None</span><span class="s1">)</span>
            <span class="s3"># from here, col can only be a column label</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">arrays.append(frame[col]._values)</span>
                <span class="s1">names.append(col)</span>
                <span class="s2">if </span><span class="s1">drop:</span>
                    <span class="s1">to_remove.append(col)</span>

            <span class="s2">if </span><span class="s1">len(arrays[-</span><span class="s5">1</span><span class="s1">]) != len(self):</span>
                <span class="s3"># check newest element against length of calling frame, since</span>
                <span class="s3"># ensure_index_from_sequences would not raise for append=False.</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">f&quot;Length mismatch: Expected </span><span class="s2">{</span><span class="s1">len(self)</span><span class="s2">} </span><span class="s4">rows, &quot;</span>
                    <span class="s4">f&quot;received array of length </span><span class="s2">{</span><span class="s1">len(arrays[-</span><span class="s5">1</span><span class="s1">])</span><span class="s2">}</span><span class="s4">&quot;</span>
                <span class="s1">)</span>

        <span class="s1">index = ensure_index_from_sequences(arrays</span><span class="s2">, </span><span class="s1">names)</span>

        <span class="s2">if </span><span class="s1">verify_integrity </span><span class="s2">and not </span><span class="s1">index.is_unique:</span>
            <span class="s1">duplicates = index[index.duplicated()].unique()</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;Index has duplicate keys: </span><span class="s2">{</span><span class="s1">duplicates</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

        <span class="s3"># use set to handle duplicate column names gracefully in case of drop</span>
        <span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">set(to_remove):</span>
            <span class="s2">del </span><span class="s1">frame[c]</span>

        <span class="s3"># clear up memory usage</span>
        <span class="s1">index._cleanup()</span>

        <span class="s1">frame.index = index</span>

        <span class="s2">if not </span><span class="s1">inplace:</span>
            <span class="s2">return </span><span class="s1">frame</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">reset_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">level: Hashable | Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">drop: bool = ...</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">False</span><span class="s1">] = ...</span><span class="s2">,</span>
        <span class="s1">col_level: Hashable = ...</span><span class="s2">,</span>
        <span class="s1">col_fill: Hashable = ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">reset_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">level: Hashable | Sequence[Hashable] | </span><span class="s2">None,</span>
        <span class="s1">drop: bool</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">col_level: Hashable = ...</span><span class="s2">,</span>
        <span class="s1">col_fill: Hashable = ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">reset_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">drop: bool</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">col_level: Hashable = ...</span><span class="s2">,</span>
        <span class="s1">col_fill: Hashable = ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">reset_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">level: Hashable | Sequence[Hashable] | </span><span class="s2">None,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">col_level: Hashable = ...</span><span class="s2">,</span>
        <span class="s1">col_fill: Hashable = ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">reset_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">inplace: Literal[</span><span class="s2">True</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">col_level: Hashable = ...</span><span class="s2">,</span>
        <span class="s1">col_fill: Hashable = ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@overload</span>
    <span class="s2">def </span><span class="s1">reset_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">level: Hashable | Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= ...</span><span class="s2">,</span>
        <span class="s1">drop: bool = ...</span><span class="s2">,</span>
        <span class="s1">inplace: bool = ...</span><span class="s2">,</span>
        <span class="s1">col_level: Hashable = ...</span><span class="s2">,</span>
        <span class="s1">col_fill: Hashable = ...</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">...</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;level&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">reset_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">level: Hashable | Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">drop: bool = </span><span class="s2">False,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">col_level: Hashable = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">col_fill: Hashable = </span><span class="s4">&quot;&quot;</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Reset the index, or a level of it. 
 
        Reset the index of the DataFrame, and use the default one instead. 
        If the DataFrame has a MultiIndex, this method can remove one or more 
        levels. 
 
        Parameters 
        ---------- 
        level : int, str, tuple, or list, default None 
            Only remove the given levels from the index. Removes all levels by 
            default. 
        drop : bool, default False 
            Do not try to insert index into dataframe columns. This resets 
            the index to the default integer index. 
        inplace : bool, default False 
            Modify the DataFrame in place (do not create a new object). 
        col_level : int or str, default 0 
            If the columns have multiple levels, determines which level the 
            labels are inserted into. By default it is inserted into the first 
            level. 
        col_fill : object, default '' 
            If the columns have multiple levels, determines how the other 
            levels are named. If None then the index name is repeated. 
 
        Returns 
        ------- 
        DataFrame or None 
            DataFrame with the new index or None if ``inplace=True``. 
 
        See Also 
        -------- 
        DataFrame.set_index : Opposite of reset_index. 
        DataFrame.reindex : Change to new indices or expand indices. 
        DataFrame.reindex_like : Change to same indices as other DataFrame. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([('bird', 389.0), 
        ...                    ('bird', 24.0), 
        ...                    ('mammal', 80.5), 
        ...                    ('mammal', np.nan)], 
        ...                   index=['falcon', 'parrot', 'lion', 'monkey'], 
        ...                   columns=('class', 'max_speed')) 
        &gt;&gt;&gt; df 
                 class  max_speed 
        falcon    bird      389.0 
        parrot    bird       24.0 
        lion    mammal       80.5 
        monkey  mammal        NaN 
 
        When we reset the index, the old index is added as a column, and a 
        new sequential index is used: 
 
        &gt;&gt;&gt; df.reset_index() 
            index   class  max_speed 
        0  falcon    bird      389.0 
        1  parrot    bird       24.0 
        2    lion  mammal       80.5 
        3  monkey  mammal        NaN 
 
        We can use the `drop` parameter to avoid the old index being added as 
        a column: 
 
        &gt;&gt;&gt; df.reset_index(drop=True) 
            class  max_speed 
        0    bird      389.0 
        1    bird       24.0 
        2  mammal       80.5 
        3  mammal        NaN 
 
        You can also use `reset_index` with `MultiIndex`. 
 
        &gt;&gt;&gt; index = pd.MultiIndex.from_tuples([('bird', 'falcon'), 
        ...                                    ('bird', 'parrot'), 
        ...                                    ('mammal', 'lion'), 
        ...                                    ('mammal', 'monkey')], 
        ...                                   names=['class', 'name']) 
        &gt;&gt;&gt; columns = pd.MultiIndex.from_tuples([('speed', 'max'), 
        ...                                      ('species', 'type')]) 
        &gt;&gt;&gt; df = pd.DataFrame([(389.0, 'fly'), 
        ...                    ( 24.0, 'fly'), 
        ...                    ( 80.5, 'run'), 
        ...                    (np.nan, 'jump')], 
        ...                   index=index, 
        ...                   columns=columns) 
        &gt;&gt;&gt; df 
                       speed species 
                         max    type 
        class  name 
        bird   falcon  389.0     fly 
               parrot   24.0     fly 
        mammal lion     80.5     run 
               monkey    NaN    jump 
 
        If the index has multiple levels, we can reset a subset of them: 
 
        &gt;&gt;&gt; df.reset_index(level='class') 
                 class  speed species 
                          max    type 
        name 
        falcon    bird  389.0     fly 
        parrot    bird   24.0     fly 
        lion    mammal   80.5     run 
        monkey  mammal    NaN    jump 
 
        If we are not dropping the index, by default, it is placed in the top 
        level. We can place it in another level: 
 
        &gt;&gt;&gt; df.reset_index(level='class', col_level=1) 
                        speed species 
                 class    max    type 
        name 
        falcon    bird  389.0     fly 
        parrot    bird   24.0     fly 
        lion    mammal   80.5     run 
        monkey  mammal    NaN    jump 
 
        When the index is inserted under another level, we can specify under 
        which one with the parameter `col_fill`: 
 
        &gt;&gt;&gt; df.reset_index(level='class', col_level=1, col_fill='species') 
                      species  speed species 
                        class    max    type 
        name 
        falcon           bird  389.0     fly 
        parrot           bird   24.0     fly 
        lion           mammal   80.5     run 
        monkey         mammal    NaN    jump 
 
        If we specify a nonexistent level for `col_fill`, it is created: 
 
        &gt;&gt;&gt; df.reset_index(level='class', col_level=1, col_fill='genus') 
                        genus  speed species 
                        class    max    type 
        name 
        falcon           bird  389.0     fly 
        parrot           bird   24.0     fly 
        lion           mammal   80.5     run 
        monkey         mammal    NaN    jump 
        &quot;&quot;&quot;</span>
        <span class="s1">inplace = validate_bool_kwarg(inplace</span><span class="s2">, </span><span class="s4">&quot;inplace&quot;</span><span class="s1">)</span>
        <span class="s1">self._check_inplace_and_allows_duplicate_labels(inplace)</span>
        <span class="s2">if </span><span class="s1">inplace:</span>
            <span class="s1">new_obj = self</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">new_obj = self.copy()</span>

        <span class="s1">new_index = default_index(len(new_obj))</span>
        <span class="s2">if </span><span class="s1">level </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">isinstance(level</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)):</span>
                <span class="s1">level = [level]</span>
            <span class="s1">level = [self.index._get_level_number(lev) </span><span class="s2">for </span><span class="s1">lev </span><span class="s2">in </span><span class="s1">level]</span>
            <span class="s2">if </span><span class="s1">len(level) &lt; self.index.nlevels:</span>
                <span class="s1">new_index = self.index.droplevel(level)</span>

        <span class="s2">if not </span><span class="s1">drop:</span>
            <span class="s1">to_insert: Iterable[tuple[Any</span><span class="s2">, </span><span class="s1">Any | </span><span class="s2">None</span><span class="s1">]]</span>
            <span class="s2">if </span><span class="s1">isinstance(self.index</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
                <span class="s1">names = com.fill_missing_names(self.index.names)</span>
                <span class="s1">to_insert = zip(self.index.levels</span><span class="s2">, </span><span class="s1">self.index.codes)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">default = </span><span class="s4">&quot;index&quot; </span><span class="s2">if </span><span class="s4">&quot;index&quot; </span><span class="s2">not in </span><span class="s1">self </span><span class="s2">else </span><span class="s4">&quot;level_0&quot;</span>
                <span class="s1">names = [default] </span><span class="s2">if </span><span class="s1">self.index.name </span><span class="s2">is None else </span><span class="s1">[self.index.name]</span>
                <span class="s1">to_insert = ((self.index</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span><span class="s1">)</span>

            <span class="s1">multi_col = isinstance(self.columns</span><span class="s2">, </span><span class="s1">MultiIndex)</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">(lev</span><span class="s2">, </span><span class="s1">lab) </span><span class="s2">in </span><span class="s1">reversed(list(enumerate(to_insert))):</span>
                <span class="s2">if </span><span class="s1">level </span><span class="s2">is not None and </span><span class="s1">i </span><span class="s2">not in </span><span class="s1">level:</span>
                    <span class="s2">continue</span>
                <span class="s1">name = names[i]</span>
                <span class="s2">if </span><span class="s1">multi_col:</span>
                    <span class="s1">col_name = list(name) </span><span class="s2">if </span><span class="s1">isinstance(name</span><span class="s2">, </span><span class="s1">tuple) </span><span class="s2">else </span><span class="s1">[name]</span>
                    <span class="s2">if </span><span class="s1">col_fill </span><span class="s2">is None</span><span class="s1">:</span>
                        <span class="s2">if </span><span class="s1">len(col_name) </span><span class="s2">not in </span><span class="s1">(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">self.columns.nlevels):</span>
                            <span class="s2">raise </span><span class="s1">ValueError(</span>
                                <span class="s4">&quot;col_fill=None is incompatible &quot;</span>
                                <span class="s4">f&quot;with incomplete column name </span><span class="s2">{</span><span class="s1">name</span><span class="s2">}</span><span class="s4">&quot;</span>
                            <span class="s1">)</span>
                        <span class="s1">col_fill = col_name[</span><span class="s5">0</span><span class="s1">]</span>

                    <span class="s1">lev_num = self.columns._get_level_number(col_level)</span>
                    <span class="s1">name_lst = [col_fill] * lev_num + col_name</span>
                    <span class="s1">missing = self.columns.nlevels - len(name_lst)</span>
                    <span class="s1">name_lst += [col_fill] * missing</span>
                    <span class="s1">name = tuple(name_lst)</span>

                <span class="s3"># to ndarray and maybe infer different dtype</span>
                <span class="s1">level_values = lev._values</span>
                <span class="s2">if </span><span class="s1">level_values.dtype == np.object_:</span>
                    <span class="s1">level_values = lib.maybe_convert_objects(level_values)</span>

                <span class="s2">if </span><span class="s1">lab </span><span class="s2">is not None</span><span class="s1">:</span>
                    <span class="s3"># if we have the codes, extract the values with a mask</span>
                    <span class="s1">level_values = algorithms.take(</span>
                        <span class="s1">level_values</span><span class="s2">, </span><span class="s1">lab</span><span class="s2">, </span><span class="s1">allow_fill=</span><span class="s2">True, </span><span class="s1">fill_value=lev._na_value</span>
                    <span class="s1">)</span>

                <span class="s1">new_obj.insert(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">level_values)</span>

        <span class="s1">new_obj.index = new_index</span>
        <span class="s2">if not </span><span class="s1">inplace:</span>
            <span class="s2">return </span><span class="s1">new_obj</span>

        <span class="s2">return None</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Reindex-based selection methods</span>

    <span class="s1">@doc(NDFrame.isna</span><span class="s2">, </span><span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">isna(self) -&gt; DataFrame:</span>
        <span class="s1">result = self._constructor(self._mgr.isna(func=isna))</span>
        <span class="s2">return </span><span class="s1">result.__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;isna&quot;</span><span class="s1">)</span>

    <span class="s1">@doc(NDFrame.isna</span><span class="s2">, </span><span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">isnull(self) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        DataFrame.isnull is an alias for DataFrame.isna. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.isna()</span>

    <span class="s1">@doc(NDFrame.notna</span><span class="s2">, </span><span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">notna(self) -&gt; DataFrame:</span>
        <span class="s2">return </span><span class="s1">~self.isna()</span>

    <span class="s1">@doc(NDFrame.notna</span><span class="s2">, </span><span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">notnull(self) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        DataFrame.notnull is an alias for DataFrame.notna. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">~self.isna()</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">dropna(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">how: str = </span><span class="s4">&quot;any&quot;</span><span class="s2">,</span>
        <span class="s1">thresh=</span><span class="s2">None,</span>
        <span class="s1">subset: IndexLabel = </span><span class="s2">None,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Remove missing values. 
 
        See the :ref:`User Guide &lt;missing_data&gt;` for more on which values are 
        considered missing, and how to work with missing data. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            Determine if rows or columns which contain missing values are 
            removed. 
 
            * 0, or 'index' : Drop rows which contain missing values. 
            * 1, or 'columns' : Drop columns which contain missing value. 
 
            .. versionchanged:: 1.0.0 
 
               Pass tuple or list to drop on multiple axes. 
               Only a single axis is allowed. 
 
        how : {'any', 'all'}, default 'any' 
            Determine if row or column is removed from DataFrame, when we have 
            at least one NA or all NA. 
 
            * 'any' : If any NA values are present, drop that row or column. 
            * 'all' : If all values are NA, drop that row or column. 
 
        thresh : int, optional 
            Require that many non-NA values. 
        subset : column label or sequence of labels, optional 
            Labels along other axis to consider, e.g. if you are dropping rows 
            these would be a list of columns to include. 
        inplace : bool, default False 
            If True, do operation inplace and return None. 
 
        Returns 
        ------- 
        DataFrame or None 
            DataFrame with NA entries dropped from it or None if ``inplace=True``. 
 
        See Also 
        -------- 
        DataFrame.isna: Indicate missing values. 
        DataFrame.notna : Indicate existing (non-missing) values. 
        DataFrame.fillna : Replace missing values. 
        Series.dropna : Drop missing values. 
        Index.dropna : Drop missing indices. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;name&quot;: ['Alfred', 'Batman', 'Catwoman'], 
        ...                    &quot;toy&quot;: [np.nan, 'Batmobile', 'Bullwhip'], 
        ...                    &quot;born&quot;: [pd.NaT, pd.Timestamp(&quot;1940-04-25&quot;), 
        ...                             pd.NaT]}) 
        &gt;&gt;&gt; df 
               name        toy       born 
        0    Alfred        NaN        NaT 
        1    Batman  Batmobile 1940-04-25 
        2  Catwoman   Bullwhip        NaT 
 
        Drop the rows where at least one element is missing. 
 
        &gt;&gt;&gt; df.dropna() 
             name        toy       born 
        1  Batman  Batmobile 1940-04-25 
 
        Drop the columns where at least one element is missing. 
 
        &gt;&gt;&gt; df.dropna(axis='columns') 
               name 
        0    Alfred 
        1    Batman 
        2  Catwoman 
 
        Drop the rows where all elements are missing. 
 
        &gt;&gt;&gt; df.dropna(how='all') 
               name        toy       born 
        0    Alfred        NaN        NaT 
        1    Batman  Batmobile 1940-04-25 
        2  Catwoman   Bullwhip        NaT 
 
        Keep only the rows with at least 2 non-NA values. 
 
        &gt;&gt;&gt; df.dropna(thresh=2) 
               name        toy       born 
        1    Batman  Batmobile 1940-04-25 
        2  Catwoman   Bullwhip        NaT 
 
        Define in which columns to look for missing values. 
 
        &gt;&gt;&gt; df.dropna(subset=['name', 'toy']) 
               name        toy       born 
        1    Batman  Batmobile 1940-04-25 
        2  Catwoman   Bullwhip        NaT 
 
        Keep the DataFrame with valid entries in the same variable. 
 
        &gt;&gt;&gt; df.dropna(inplace=True) 
        &gt;&gt;&gt; df 
             name        toy       born 
        1  Batman  Batmobile 1940-04-25 
        &quot;&quot;&quot;</span>
        <span class="s1">inplace = validate_bool_kwarg(inplace</span><span class="s2">, </span><span class="s4">&quot;inplace&quot;</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">isinstance(axis</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)):</span>
            <span class="s3"># GH20987</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;supplying multiple axes to axis is no longer supported.&quot;</span><span class="s1">)</span>

        <span class="s1">axis = self._get_axis_number(axis)</span>
        <span class="s1">agg_axis = </span><span class="s5">1 </span><span class="s1">- axis</span>

        <span class="s1">agg_obj = self</span>
        <span class="s2">if </span><span class="s1">subset </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s3"># subset needs to be list</span>
            <span class="s2">if not </span><span class="s1">is_list_like(subset):</span>
                <span class="s1">subset = [subset]</span>
            <span class="s1">ax = self._get_axis(agg_axis)</span>
            <span class="s1">indices = ax.get_indexer_for(subset)</span>
            <span class="s1">check = indices == -</span><span class="s5">1</span>
            <span class="s2">if </span><span class="s1">check.any():</span>
                <span class="s2">raise </span><span class="s1">KeyError(np.array(subset)[check].tolist())</span>
            <span class="s1">agg_obj = self.take(indices</span><span class="s2">, </span><span class="s1">axis=agg_axis)</span>

        <span class="s2">if </span><span class="s1">thresh </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">count = agg_obj.count(axis=agg_axis)</span>
            <span class="s1">mask = count &gt;= thresh</span>
        <span class="s2">elif </span><span class="s1">how == </span><span class="s4">&quot;any&quot;</span><span class="s1">:</span>
            <span class="s3"># faster equivalent to 'agg_obj.count(agg_axis) == self.shape[agg_axis]'</span>
            <span class="s1">mask = notna(agg_obj).all(axis=agg_axis</span><span class="s2">, </span><span class="s1">bool_only=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">how == </span><span class="s4">&quot;all&quot;</span><span class="s1">:</span>
            <span class="s3"># faster equivalent to 'agg_obj.count(agg_axis) &gt; 0'</span>
            <span class="s1">mask = notna(agg_obj).any(axis=agg_axis</span><span class="s2">, </span><span class="s1">bool_only=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">how </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;invalid how option: </span><span class="s2">{</span><span class="s1">how</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;must specify how or thresh&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">np.all(mask):</span>
            <span class="s1">result = self.copy()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = self.loc(axis=axis)[mask]</span>

        <span class="s2">if </span><span class="s1">inplace:</span>
            <span class="s1">self._update_inplace(result)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;subset&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">drop_duplicates(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">subset: Hashable | Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">keep: Literal[</span><span class="s4">&quot;first&quot;</span><span class="s1">] | Literal[</span><span class="s4">&quot;last&quot;</span><span class="s1">] | Literal[</span><span class="s2">False</span><span class="s1">] = </span><span class="s4">&quot;first&quot;</span><span class="s2">,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">ignore_index: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return DataFrame with duplicate rows removed. 
 
        Considering certain columns is optional. Indexes, including time indexes 
        are ignored. 
 
        Parameters 
        ---------- 
        subset : column label or sequence of labels, optional 
            Only consider certain columns for identifying duplicates, by 
            default use all of the columns. 
        keep : {'first', 'last', False}, default 'first' 
            Determines which duplicates (if any) to keep. 
            - ``first`` : Drop duplicates except for the first occurrence. 
            - ``last`` : Drop duplicates except for the last occurrence. 
            - False : Drop all duplicates. 
        inplace : bool, default False 
            Whether to drop duplicates in place or to return a copy. 
        ignore_index : bool, default False 
            If True, the resulting axis will be labeled 0, 1, , n - 1. 
 
            .. versionadded:: 1.0.0 
 
        Returns 
        ------- 
        DataFrame or None 
            DataFrame with duplicates removed or None if ``inplace=True``. 
 
        See Also 
        -------- 
        DataFrame.value_counts: Count unique combinations of columns. 
 
        Examples 
        -------- 
        Consider dataset containing ramen rating. 
 
        &gt;&gt;&gt; df = pd.DataFrame({ 
        ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'], 
        ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'], 
        ...     'rating': [4, 4, 3.5, 15, 5] 
        ... }) 
        &gt;&gt;&gt; df 
            brand style  rating 
        0  Yum Yum   cup     4.0 
        1  Yum Yum   cup     4.0 
        2  Indomie   cup     3.5 
        3  Indomie  pack    15.0 
        4  Indomie  pack     5.0 
 
        By default, it removes duplicate rows based on all columns. 
 
        &gt;&gt;&gt; df.drop_duplicates() 
            brand style  rating 
        0  Yum Yum   cup     4.0 
        2  Indomie   cup     3.5 
        3  Indomie  pack    15.0 
        4  Indomie  pack     5.0 
 
        To remove duplicates on specific column(s), use ``subset``. 
 
        &gt;&gt;&gt; df.drop_duplicates(subset=['brand']) 
            brand style  rating 
        0  Yum Yum   cup     4.0 
        2  Indomie   cup     3.5 
 
        To remove duplicates and keep last occurrences, use ``keep``. 
 
        &gt;&gt;&gt; df.drop_duplicates(subset=['brand', 'style'], keep='last') 
            brand style  rating 
        1  Yum Yum   cup     4.0 
        2  Indomie   cup     3.5 
        4  Indomie  pack     5.0 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.empty:</span>
            <span class="s2">return </span><span class="s1">self.copy()</span>

        <span class="s1">inplace = validate_bool_kwarg(inplace</span><span class="s2">, </span><span class="s4">&quot;inplace&quot;</span><span class="s1">)</span>
        <span class="s1">ignore_index = validate_bool_kwarg(ignore_index</span><span class="s2">, </span><span class="s4">&quot;ignore_index&quot;</span><span class="s1">)</span>
        <span class="s1">duplicated = self.duplicated(subset</span><span class="s2">, </span><span class="s1">keep=keep)</span>

        <span class="s1">result = self[-duplicated]</span>
        <span class="s2">if </span><span class="s1">ignore_index:</span>
            <span class="s1">result.index = default_index(len(result))</span>

        <span class="s2">if </span><span class="s1">inplace:</span>
            <span class="s1">self._update_inplace(result)</span>
            <span class="s2">return None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">duplicated(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">subset: Hashable | Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">keep: Literal[</span><span class="s4">&quot;first&quot;</span><span class="s1">] | Literal[</span><span class="s4">&quot;last&quot;</span><span class="s1">] | Literal[</span><span class="s2">False</span><span class="s1">] = </span><span class="s4">&quot;first&quot;</span><span class="s2">,</span>
    <span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return boolean Series denoting duplicate rows. 
 
        Considering certain columns is optional. 
 
        Parameters 
        ---------- 
        subset : column label or sequence of labels, optional 
            Only consider certain columns for identifying duplicates, by 
            default use all of the columns. 
        keep : {'first', 'last', False}, default 'first' 
            Determines which duplicates (if any) to mark. 
 
            - ``first`` : Mark duplicates as ``True`` except for the first occurrence. 
            - ``last`` : Mark duplicates as ``True`` except for the last occurrence. 
            - False : Mark all duplicates as ``True``. 
 
        Returns 
        ------- 
        Series 
            Boolean series for each duplicated rows. 
 
        See Also 
        -------- 
        Index.duplicated : Equivalent method on index. 
        Series.duplicated : Equivalent method on Series. 
        Series.drop_duplicates : Remove duplicate values from Series. 
        DataFrame.drop_duplicates : Remove duplicate values from DataFrame. 
 
        Examples 
        -------- 
        Consider dataset containing ramen rating. 
 
        &gt;&gt;&gt; df = pd.DataFrame({ 
        ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'], 
        ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'], 
        ...     'rating': [4, 4, 3.5, 15, 5] 
        ... }) 
        &gt;&gt;&gt; df 
            brand style  rating 
        0  Yum Yum   cup     4.0 
        1  Yum Yum   cup     4.0 
        2  Indomie   cup     3.5 
        3  Indomie  pack    15.0 
        4  Indomie  pack     5.0 
 
        By default, for each set of duplicated values, the first occurrence 
        is set on False and all others on True. 
 
        &gt;&gt;&gt; df.duplicated() 
        0    False 
        1     True 
        2    False 
        3    False 
        4    False 
        dtype: bool 
 
        By using 'last', the last occurrence of each set of duplicated values 
        is set on False and all others on True. 
 
        &gt;&gt;&gt; df.duplicated(keep='last') 
        0     True 
        1    False 
        2    False 
        3    False 
        4    False 
        dtype: bool 
 
        By setting ``keep`` on False, all duplicates are True. 
 
        &gt;&gt;&gt; df.duplicated(keep=False) 
        0     True 
        1     True 
        2    False 
        3    False 
        4    False 
        dtype: bool 
 
        To find duplicates on specific column(s), use ``subset``. 
 
        &gt;&gt;&gt; df.duplicated(subset=['brand']) 
        0    False 
        1     True 
        2    False 
        3     True 
        4     True 
        dtype: bool 
        &quot;&quot;&quot;</span>

        <span class="s2">if </span><span class="s1">self.empty:</span>
            <span class="s2">return </span><span class="s1">self._constructor_sliced(dtype=bool)</span>

        <span class="s2">def </span><span class="s1">f(vals) -&gt; tuple[np.ndarray</span><span class="s2">, </span><span class="s1">int]:</span>
            <span class="s1">labels</span><span class="s2">, </span><span class="s1">shape = algorithms.factorize(vals</span><span class="s2">, </span><span class="s1">size_hint=len(self))</span>
            <span class="s2">return </span><span class="s1">labels.astype(</span><span class="s4">&quot;i8&quot;</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span><span class="s2">, </span><span class="s1">len(shape)</span>

        <span class="s2">if </span><span class="s1">subset </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s3"># https://github.com/pandas-dev/pandas/issues/28770</span>
            <span class="s3"># Incompatible types in assignment (expression has type &quot;Index&quot;, variable</span>
            <span class="s3"># has type &quot;Sequence[Any]&quot;)</span>
            <span class="s1">subset = self.columns  </span><span class="s3"># type: ignore[assignment]</span>
        <span class="s2">elif </span><span class="s1">(</span>
            <span class="s2">not </span><span class="s1">np.iterable(subset)</span>
            <span class="s2">or </span><span class="s1">isinstance(subset</span><span class="s2">, </span><span class="s1">str)</span>
            <span class="s2">or </span><span class="s1">isinstance(subset</span><span class="s2">, </span><span class="s1">tuple)</span>
            <span class="s2">and </span><span class="s1">subset </span><span class="s2">in </span><span class="s1">self.columns</span>
        <span class="s1">):</span>
            <span class="s1">subset = (subset</span><span class="s2">,</span><span class="s1">)</span>

        <span class="s3">#  needed for mypy since can't narrow types using np.iterable</span>
        <span class="s1">subset = cast(Sequence</span><span class="s2">, </span><span class="s1">subset)</span>

        <span class="s3"># Verify all columns in subset exist in the queried dataframe</span>
        <span class="s3"># Otherwise, raise a KeyError, same as if you try to __getitem__ with a</span>
        <span class="s3"># key that doesn't exist.</span>
        <span class="s1">diff = Index(subset).difference(self.columns)</span>
        <span class="s2">if not </span><span class="s1">diff.empty:</span>
            <span class="s2">raise </span><span class="s1">KeyError(diff)</span>

        <span class="s1">vals = (col.values </span><span class="s2">for </span><span class="s1">name</span><span class="s2">, </span><span class="s1">col </span><span class="s2">in </span><span class="s1">self.items() </span><span class="s2">if </span><span class="s1">name </span><span class="s2">in </span><span class="s1">subset)</span>
        <span class="s1">labels</span><span class="s2">, </span><span class="s1">shape = map(list</span><span class="s2">, </span><span class="s1">zip(*map(f</span><span class="s2">, </span><span class="s1">vals)))</span>

        <span class="s1">ids = get_group_index(</span>
            <span class="s1">labels</span><span class="s2">,</span>
            <span class="s3"># error: Argument 1 to &quot;tuple&quot; has incompatible type &quot;List[_T]&quot;;</span>
            <span class="s3"># expected &quot;Iterable[int]&quot;</span>
            <span class="s1">tuple(shape)</span><span class="s2">,  </span><span class="s3"># type: ignore[arg-type]</span>
            <span class="s1">sort=</span><span class="s2">False,</span>
            <span class="s1">xnull=</span><span class="s2">False,</span>
        <span class="s1">)</span>
        <span class="s1">result = self._constructor_sliced(duplicated(ids</span><span class="s2">, </span><span class="s1">keep)</span><span class="s2">, </span><span class="s1">index=self.index)</span>
        <span class="s2">return </span><span class="s1">result.__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;duplicated&quot;</span><span class="s1">)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Sorting</span>
    <span class="s3"># TODO: Just move the sort_values doc here.</span>
    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;by&quot;</span><span class="s1">])</span>
    <span class="s1">@Substitution(**_shared_doc_kwargs)</span>
    <span class="s1">@Appender(NDFrame.sort_values.__doc__)</span>
    <span class="s3"># error: Signature of &quot;sort_values&quot; incompatible with supertype &quot;NDFrame&quot;</span>
    <span class="s2">def </span><span class="s1">sort_values(  </span><span class="s3"># type: ignore[override]</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">by</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">ascending=</span><span class="s2">True,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">kind: str = </span><span class="s4">&quot;quicksort&quot;</span><span class="s2">,</span>
        <span class="s1">na_position: str = </span><span class="s4">&quot;last&quot;</span><span class="s2">,</span>
        <span class="s1">ignore_index: bool = </span><span class="s2">False,</span>
        <span class="s1">key: ValueKeyFunc = </span><span class="s2">None,</span>
    <span class="s1">):</span>
        <span class="s1">inplace = validate_bool_kwarg(inplace</span><span class="s2">, </span><span class="s4">&quot;inplace&quot;</span><span class="s1">)</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>
        <span class="s1">ascending = validate_ascending(ascending)</span>
        <span class="s2">if not </span><span class="s1">isinstance(by</span><span class="s2">, </span><span class="s1">list):</span>
            <span class="s1">by = [by]</span>
        <span class="s2">if </span><span class="s1">is_sequence(ascending) </span><span class="s2">and </span><span class="s1">len(by) != len(ascending):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">f&quot;Length of ascending (</span><span class="s2">{</span><span class="s1">len(ascending)</span><span class="s2">}</span><span class="s4">) != length of by (</span><span class="s2">{</span><span class="s1">len(by)</span><span class="s2">}</span><span class="s4">)&quot;</span>
            <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">len(by) &gt; </span><span class="s5">1</span><span class="s1">:</span>

            <span class="s1">keys = [self._get_label_or_level_values(x</span><span class="s2">, </span><span class="s1">axis=axis) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">by]</span>

            <span class="s3"># need to rewrap columns in Series to apply key function</span>
            <span class="s2">if </span><span class="s1">key </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s3"># error: List comprehension has incompatible type List[Series];</span>
                <span class="s3"># expected List[ndarray]</span>
                <span class="s1">keys = [</span>
                    <span class="s1">Series(k</span><span class="s2">, </span><span class="s1">name=name)  </span><span class="s3"># type: ignore[misc]</span>
                    <span class="s2">for </span><span class="s1">(k</span><span class="s2">, </span><span class="s1">name) </span><span class="s2">in </span><span class="s1">zip(keys</span><span class="s2">, </span><span class="s1">by)</span>
                <span class="s1">]</span>

            <span class="s1">indexer = lexsort_indexer(</span>
                <span class="s1">keys</span><span class="s2">, </span><span class="s1">orders=ascending</span><span class="s2">, </span><span class="s1">na_position=na_position</span><span class="s2">, </span><span class="s1">key=key</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">len(by):</span>
            <span class="s3"># len(by) == 1</span>

            <span class="s1">by = by[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">k = self._get_label_or_level_values(by</span><span class="s2">, </span><span class="s1">axis=axis)</span>

            <span class="s3"># need to rewrap column in Series to apply key function</span>
            <span class="s2">if </span><span class="s1">key </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s3"># error: Incompatible types in assignment (expression has type</span>
                <span class="s3"># &quot;Series&quot;, variable has type &quot;ndarray&quot;)</span>
                <span class="s1">k = Series(k</span><span class="s2">, </span><span class="s1">name=by)  </span><span class="s3"># type: ignore[assignment]</span>

            <span class="s2">if </span><span class="s1">isinstance(ascending</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)):</span>
                <span class="s1">ascending = ascending[</span><span class="s5">0</span><span class="s1">]</span>

            <span class="s1">indexer = nargsort(</span>
                <span class="s1">k</span><span class="s2">, </span><span class="s1">kind=kind</span><span class="s2">, </span><span class="s1">ascending=ascending</span><span class="s2">, </span><span class="s1">na_position=na_position</span><span class="s2">, </span><span class="s1">key=key</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.copy()</span>

        <span class="s1">new_data = self._mgr.take(</span>
            <span class="s1">indexer</span><span class="s2">, </span><span class="s1">axis=self._get_block_manager_axis(axis)</span><span class="s2">, </span><span class="s1">verify=</span><span class="s2">False</span>
        <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">ignore_index:</span>
            <span class="s1">new_data.set_axis(</span>
                <span class="s1">self._get_block_manager_axis(axis)</span><span class="s2">, </span><span class="s1">default_index(len(indexer))</span>
            <span class="s1">)</span>

        <span class="s1">result = self._constructor(new_data)</span>
        <span class="s2">if </span><span class="s1">inplace:</span>
            <span class="s2">return </span><span class="s1">self._update_inplace(result)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">result.__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;sort_values&quot;</span><span class="s1">)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">sort_index(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">level: Level | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">ascending: bool | int | Sequence[bool | int] = </span><span class="s2">True,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">kind: str = </span><span class="s4">&quot;quicksort&quot;</span><span class="s2">,</span>
        <span class="s1">na_position: str = </span><span class="s4">&quot;last&quot;</span><span class="s2">,</span>
        <span class="s1">sort_remaining: bool = </span><span class="s2">True,</span>
        <span class="s1">ignore_index: bool = </span><span class="s2">False,</span>
        <span class="s1">key: IndexKeyFunc = </span><span class="s2">None,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Sort object by labels (along an axis). 
 
        Returns a new DataFrame sorted by label if `inplace` argument is 
        ``False``, otherwise updates the original DataFrame and returns None. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis along which to sort.  The value 0 identifies the rows, 
            and 1 identifies the columns. 
        level : int or level name or list of ints or list of level names 
            If not None, sort on values in specified index level(s). 
        ascending : bool or list-like of bools, default True 
            Sort ascending vs. descending. When the index is a MultiIndex the 
            sort direction can be controlled for each level individually. 
        inplace : bool, default False 
            If True, perform operation in-place. 
        kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort' 
            Choice of sorting algorithm. See also :func:`numpy.sort` for more 
            information. `mergesort` and `stable` are the only stable algorithms. For 
            DataFrames, this option is only applied when sorting on a single 
            column or label. 
        na_position : {'first', 'last'}, default 'last' 
            Puts NaNs at the beginning if `first`; `last` puts NaNs at the end. 
            Not implemented for MultiIndex. 
        sort_remaining : bool, default True 
            If True and sorting by level and index is multilevel, sort by other 
            levels too (in order) after sorting by specified level. 
        ignore_index : bool, default False 
            If True, the resulting axis will be labeled 0, 1, , n - 1. 
 
            .. versionadded:: 1.0.0 
 
        key : callable, optional 
            If not None, apply the key function to the index values 
            before sorting. This is similar to the `key` argument in the 
            builtin :meth:`sorted` function, with the notable difference that 
            this `key` function should be *vectorized*. It should expect an 
            ``Index`` and return an ``Index`` of the same shape. For MultiIndex 
            inputs, the key is applied *per level*. 
 
            .. versionadded:: 1.1.0 
 
        Returns 
        ------- 
        DataFrame or None 
            The original DataFrame sorted by the labels or None if ``inplace=True``. 
 
        See Also 
        -------- 
        Series.sort_index : Sort Series by the index. 
        DataFrame.sort_values : Sort DataFrame by the value. 
        Series.sort_values : Sort Series by the value. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150], 
        ...                   columns=['A']) 
        &gt;&gt;&gt; df.sort_index() 
             A 
        1    4 
        29   2 
        100  1 
        150  5 
        234  3 
 
        By default, it sorts in ascending order, to sort in descending order, 
        use ``ascending=False`` 
 
        &gt;&gt;&gt; df.sort_index(ascending=False) 
             A 
        234  3 
        150  5 
        100  1 
        29   2 
        1    4 
 
        A key function can be specified which is applied to the index before 
        sorting. For a ``MultiIndex`` this is applied to each level separately. 
 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;a&quot;: [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd']) 
        &gt;&gt;&gt; df.sort_index(key=lambda x: x.str.lower()) 
           a 
        A  1 
        b  2 
        C  3 
        d  4 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">super().sort_index(</span>
            <span class="s1">axis</span><span class="s2">,</span>
            <span class="s1">level</span><span class="s2">,</span>
            <span class="s1">ascending</span><span class="s2">,</span>
            <span class="s1">inplace</span><span class="s2">,</span>
            <span class="s1">kind</span><span class="s2">,</span>
            <span class="s1">na_position</span><span class="s2">,</span>
            <span class="s1">sort_remaining</span><span class="s2">,</span>
            <span class="s1">ignore_index</span><span class="s2">,</span>
            <span class="s1">key</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">value_counts(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">subset: Sequence[Hashable] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">normalize: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">True,</span>
        <span class="s1">ascending: bool = </span><span class="s2">False,</span>
        <span class="s1">dropna: bool = </span><span class="s2">True,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a Series containing counts of unique rows in the DataFrame. 
 
        .. versionadded:: 1.1.0 
 
        Parameters 
        ---------- 
        subset : list-like, optional 
            Columns to use when counting unique combinations. 
        normalize : bool, default False 
            Return proportions rather than frequencies. 
        sort : bool, default True 
            Sort by frequencies. 
        ascending : bool, default False 
            Sort in ascending order. 
        dropna : bool, default True 
            Dont include counts of rows that contain NA values. 
 
            .. versionadded:: 1.3.0 
 
        Returns 
        ------- 
        Series 
 
        See Also 
        -------- 
        Series.value_counts: Equivalent method on Series. 
 
        Notes 
        ----- 
        The returned Series will have a MultiIndex with one level per input 
        column. By default, rows that contain any NA values are omitted from 
        the result. By default, the resulting Series will be in descending 
        order so that the first element is the most frequently-occurring row. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'num_legs': [2, 4, 4, 6], 
        ...                    'num_wings': [2, 0, 0, 0]}, 
        ...                   index=['falcon', 'dog', 'cat', 'ant']) 
        &gt;&gt;&gt; df 
                num_legs  num_wings 
        falcon         2          2 
        dog            4          0 
        cat            4          0 
        ant            6          0 
 
        &gt;&gt;&gt; df.value_counts() 
        num_legs  num_wings 
        4         0            2 
        2         2            1 
        6         0            1 
        dtype: int64 
 
        &gt;&gt;&gt; df.value_counts(sort=False) 
        num_legs  num_wings 
        2         2            1 
        4         0            2 
        6         0            1 
        dtype: int64 
 
        &gt;&gt;&gt; df.value_counts(ascending=True) 
        num_legs  num_wings 
        2         2            1 
        6         0            1 
        4         0            2 
        dtype: int64 
 
        &gt;&gt;&gt; df.value_counts(normalize=True) 
        num_legs  num_wings 
        4         0            0.50 
        2         2            0.25 
        6         0            0.25 
        dtype: float64 
 
        With `dropna` set to `False` we can also count rows with NA values. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'], 
        ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']}) 
        &gt;&gt;&gt; df 
          first_name middle_name 
        0       John       Smith 
        1       Anne        &lt;NA&gt; 
        2       John        &lt;NA&gt; 
        3       Beth      Louise 
 
        &gt;&gt;&gt; df.value_counts() 
        first_name  middle_name 
        Beth        Louise         1 
        John        Smith          1 
        dtype: int64 
 
        &gt;&gt;&gt; df.value_counts(dropna=False) 
        first_name  middle_name 
        Anne        NaN            1 
        Beth        Louise         1 
        John        Smith          1 
                    NaN            1 
        dtype: int64 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">subset </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">subset = self.columns.tolist()</span>

        <span class="s1">counts = self.groupby(subset</span><span class="s2">, </span><span class="s1">dropna=dropna).grouper.size()</span>

        <span class="s2">if </span><span class="s1">sort:</span>
            <span class="s1">counts = counts.sort_values(ascending=ascending)</span>
        <span class="s2">if </span><span class="s1">normalize:</span>
            <span class="s1">counts /= counts.sum()</span>

        <span class="s3"># Force MultiIndex for single column</span>
        <span class="s2">if </span><span class="s1">len(subset) == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">counts.index = MultiIndex.from_arrays(</span>
                <span class="s1">[counts.index]</span><span class="s2">, </span><span class="s1">names=[counts.index.name]</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">counts</span>

    <span class="s2">def </span><span class="s1">nlargest(self</span><span class="s2">, </span><span class="s1">n: int</span><span class="s2">, </span><span class="s1">columns: IndexLabel</span><span class="s2">, </span><span class="s1">keep: str = </span><span class="s4">&quot;first&quot;</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the first `n` rows ordered by `columns` in descending order. 
 
        Return the first `n` rows with the largest values in `columns`, in 
        descending order. The columns that are not specified are returned as 
        well, but not used for ordering. 
 
        This method is equivalent to 
        ``df.sort_values(columns, ascending=False).head(n)``, but more 
        performant. 
 
        Parameters 
        ---------- 
        n : int 
            Number of rows to return. 
        columns : label or list of labels 
            Column label(s) to order by. 
        keep : {'first', 'last', 'all'}, default 'first' 
            Where there are duplicate values: 
 
            - ``first`` : prioritize the first occurrence(s) 
            - ``last`` : prioritize the last occurrence(s) 
            - ``all`` : do not drop any duplicates, even it means 
              selecting more than `n` items. 
 
        Returns 
        ------- 
        DataFrame 
            The first `n` rows ordered by the given columns in descending 
            order. 
 
        See Also 
        -------- 
        DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in 
            ascending order. 
        DataFrame.sort_values : Sort DataFrame by the values. 
        DataFrame.head : Return the first `n` rows without re-ordering. 
 
        Notes 
        ----- 
        This function cannot be used with all column types. For example, when 
        specifying columns with `object` or `category` dtypes, ``TypeError`` is 
        raised. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'population': [59000000, 65000000, 434000, 
        ...                                   434000, 434000, 337000, 11300, 
        ...                                   11300, 11300], 
        ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128, 
        ...                            17036, 182, 38, 311], 
        ...                    'alpha-2': [&quot;IT&quot;, &quot;FR&quot;, &quot;MT&quot;, &quot;MV&quot;, &quot;BN&quot;, 
        ...                                &quot;IS&quot;, &quot;NR&quot;, &quot;TV&quot;, &quot;AI&quot;]}, 
        ...                   index=[&quot;Italy&quot;, &quot;France&quot;, &quot;Malta&quot;, 
        ...                          &quot;Maldives&quot;, &quot;Brunei&quot;, &quot;Iceland&quot;, 
        ...                          &quot;Nauru&quot;, &quot;Tuvalu&quot;, &quot;Anguilla&quot;]) 
        &gt;&gt;&gt; df 
                  population      GDP alpha-2 
        Italy       59000000  1937894      IT 
        France      65000000  2583560      FR 
        Malta         434000    12011      MT 
        Maldives      434000     4520      MV 
        Brunei        434000    12128      BN 
        Iceland       337000    17036      IS 
        Nauru          11300      182      NR 
        Tuvalu         11300       38      TV 
        Anguilla       11300      311      AI 
 
        In the following example, we will use ``nlargest`` to select the three 
        rows having the largest values in column &quot;population&quot;. 
 
        &gt;&gt;&gt; df.nlargest(3, 'population') 
                population      GDP alpha-2 
        France    65000000  2583560      FR 
        Italy     59000000  1937894      IT 
        Malta       434000    12011      MT 
 
        When using ``keep='last'``, ties are resolved in reverse order: 
 
        &gt;&gt;&gt; df.nlargest(3, 'population', keep='last') 
                population      GDP alpha-2 
        France    65000000  2583560      FR 
        Italy     59000000  1937894      IT 
        Brunei      434000    12128      BN 
 
        When using ``keep='all'``, all duplicate items are maintained: 
 
        &gt;&gt;&gt; df.nlargest(3, 'population', keep='all') 
                  population      GDP alpha-2 
        France      65000000  2583560      FR 
        Italy       59000000  1937894      IT 
        Malta         434000    12011      MT 
        Maldives      434000     4520      MV 
        Brunei        434000    12128      BN 
 
        To order by the largest values in column &quot;population&quot; and then &quot;GDP&quot;, 
        we can specify multiple columns like in the next example. 
 
        &gt;&gt;&gt; df.nlargest(3, ['population', 'GDP']) 
                population      GDP alpha-2 
        France    65000000  2583560      FR 
        Italy     59000000  1937894      IT 
        Brunei      434000    12128      BN 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">algorithms.SelectNFrame(self</span><span class="s2">, </span><span class="s1">n=n</span><span class="s2">, </span><span class="s1">keep=keep</span><span class="s2">, </span><span class="s1">columns=columns).nlargest()</span>

    <span class="s2">def </span><span class="s1">nsmallest(self</span><span class="s2">, </span><span class="s1">n: int</span><span class="s2">, </span><span class="s1">columns: IndexLabel</span><span class="s2">, </span><span class="s1">keep: str = </span><span class="s4">&quot;first&quot;</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return the first `n` rows ordered by `columns` in ascending order. 
 
        Return the first `n` rows with the smallest values in `columns`, in 
        ascending order. The columns that are not specified are returned as 
        well, but not used for ordering. 
 
        This method is equivalent to 
        ``df.sort_values(columns, ascending=True).head(n)``, but more 
        performant. 
 
        Parameters 
        ---------- 
        n : int 
            Number of items to retrieve. 
        columns : list or str 
            Column name or names to order by. 
        keep : {'first', 'last', 'all'}, default 'first' 
            Where there are duplicate values: 
 
            - ``first`` : take the first occurrence. 
            - ``last`` : take the last occurrence. 
            - ``all`` : do not drop any duplicates, even it means 
              selecting more than `n` items. 
 
        Returns 
        ------- 
        DataFrame 
 
        See Also 
        -------- 
        DataFrame.nlargest : Return the first `n` rows ordered by `columns` in 
            descending order. 
        DataFrame.sort_values : Sort DataFrame by the values. 
        DataFrame.head : Return the first `n` rows without re-ordering. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'population': [59000000, 65000000, 434000, 
        ...                                   434000, 434000, 337000, 337000, 
        ...                                   11300, 11300], 
        ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128, 
        ...                            17036, 182, 38, 311], 
        ...                    'alpha-2': [&quot;IT&quot;, &quot;FR&quot;, &quot;MT&quot;, &quot;MV&quot;, &quot;BN&quot;, 
        ...                                &quot;IS&quot;, &quot;NR&quot;, &quot;TV&quot;, &quot;AI&quot;]}, 
        ...                   index=[&quot;Italy&quot;, &quot;France&quot;, &quot;Malta&quot;, 
        ...                          &quot;Maldives&quot;, &quot;Brunei&quot;, &quot;Iceland&quot;, 
        ...                          &quot;Nauru&quot;, &quot;Tuvalu&quot;, &quot;Anguilla&quot;]) 
        &gt;&gt;&gt; df 
                  population      GDP alpha-2 
        Italy       59000000  1937894      IT 
        France      65000000  2583560      FR 
        Malta         434000    12011      MT 
        Maldives      434000     4520      MV 
        Brunei        434000    12128      BN 
        Iceland       337000    17036      IS 
        Nauru         337000      182      NR 
        Tuvalu         11300       38      TV 
        Anguilla       11300      311      AI 
 
        In the following example, we will use ``nsmallest`` to select the 
        three rows having the smallest values in column &quot;population&quot;. 
 
        &gt;&gt;&gt; df.nsmallest(3, 'population') 
                  population    GDP alpha-2 
        Tuvalu         11300     38      TV 
        Anguilla       11300    311      AI 
        Iceland       337000  17036      IS 
 
        When using ``keep='last'``, ties are resolved in reverse order: 
 
        &gt;&gt;&gt; df.nsmallest(3, 'population', keep='last') 
                  population  GDP alpha-2 
        Anguilla       11300  311      AI 
        Tuvalu         11300   38      TV 
        Nauru         337000  182      NR 
 
        When using ``keep='all'``, all duplicate items are maintained: 
 
        &gt;&gt;&gt; df.nsmallest(3, 'population', keep='all') 
                  population    GDP alpha-2 
        Tuvalu         11300     38      TV 
        Anguilla       11300    311      AI 
        Iceland       337000  17036      IS 
        Nauru         337000    182      NR 
 
        To order by the smallest values in column &quot;population&quot; and then &quot;GDP&quot;, we can 
        specify multiple columns like in the next example. 
 
        &gt;&gt;&gt; df.nsmallest(3, ['population', 'GDP']) 
                  population  GDP alpha-2 
        Tuvalu         11300   38      TV 
        Anguilla       11300  311      AI 
        Nauru         337000  182      NR 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">algorithms.SelectNFrame(</span>
            <span class="s1">self</span><span class="s2">, </span><span class="s1">n=n</span><span class="s2">, </span><span class="s1">keep=keep</span><span class="s2">, </span><span class="s1">columns=columns</span>
        <span class="s1">).nsmallest()</span>

    <span class="s1">@doc(</span>
        <span class="s1">Series.swaplevel</span><span class="s2">,</span>
        <span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">extra_params=dedent(</span>
            <span class="s4">&quot;&quot;&quot;axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to swap levels on. 0 or 'index' for row-wise, 1 or 
            'columns' for column-wise.&quot;&quot;&quot;</span>
        <span class="s1">)</span><span class="s2">,</span>
        <span class="s1">examples=dedent(</span>
            <span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
        </span><span class="s4">Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame( 
        ...     {&quot;Grade&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;]}, 
        ...     index=[ 
        ...         [&quot;Final exam&quot;, &quot;Final exam&quot;, &quot;Coursework&quot;, &quot;Coursework&quot;], 
        ...         [&quot;History&quot;, &quot;Geography&quot;, &quot;History&quot;, &quot;Geography&quot;], 
        ...         [&quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;], 
        ...     ], 
        ... ) 
        &gt;&gt;&gt; df 
                                            Grade 
        Final exam  History     January      A 
                    Geography   February     B 
        Coursework  History     March        A 
                    Geography   April        C 
 
        In the following example, we will swap the levels of the indices. 
        Here, we will swap the levels column-wise, but levels can be swapped row-wise 
        in a similar manner. Note that column-wise is the default behaviour. 
        By not supplying any arguments for i and j, we swap the last and second to 
        last indices. 
 
        &gt;&gt;&gt; df.swaplevel() 
                                            Grade 
        Final exam  January     History         A 
                    February    Geography       B 
        Coursework  March       History         A 
                    April       Geography       C 
 
        By supplying one argument, we can choose which index to swap the last 
        index with. We can for example swap the first index with the last one as 
        follows. 
 
        &gt;&gt;&gt; df.swaplevel(0) 
                                            Grade 
        January     History     Final exam      A 
        February    Geography   Final exam      B 
        March       History     Coursework      A 
        April       Geography   Coursework      C 
 
        We can also define explicitly which indices we want to swap by supplying values 
        for both i and j. Here, we for example swap the first and second indices. 
 
        &gt;&gt;&gt; df.swaplevel(0, 1) 
                                            Grade 
        History     Final exam  January         A 
        Geography   Final exam  February        B 
        History     Coursework  March           A 
        Geography   Coursework  April           C&quot;&quot;&quot;</span>
        <span class="s1">)</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">swaplevel(self</span><span class="s2">, </span><span class="s1">i: Axis = -</span><span class="s5">2</span><span class="s2">, </span><span class="s1">j: Axis = -</span><span class="s5">1</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">result = self.copy()</span>

        <span class="s1">axis = self._get_axis_number(axis)</span>

        <span class="s2">if not </span><span class="s1">isinstance(result._get_axis(axis)</span><span class="s2">, </span><span class="s1">MultiIndex):  </span><span class="s3"># pragma: no cover</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Can only swap levels on a hierarchical axis.&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">assert </span><span class="s1">isinstance(result.index</span><span class="s2">, </span><span class="s1">MultiIndex)</span>
            <span class="s1">result.index = result.index.swaplevel(i</span><span class="s2">, </span><span class="s1">j)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">assert </span><span class="s1">isinstance(result.columns</span><span class="s2">, </span><span class="s1">MultiIndex)</span>
            <span class="s1">result.columns = result.columns.swaplevel(i</span><span class="s2">, </span><span class="s1">j)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">reorder_levels(self</span><span class="s2">, </span><span class="s1">order: Sequence[Axis]</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Rearrange index levels using input order. May not drop or duplicate levels. 
 
        Parameters 
        ---------- 
        order : list of int or list of str 
            List representing new level order. Reference level by number 
            (position) or by key (label). 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            Where to reorder levels. 
 
        Returns 
        ------- 
        DataFrame 
 
        Examples 
        -------- 
        &gt;&gt;&gt; data = { 
        ...     &quot;class&quot;: [&quot;Mammals&quot;, &quot;Mammals&quot;, &quot;Reptiles&quot;], 
        ...     &quot;diet&quot;: [&quot;Omnivore&quot;, &quot;Carnivore&quot;, &quot;Carnivore&quot;], 
        ...     &quot;species&quot;: [&quot;Humans&quot;, &quot;Dogs&quot;, &quot;Snakes&quot;], 
        ... } 
        &gt;&gt;&gt; df = pd.DataFrame(data, columns=[&quot;class&quot;, &quot;diet&quot;, &quot;species&quot;]) 
        &gt;&gt;&gt; df = df.set_index([&quot;class&quot;, &quot;diet&quot;]) 
        &gt;&gt;&gt; df 
                                          species 
        class      diet 
        Mammals    Omnivore                Humans 
                   Carnivore                 Dogs 
        Reptiles   Carnivore               Snakes 
 
        Let's reorder the levels of the index: 
 
        &gt;&gt;&gt; df.reorder_levels([&quot;diet&quot;, &quot;class&quot;]) 
                                          species 
        diet      class 
        Omnivore  Mammals                  Humans 
        Carnivore Mammals                    Dogs 
                  Reptiles                 Snakes 
        &quot;&quot;&quot;</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>
        <span class="s2">if not </span><span class="s1">isinstance(self._get_axis(axis)</span><span class="s2">, </span><span class="s1">MultiIndex):  </span><span class="s3"># pragma: no cover</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Can only reorder levels on a hierarchical axis.&quot;</span><span class="s1">)</span>

        <span class="s1">result = self.copy()</span>

        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">assert </span><span class="s1">isinstance(result.index</span><span class="s2">, </span><span class="s1">MultiIndex)</span>
            <span class="s1">result.index = result.index.reorder_levels(order)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">assert </span><span class="s1">isinstance(result.columns</span><span class="s2">, </span><span class="s1">MultiIndex)</span>
            <span class="s1">result.columns = result.columns.reorder_levels(order)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Arithmetic Methods</span>

    <span class="s2">def </span><span class="s1">_cmp_method(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">op):</span>
        <span class="s1">axis = </span><span class="s5">1  </span><span class="s3"># only relevant for Series other case</span>

        <span class="s1">self</span><span class="s2">, </span><span class="s1">other = ops.align_method_FRAME(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">flex=</span><span class="s2">False, </span><span class="s1">level=</span><span class="s2">None</span><span class="s1">)</span>

        <span class="s3"># See GH#4537 for discussion of scalar op behavior</span>
        <span class="s1">new_data = self._dispatch_frame_op(other</span><span class="s2">, </span><span class="s1">op</span><span class="s2">, </span><span class="s1">axis=axis)</span>
        <span class="s2">return </span><span class="s1">self._construct_result(new_data)</span>

    <span class="s2">def </span><span class="s1">_arith_method(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">op):</span>
        <span class="s2">if </span><span class="s1">ops.should_reindex_frame_op(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">op</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s2">, None, None</span><span class="s1">):</span>
            <span class="s2">return </span><span class="s1">ops.frame_arith_method_with_reindex(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">op)</span>

        <span class="s1">axis = </span><span class="s5">1  </span><span class="s3"># only relevant for Series other case</span>
        <span class="s1">other = ops.maybe_prepare_scalar_for_op(other</span><span class="s2">, </span><span class="s1">(self.shape[axis]</span><span class="s2">,</span><span class="s1">))</span>

        <span class="s1">self</span><span class="s2">, </span><span class="s1">other = ops.align_method_FRAME(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">flex=</span><span class="s2">True, </span><span class="s1">level=</span><span class="s2">None</span><span class="s1">)</span>

        <span class="s1">new_data = self._dispatch_frame_op(other</span><span class="s2">, </span><span class="s1">op</span><span class="s2">, </span><span class="s1">axis=axis)</span>
        <span class="s2">return </span><span class="s1">self._construct_result(new_data)</span>

    <span class="s1">_logical_method = _arith_method</span>

    <span class="s2">def </span><span class="s1">_dispatch_frame_op(self</span><span class="s2">, </span><span class="s1">right</span><span class="s2">, </span><span class="s1">func: Callable</span><span class="s2">, </span><span class="s1">axis: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Evaluate the frame operation func(left, right) by evaluating 
        column-by-column, dispatching to the Series implementation. 
 
        Parameters 
        ---------- 
        right : scalar, Series, or DataFrame 
        func : arithmetic or comparison operator 
        axis : {None, 0, 1} 
 
        Returns 
        ------- 
        DataFrame 
        &quot;&quot;&quot;</span>
        <span class="s3"># Get the appropriate array-op to apply to each column/block's values.</span>
        <span class="s1">array_op = ops.get_array_op(func)</span>

        <span class="s1">right = lib.item_from_zerodim(right)</span>
        <span class="s2">if not </span><span class="s1">is_list_like(right):</span>
            <span class="s3"># i.e. scalar, faster than checking np.ndim(right) == 0</span>
            <span class="s2">with </span><span class="s1">np.errstate(all=</span><span class="s4">&quot;ignore&quot;</span><span class="s1">):</span>
                <span class="s1">bm = self._mgr.apply(array_op</span><span class="s2">, </span><span class="s1">right=right)</span>
            <span class="s2">return </span><span class="s1">self._constructor(bm)</span>

        <span class="s2">elif </span><span class="s1">isinstance(right</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">assert </span><span class="s1">self.index.equals(right.index)</span>
            <span class="s2">assert </span><span class="s1">self.columns.equals(right.columns)</span>
            <span class="s3"># TODO: The previous assertion `assert right._indexed_same(self)`</span>
            <span class="s3">#  fails in cases with empty columns reached via</span>
            <span class="s3">#  _frame_arith_method_with_reindex</span>

            <span class="s3"># TODO operate_blockwise expects a manager of the same type</span>
            <span class="s2">with </span><span class="s1">np.errstate(all=</span><span class="s4">&quot;ignore&quot;</span><span class="s1">):</span>
                <span class="s1">bm = self._mgr.operate_blockwise(</span>
                    <span class="s3"># error: Argument 1 to &quot;operate_blockwise&quot; of &quot;ArrayManager&quot; has</span>
                    <span class="s3"># incompatible type &quot;Union[ArrayManager, BlockManager]&quot;; expected</span>
                    <span class="s3"># &quot;ArrayManager&quot;</span>
                    <span class="s3"># error: Argument 1 to &quot;operate_blockwise&quot; of &quot;BlockManager&quot; has</span>
                    <span class="s3"># incompatible type &quot;Union[ArrayManager, BlockManager]&quot;; expected</span>
                    <span class="s3"># &quot;BlockManager&quot;</span>
                    <span class="s1">right._mgr</span><span class="s2">,  </span><span class="s3"># type: ignore[arg-type]</span>
                    <span class="s1">array_op</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">self._constructor(bm)</span>

        <span class="s2">elif </span><span class="s1">isinstance(right</span><span class="s2">, </span><span class="s1">Series) </span><span class="s2">and </span><span class="s1">axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s3"># axis=1 means we want to operate row-by-row</span>
            <span class="s2">assert </span><span class="s1">right.index.equals(self.columns)</span>

            <span class="s1">right = right._values</span>
            <span class="s3"># maybe_align_as_frame ensures we do not have an ndarray here</span>
            <span class="s2">assert not </span><span class="s1">isinstance(right</span><span class="s2">, </span><span class="s1">np.ndarray)</span>

            <span class="s2">with </span><span class="s1">np.errstate(all=</span><span class="s4">&quot;ignore&quot;</span><span class="s1">):</span>
                <span class="s1">arrays = [</span>
                    <span class="s1">array_op(_left</span><span class="s2">, </span><span class="s1">_right)</span>
                    <span class="s2">for </span><span class="s1">_left</span><span class="s2">, </span><span class="s1">_right </span><span class="s2">in </span><span class="s1">zip(self._iter_column_arrays()</span><span class="s2">, </span><span class="s1">right)</span>
                <span class="s1">]</span>

        <span class="s2">elif </span><span class="s1">isinstance(right</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s2">assert </span><span class="s1">right.index.equals(self.index)  </span><span class="s3"># Handle other cases later</span>
            <span class="s1">right = right._values</span>

            <span class="s2">with </span><span class="s1">np.errstate(all=</span><span class="s4">&quot;ignore&quot;</span><span class="s1">):</span>
                <span class="s1">arrays = [array_op(left</span><span class="s2">, </span><span class="s1">right) </span><span class="s2">for </span><span class="s1">left </span><span class="s2">in </span><span class="s1">self._iter_column_arrays()]</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># Remaining cases have less-obvious dispatch rules</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError(right)</span>

        <span class="s2">return </span><span class="s1">type(self)._from_arrays(</span>
            <span class="s1">arrays</span><span class="s2">, </span><span class="s1">self.columns</span><span class="s2">, </span><span class="s1">self.index</span><span class="s2">, </span><span class="s1">verify_integrity=</span><span class="s2">False</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_combine_frame(self</span><span class="s2">, </span><span class="s1">other: DataFrame</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s3"># at this point we have `self._indexed_same(other)`</span>

        <span class="s2">if </span><span class="s1">fill_value </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s3"># since _arith_op may be called in a loop, avoid function call</span>
            <span class="s3">#  overhead if possible by doing this check once</span>
            <span class="s1">_arith_op = func</span>

        <span class="s2">else</span><span class="s1">:</span>

            <span class="s2">def </span><span class="s1">_arith_op(left</span><span class="s2">, </span><span class="s1">right):</span>
                <span class="s3"># for the mixed_type case where we iterate over columns,</span>
                <span class="s3"># _arith_op(left, right) is equivalent to</span>
                <span class="s3"># left._binop(right, func, fill_value=fill_value)</span>
                <span class="s1">left</span><span class="s2">, </span><span class="s1">right = ops.fill_binop(left</span><span class="s2">, </span><span class="s1">right</span><span class="s2">, </span><span class="s1">fill_value)</span>
                <span class="s2">return </span><span class="s1">func(left</span><span class="s2">, </span><span class="s1">right)</span>

        <span class="s1">new_data = self._dispatch_frame_op(other</span><span class="s2">, </span><span class="s1">_arith_op)</span>
        <span class="s2">return </span><span class="s1">new_data</span>

    <span class="s2">def </span><span class="s1">_construct_result(self</span><span class="s2">, </span><span class="s1">result) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Wrap the result of an arithmetic, comparison, or logical operation. 
 
        Parameters 
        ---------- 
        result : DataFrame 
 
        Returns 
        ------- 
        DataFrame 
        &quot;&quot;&quot;</span>
        <span class="s1">out = self._constructor(result</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s3"># Pin columns instead of passing to constructor for compat with</span>
        <span class="s3">#  non-unique columns case</span>
        <span class="s1">out.columns = self.columns</span>
        <span class="s1">out.index = self.index</span>
        <span class="s2">return </span><span class="s1">out</span>

    <span class="s2">def </span><span class="s1">__divmod__(self</span><span class="s2">, </span><span class="s1">other) -&gt; tuple[DataFrame</span><span class="s2">, </span><span class="s1">DataFrame]:</span>
        <span class="s3"># Naive implementation, room for optimization</span>
        <span class="s1">div = self // other</span>
        <span class="s1">mod = self - div * other</span>
        <span class="s2">return </span><span class="s1">div</span><span class="s2">, </span><span class="s1">mod</span>

    <span class="s2">def </span><span class="s1">__rdivmod__(self</span><span class="s2">, </span><span class="s1">other) -&gt; tuple[DataFrame</span><span class="s2">, </span><span class="s1">DataFrame]:</span>
        <span class="s3"># Naive implementation, room for optimization</span>
        <span class="s1">div = other // self</span>
        <span class="s1">mod = other - div * self</span>
        <span class="s2">return </span><span class="s1">div</span><span class="s2">, </span><span class="s1">mod</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Combination-Related</span>

    <span class="s1">@doc(</span>
        <span class="s1">_shared_docs[</span><span class="s4">&quot;compare&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s4">&quot;&quot;&quot; 
Returns 
------- 
DataFrame 
    DataFrame that shows the differences stacked side by side. 
 
    The resulting index will be a MultiIndex with 'self' and 'other' 
    stacked alternately at the inner level. 
 
Raises 
------ 
ValueError 
    When the two DataFrames don't have identical labels or shape. 
 
See Also 
-------- 
Series.compare : Compare with another Series and show differences. 
DataFrame.equals : Test whether two objects contain the same elements. 
 
Notes 
----- 
Matching NaNs will not appear as a difference. 
 
Can only compare identically-labeled 
(i.e. same shape, identical row and column labels) DataFrames 
 
Examples 
-------- 
&gt;&gt;&gt; df = pd.DataFrame( 
...     {{ 
...         &quot;col1&quot;: [&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;], 
...         &quot;col2&quot;: [1.0, 2.0, 3.0, np.nan, 5.0], 
...         &quot;col3&quot;: [1.0, 2.0, 3.0, 4.0, 5.0] 
...     }}, 
...     columns=[&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;], 
... ) 
&gt;&gt;&gt; df 
  col1  col2  col3 
0    a   1.0   1.0 
1    a   2.0   2.0 
2    b   3.0   3.0 
3    b   NaN   4.0 
4    a   5.0   5.0 
 
&gt;&gt;&gt; df2 = df.copy() 
&gt;&gt;&gt; df2.loc[0, 'col1'] = 'c' 
&gt;&gt;&gt; df2.loc[2, 'col3'] = 4.0 
&gt;&gt;&gt; df2 
  col1  col2  col3 
0    c   1.0   1.0 
1    a   2.0   2.0 
2    b   3.0   4.0 
3    b   NaN   4.0 
4    a   5.0   5.0 
 
Align the differences on columns 
 
&gt;&gt;&gt; df.compare(df2) 
  col1       col3 
  self other self other 
0    a     c  NaN   NaN 
2  NaN   NaN  3.0   4.0 
 
Stack the differences on rows 
 
&gt;&gt;&gt; df.compare(df2, align_axis=0) 
        col1  col3 
0 self     a   NaN 
  other    c   NaN 
2 self   NaN   3.0 
  other  NaN   4.0 
 
Keep the equal values 
 
&gt;&gt;&gt; df.compare(df2, keep_equal=True) 
  col1       col3 
  self other self other 
0    a     c  1.0   1.0 
2    b     b  3.0   4.0 
 
Keep all original rows and columns 
 
&gt;&gt;&gt; df.compare(df2, keep_shape=True) 
  col1       col2       col3 
  self other self other self other 
0    a     c  NaN   NaN  NaN   NaN 
1  NaN   NaN  NaN   NaN  NaN   NaN 
2  NaN   NaN  NaN   NaN  3.0   4.0 
3  NaN   NaN  NaN   NaN  NaN   NaN 
4  NaN   NaN  NaN   NaN  NaN   NaN 
 
Keep all original rows and columns and also all original values 
 
&gt;&gt;&gt; df.compare(df2, keep_shape=True, keep_equal=True) 
  col1       col2       col3 
  self other self other self other 
0    a     c  1.0   1.0  1.0   1.0 
1    a     a  2.0   2.0  2.0   2.0 
2    b     b  3.0   3.0  3.0   4.0 
3    b     b  NaN   NaN  4.0   4.0 
4    a     a  5.0   5.0  5.0   5.0 
&quot;&quot;&quot;</span><span class="s2">,</span>
        <span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">]</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">compare(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other: DataFrame</span><span class="s2">,</span>
        <span class="s1">align_axis: Axis = </span><span class="s5">1</span><span class="s2">,</span>
        <span class="s1">keep_shape: bool = </span><span class="s2">False,</span>
        <span class="s1">keep_equal: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">return </span><span class="s1">super().compare(</span>
            <span class="s1">other=other</span><span class="s2">,</span>
            <span class="s1">align_axis=align_axis</span><span class="s2">,</span>
            <span class="s1">keep_shape=keep_shape</span><span class="s2">,</span>
            <span class="s1">keep_equal=keep_equal</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">combine(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">other: DataFrame</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s2">None, </span><span class="s1">overwrite: bool = </span><span class="s2">True</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Perform column-wise combine with another DataFrame. 
 
        Combines a DataFrame with `other` DataFrame using `func` 
        to element-wise combine columns. The row and column indexes of the 
        resulting DataFrame will be the union of the two. 
 
        Parameters 
        ---------- 
        other : DataFrame 
            The DataFrame to merge column-wise. 
        func : function 
            Function that takes two series as inputs and return a Series or a 
            scalar. Used to merge the two dataframes column by columns. 
        fill_value : scalar value, default None 
            The value to fill NaNs with prior to passing any column to the 
            merge func. 
        overwrite : bool, default True 
            If True, columns in `self` that do not exist in `other` will be 
            overwritten with NaNs. 
 
        Returns 
        ------- 
        DataFrame 
            Combination of the provided DataFrames. 
 
        See Also 
        -------- 
        DataFrame.combine_first : Combine two DataFrame objects and default to 
            non-null values in frame calling the method. 
 
        Examples 
        -------- 
        Combine using a simple function that chooses the smaller column. 
 
        &gt;&gt;&gt; df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]}) 
        &gt;&gt;&gt; df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]}) 
        &gt;&gt;&gt; take_smaller = lambda s1, s2: s1 if s1.sum() &lt; s2.sum() else s2 
        &gt;&gt;&gt; df1.combine(df2, take_smaller) 
           A  B 
        0  0  3 
        1  0  3 
 
        Example using a true element-wise combine function. 
 
        &gt;&gt;&gt; df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]}) 
        &gt;&gt;&gt; df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]}) 
        &gt;&gt;&gt; df1.combine(df2, np.minimum) 
           A  B 
        0  1  2 
        1  0  3 
 
        Using `fill_value` fills Nones prior to passing the column to the 
        merge function. 
 
        &gt;&gt;&gt; df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]}) 
        &gt;&gt;&gt; df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]}) 
        &gt;&gt;&gt; df1.combine(df2, take_smaller, fill_value=-5) 
           A    B 
        0  0 -5.0 
        1  0  4.0 
 
        However, if the same element in both dataframes is None, that None 
        is preserved 
 
        &gt;&gt;&gt; df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]}) 
        &gt;&gt;&gt; df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]}) 
        &gt;&gt;&gt; df1.combine(df2, take_smaller, fill_value=-5) 
            A    B 
        0  0 -5.0 
        1  0  3.0 
 
        Example that demonstrates the use of `overwrite` and behavior when 
        the axis differ between the dataframes. 
 
        &gt;&gt;&gt; df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]}) 
        &gt;&gt;&gt; df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2]) 
        &gt;&gt;&gt; df1.combine(df2, take_smaller) 
             A    B     C 
        0  NaN  NaN   NaN 
        1  NaN  3.0 -10.0 
        2  NaN  3.0   1.0 
 
        &gt;&gt;&gt; df1.combine(df2, take_smaller, overwrite=False) 
             A    B     C 
        0  0.0  NaN   NaN 
        1  0.0  3.0 -10.0 
        2  NaN  3.0   1.0 
 
        Demonstrating the preference of the passed in dataframe. 
 
        &gt;&gt;&gt; df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2]) 
        &gt;&gt;&gt; df2.combine(df1, take_smaller) 
           A    B   C 
        0  0.0  NaN NaN 
        1  0.0  3.0 NaN 
        2  NaN  3.0 NaN 
 
        &gt;&gt;&gt; df2.combine(df1, take_smaller, overwrite=False) 
             A    B   C 
        0  0.0  NaN NaN 
        1  0.0  3.0 1.0 
        2  NaN  3.0 1.0 
        &quot;&quot;&quot;</span>
        <span class="s1">other_idxlen = len(other.index)  </span><span class="s3"># save for compare</span>

        <span class="s1">this</span><span class="s2">, </span><span class="s1">other = self.align(other</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">new_index = this.index</span>

        <span class="s2">if </span><span class="s1">other.empty </span><span class="s2">and </span><span class="s1">len(new_index) == len(self.index):</span>
            <span class="s2">return </span><span class="s1">self.copy()</span>

        <span class="s2">if </span><span class="s1">self.empty </span><span class="s2">and </span><span class="s1">len(other) == other_idxlen:</span>
            <span class="s2">return </span><span class="s1">other.copy()</span>

        <span class="s3"># sorts if possible</span>
        <span class="s1">new_columns = this.columns.union(other.columns)</span>
        <span class="s1">do_fill = fill_value </span><span class="s2">is not None</span>
        <span class="s1">result = {}</span>
        <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">new_columns:</span>
            <span class="s1">series = this[col]</span>
            <span class="s1">otherSeries = other[col]</span>

            <span class="s1">this_dtype = series.dtype</span>
            <span class="s1">other_dtype = otherSeries.dtype</span>

            <span class="s1">this_mask = isna(series)</span>
            <span class="s1">other_mask = isna(otherSeries)</span>

            <span class="s3"># don't overwrite columns unnecessarily</span>
            <span class="s3"># DO propagate if this column is not in the intersection</span>
            <span class="s2">if not </span><span class="s1">overwrite </span><span class="s2">and </span><span class="s1">other_mask.all():</span>
                <span class="s1">result[col] = this[col].copy()</span>
                <span class="s2">continue</span>

            <span class="s2">if </span><span class="s1">do_fill:</span>
                <span class="s1">series = series.copy()</span>
                <span class="s1">otherSeries = otherSeries.copy()</span>
                <span class="s1">series[this_mask] = fill_value</span>
                <span class="s1">otherSeries[other_mask] = fill_value</span>

            <span class="s2">if </span><span class="s1">col </span><span class="s2">not in </span><span class="s1">self.columns:</span>
                <span class="s3"># If self DataFrame does not have col in other DataFrame,</span>
                <span class="s3"># try to promote series, which is all NaN, as other_dtype.</span>
                <span class="s1">new_dtype = other_dtype</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">series = series.astype(new_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
                <span class="s2">except </span><span class="s1">ValueError:</span>
                    <span class="s3"># e.g. new_dtype is integer types</span>
                    <span class="s2">pass</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># if we have different dtypes, possibly promote</span>
                <span class="s1">new_dtype = find_common_type([this_dtype</span><span class="s2">, </span><span class="s1">other_dtype])</span>
                <span class="s1">series = series.astype(new_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
                <span class="s1">otherSeries = otherSeries.astype(new_dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

            <span class="s1">arr = func(series</span><span class="s2">, </span><span class="s1">otherSeries)</span>
            <span class="s2">if </span><span class="s1">isinstance(new_dtype</span><span class="s2">, </span><span class="s1">np.dtype):</span>
                <span class="s3"># if new_dtype is an EA Dtype, then `func` is expected to return</span>
                <span class="s3"># the correct dtype without any additional casting</span>
                <span class="s1">arr = maybe_downcast_to_dtype(arr</span><span class="s2">, </span><span class="s1">new_dtype)</span>

            <span class="s1">result[col] = arr</span>

        <span class="s3"># convert_objects just in case</span>
        <span class="s2">return </span><span class="s1">self._constructor(result</span><span class="s2">, </span><span class="s1">index=new_index</span><span class="s2">, </span><span class="s1">columns=new_columns)</span>

    <span class="s2">def </span><span class="s1">combine_first(self</span><span class="s2">, </span><span class="s1">other: DataFrame) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Update null elements with value in the same location in `other`. 
 
        Combine two DataFrame objects by filling null values in one DataFrame 
        with non-null values from other DataFrame. The row and column indexes 
        of the resulting DataFrame will be the union of the two. 
 
        Parameters 
        ---------- 
        other : DataFrame 
            Provided DataFrame to use to fill null values. 
 
        Returns 
        ------- 
        DataFrame 
            The result of combining the provided DataFrame with the other object. 
 
        See Also 
        -------- 
        DataFrame.combine : Perform series-wise operation on two DataFrames 
            using a given function. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]}) 
        &gt;&gt;&gt; df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]}) 
        &gt;&gt;&gt; df1.combine_first(df2) 
             A    B 
        0  1.0  3.0 
        1  0.0  4.0 
 
        Null values still persist if the location of that null value 
        does not exist in `other` 
 
        &gt;&gt;&gt; df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]}) 
        &gt;&gt;&gt; df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2]) 
        &gt;&gt;&gt; df1.combine_first(df2) 
             A    B    C 
        0  NaN  4.0  NaN 
        1  0.0  3.0  1.0 
        2  NaN  3.0  1.0 
        &quot;&quot;&quot;</span>
        <span class="s2">import </span><span class="s1">pandas.core.computation.expressions </span><span class="s2">as </span><span class="s1">expressions</span>

        <span class="s2">def </span><span class="s1">combiner(x</span><span class="s2">, </span><span class="s1">y):</span>
            <span class="s1">mask = extract_array(isna(x))</span>

            <span class="s1">x_values = extract_array(x</span><span class="s2">, </span><span class="s1">extract_numpy=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">y_values = extract_array(y</span><span class="s2">, </span><span class="s1">extract_numpy=</span><span class="s2">True</span><span class="s1">)</span>

            <span class="s3"># If the column y in other DataFrame is not in first DataFrame,</span>
            <span class="s3"># just return y_values.</span>
            <span class="s2">if </span><span class="s1">y.name </span><span class="s2">not in </span><span class="s1">self.columns:</span>
                <span class="s2">return </span><span class="s1">y_values</span>

            <span class="s2">return </span><span class="s1">expressions.where(mask</span><span class="s2">, </span><span class="s1">y_values</span><span class="s2">, </span><span class="s1">x_values)</span>

        <span class="s1">combined = self.combine(other</span><span class="s2">, </span><span class="s1">combiner</span><span class="s2">, </span><span class="s1">overwrite=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s1">dtypes = {</span>
            <span class="s1">col: find_common_type([self.dtypes[col]</span><span class="s2">, </span><span class="s1">other.dtypes[col]])</span>
            <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">self.columns.intersection(other.columns)</span>
            <span class="s2">if not </span><span class="s1">is_dtype_equal(combined.dtypes[col]</span><span class="s2">, </span><span class="s1">self.dtypes[col])</span>
        <span class="s1">}</span>

        <span class="s2">if </span><span class="s1">dtypes:</span>
            <span class="s1">combined = combined.astype(dtypes)</span>

        <span class="s2">return </span><span class="s1">combined</span>

    <span class="s2">def </span><span class="s1">update(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other</span><span class="s2">,</span>
        <span class="s1">join: str = </span><span class="s4">&quot;left&quot;</span><span class="s2">,</span>
        <span class="s1">overwrite: bool = </span><span class="s2">True,</span>
        <span class="s1">filter_func=</span><span class="s2">None,</span>
        <span class="s1">errors: str = </span><span class="s4">&quot;ignore&quot;</span><span class="s2">,</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot; 
        Modify in place using non-NA values from another DataFrame. 
 
        Aligns on indices. There is no return value. 
 
        Parameters 
        ---------- 
        other : DataFrame, or object coercible into a DataFrame 
            Should have at least one matching index/column label 
            with the original DataFrame. If a Series is passed, 
            its name attribute must be set, and that will be 
            used as the column name to align with the original DataFrame. 
        join : {'left'}, default 'left' 
            Only left join is implemented, keeping the index and columns of the 
            original object. 
        overwrite : bool, default True 
            How to handle non-NA values for overlapping keys: 
 
            * True: overwrite original DataFrame's values 
              with values from `other`. 
            * False: only update values that are NA in 
              the original DataFrame. 
 
        filter_func : callable(1d-array) -&gt; bool 1d-array, optional 
            Can choose to replace values other than NA. Return True for values 
            that should be updated. 
        errors : {'raise', 'ignore'}, default 'ignore' 
            If 'raise', will raise a ValueError if the DataFrame and `other` 
            both contain non-NA data in the same place. 
 
        Returns 
        ------- 
        None : method directly changes calling object 
 
        Raises 
        ------ 
        ValueError 
            * When `errors='raise'` and there's overlapping non-NA data. 
            * When `errors` is not either `'ignore'` or `'raise'` 
        NotImplementedError 
            * If `join != 'left'` 
 
        See Also 
        -------- 
        dict.update : Similar method for dictionaries. 
        DataFrame.merge : For column(s)-on-column(s) operations. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2, 3], 
        ...                    'B': [400, 500, 600]}) 
        &gt;&gt;&gt; new_df = pd.DataFrame({'B': [4, 5, 6], 
        ...                        'C': [7, 8, 9]}) 
        &gt;&gt;&gt; df.update(new_df) 
        &gt;&gt;&gt; df 
           A  B 
        0  1  4 
        1  2  5 
        2  3  6 
 
        The DataFrame's length does not increase as a result of the update, 
        only values at matching index/column labels are updated. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'A': ['a', 'b', 'c'], 
        ...                    'B': ['x', 'y', 'z']}) 
        &gt;&gt;&gt; new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']}) 
        &gt;&gt;&gt; df.update(new_df) 
        &gt;&gt;&gt; df 
           A  B 
        0  a  d 
        1  b  e 
        2  c  f 
 
        For Series, its name attribute must be set. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'A': ['a', 'b', 'c'], 
        ...                    'B': ['x', 'y', 'z']}) 
        &gt;&gt;&gt; new_column = pd.Series(['d', 'e'], name='B', index=[0, 2]) 
        &gt;&gt;&gt; df.update(new_column) 
        &gt;&gt;&gt; df 
           A  B 
        0  a  d 
        1  b  y 
        2  c  e 
        &gt;&gt;&gt; df = pd.DataFrame({'A': ['a', 'b', 'c'], 
        ...                    'B': ['x', 'y', 'z']}) 
        &gt;&gt;&gt; new_df = pd.DataFrame({'B': ['d', 'e']}, index=[1, 2]) 
        &gt;&gt;&gt; df.update(new_df) 
        &gt;&gt;&gt; df 
           A  B 
        0  a  x 
        1  b  d 
        2  c  e 
 
        If `other` contains NaNs the corresponding values are not updated 
        in the original dataframe. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2, 3], 
        ...                    'B': [400, 500, 600]}) 
        &gt;&gt;&gt; new_df = pd.DataFrame({'B': [4, np.nan, 6]}) 
        &gt;&gt;&gt; df.update(new_df) 
        &gt;&gt;&gt; df 
           A      B 
        0  1    4.0 
        1  2  500.0 
        2  3    6.0 
        &quot;&quot;&quot;</span>
        <span class="s2">import </span><span class="s1">pandas.core.computation.expressions </span><span class="s2">as </span><span class="s1">expressions</span>

        <span class="s3"># TODO: Support other joins</span>
        <span class="s2">if </span><span class="s1">join != </span><span class="s4">&quot;left&quot;</span><span class="s1">:  </span><span class="s3"># pragma: no cover</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s4">&quot;Only left join is supported&quot;</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">errors </span><span class="s2">not in </span><span class="s1">[</span><span class="s4">&quot;ignore&quot;</span><span class="s2">, </span><span class="s4">&quot;raise&quot;</span><span class="s1">]:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;The parameter errors must be either 'ignore' or 'raise'&quot;</span><span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s1">other = DataFrame(other)</span>

        <span class="s1">other = other.reindex_like(self)</span>

        <span class="s2">for </span><span class="s1">col </span><span class="s2">in </span><span class="s1">self.columns:</span>
            <span class="s1">this = self[col]._values</span>
            <span class="s1">that = other[col]._values</span>
            <span class="s2">if </span><span class="s1">filter_func </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">with </span><span class="s1">np.errstate(all=</span><span class="s4">&quot;ignore&quot;</span><span class="s1">):</span>
                    <span class="s1">mask = ~filter_func(this) | isna(that)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">errors == </span><span class="s4">&quot;raise&quot;</span><span class="s1">:</span>
                    <span class="s1">mask_this = notna(that)</span>
                    <span class="s1">mask_that = notna(this)</span>
                    <span class="s2">if </span><span class="s1">any(mask_this &amp; mask_that):</span>
                        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Data overlaps.&quot;</span><span class="s1">)</span>

                <span class="s2">if </span><span class="s1">overwrite:</span>
                    <span class="s1">mask = isna(that)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">mask = notna(this)</span>

            <span class="s3"># don't overwrite columns unnecessarily</span>
            <span class="s2">if </span><span class="s1">mask.all():</span>
                <span class="s2">continue</span>

            <span class="s1">self[col] = expressions.where(mask</span><span class="s2">, </span><span class="s1">this</span><span class="s2">, </span><span class="s1">that)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Data reshaping</span>
    <span class="s1">@Appender(</span>
        <span class="s4">&quot;&quot;&quot; 
Examples 
-------- 
&gt;&gt;&gt; df = pd.DataFrame({'Animal': ['Falcon', 'Falcon', 
...                               'Parrot', 'Parrot'], 
...                    'Max Speed': [380., 370., 24., 26.]}) 
&gt;&gt;&gt; df 
   Animal  Max Speed 
0  Falcon      380.0 
1  Falcon      370.0 
2  Parrot       24.0 
3  Parrot       26.0 
&gt;&gt;&gt; df.groupby(['Animal']).mean() 
        Max Speed 
Animal 
Falcon      375.0 
Parrot       25.0 
 
**Hierarchical Indexes** 
 
We can groupby different levels of a hierarchical index 
using the `level` parameter: 
 
&gt;&gt;&gt; arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'], 
...           ['Captive', 'Wild', 'Captive', 'Wild']] 
&gt;&gt;&gt; index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type')) 
&gt;&gt;&gt; df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]}, 
...                   index=index) 
&gt;&gt;&gt; df 
                Max Speed 
Animal Type 
Falcon Captive      390.0 
       Wild         350.0 
Parrot Captive       30.0 
       Wild          20.0 
&gt;&gt;&gt; df.groupby(level=0).mean() 
        Max Speed 
Animal 
Falcon      370.0 
Parrot       25.0 
&gt;&gt;&gt; df.groupby(level=&quot;Type&quot;).mean() 
         Max Speed 
Type 
Captive      210.0 
Wild         185.0 
 
We can also choose to include NA in group keys or not by setting 
`dropna` parameter, the default setting is `True`. 
 
&gt;&gt;&gt; l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]] 
&gt;&gt;&gt; df = pd.DataFrame(l, columns=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]) 
 
&gt;&gt;&gt; df.groupby(by=[&quot;b&quot;]).sum() 
    a   c 
b 
1.0 2   3 
2.0 2   5 
 
&gt;&gt;&gt; df.groupby(by=[&quot;b&quot;], dropna=False).sum() 
    a   c 
b 
1.0 2   3 
2.0 2   5 
NaN 1   4 
 
&gt;&gt;&gt; l = [[&quot;a&quot;, 12, 12], [None, 12.3, 33.], [&quot;b&quot;, 12.3, 123], [&quot;a&quot;, 1, 1]] 
&gt;&gt;&gt; df = pd.DataFrame(l, columns=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]) 
 
&gt;&gt;&gt; df.groupby(by=&quot;a&quot;).sum() 
    b     c 
a 
a   13.0   13.0 
b   12.3  123.0 
 
&gt;&gt;&gt; df.groupby(by=&quot;a&quot;, dropna=False).sum() 
    b     c 
a 
a   13.0   13.0 
b   12.3  123.0 
NaN 12.3   33.0 
&quot;&quot;&quot;</span>
    <span class="s1">)</span>
    <span class="s1">@Appender(_shared_docs[</span><span class="s4">&quot;groupby&quot;</span><span class="s1">] % _shared_doc_kwargs)</span>
    <span class="s2">def </span><span class="s1">groupby(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">by=</span><span class="s2">None,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">level: Level | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">as_index: bool = </span><span class="s2">True,</span>
        <span class="s1">sort: bool = </span><span class="s2">True,</span>
        <span class="s1">group_keys: bool = </span><span class="s2">True,</span>
        <span class="s1">squeeze: bool | lib.NoDefault = no_default</span><span class="s2">,</span>
        <span class="s1">observed: bool = </span><span class="s2">False,</span>
        <span class="s1">dropna: bool = </span><span class="s2">True,</span>
    <span class="s1">) -&gt; DataFrameGroupBy:</span>
        <span class="s2">from </span><span class="s1">pandas.core.groupby.generic </span><span class="s2">import </span><span class="s1">DataFrameGroupBy</span>

        <span class="s2">if </span><span class="s1">squeeze </span><span class="s2">is not </span><span class="s1">no_default:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s1">(</span>
                    <span class="s4">&quot;The `squeeze` parameter is deprecated and &quot;</span>
                    <span class="s4">&quot;will be removed in a future version.&quot;</span>
                <span class="s1">)</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">squeeze = </span><span class="s2">False</span>

        <span class="s2">if </span><span class="s1">level </span><span class="s2">is None and </span><span class="s1">by </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;You have to supply one of 'by' and 'level'&quot;</span><span class="s1">)</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>

        <span class="s3"># https://github.com/python/mypy/issues/7642</span>
        <span class="s3"># error: Argument &quot;squeeze&quot; to &quot;DataFrameGroupBy&quot; has incompatible type</span>
        <span class="s3"># &quot;Union[bool, NoDefault]&quot;; expected &quot;bool&quot;</span>
        <span class="s2">return </span><span class="s1">DataFrameGroupBy(</span>
            <span class="s1">obj=self</span><span class="s2">,</span>
            <span class="s1">keys=by</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">level=level</span><span class="s2">,</span>
            <span class="s1">as_index=as_index</span><span class="s2">,</span>
            <span class="s1">sort=sort</span><span class="s2">,</span>
            <span class="s1">group_keys=group_keys</span><span class="s2">,</span>
            <span class="s1">squeeze=squeeze</span><span class="s2">,  </span><span class="s3"># type: ignore[arg-type]</span>
            <span class="s1">observed=observed</span><span class="s2">,</span>
            <span class="s1">dropna=dropna</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">_shared_docs[</span>
        <span class="s4">&quot;pivot&quot;</span>
    <span class="s1">] = </span><span class="s4">&quot;&quot;&quot; 
        Return reshaped DataFrame organized by given index / column values. 
 
        Reshape data (produce a &quot;pivot&quot; table) based on column values. Uses 
        unique values from specified `index` / `columns` to form axes of the 
        resulting DataFrame. This function does not support data 
        aggregation, multiple values will result in a MultiIndex in the 
        columns. See the :ref:`User Guide &lt;reshaping&gt;` for more on reshaping. 
 
        Parameters 
        ----------%s 
        index : str or object or a list of str, optional 
            Column to use to make new frame's index. If None, uses 
            existing index. 
 
            .. versionchanged:: 1.1.0 
               Also accept list of index names. 
 
        columns : str or object or a list of str 
            Column to use to make new frame's columns. 
 
            .. versionchanged:: 1.1.0 
               Also accept list of columns names. 
 
        values : str, object or a list of the previous, optional 
            Column(s) to use for populating new frame's values. If not 
            specified, all remaining columns will be used and the result will 
            have hierarchically indexed columns. 
 
        Returns 
        ------- 
        DataFrame 
            Returns reshaped DataFrame. 
 
        Raises 
        ------ 
        ValueError: 
            When there are any `index`, `columns` combinations with multiple 
            values. `DataFrame.pivot_table` when you need to aggregate. 
 
        See Also 
        -------- 
        DataFrame.pivot_table : Generalization of pivot that can handle 
            duplicate values for one index/column pair. 
        DataFrame.unstack : Pivot based on the index values instead of a 
            column. 
        wide_to_long : Wide panel to long format. Less flexible but more 
            user-friendly than melt. 
 
        Notes 
        ----- 
        For finer-tuned control, see hierarchical indexing documentation along 
        with the related stack/unstack methods. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two', 
        ...                            'two'], 
        ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'], 
        ...                    'baz': [1, 2, 3, 4, 5, 6], 
        ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']}) 
        &gt;&gt;&gt; df 
            foo   bar  baz  zoo 
        0   one   A    1    x 
        1   one   B    2    y 
        2   one   C    3    z 
        3   two   A    4    q 
        4   two   B    5    w 
        5   two   C    6    t 
 
        &gt;&gt;&gt; df.pivot(index='foo', columns='bar', values='baz') 
        bar  A   B   C 
        foo 
        one  1   2   3 
        two  4   5   6 
 
        &gt;&gt;&gt; df.pivot(index='foo', columns='bar')['baz'] 
        bar  A   B   C 
        foo 
        one  1   2   3 
        two  4   5   6 
 
        &gt;&gt;&gt; df.pivot(index='foo', columns='bar', values=['baz', 'zoo']) 
              baz       zoo 
        bar   A  B  C   A  B  C 
        foo 
        one   1  2  3   x  y  z 
        two   4  5  6   q  w  t 
 
        You could also assign a list of column names or a list of index names. 
 
        &gt;&gt;&gt; df = pd.DataFrame({ 
        ...        &quot;lev1&quot;: [1, 1, 1, 2, 2, 2], 
        ...        &quot;lev2&quot;: [1, 1, 2, 1, 1, 2], 
        ...        &quot;lev3&quot;: [1, 2, 1, 2, 1, 2], 
        ...        &quot;lev4&quot;: [1, 2, 3, 4, 5, 6], 
        ...        &quot;values&quot;: [0, 1, 2, 3, 4, 5]}) 
        &gt;&gt;&gt; df 
            lev1 lev2 lev3 lev4 values 
        0   1    1    1    1    0 
        1   1    1    2    2    1 
        2   1    2    1    3    2 
        3   2    1    2    4    3 
        4   2    1    1    5    4 
        5   2    2    2    6    5 
 
        &gt;&gt;&gt; df.pivot(index=&quot;lev1&quot;, columns=[&quot;lev2&quot;, &quot;lev3&quot;],values=&quot;values&quot;) 
        lev2    1         2 
        lev3    1    2    1    2 
        lev1 
        1     0.0  1.0  2.0  NaN 
        2     4.0  3.0  NaN  5.0 
 
        &gt;&gt;&gt; df.pivot(index=[&quot;lev1&quot;, &quot;lev2&quot;], columns=[&quot;lev3&quot;],values=&quot;values&quot;) 
              lev3    1    2 
        lev1  lev2 
           1     1  0.0  1.0 
                 2  2.0  NaN 
           2     1  4.0  3.0 
                 2  NaN  5.0 
 
        A ValueError is raised if there are any duplicates. 
 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;foo&quot;: ['one', 'one', 'two', 'two'], 
        ...                    &quot;bar&quot;: ['A', 'A', 'B', 'C'], 
        ...                    &quot;baz&quot;: [1, 2, 3, 4]}) 
        &gt;&gt;&gt; df 
           foo bar  baz 
        0  one   A    1 
        1  one   A    2 
        2  two   B    3 
        3  two   C    4 
 
        Notice that the first two rows are the same for our `index` 
        and `columns` arguments. 
 
        &gt;&gt;&gt; df.pivot(index='foo', columns='bar', values='baz') 
        Traceback (most recent call last): 
           ... 
        ValueError: Index contains duplicate entries, cannot reshape 
        &quot;&quot;&quot;</span>

    <span class="s1">@Substitution(</span><span class="s4">&quot;&quot;</span><span class="s1">)</span>
    <span class="s1">@Appender(_shared_docs[</span><span class="s4">&quot;pivot&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">pivot(self</span><span class="s2">, </span><span class="s1">index=</span><span class="s2">None, </span><span class="s1">columns=</span><span class="s2">None, </span><span class="s1">values=</span><span class="s2">None</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.pivot </span><span class="s2">import </span><span class="s1">pivot</span>

        <span class="s2">return </span><span class="s1">pivot(self</span><span class="s2">, </span><span class="s1">index=index</span><span class="s2">, </span><span class="s1">columns=columns</span><span class="s2">, </span><span class="s1">values=values)</span>

    <span class="s1">_shared_docs[</span>
        <span class="s4">&quot;pivot_table&quot;</span>
    <span class="s1">] = </span><span class="s4">&quot;&quot;&quot; 
        Create a spreadsheet-style pivot table as a DataFrame. 
 
        The levels in the pivot table will be stored in MultiIndex objects 
        (hierarchical indexes) on the index and columns of the result DataFrame. 
 
        Parameters 
        ----------%s 
        values : column to aggregate, optional 
        index : column, Grouper, array, or list of the previous 
            If an array is passed, it must be the same length as the data. The 
            list can contain any of the other types (except list). 
            Keys to group by on the pivot table index.  If an array is passed, 
            it is being used as the same manner as column values. 
        columns : column, Grouper, array, or list of the previous 
            If an array is passed, it must be the same length as the data. The 
            list can contain any of the other types (except list). 
            Keys to group by on the pivot table column.  If an array is passed, 
            it is being used as the same manner as column values. 
        aggfunc : function, list of functions, dict, default numpy.mean 
            If list of functions passed, the resulting pivot table will have 
            hierarchical columns whose top level are the function names 
            (inferred from the function objects themselves) 
            If dict is passed, the key is column to aggregate and value 
            is function or list of functions. 
        fill_value : scalar, default None 
            Value to replace missing values with (in the resulting pivot table, 
            after aggregation). 
        margins : bool, default False 
            Add all row / columns (e.g. for subtotal / grand totals). 
        dropna : bool, default True 
            Do not include columns whose entries are all NaN. 
        margins_name : str, default 'All' 
            Name of the row / column that will contain the totals 
            when margins is True. 
        observed : bool, default False 
            This only applies if any of the groupers are Categoricals. 
            If True: only show observed values for categorical groupers. 
            If False: show all values for categorical groupers. 
 
            .. versionchanged:: 0.25.0 
 
        sort : bool, default True 
            Specifies if the result should be sorted. 
 
            .. versionadded:: 1.3.0 
 
        Returns 
        ------- 
        DataFrame 
            An Excel style pivot table. 
 
        See Also 
        -------- 
        DataFrame.pivot : Pivot without aggregation that can handle 
            non-numeric data. 
        DataFrame.melt: Unpivot a DataFrame from wide to long format, 
            optionally leaving identifiers set. 
        wide_to_long : Wide panel to long format. Less flexible but more 
            user-friendly than melt. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [&quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, 
        ...                          &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;], 
        ...                    &quot;B&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;, 
        ...                          &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;], 
        ...                    &quot;C&quot;: [&quot;small&quot;, &quot;large&quot;, &quot;large&quot;, &quot;small&quot;, 
        ...                          &quot;small&quot;, &quot;large&quot;, &quot;small&quot;, &quot;small&quot;, 
        ...                          &quot;large&quot;], 
        ...                    &quot;D&quot;: [1, 2, 2, 3, 3, 4, 5, 6, 7], 
        ...                    &quot;E&quot;: [2, 4, 5, 5, 6, 6, 8, 9, 9]}) 
        &gt;&gt;&gt; df 
             A    B      C  D  E 
        0  foo  one  small  1  2 
        1  foo  one  large  2  4 
        2  foo  one  large  2  5 
        3  foo  two  small  3  5 
        4  foo  two  small  3  6 
        5  bar  one  large  4  6 
        6  bar  one  small  5  8 
        7  bar  two  small  6  9 
        8  bar  two  large  7  9 
 
        This first example aggregates values by taking the sum. 
 
        &gt;&gt;&gt; table = pd.pivot_table(df, values='D', index=['A', 'B'], 
        ...                     columns=['C'], aggfunc=np.sum) 
        &gt;&gt;&gt; table 
        C        large  small 
        A   B 
        bar one    4.0    5.0 
            two    7.0    6.0 
        foo one    4.0    1.0 
            two    NaN    6.0 
 
        We can also fill missing values using the `fill_value` parameter. 
 
        &gt;&gt;&gt; table = pd.pivot_table(df, values='D', index=['A', 'B'], 
        ...                     columns=['C'], aggfunc=np.sum, fill_value=0) 
        &gt;&gt;&gt; table 
        C        large  small 
        A   B 
        bar one      4      5 
            two      7      6 
        foo one      4      1 
            two      0      6 
 
        The next example aggregates by taking the mean across multiple columns. 
 
        &gt;&gt;&gt; table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'], 
        ...                     aggfunc={'D': np.mean, 
        ...                              'E': np.mean}) 
        &gt;&gt;&gt; table 
                        D         E 
        A   C 
        bar large  5.500000  7.500000 
            small  5.500000  8.500000 
        foo large  2.000000  4.500000 
            small  2.333333  4.333333 
 
        We can also calculate multiple types of aggregations for any given 
        value column. 
 
        &gt;&gt;&gt; table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'], 
        ...                     aggfunc={'D': np.mean, 
        ...                              'E': [min, max, np.mean]}) 
        &gt;&gt;&gt; table 
                          D   E 
                       mean max      mean  min 
        A   C 
        bar large  5.500000   9  7.500000    6 
            small  5.500000   9  8.500000    8 
        foo large  2.000000   5  4.500000    4 
            small  2.333333   6  4.333333    2 
        &quot;&quot;&quot;</span>

    <span class="s1">@Substitution(</span><span class="s4">&quot;&quot;</span><span class="s1">)</span>
    <span class="s1">@Appender(_shared_docs[</span><span class="s4">&quot;pivot_table&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">pivot_table(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">values=</span><span class="s2">None,</span>
        <span class="s1">index=</span><span class="s2">None,</span>
        <span class="s1">columns=</span><span class="s2">None,</span>
        <span class="s1">aggfunc=</span><span class="s4">&quot;mean&quot;</span><span class="s2">,</span>
        <span class="s1">fill_value=</span><span class="s2">None,</span>
        <span class="s1">margins=</span><span class="s2">False,</span>
        <span class="s1">dropna=</span><span class="s2">True,</span>
        <span class="s1">margins_name=</span><span class="s4">&quot;All&quot;</span><span class="s2">,</span>
        <span class="s1">observed=</span><span class="s2">False,</span>
        <span class="s1">sort=</span><span class="s2">True,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.pivot </span><span class="s2">import </span><span class="s1">pivot_table</span>

        <span class="s2">return </span><span class="s1">pivot_table(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">values=values</span><span class="s2">,</span>
            <span class="s1">index=index</span><span class="s2">,</span>
            <span class="s1">columns=columns</span><span class="s2">,</span>
            <span class="s1">aggfunc=aggfunc</span><span class="s2">,</span>
            <span class="s1">fill_value=fill_value</span><span class="s2">,</span>
            <span class="s1">margins=margins</span><span class="s2">,</span>
            <span class="s1">dropna=dropna</span><span class="s2">,</span>
            <span class="s1">margins_name=margins_name</span><span class="s2">,</span>
            <span class="s1">observed=observed</span><span class="s2">,</span>
            <span class="s1">sort=sort</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">stack(self</span><span class="s2">, </span><span class="s1">level: Level = -</span><span class="s5">1</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Stack the prescribed level(s) from columns to index. 
 
        Return a reshaped DataFrame or Series having a multi-level 
        index with one or more new inner-most levels compared to the current 
        DataFrame. The new inner-most levels are created by pivoting the 
        columns of the current dataframe: 
 
          - if the columns have a single level, the output is a Series; 
          - if the columns have multiple levels, the new index 
            level(s) is (are) taken from the prescribed level(s) and 
            the output is a DataFrame. 
 
        Parameters 
        ---------- 
        level : int, str, list, default -1 
            Level(s) to stack from the column axis onto the index 
            axis, defined as one index or label, or a list of indices 
            or labels. 
        dropna : bool, default True 
            Whether to drop rows in the resulting Frame/Series with 
            missing values. Stacking a column level onto the index 
            axis can create combinations of index and column values 
            that are missing from the original dataframe. See Examples 
            section. 
 
        Returns 
        ------- 
        DataFrame or Series 
            Stacked dataframe or series. 
 
        See Also 
        -------- 
        DataFrame.unstack : Unstack prescribed level(s) from index axis 
             onto column axis. 
        DataFrame.pivot : Reshape dataframe from long format to wide 
             format. 
        DataFrame.pivot_table : Create a spreadsheet-style pivot table 
             as a DataFrame. 
 
        Notes 
        ----- 
        The function is named by analogy with a collection of books 
        being reorganized from being side by side on a horizontal 
        position (the columns of the dataframe) to being stacked 
        vertically on top of each other (in the index of the 
        dataframe). 
 
        Examples 
        -------- 
        **Single level columns** 
 
        &gt;&gt;&gt; df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]], 
        ...                                     index=['cat', 'dog'], 
        ...                                     columns=['weight', 'height']) 
 
        Stacking a dataframe with a single level column axis returns a Series: 
 
        &gt;&gt;&gt; df_single_level_cols 
             weight height 
        cat       0      1 
        dog       2      3 
        &gt;&gt;&gt; df_single_level_cols.stack() 
        cat  weight    0 
             height    1 
        dog  weight    2 
             height    3 
        dtype: int64 
 
        **Multi level columns: simple case** 
 
        &gt;&gt;&gt; multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'), 
        ...                                        ('weight', 'pounds')]) 
        &gt;&gt;&gt; df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]], 
        ...                                     index=['cat', 'dog'], 
        ...                                     columns=multicol1) 
 
        Stacking a dataframe with a multi-level column axis: 
 
        &gt;&gt;&gt; df_multi_level_cols1 
             weight 
                 kg    pounds 
        cat       1        2 
        dog       2        4 
        &gt;&gt;&gt; df_multi_level_cols1.stack() 
                    weight 
        cat kg           1 
            pounds       2 
        dog kg           2 
            pounds       4 
 
        **Missing values** 
 
        &gt;&gt;&gt; multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'), 
        ...                                        ('height', 'm')]) 
        &gt;&gt;&gt; df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]], 
        ...                                     index=['cat', 'dog'], 
        ...                                     columns=multicol2) 
 
        It is common to have missing values when stacking a dataframe 
        with multi-level columns, as the stacked dataframe typically 
        has more values than the original dataframe. Missing values 
        are filled with NaNs: 
 
        &gt;&gt;&gt; df_multi_level_cols2 
            weight height 
                kg      m 
        cat    1.0    2.0 
        dog    3.0    4.0 
        &gt;&gt;&gt; df_multi_level_cols2.stack() 
                height  weight 
        cat kg     NaN     1.0 
            m      2.0     NaN 
        dog kg     NaN     3.0 
            m      4.0     NaN 
 
        **Prescribing the level(s) to be stacked** 
 
        The first parameter controls which level or levels are stacked: 
 
        &gt;&gt;&gt; df_multi_level_cols2.stack(0) 
                     kg    m 
        cat height  NaN  2.0 
            weight  1.0  NaN 
        dog height  NaN  4.0 
            weight  3.0  NaN 
        &gt;&gt;&gt; df_multi_level_cols2.stack([0, 1]) 
        cat  height  m     2.0 
             weight  kg    1.0 
        dog  height  m     4.0 
             weight  kg    3.0 
        dtype: float64 
 
        **Dropping missing values** 
 
        &gt;&gt;&gt; df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]], 
        ...                                     index=['cat', 'dog'], 
        ...                                     columns=multicol2) 
 
        Note that rows where all values are missing are dropped by 
        default but this behaviour can be controlled via the dropna 
        keyword parameter: 
 
        &gt;&gt;&gt; df_multi_level_cols3 
            weight height 
                kg      m 
        cat    NaN    1.0 
        dog    2.0    3.0 
        &gt;&gt;&gt; df_multi_level_cols3.stack(dropna=False) 
                height  weight 
        cat kg     NaN     NaN 
            m      1.0     NaN 
        dog kg     NaN     2.0 
            m      3.0     NaN 
        &gt;&gt;&gt; df_multi_level_cols3.stack(dropna=True) 
                height  weight 
        cat m      1.0     NaN 
        dog kg     NaN     2.0 
            m      3.0     NaN 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.reshape </span><span class="s2">import </span><span class="s1">(</span>
            <span class="s1">stack</span><span class="s2">,</span>
            <span class="s1">stack_multiple</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">isinstance(level</span><span class="s2">, </span><span class="s1">(tuple</span><span class="s2">, </span><span class="s1">list)):</span>
            <span class="s1">result = stack_multiple(self</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">dropna=dropna)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = stack(self</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">dropna=dropna)</span>

        <span class="s2">return </span><span class="s1">result.__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;stack&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">explode(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">column: IndexLabel</span><span class="s2">,</span>
        <span class="s1">ignore_index: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Transform each element of a list-like to a row, replicating index values. 
 
        .. versionadded:: 0.25.0 
 
        Parameters 
        ---------- 
        column : IndexLabel 
            Column(s) to explode. 
            For multiple columns, specify a non-empty list with each element 
            be str or tuple, and all specified columns their list-like data 
            on same row of the frame must have matching length. 
 
            .. versionadded:: 1.3.0 
                Multi-column explode 
 
        ignore_index : bool, default False 
            If True, the resulting index will be labeled 0, 1, , n - 1. 
 
            .. versionadded:: 1.1.0 
 
        Returns 
        ------- 
        DataFrame 
            Exploded lists to rows of the subset columns; 
            index will be duplicated for these rows. 
 
        Raises 
        ------ 
        ValueError : 
            * If columns of the frame are not unique. 
            * If specified columns to explode is empty list. 
            * If specified columns to explode have not matching count of 
              elements rowwise in the frame. 
 
        See Also 
        -------- 
        DataFrame.unstack : Pivot a level of the (necessarily hierarchical) 
            index labels. 
        DataFrame.melt : Unpivot a DataFrame from wide format to long format. 
        Series.explode : Explode a DataFrame from list-like columns to long format. 
 
        Notes 
        ----- 
        This routine will explode list-likes including lists, tuples, sets, 
        Series, and np.ndarray. The result dtype of the subset rows will 
        be object. Scalars will be returned unchanged, and empty list-likes will 
        result in a np.nan for that row. In addition, the ordering of rows in the 
        output will be non-deterministic when exploding sets. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]], 
        ...                    'B': 1, 
        ...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]}) 
        &gt;&gt;&gt; df 
                   A  B          C 
        0  [0, 1, 2]  1  [a, b, c] 
        1        foo  1        NaN 
        2         []  1         [] 
        3     [3, 4]  1     [d, e] 
 
        Single-column explode. 
 
        &gt;&gt;&gt; df.explode('A') 
             A  B          C 
        0    0  1  [a, b, c] 
        0    1  1  [a, b, c] 
        0    2  1  [a, b, c] 
        1  foo  1        NaN 
        2  NaN  1         [] 
        3    3  1     [d, e] 
        3    4  1     [d, e] 
 
        Multi-column explode. 
 
        &gt;&gt;&gt; df.explode(list('AC')) 
             A  B    C 
        0    0  1    a 
        0    1  1    b 
        0    2  1    c 
        1  foo  1  NaN 
        2  NaN  1  NaN 
        3    3  1    d 
        3    4  1    e 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">self.columns.is_unique:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;columns must be unique&quot;</span><span class="s1">)</span>

        <span class="s1">columns: list[Hashable]</span>
        <span class="s2">if </span><span class="s1">is_scalar(column) </span><span class="s2">or </span><span class="s1">isinstance(column</span><span class="s2">, </span><span class="s1">tuple):</span>
            <span class="s1">columns = [column]</span>
        <span class="s2">elif </span><span class="s1">isinstance(column</span><span class="s2">, </span><span class="s1">list) </span><span class="s2">and </span><span class="s1">all(</span>
            <span class="s1">map(</span><span class="s2">lambda </span><span class="s1">c: is_scalar(c) </span><span class="s2">or </span><span class="s1">isinstance(c</span><span class="s2">, </span><span class="s1">tuple)</span><span class="s2">, </span><span class="s1">column)</span>
        <span class="s1">):</span>
            <span class="s2">if not </span><span class="s1">column:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;column must be nonempty&quot;</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">len(column) &gt; len(set(column)):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;column must be unique&quot;</span><span class="s1">)</span>
            <span class="s1">columns = column</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;column must be a scalar, tuple, or list thereof&quot;</span><span class="s1">)</span>

        <span class="s1">df = self.reset_index(drop=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">len(columns) == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">result = df[columns[</span><span class="s5">0</span><span class="s1">]].explode()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">mylen = </span><span class="s2">lambda </span><span class="s1">x: len(x) </span><span class="s2">if </span><span class="s1">is_list_like(x) </span><span class="s2">else </span><span class="s1">-</span><span class="s5">1</span>
            <span class="s1">counts0 = self[columns[</span><span class="s5">0</span><span class="s1">]].apply(mylen)</span>
            <span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">columns[</span><span class="s5">1</span><span class="s1">:]:</span>
                <span class="s2">if not </span><span class="s1">all(counts0 == self[c].apply(mylen)):</span>
                    <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;columns must have matching element counts&quot;</span><span class="s1">)</span>
            <span class="s1">result = DataFrame({c: df[c].explode() </span><span class="s2">for </span><span class="s1">c </span><span class="s2">in </span><span class="s1">columns})</span>
        <span class="s1">result = df.drop(columns</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">).join(result)</span>
        <span class="s2">if </span><span class="s1">ignore_index:</span>
            <span class="s1">result.index = default_index(len(result))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result.index = self.index.take(result.index)</span>
        <span class="s1">result = result.reindex(columns=self.columns</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">unstack(self</span><span class="s2">, </span><span class="s1">level: Level = -</span><span class="s5">1</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Pivot a level of the (necessarily hierarchical) index labels. 
 
        Returns a DataFrame having a new level of column labels whose inner-most level 
        consists of the pivoted index labels. 
 
        If the index is not a MultiIndex, the output will be a Series 
        (the analogue of stack when the columns are not a MultiIndex). 
 
        Parameters 
        ---------- 
        level : int, str, or list of these, default -1 (last level) 
            Level(s) of index to unstack, can pass level name. 
        fill_value : int, str or dict 
            Replace NaN with this value if the unstack produces missing values. 
 
        Returns 
        ------- 
        Series or DataFrame 
 
        See Also 
        -------- 
        DataFrame.pivot : Pivot a table based on column values. 
        DataFrame.stack : Pivot a level of the column labels (inverse operation 
            from `unstack`). 
 
        Examples 
        -------- 
        &gt;&gt;&gt; index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'), 
        ...                                    ('two', 'a'), ('two', 'b')]) 
        &gt;&gt;&gt; s = pd.Series(np.arange(1.0, 5.0), index=index) 
        &gt;&gt;&gt; s 
        one  a   1.0 
             b   2.0 
        two  a   3.0 
             b   4.0 
        dtype: float64 
 
        &gt;&gt;&gt; s.unstack(level=-1) 
             a   b 
        one  1.0  2.0 
        two  3.0  4.0 
 
        &gt;&gt;&gt; s.unstack(level=0) 
           one  two 
        a  1.0   3.0 
        b  2.0   4.0 
 
        &gt;&gt;&gt; df = s.unstack(level=0) 
        &gt;&gt;&gt; df.unstack() 
        one  a  1.0 
             b  2.0 
        two  a  3.0 
             b  4.0 
        dtype: float64 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.reshape </span><span class="s2">import </span><span class="s1">unstack</span>

        <span class="s1">result = unstack(self</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">fill_value)</span>

        <span class="s2">return </span><span class="s1">result.__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;unstack&quot;</span><span class="s1">)</span>

    <span class="s1">@Appender(_shared_docs[</span><span class="s4">&quot;melt&quot;</span><span class="s1">] % {</span><span class="s4">&quot;caller&quot;</span><span class="s1">: </span><span class="s4">&quot;df.melt(&quot;</span><span class="s2">, </span><span class="s4">&quot;other&quot;</span><span class="s1">: </span><span class="s4">&quot;melt&quot;</span><span class="s1">})</span>
    <span class="s2">def </span><span class="s1">melt(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">id_vars=</span><span class="s2">None,</span>
        <span class="s1">value_vars=</span><span class="s2">None,</span>
        <span class="s1">var_name=</span><span class="s2">None,</span>
        <span class="s1">value_name=</span><span class="s4">&quot;value&quot;</span><span class="s2">,</span>
        <span class="s1">col_level: Level | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">ignore_index: bool = </span><span class="s2">True,</span>
    <span class="s1">) -&gt; DataFrame:</span>

        <span class="s2">return </span><span class="s1">melt(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">id_vars=id_vars</span><span class="s2">,</span>
            <span class="s1">value_vars=value_vars</span><span class="s2">,</span>
            <span class="s1">var_name=var_name</span><span class="s2">,</span>
            <span class="s1">value_name=value_name</span><span class="s2">,</span>
            <span class="s1">col_level=col_level</span><span class="s2">,</span>
            <span class="s1">ignore_index=ignore_index</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Time series-related</span>

    <span class="s1">@doc(</span>
        <span class="s1">Series.diff</span><span class="s2">,</span>
        <span class="s1">klass=</span><span class="s4">&quot;Dataframe&quot;</span><span class="s2">,</span>
        <span class="s1">extra_params=</span><span class="s4">&quot;axis : {0 or 'index', 1 or 'columns'}, default 0</span><span class="s2">\n    </span><span class="s4">&quot;</span>
        <span class="s4">&quot;Take difference over rows (0) or columns (1).</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s2">,</span>
        <span class="s1">other_klass=</span><span class="s4">&quot;Series&quot;</span><span class="s2">,</span>
        <span class="s1">examples=dedent(</span>
            <span class="s4">&quot;&quot;&quot; 
        Difference with previous row 
 
        &gt;&gt;&gt; df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6], 
        ...                    'b': [1, 1, 2, 3, 5, 8], 
        ...                    'c': [1, 4, 9, 16, 25, 36]}) 
        &gt;&gt;&gt; df 
           a  b   c 
        0  1  1   1 
        1  2  1   4 
        2  3  2   9 
        3  4  3  16 
        4  5  5  25 
        5  6  8  36 
 
        &gt;&gt;&gt; df.diff() 
             a    b     c 
        0  NaN  NaN   NaN 
        1  1.0  0.0   3.0 
        2  1.0  1.0   5.0 
        3  1.0  1.0   7.0 
        4  1.0  2.0   9.0 
        5  1.0  3.0  11.0 
 
        Difference with previous column 
 
        &gt;&gt;&gt; df.diff(axis=1) 
            a  b   c 
        0 NaN  0   0 
        1 NaN -1   3 
        2 NaN -1   7 
        3 NaN -1  13 
        4 NaN  0  20 
        5 NaN  2  28 
 
        Difference with 3rd previous row 
 
        &gt;&gt;&gt; df.diff(periods=3) 
             a    b     c 
        0  NaN  NaN   NaN 
        1  NaN  NaN   NaN 
        2  NaN  NaN   NaN 
        3  3.0  2.0  15.0 
        4  3.0  4.0  21.0 
        5  3.0  6.0  27.0 
 
        Difference with following row 
 
        &gt;&gt;&gt; df.diff(periods=-1) 
             a    b     c 
        0 -1.0  0.0  -3.0 
        1 -1.0 -1.0  -5.0 
        2 -1.0 -1.0  -7.0 
        3 -1.0 -2.0  -9.0 
        4 -1.0 -3.0 -11.0 
        5  NaN  NaN   NaN 
 
        Overflow in input dtype 
 
        &gt;&gt;&gt; df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8) 
        &gt;&gt;&gt; df.diff() 
               a 
        0    NaN 
        1  255.0&quot;&quot;&quot;</span>
        <span class="s1">)</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">diff(self</span><span class="s2">, </span><span class="s1">periods: int = </span><span class="s5">1</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">if not </span><span class="s1">lib.is_integer(periods):</span>
            <span class="s2">if not </span><span class="s1">(</span>
                <span class="s1">is_float(periods)</span>
                <span class="s3"># error: &quot;int&quot; has no attribute &quot;is_integer&quot;</span>
                <span class="s2">and </span><span class="s1">periods.is_integer()  </span><span class="s3"># type: ignore[attr-defined]</span>
            <span class="s1">):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;periods must be an integer&quot;</span><span class="s1">)</span>
            <span class="s1">periods = int(periods)</span>

        <span class="s1">axis = self._get_axis_number(axis)</span>
        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">1 </span><span class="s2">and </span><span class="s1">periods != </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self - self.shift(periods</span><span class="s2">, </span><span class="s1">axis=axis)</span>

        <span class="s1">new_data = self._mgr.diff(n=periods</span><span class="s2">, </span><span class="s1">axis=axis)</span>
        <span class="s2">return </span><span class="s1">self._constructor(new_data).__finalize__(self</span><span class="s2">, </span><span class="s4">&quot;diff&quot;</span><span class="s1">)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Function application</span>

    <span class="s2">def </span><span class="s1">_gotitem(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">key: IndexLabel</span><span class="s2">,</span>
        <span class="s1">ndim: int</span><span class="s2">,</span>
        <span class="s1">subset: DataFrame | Series | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame | Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Sub-classes to define. Return a sliced object. 
 
        Parameters 
        ---------- 
        key : string / list of selections 
        ndim : {1, 2} 
            requested ndim of result 
        subset : object, default None 
            subset to act on 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">subset </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">subset = self</span>
        <span class="s2">elif </span><span class="s1">subset.ndim == </span><span class="s5">1</span><span class="s1">:  </span><span class="s3"># is Series</span>
            <span class="s2">return </span><span class="s1">subset</span>

        <span class="s3"># TODO: _shallow_copy(subset)?</span>
        <span class="s2">return </span><span class="s1">subset[key]</span>

    <span class="s1">_agg_summary_and_see_also_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    The aggregation operations are always performed over an axis, either the 
    index (default) or the column axis. This behavior is different from 
    `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`, 
    `var`), where the default is to compute the aggregation of the flattened 
    array, e.g., ``numpy.mean(arr_2d)`` as opposed to 
    ``numpy.mean(arr_2d, axis=0)``. 
 
    `agg` is an alias for `aggregate`. Use the alias. 
 
    See Also 
    -------- 
    DataFrame.apply : Perform any type of operations. 
    DataFrame.transform : Perform transformation type operations. 
    core.groupby.GroupBy : Perform operations over groups. 
    core.resample.Resampler : Perform operations over resampled bins. 
    core.window.Rolling : Perform operations over rolling window. 
    core.window.Expanding : Perform operations over expanding window. 
    core.window.ExponentialMovingWindow : Perform operation over exponential weighted 
        window. 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">_agg_examples_doc = dedent(</span>
        <span class="s4">&quot;&quot;&quot; 
    Examples 
    -------- 
    &gt;&gt;&gt; df = pd.DataFrame([[1, 2, 3], 
    ...                    [4, 5, 6], 
    ...                    [7, 8, 9], 
    ...                    [np.nan, np.nan, np.nan]], 
    ...                   columns=['A', 'B', 'C']) 
 
    Aggregate these functions over the rows. 
 
    &gt;&gt;&gt; df.agg(['sum', 'min']) 
            A     B     C 
    sum  12.0  15.0  18.0 
    min   1.0   2.0   3.0 
 
    Different aggregations per column. 
 
    &gt;&gt;&gt; df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']}) 
            A    B 
    sum  12.0  NaN 
    min   1.0  2.0 
    max   NaN  8.0 
 
    Aggregate different functions over the columns and rename the index of the resulting 
    DataFrame. 
 
    &gt;&gt;&gt; df.agg(x=('A', max), y=('B', 'min'), z=('C', np.mean)) 
         A    B    C 
    x  7.0  NaN  NaN 
    y  NaN  2.0  NaN 
    z  NaN  NaN  6.0 
 
    Aggregate over the columns. 
 
    &gt;&gt;&gt; df.agg(&quot;mean&quot;, axis=&quot;columns&quot;) 
    0    2.0 
    1    5.0 
    2    8.0 
    3    NaN 
    dtype: float64 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@doc(</span>
        <span class="s1">_shared_docs[</span><span class="s4">&quot;aggregate&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">axis=_shared_doc_kwargs[</span><span class="s4">&quot;axis&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">see_also=_agg_summary_and_see_also_doc</span><span class="s2">,</span>
        <span class="s1">examples=_agg_examples_doc</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">aggregate(self</span><span class="s2">, </span><span class="s1">func=</span><span class="s2">None, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s2">from </span><span class="s1">pandas.core.apply </span><span class="s2">import </span><span class="s1">frame_apply</span>

        <span class="s1">axis = self._get_axis_number(axis)</span>

        <span class="s1">relabeling</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">order = reconstruct_func(func</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s1">op = frame_apply(self</span><span class="s2">, </span><span class="s1">func=func</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">args=args</span><span class="s2">, </span><span class="s1">kwargs=kwargs)</span>
        <span class="s1">result = op.agg()</span>

        <span class="s2">if </span><span class="s1">relabeling:</span>
            <span class="s3"># This is to keep the order to columns occurrence unchanged, and also</span>
            <span class="s3"># keep the order of new columns occurrence unchanged</span>

            <span class="s3"># For the return values of reconstruct_func, if relabeling is</span>
            <span class="s3"># False, columns and order will be None.</span>
            <span class="s2">assert </span><span class="s1">columns </span><span class="s2">is not None</span>
            <span class="s2">assert </span><span class="s1">order </span><span class="s2">is not None</span>

            <span class="s1">result_in_dict = relabel_result(result</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">columns</span><span class="s2">, </span><span class="s1">order)</span>
            <span class="s1">result = DataFrame(result_in_dict</span><span class="s2">, </span><span class="s1">index=columns)</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">agg = aggregate</span>

    <span class="s1">@doc(</span>
        <span class="s1">_shared_docs[</span><span class="s4">&quot;transform&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">klass=_shared_doc_kwargs[</span><span class="s4">&quot;klass&quot;</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">axis=_shared_doc_kwargs[</span><span class="s4">&quot;axis&quot;</span><span class="s1">]</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">transform(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">func: AggFuncType</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">from </span><span class="s1">pandas.core.apply </span><span class="s2">import </span><span class="s1">frame_apply</span>

        <span class="s1">op = frame_apply(self</span><span class="s2">, </span><span class="s1">func=func</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">args=args</span><span class="s2">, </span><span class="s1">kwargs=kwargs)</span>
        <span class="s1">result = op.transform()</span>
        <span class="s2">assert </span><span class="s1">isinstance(result</span><span class="s2">, </span><span class="s1">DataFrame)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">apply(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">func: AggFuncType</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">raw: bool = </span><span class="s2">False,</span>
        <span class="s1">result_type=</span><span class="s2">None,</span>
        <span class="s1">args=()</span><span class="s2">,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Apply a function along an axis of the DataFrame. 
 
        Objects passed to the function are Series objects whose index is 
        either the DataFrame's index (``axis=0``) or the DataFrame's columns 
        (``axis=1``). By default (``result_type=None``), the final return type 
        is inferred from the return type of the applied function. Otherwise, 
        it depends on the `result_type` argument. 
 
        Parameters 
        ---------- 
        func : function 
            Function to apply to each column or row. 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            Axis along which the function is applied: 
 
            * 0 or 'index': apply function to each column. 
            * 1 or 'columns': apply function to each row. 
 
        raw : bool, default False 
            Determines if row or column is passed as a Series or ndarray object: 
 
            * ``False`` : passes each row or column as a Series to the 
              function. 
            * ``True`` : the passed function will receive ndarray objects 
              instead. 
              If you are just applying a NumPy reduction function this will 
              achieve much better performance. 
 
        result_type : {'expand', 'reduce', 'broadcast', None}, default None 
            These only act when ``axis=1`` (columns): 
 
            * 'expand' : list-like results will be turned into columns. 
            * 'reduce' : returns a Series if possible rather than expanding 
              list-like results. This is the opposite of 'expand'. 
            * 'broadcast' : results will be broadcast to the original shape 
              of the DataFrame, the original index and columns will be 
              retained. 
 
            The default behaviour (None) depends on the return value of the 
            applied function: list-like results will be returned as a Series 
            of those. However if the apply function returns a Series these 
            are expanded to columns. 
        args : tuple 
            Positional arguments to pass to `func` in addition to the 
            array/series. 
        **kwargs 
            Additional keyword arguments to pass as keywords arguments to 
            `func`. 
 
        Returns 
        ------- 
        Series or DataFrame 
            Result of applying ``func`` along the given axis of the 
            DataFrame. 
 
        See Also 
        -------- 
        DataFrame.applymap: For elementwise operations. 
        DataFrame.aggregate: Only perform aggregating type operations. 
        DataFrame.transform: Only perform transforming type operations. 
 
        Notes 
        ----- 
        Functions that mutate the passed object can produce unexpected 
        behavior or errors and are not supported. See :ref:`gotchas.udf-mutation` 
        for more details. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B']) 
        &gt;&gt;&gt; df 
           A  B 
        0  4  9 
        1  4  9 
        2  4  9 
 
        Using a numpy universal function (in this case the same as 
        ``np.sqrt(df)``): 
 
        &gt;&gt;&gt; df.apply(np.sqrt) 
             A    B 
        0  2.0  3.0 
        1  2.0  3.0 
        2  2.0  3.0 
 
        Using a reducing function on either axis 
 
        &gt;&gt;&gt; df.apply(np.sum, axis=0) 
        A    12 
        B    27 
        dtype: int64 
 
        &gt;&gt;&gt; df.apply(np.sum, axis=1) 
        0    13 
        1    13 
        2    13 
        dtype: int64 
 
        Returning a list-like will result in a Series 
 
        &gt;&gt;&gt; df.apply(lambda x: [1, 2], axis=1) 
        0    [1, 2] 
        1    [1, 2] 
        2    [1, 2] 
        dtype: object 
 
        Passing ``result_type='expand'`` will expand list-like results 
        to columns of a Dataframe 
 
        &gt;&gt;&gt; df.apply(lambda x: [1, 2], axis=1, result_type='expand') 
           0  1 
        0  1  2 
        1  1  2 
        2  1  2 
 
        Returning a Series inside the function is similar to passing 
        ``result_type='expand'``. The resulting column names 
        will be the Series index. 
 
        &gt;&gt;&gt; df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1) 
           foo  bar 
        0    1    2 
        1    1    2 
        2    1    2 
 
        Passing ``result_type='broadcast'`` will ensure the same shape 
        result, whether list-like or scalar is returned by the function, 
        and broadcast it along the axis. The resulting column names will 
        be the originals. 
 
        &gt;&gt;&gt; df.apply(lambda x: [1, 2], axis=1, result_type='broadcast') 
           A  B 
        0  1  2 
        1  1  2 
        2  1  2 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.core.apply </span><span class="s2">import </span><span class="s1">frame_apply</span>

        <span class="s1">op = frame_apply(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">func=func</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">raw=raw</span><span class="s2">,</span>
            <span class="s1">result_type=result_type</span><span class="s2">,</span>
            <span class="s1">args=args</span><span class="s2">,</span>
            <span class="s1">kwargs=kwargs</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">return </span><span class="s1">op.apply().__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;apply&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">applymap(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">func: PythonFuncType</span><span class="s2">, </span><span class="s1">na_action: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">**kwargs</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Apply a function to a Dataframe elementwise. 
 
        This method applies a function that accepts and returns a scalar 
        to every element of a DataFrame. 
 
        Parameters 
        ---------- 
        func : callable 
            Python function, returns a single value from a single value. 
        na_action : {None, 'ignore'}, default None 
            If ignore, propagate NaN values, without passing them to func. 
 
            .. versionadded:: 1.2 
 
        **kwargs 
            Additional keyword arguments to pass as keywords arguments to 
            `func`. 
 
            .. versionadded:: 1.3.0 
 
        Returns 
        ------- 
        DataFrame 
            Transformed DataFrame. 
 
        See Also 
        -------- 
        DataFrame.apply : Apply a function along input axis of DataFrame. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([[1, 2.12], [3.356, 4.567]]) 
        &gt;&gt;&gt; df 
               0      1 
        0  1.000  2.120 
        1  3.356  4.567 
 
        &gt;&gt;&gt; df.applymap(lambda x: len(str(x))) 
           0  1 
        0  3  4 
        1  5  5 
 
        Like Series.map, NA values can be ignored: 
 
        &gt;&gt;&gt; df_copy = df.copy() 
        &gt;&gt;&gt; df_copy.iloc[0, 0] = pd.NA 
        &gt;&gt;&gt; df_copy.applymap(lambda x: len(str(x)), na_action='ignore') 
              0  1 
        0  &lt;NA&gt;  4 
        1     5  5 
 
        Note that a vectorized version of `func` often exists, which will 
        be much faster. You could square each number elementwise. 
 
        &gt;&gt;&gt; df.applymap(lambda x: x**2) 
                   0          1 
        0   1.000000   4.494400 
        1  11.262736  20.857489 
 
        But it's better to avoid applymap in that case. 
 
        &gt;&gt;&gt; df ** 2 
                   0          1 
        0   1.000000   4.494400 
        1  11.262736  20.857489 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">na_action </span><span class="s2">not in </span><span class="s1">{</span><span class="s4">&quot;ignore&quot;</span><span class="s2">, None</span><span class="s1">}:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">f&quot;na_action must be 'ignore' or None. Got </span><span class="s2">{</span><span class="s1">repr(na_action)</span><span class="s2">}</span><span class="s4">&quot;</span>
            <span class="s1">)</span>
        <span class="s1">ignore_na = na_action == </span><span class="s4">&quot;ignore&quot;</span>
        <span class="s1">func = functools.partial(func</span><span class="s2">, </span><span class="s1">**kwargs)</span>

        <span class="s3"># if we have a dtype == 'M8[ns]', provide boxed values</span>
        <span class="s2">def </span><span class="s1">infer(x):</span>
            <span class="s2">if </span><span class="s1">x.empty:</span>
                <span class="s2">return </span><span class="s1">lib.map_infer(x</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">ignore_na=ignore_na)</span>
            <span class="s2">return </span><span class="s1">lib.map_infer(x.astype(object)._values</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">ignore_na=ignore_na)</span>

        <span class="s2">return </span><span class="s1">self.apply(infer).__finalize__(self</span><span class="s2">, </span><span class="s4">&quot;applymap&quot;</span><span class="s1">)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Merging / joining methods</span>

    <span class="s2">def </span><span class="s1">append(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other</span><span class="s2">,</span>
        <span class="s1">ignore_index: bool = </span><span class="s2">False,</span>
        <span class="s1">verify_integrity: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Append rows of `other` to the end of caller, returning a new object. 
 
        Columns in `other` that are not in the caller are added as new columns. 
 
        Parameters 
        ---------- 
        other : DataFrame or Series/dict-like object, or list of these 
            The data to append. 
        ignore_index : bool, default False 
            If True, the resulting axis will be labeled 0, 1, , n - 1. 
        verify_integrity : bool, default False 
            If True, raise ValueError on creating index with duplicates. 
        sort : bool, default False 
            Sort columns if the columns of `self` and `other` are not aligned. 
 
            .. versionchanged:: 1.0.0 
 
                Changed to not sort by default. 
 
        Returns 
        ------- 
        DataFrame 
            A new DataFrame consisting of the rows of caller and the rows of `other`. 
 
        See Also 
        -------- 
        concat : General function to concatenate DataFrame or Series objects. 
 
        Notes 
        ----- 
        If a list of dict/series is passed and the keys are all contained in 
        the DataFrame's index, the order of the columns in the resulting 
        DataFrame will be unchanged. 
 
        Iteratively appending rows to a DataFrame can be more computationally 
        intensive than a single concatenate. A better solution is to append 
        those rows to a list and then concatenate the list with the original 
        DataFrame all at once. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'), index=['x', 'y']) 
        &gt;&gt;&gt; df 
           A  B 
        x  1  2 
        y  3  4 
        &gt;&gt;&gt; df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'), index=['x', 'y']) 
        &gt;&gt;&gt; df.append(df2) 
           A  B 
        x  1  2 
        y  3  4 
        x  5  6 
        y  7  8 
 
        With `ignore_index` set to True: 
 
        &gt;&gt;&gt; df.append(df2, ignore_index=True) 
           A  B 
        0  1  2 
        1  3  4 
        2  5  6 
        3  7  8 
 
        The following, while not recommended methods for generating DataFrames, 
        show two ways to generate a DataFrame from multiple data sources. 
 
        Less efficient: 
 
        &gt;&gt;&gt; df = pd.DataFrame(columns=['A']) 
        &gt;&gt;&gt; for i in range(5): 
        ...     df = df.append({'A': i}, ignore_index=True) 
        &gt;&gt;&gt; df 
           A 
        0  0 
        1  1 
        2  2 
        3  3 
        4  4 
 
        More efficient: 
 
        &gt;&gt;&gt; pd.concat([pd.DataFrame([i], columns=['A']) for i in range(5)], 
        ...           ignore_index=True) 
           A 
        0  0 
        1  1 
        2  2 
        3  3 
        4  4 
        &quot;&quot;&quot;</span>
        <span class="s1">warnings.warn(</span>
            <span class="s4">&quot;The frame.append method is deprecated &quot;</span>
            <span class="s4">&quot;and will be removed from pandas in a future version. &quot;</span>
            <span class="s4">&quot;Use pandas.concat instead.&quot;</span><span class="s2">,</span>
            <span class="s1">FutureWarning</span><span class="s2">,</span>
            <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
        <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">self._append(other</span><span class="s2">, </span><span class="s1">ignore_index</span><span class="s2">, </span><span class="s1">verify_integrity</span><span class="s2">, </span><span class="s1">sort)</span>

    <span class="s2">def </span><span class="s1">_append(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other</span><span class="s2">,</span>
        <span class="s1">ignore_index: bool = </span><span class="s2">False,</span>
        <span class="s1">verify_integrity: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s1">combined_columns = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">(Series</span><span class="s2">, </span><span class="s1">dict)):</span>
            <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">dict):</span>
                <span class="s2">if not </span><span class="s1">ignore_index:</span>
                    <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Can only append a dict if ignore_index=True&quot;</span><span class="s1">)</span>
                <span class="s1">other = Series(other)</span>
            <span class="s2">if </span><span class="s1">other.name </span><span class="s2">is None and not </span><span class="s1">ignore_index:</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span>
                    <span class="s4">&quot;Can only append a Series if ignore_index=True &quot;</span>
                    <span class="s4">&quot;or if the Series has a name&quot;</span>
                <span class="s1">)</span>

            <span class="s1">index = Index([other.name]</span><span class="s2">, </span><span class="s1">name=self.index.name)</span>
            <span class="s1">idx_diff = other.index.difference(self.columns)</span>
            <span class="s1">combined_columns = self.columns.append(idx_diff)</span>
            <span class="s1">row_df = other.to_frame().T</span>
            <span class="s3"># infer_objects is needed for</span>
            <span class="s3">#  test_append_empty_frame_to_series_with_dateutil_tz</span>
            <span class="s1">other = row_df.infer_objects().rename_axis(index.names</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">list):</span>
            <span class="s2">if not </span><span class="s1">other:</span>
                <span class="s2">pass</span>
            <span class="s2">elif not </span><span class="s1">isinstance(other[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">DataFrame):</span>
                <span class="s1">other = DataFrame(other)</span>
                <span class="s2">if </span><span class="s1">self.index.name </span><span class="s2">is not None and not </span><span class="s1">ignore_index:</span>
                    <span class="s1">other.index.name = self.index.name</span>

        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

        <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">(list</span><span class="s2">, </span><span class="s1">tuple)):</span>
            <span class="s1">to_concat = [self</span><span class="s2">, </span><span class="s1">*other]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">to_concat = [self</span><span class="s2">, </span><span class="s1">other]</span>

        <span class="s1">result = concat(</span>
            <span class="s1">to_concat</span><span class="s2">,</span>
            <span class="s1">ignore_index=ignore_index</span><span class="s2">,</span>
            <span class="s1">verify_integrity=verify_integrity</span><span class="s2">,</span>
            <span class="s1">sort=sort</span><span class="s2">,</span>
        <span class="s1">)</span>
        <span class="s2">if </span><span class="s1">(</span>
            <span class="s1">combined_columns </span><span class="s2">is not None</span>
            <span class="s2">and not </span><span class="s1">sort</span>
            <span class="s2">and not </span><span class="s1">combined_columns.equals(result.columns)</span>
        <span class="s1">):</span>
            <span class="s3"># TODO: reindexing here is a kludge bc union_indexes does not</span>
            <span class="s3">#  pass sort to index.union, xref #43375</span>
            <span class="s3"># combined_columns.equals check is necessary for preserving dtype</span>
            <span class="s3">#  in test_crosstab_normalize</span>
            <span class="s1">result = result.reindex(combined_columns</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result.__finalize__(self</span><span class="s2">, </span><span class="s1">method=</span><span class="s4">&quot;append&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">join(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other: DataFrame | Series</span><span class="s2">,</span>
        <span class="s1">on: IndexLabel | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">how: str = </span><span class="s4">&quot;left&quot;</span><span class="s2">,</span>
        <span class="s1">lsuffix: str = </span><span class="s4">&quot;&quot;</span><span class="s2">,</span>
        <span class="s1">rsuffix: str = </span><span class="s4">&quot;&quot;</span><span class="s2">,</span>
        <span class="s1">sort: bool = </span><span class="s2">False,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Join columns of another DataFrame. 
 
        Join columns with `other` DataFrame either on index or on a key 
        column. Efficiently join multiple DataFrame objects by index at once by 
        passing a list. 
 
        Parameters 
        ---------- 
        other : DataFrame, Series, or list of DataFrame 
            Index should be similar to one of the columns in this one. If a 
            Series is passed, its name attribute must be set, and that will be 
            used as the column name in the resulting joined DataFrame. 
        on : str, list of str, or array-like, optional 
            Column or index level name(s) in the caller to join on the index 
            in `other`, otherwise joins index-on-index. If multiple 
            values given, the `other` DataFrame must have a MultiIndex. Can 
            pass an array as the join key if it is not already contained in 
            the calling DataFrame. Like an Excel VLOOKUP operation. 
        how : {'left', 'right', 'outer', 'inner'}, default 'left' 
            How to handle the operation of the two objects. 
 
            * left: use calling frame's index (or column if on is specified) 
            * right: use `other`'s index. 
            * outer: form union of calling frame's index (or column if on is 
              specified) with `other`'s index, and sort it. 
              lexicographically. 
            * inner: form intersection of calling frame's index (or column if 
              on is specified) with `other`'s index, preserving the order 
              of the calling's one. 
            * cross: creates the cartesian product from both frames, preserves the order 
              of the left keys. 
 
              .. versionadded:: 1.2.0 
 
        lsuffix : str, default '' 
            Suffix to use from left frame's overlapping columns. 
        rsuffix : str, default '' 
            Suffix to use from right frame's overlapping columns. 
        sort : bool, default False 
            Order result DataFrame lexicographically by the join key. If False, 
            the order of the join key depends on the join type (how keyword). 
 
        Returns 
        ------- 
        DataFrame 
            A dataframe containing columns from both the caller and `other`. 
 
        See Also 
        -------- 
        DataFrame.merge : For column(s)-on-column(s) operations. 
 
        Notes 
        ----- 
        Parameters `on`, `lsuffix`, and `rsuffix` are not supported when 
        passing a list of `DataFrame` objects. 
 
        Support for specifying index levels as the `on` parameter was added 
        in version 0.23.0. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 
        ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']}) 
 
        &gt;&gt;&gt; df 
          key   A 
        0  K0  A0 
        1  K1  A1 
        2  K2  A2 
        3  K3  A3 
        4  K4  A4 
        5  K5  A5 
 
        &gt;&gt;&gt; other = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 
        ...                       'B': ['B0', 'B1', 'B2']}) 
 
        &gt;&gt;&gt; other 
          key   B 
        0  K0  B0 
        1  K1  B1 
        2  K2  B2 
 
        Join DataFrames using their indexes. 
 
        &gt;&gt;&gt; df.join(other, lsuffix='_caller', rsuffix='_other') 
          key_caller   A key_other    B 
        0         K0  A0        K0   B0 
        1         K1  A1        K1   B1 
        2         K2  A2        K2   B2 
        3         K3  A3       NaN  NaN 
        4         K4  A4       NaN  NaN 
        5         K5  A5       NaN  NaN 
 
        If we want to join using the key columns, we need to set key to be 
        the index in both `df` and `other`. The joined DataFrame will have 
        key as its index. 
 
        &gt;&gt;&gt; df.set_index('key').join(other.set_index('key')) 
              A    B 
        key 
        K0   A0   B0 
        K1   A1   B1 
        K2   A2   B2 
        K3   A3  NaN 
        K4   A4  NaN 
        K5   A5  NaN 
 
        Another option to join using the key columns is to use the `on` 
        parameter. DataFrame.join always uses `other`'s index but we can use 
        any column in `df`. This method preserves the original DataFrame's 
        index in the result. 
 
        &gt;&gt;&gt; df.join(other.set_index('key'), on='key') 
          key   A    B 
        0  K0  A0   B0 
        1  K1  A1   B1 
        2  K2  A2   B2 
        3  K3  A3  NaN 
        4  K4  A4  NaN 
        5  K5  A5  NaN 
 
        Using non-unique key values shows how they are matched. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'], 
        ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']}) 
 
        &gt;&gt;&gt; df 
          key   A 
        0  K0  A0 
        1  K1  A1 
        2  K1  A2 
        3  K3  A3 
        4  K0  A4 
        5  K1  A5 
 
        &gt;&gt;&gt; df.join(other.set_index('key'), on='key') 
          key   A    B 
        0  K0  A0   B0 
        1  K1  A1   B1 
        2  K1  A2   B1 
        3  K3  A3  NaN 
        4  K0  A4   B0 
        5  K1  A5   B1 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self._join_compat(</span>
            <span class="s1">other</span><span class="s2">, </span><span class="s1">on=on</span><span class="s2">, </span><span class="s1">how=how</span><span class="s2">, </span><span class="s1">lsuffix=lsuffix</span><span class="s2">, </span><span class="s1">rsuffix=rsuffix</span><span class="s2">, </span><span class="s1">sort=sort</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_join_compat(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">other: DataFrame | Series</span><span class="s2">,</span>
        <span class="s1">on: IndexLabel | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">how: str = </span><span class="s4">&quot;left&quot;</span><span class="s2">,</span>
        <span class="s1">lsuffix: str = </span><span class="s4">&quot;&quot;</span><span class="s2">,</span>
        <span class="s1">rsuffix: str = </span><span class="s4">&quot;&quot;</span><span class="s2">,</span>
        <span class="s1">sort: bool = </span><span class="s2">False,</span>
    <span class="s1">):</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.merge </span><span class="s2">import </span><span class="s1">merge</span>

        <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s2">if </span><span class="s1">other.name </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Other Series must have a name&quot;</span><span class="s1">)</span>
            <span class="s1">other = DataFrame({other.name: other})</span>

        <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">if </span><span class="s1">how == </span><span class="s4">&quot;cross&quot;</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">merge(</span>
                    <span class="s1">self</span><span class="s2">,</span>
                    <span class="s1">other</span><span class="s2">,</span>
                    <span class="s1">how=how</span><span class="s2">,</span>
                    <span class="s1">on=on</span><span class="s2">,</span>
                    <span class="s1">suffixes=(lsuffix</span><span class="s2">, </span><span class="s1">rsuffix)</span><span class="s2">,</span>
                    <span class="s1">sort=sort</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">merge(</span>
                <span class="s1">self</span><span class="s2">,</span>
                <span class="s1">other</span><span class="s2">,</span>
                <span class="s1">left_on=on</span><span class="s2">,</span>
                <span class="s1">how=how</span><span class="s2">,</span>
                <span class="s1">left_index=on </span><span class="s2">is None,</span>
                <span class="s1">right_index=</span><span class="s2">True,</span>
                <span class="s1">suffixes=(lsuffix</span><span class="s2">, </span><span class="s1">rsuffix)</span><span class="s2">,</span>
                <span class="s1">sort=sort</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">on </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span>
                    <span class="s4">&quot;Joining multiple DataFrames only supported for joining on index&quot;</span>
                <span class="s1">)</span>

            <span class="s1">frames = [self] + list(other)</span>

            <span class="s1">can_concat = all(df.index.is_unique </span><span class="s2">for </span><span class="s1">df </span><span class="s2">in </span><span class="s1">frames)</span>

            <span class="s3"># join indexes only using concat</span>
            <span class="s2">if </span><span class="s1">can_concat:</span>
                <span class="s2">if </span><span class="s1">how == </span><span class="s4">&quot;left&quot;</span><span class="s1">:</span>
                    <span class="s1">res = concat(</span>
                        <span class="s1">frames</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">join=</span><span class="s4">&quot;outer&quot;</span><span class="s2">, </span><span class="s1">verify_integrity=</span><span class="s2">True, </span><span class="s1">sort=sort</span>
                    <span class="s1">)</span>
                    <span class="s2">return </span><span class="s1">res.reindex(self.index</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s2">return </span><span class="s1">concat(</span>
                        <span class="s1">frames</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">join=how</span><span class="s2">, </span><span class="s1">verify_integrity=</span><span class="s2">True, </span><span class="s1">sort=sort</span>
                    <span class="s1">)</span>

            <span class="s1">joined = frames[</span><span class="s5">0</span><span class="s1">]</span>

            <span class="s2">for </span><span class="s1">frame </span><span class="s2">in </span><span class="s1">frames[</span><span class="s5">1</span><span class="s1">:]:</span>
                <span class="s1">joined = merge(</span>
                    <span class="s1">joined</span><span class="s2">, </span><span class="s1">frame</span><span class="s2">, </span><span class="s1">how=how</span><span class="s2">, </span><span class="s1">left_index=</span><span class="s2">True, </span><span class="s1">right_index=</span><span class="s2">True</span>
                <span class="s1">)</span>

            <span class="s2">return </span><span class="s1">joined</span>

    <span class="s1">@Substitution(</span><span class="s4">&quot;&quot;</span><span class="s1">)</span>
    <span class="s1">@Appender(_merge_doc</span><span class="s2">, </span><span class="s1">indents=</span><span class="s5">2</span><span class="s1">)</span>
    <span class="s2">def </span><span class="s1">merge(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">right: DataFrame | Series</span><span class="s2">,</span>
        <span class="s1">how: str = </span><span class="s4">&quot;inner&quot;</span><span class="s2">,</span>
        <span class="s1">on: IndexLabel | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">left_on: IndexLabel | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">right_on: IndexLabel | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">left_index: bool = </span><span class="s2">False,</span>
        <span class="s1">right_index: bool = </span><span class="s2">False,</span>
        <span class="s1">sort: bool = </span><span class="s2">False,</span>
        <span class="s1">suffixes: Suffixes = (</span><span class="s4">&quot;_x&quot;</span><span class="s2">, </span><span class="s4">&quot;_y&quot;</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">copy: bool = </span><span class="s2">True,</span>
        <span class="s1">indicator: bool = </span><span class="s2">False,</span>
        <span class="s1">validate: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.merge </span><span class="s2">import </span><span class="s1">merge</span>

        <span class="s2">return </span><span class="s1">merge(</span>
            <span class="s1">self</span><span class="s2">,</span>
            <span class="s1">right</span><span class="s2">,</span>
            <span class="s1">how=how</span><span class="s2">,</span>
            <span class="s1">on=on</span><span class="s2">,</span>
            <span class="s1">left_on=left_on</span><span class="s2">,</span>
            <span class="s1">right_on=right_on</span><span class="s2">,</span>
            <span class="s1">left_index=left_index</span><span class="s2">,</span>
            <span class="s1">right_index=right_index</span><span class="s2">,</span>
            <span class="s1">sort=sort</span><span class="s2">,</span>
            <span class="s1">suffixes=suffixes</span><span class="s2">,</span>
            <span class="s1">copy=copy</span><span class="s2">,</span>
            <span class="s1">indicator=indicator</span><span class="s2">,</span>
            <span class="s1">validate=validate</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">round(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">decimals: int | dict[IndexLabel</span><span class="s2">, </span><span class="s1">int] | Series = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Round a DataFrame to a variable number of decimal places. 
 
        Parameters 
        ---------- 
        decimals : int, dict, Series 
            Number of decimal places to round each column to. If an int is 
            given, round each column to the same number of places. 
            Otherwise dict and Series round to variable numbers of places. 
            Column names should be in the keys if `decimals` is a 
            dict-like, or in the index if `decimals` is a Series. Any 
            columns not included in `decimals` will be left as is. Elements 
            of `decimals` which are not columns of the input will be 
            ignored. 
        *args 
            Additional keywords have no effect but might be accepted for 
            compatibility with numpy. 
        **kwargs 
            Additional keywords have no effect but might be accepted for 
            compatibility with numpy. 
 
        Returns 
        ------- 
        DataFrame 
            A DataFrame with the affected columns rounded to the specified 
            number of decimal places. 
 
        See Also 
        -------- 
        numpy.around : Round a numpy array to the given number of decimals. 
        Series.round : Round a Series to the given number of decimals. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)], 
        ...                   columns=['dogs', 'cats']) 
        &gt;&gt;&gt; df 
            dogs  cats 
        0  0.21  0.32 
        1  0.01  0.67 
        2  0.66  0.03 
        3  0.21  0.18 
 
        By providing an integer each column is rounded to the same number 
        of decimal places 
 
        &gt;&gt;&gt; df.round(1) 
            dogs  cats 
        0   0.2   0.3 
        1   0.0   0.7 
        2   0.7   0.0 
        3   0.2   0.2 
 
        With a dict, the number of places for specific columns can be 
        specified with the column names as key and the number of decimal 
        places as value 
 
        &gt;&gt;&gt; df.round({'dogs': 1, 'cats': 0}) 
            dogs  cats 
        0   0.2   0.0 
        1   0.0   1.0 
        2   0.7   0.0 
        3   0.2   0.0 
 
        Using a Series, the number of places for specific columns can be 
        specified with the column names as index and the number of 
        decimal places as value 
 
        &gt;&gt;&gt; decimals = pd.Series([0, 1], index=['cats', 'dogs']) 
        &gt;&gt;&gt; df.round(decimals) 
            dogs  cats 
        0   0.2   0.0 
        1   0.0   1.0 
        2   0.7   0.0 
        3   0.2   0.0 
        &quot;&quot;&quot;</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

        <span class="s2">def </span><span class="s1">_dict_round(df: DataFrame</span><span class="s2">, </span><span class="s1">decimals):</span>
            <span class="s2">for </span><span class="s1">col</span><span class="s2">, </span><span class="s1">vals </span><span class="s2">in </span><span class="s1">df.items():</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s2">yield </span><span class="s1">_series_round(vals</span><span class="s2">, </span><span class="s1">decimals[col])</span>
                <span class="s2">except </span><span class="s1">KeyError:</span>
                    <span class="s2">yield </span><span class="s1">vals</span>

        <span class="s2">def </span><span class="s1">_series_round(ser: Series</span><span class="s2">, </span><span class="s1">decimals: int):</span>
            <span class="s2">if </span><span class="s1">is_integer_dtype(ser.dtype) </span><span class="s2">or </span><span class="s1">is_float_dtype(ser.dtype):</span>
                <span class="s2">return </span><span class="s1">ser.round(decimals)</span>
            <span class="s2">return </span><span class="s1">ser</span>

        <span class="s1">nv.validate_round(args</span><span class="s2">, </span><span class="s1">kwargs)</span>

        <span class="s2">if </span><span class="s1">isinstance(decimals</span><span class="s2">, </span><span class="s1">(dict</span><span class="s2">, </span><span class="s1">Series)):</span>
            <span class="s2">if </span><span class="s1">isinstance(decimals</span><span class="s2">, </span><span class="s1">Series) </span><span class="s2">and not </span><span class="s1">decimals.index.is_unique:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;Index of decimals must be unique&quot;</span><span class="s1">)</span>
            <span class="s2">if </span><span class="s1">is_dict_like(decimals) </span><span class="s2">and not </span><span class="s1">all(</span>
                <span class="s1">is_integer(value) </span><span class="s2">for </span><span class="s1">_</span><span class="s2">, </span><span class="s1">value </span><span class="s2">in </span><span class="s1">decimals.items()</span>
            <span class="s1">):</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Values in decimals must be integers&quot;</span><span class="s1">)</span>
            <span class="s1">new_cols = list(_dict_round(self</span><span class="s2">, </span><span class="s1">decimals))</span>
        <span class="s2">elif </span><span class="s1">is_integer(decimals):</span>
            <span class="s3"># Dispatch to Series.round</span>
            <span class="s1">new_cols = [_series_round(v</span><span class="s2">, </span><span class="s1">decimals) </span><span class="s2">for </span><span class="s1">_</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">self.items()]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;decimals must be an integer, a dict-like or a Series&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">len(new_cols) &gt; </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self._constructor(</span>
                <span class="s1">concat(new_cols</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">)</span><span class="s2">, </span><span class="s1">index=self.index</span><span class="s2">, </span><span class="s1">columns=self.columns</span>
            <span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Statistical methods, etc.</span>

    <span class="s2">def </span><span class="s1">corr(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">method: str | Callable[[np.ndarray</span><span class="s2">, </span><span class="s1">np.ndarray]</span><span class="s2">, </span><span class="s1">float] = </span><span class="s4">&quot;pearson&quot;</span><span class="s2">,</span>
        <span class="s1">min_periods: int = </span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute pairwise correlation of columns, excluding NA/null values. 
 
        Parameters 
        ---------- 
        method : {'pearson', 'kendall', 'spearman'} or callable 
            Method of correlation: 
 
            * pearson : standard correlation coefficient 
            * kendall : Kendall Tau correlation coefficient 
            * spearman : Spearman rank correlation 
            * callable: callable with input two 1d ndarrays 
                and returning a float. Note that the returned matrix from corr 
                will have 1 along the diagonals and will be symmetric 
                regardless of the callable's behavior. 
        min_periods : int, optional 
            Minimum number of observations required per pair of columns 
            to have a valid result. Currently only available for Pearson 
            and Spearman correlation. 
 
        Returns 
        ------- 
        DataFrame 
            Correlation matrix. 
 
        See Also 
        -------- 
        DataFrame.corrwith : Compute pairwise correlation with another 
            DataFrame or Series. 
        Series.corr : Compute the correlation between two Series. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; def histogram_intersection(a, b): 
        ...     v = np.minimum(a, b).sum().round(decimals=1) 
        ...     return v 
        &gt;&gt;&gt; df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)], 
        ...                   columns=['dogs', 'cats']) 
        &gt;&gt;&gt; df.corr(method=histogram_intersection) 
              dogs  cats 
        dogs   1.0   0.3 
        cats   0.3   1.0 
        &quot;&quot;&quot;</span>
        <span class="s1">numeric_df = self._get_numeric_data()</span>
        <span class="s1">cols = numeric_df.columns</span>
        <span class="s1">idx = cols.copy()</span>
        <span class="s1">mat = numeric_df.to_numpy(dtype=float</span><span class="s2">, </span><span class="s1">na_value=np.nan</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">method == </span><span class="s4">&quot;pearson&quot;</span><span class="s1">:</span>
            <span class="s1">correl = libalgos.nancorr(mat</span><span class="s2">, </span><span class="s1">minp=min_periods)</span>
        <span class="s2">elif </span><span class="s1">method == </span><span class="s4">&quot;spearman&quot;</span><span class="s1">:</span>
            <span class="s1">correl = libalgos.nancorr_spearman(mat</span><span class="s2">, </span><span class="s1">minp=min_periods)</span>
        <span class="s2">elif </span><span class="s1">method == </span><span class="s4">&quot;kendall&quot; </span><span class="s2">or </span><span class="s1">callable(method):</span>
            <span class="s2">if </span><span class="s1">min_periods </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">min_periods = </span><span class="s5">1</span>
            <span class="s1">mat = mat.T</span>
            <span class="s1">corrf = nanops.get_corr_func(method)</span>
            <span class="s1">K = len(cols)</span>
            <span class="s1">correl = np.empty((K</span><span class="s2">, </span><span class="s1">K)</span><span class="s2">, </span><span class="s1">dtype=float)</span>
            <span class="s1">mask = np.isfinite(mat)</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">ac </span><span class="s2">in </span><span class="s1">enumerate(mat):</span>
                <span class="s2">for </span><span class="s1">j</span><span class="s2">, </span><span class="s1">bc </span><span class="s2">in </span><span class="s1">enumerate(mat):</span>
                    <span class="s2">if </span><span class="s1">i &gt; j:</span>
                        <span class="s2">continue</span>

                    <span class="s1">valid = mask[i] &amp; mask[j]</span>
                    <span class="s2">if </span><span class="s1">valid.sum() &lt; min_periods:</span>
                        <span class="s1">c = np.nan</span>
                    <span class="s2">elif </span><span class="s1">i == j:</span>
                        <span class="s1">c = </span><span class="s5">1.0</span>
                    <span class="s2">elif not </span><span class="s1">valid.all():</span>
                        <span class="s1">c = corrf(ac[valid]</span><span class="s2">, </span><span class="s1">bc[valid])</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">c = corrf(ac</span><span class="s2">, </span><span class="s1">bc)</span>
                    <span class="s1">correl[i</span><span class="s2">, </span><span class="s1">j] = c</span>
                    <span class="s1">correl[j</span><span class="s2">, </span><span class="s1">i] = c</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">&quot;method must be either 'pearson', &quot;</span>
                <span class="s4">&quot;'spearman', 'kendall', or a callable, &quot;</span>
                <span class="s4">f&quot;'</span><span class="s2">{</span><span class="s1">method</span><span class="s2">}</span><span class="s4">' was supplied&quot;</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">self._constructor(correl</span><span class="s2">, </span><span class="s1">index=idx</span><span class="s2">, </span><span class="s1">columns=cols)</span>

    <span class="s2">def </span><span class="s1">cov(self</span><span class="s2">, </span><span class="s1">min_periods: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">ddof: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s5">1</span><span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute pairwise covariance of columns, excluding NA/null values. 
 
        Compute the pairwise covariance among the series of a DataFrame. 
        The returned data frame is the `covariance matrix 
        &lt;https://en.wikipedia.org/wiki/Covariance_matrix&gt;`__ of the columns 
        of the DataFrame. 
 
        Both NA and null values are automatically excluded from the 
        calculation. (See the note below about bias from missing values.) 
        A threshold can be set for the minimum number of 
        observations for each value created. Comparisons with observations 
        below this threshold will be returned as ``NaN``. 
 
        This method is generally used for the analysis of time series data to 
        understand the relationship between different measures 
        across time. 
 
        Parameters 
        ---------- 
        min_periods : int, optional 
            Minimum number of observations required per pair of columns 
            to have a valid result. 
 
        ddof : int, default 1 
            Delta degrees of freedom.  The divisor used in calculations 
            is ``N - ddof``, where ``N`` represents the number of elements. 
 
            .. versionadded:: 1.1.0 
 
        Returns 
        ------- 
        DataFrame 
            The covariance matrix of the series of the DataFrame. 
 
        See Also 
        -------- 
        Series.cov : Compute covariance with another Series. 
        core.window.ExponentialMovingWindow.cov: Exponential weighted sample covariance. 
        core.window.Expanding.cov : Expanding sample covariance. 
        core.window.Rolling.cov : Rolling sample covariance. 
 
        Notes 
        ----- 
        Returns the covariance matrix of the DataFrame's time series. 
        The covariance is normalized by N-ddof. 
 
        For DataFrames that have Series that are missing data (assuming that 
        data is `missing at random 
        &lt;https://en.wikipedia.org/wiki/Missing_data#Missing_at_random&gt;`__) 
        the returned covariance matrix will be an unbiased estimate 
        of the variance and covariance between the member Series. 
 
        However, for many applications this estimate may not be acceptable 
        because the estimate covariance matrix is not guaranteed to be positive 
        semi-definite. This could lead to estimate correlations having 
        absolute values which are greater than one, and/or a non-invertible 
        covariance matrix. See `Estimation of covariance matrices 
        &lt;https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_ 
        matrices&gt;`__ for more details. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)], 
        ...                   columns=['dogs', 'cats']) 
        &gt;&gt;&gt; df.cov() 
                  dogs      cats 
        dogs  0.666667 -1.000000 
        cats -1.000000  1.666667 
 
        &gt;&gt;&gt; np.random.seed(42) 
        &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(1000, 5), 
        ...                   columns=['a', 'b', 'c', 'd', 'e']) 
        &gt;&gt;&gt; df.cov() 
                  a         b         c         d         e 
        a  0.998438 -0.020161  0.059277 -0.008943  0.014144 
        b -0.020161  1.059352 -0.008543 -0.024738  0.009826 
        c  0.059277 -0.008543  1.010670 -0.001486 -0.000271 
        d -0.008943 -0.024738 -0.001486  0.921297 -0.013692 
        e  0.014144  0.009826 -0.000271 -0.013692  0.977795 
 
        **Minimum number of periods** 
 
        This method also supports an optional ``min_periods`` keyword 
        that specifies the required minimum number of non-NA observations for 
        each column pair in order to have a valid result: 
 
        &gt;&gt;&gt; np.random.seed(42) 
        &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(20, 3), 
        ...                   columns=['a', 'b', 'c']) 
        &gt;&gt;&gt; df.loc[df.index[:5], 'a'] = np.nan 
        &gt;&gt;&gt; df.loc[df.index[5:10], 'b'] = np.nan 
        &gt;&gt;&gt; df.cov(min_periods=12) 
                  a         b         c 
        a  0.316741       NaN -0.150812 
        b       NaN  1.248003  0.191417 
        c -0.150812  0.191417  0.895202 
        &quot;&quot;&quot;</span>
        <span class="s1">numeric_df = self._get_numeric_data()</span>
        <span class="s1">cols = numeric_df.columns</span>
        <span class="s1">idx = cols.copy()</span>
        <span class="s1">mat = numeric_df.to_numpy(dtype=float</span><span class="s2">, </span><span class="s1">na_value=np.nan</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">notna(mat).all():</span>
            <span class="s2">if </span><span class="s1">min_periods </span><span class="s2">is not None and </span><span class="s1">min_periods &gt; len(mat):</span>
                <span class="s1">base_cov = np.empty((mat.shape[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">mat.shape[</span><span class="s5">1</span><span class="s1">]))</span>
                <span class="s1">base_cov.fill(np.nan)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">base_cov = np.cov(mat.T</span><span class="s2">, </span><span class="s1">ddof=ddof)</span>
            <span class="s1">base_cov = base_cov.reshape((len(cols)</span><span class="s2">, </span><span class="s1">len(cols)))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">base_cov = libalgos.nancorr(mat</span><span class="s2">, </span><span class="s1">cov=</span><span class="s2">True, </span><span class="s1">minp=min_periods)</span>

        <span class="s2">return </span><span class="s1">self._constructor(base_cov</span><span class="s2">, </span><span class="s1">index=idx</span><span class="s2">, </span><span class="s1">columns=cols)</span>

    <span class="s2">def </span><span class="s1">corrwith(self</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">drop=</span><span class="s2">False, </span><span class="s1">method=</span><span class="s4">&quot;pearson&quot;</span><span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Compute pairwise correlation. 
 
        Pairwise correlation is computed between rows or columns of 
        DataFrame with rows or columns of Series or DataFrame. DataFrames 
        are first aligned along both axes before computing the 
        correlations. 
 
        Parameters 
        ---------- 
        other : DataFrame, Series 
            Object with which to compute correlations. 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to use. 0 or 'index' to compute column-wise, 1 or 'columns' for 
            row-wise. 
        drop : bool, default False 
            Drop missing indices from result. 
        method : {'pearson', 'kendall', 'spearman'} or callable 
            Method of correlation: 
 
            * pearson : standard correlation coefficient 
            * kendall : Kendall Tau correlation coefficient 
            * spearman : Spearman rank correlation 
            * callable: callable with input two 1d ndarrays 
                and returning a float. 
 
        Returns 
        ------- 
        Series 
            Pairwise correlations. 
 
        See Also 
        -------- 
        DataFrame.corr : Compute pairwise correlation of columns. 
        &quot;&quot;&quot;</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>
        <span class="s1">this = self._get_numeric_data()</span>

        <span class="s2">if </span><span class="s1">isinstance(other</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s2">return </span><span class="s1">this.apply(</span><span class="s2">lambda </span><span class="s1">x: other.corr(x</span><span class="s2">, </span><span class="s1">method=method)</span><span class="s2">, </span><span class="s1">axis=axis)</span>

        <span class="s1">other = other._get_numeric_data()</span>
        <span class="s1">left</span><span class="s2">, </span><span class="s1">right = this.align(other</span><span class="s2">, </span><span class="s1">join=</span><span class="s4">&quot;inner&quot;</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">left = left.T</span>
            <span class="s1">right = right.T</span>

        <span class="s2">if </span><span class="s1">method == </span><span class="s4">&quot;pearson&quot;</span><span class="s1">:</span>
            <span class="s3"># mask missing values</span>
            <span class="s1">left = left + right * </span><span class="s5">0</span>
            <span class="s1">right = right + left * </span><span class="s5">0</span>

            <span class="s3"># demeaned data</span>
            <span class="s1">ldem = left - left.mean()</span>
            <span class="s1">rdem = right - right.mean()</span>

            <span class="s1">num = (ldem * rdem).sum()</span>
            <span class="s1">dom = (left.count() - </span><span class="s5">1</span><span class="s1">) * left.std() * right.std()</span>

            <span class="s1">correl = num / dom</span>

        <span class="s2">elif </span><span class="s1">method </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;kendall&quot;</span><span class="s2">, </span><span class="s4">&quot;spearman&quot;</span><span class="s1">] </span><span class="s2">or </span><span class="s1">callable(method):</span>

            <span class="s2">def </span><span class="s1">c(x):</span>
                <span class="s2">return </span><span class="s1">nanops.nancorr(x[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">x[</span><span class="s5">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">method=method)</span>

            <span class="s1">correl = self._constructor_sliced(</span>
                <span class="s1">map(c</span><span class="s2">, </span><span class="s1">zip(left.values.T</span><span class="s2">, </span><span class="s1">right.values.T))</span><span class="s2">, </span><span class="s1">index=left.columns</span>
            <span class="s1">)</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span>
                <span class="s4">f&quot;Invalid method </span><span class="s2">{</span><span class="s1">method</span><span class="s2">} </span><span class="s4">was passed, &quot;</span>
                <span class="s4">&quot;valid methods are: 'pearson', 'kendall', &quot;</span>
                <span class="s4">&quot;'spearman', or callable&quot;</span>
            <span class="s1">)</span>

        <span class="s2">if not </span><span class="s1">drop:</span>
            <span class="s3"># Find non-matching labels along the given axis</span>
            <span class="s3"># and append missing correlations (GH 22375)</span>
            <span class="s1">raxis = </span><span class="s5">1 </span><span class="s2">if </span><span class="s1">axis == </span><span class="s5">0 </span><span class="s2">else </span><span class="s5">0</span>
            <span class="s1">result_index = this._get_axis(raxis).union(other._get_axis(raxis))</span>
            <span class="s1">idx_diff = result_index.difference(correl.index)</span>

            <span class="s2">if </span><span class="s1">len(idx_diff) &gt; </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s1">correl = correl._append(</span>
                    <span class="s1">Series([np.nan] * len(idx_diff)</span><span class="s2">, </span><span class="s1">index=idx_diff)</span>
                <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">correl</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># ndarray-like stats methods</span>

    <span class="s2">def </span><span class="s1">count(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">level: Level | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">numeric_only: bool = </span><span class="s2">False</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Count non-NA cells for each column or row. 
 
        The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending 
        on `pandas.options.mode.use_inf_as_na`) are considered NA. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            If 0 or 'index' counts are generated for each column. 
            If 1 or 'columns' counts are generated for each row. 
        level : int or str, optional 
            If the axis is a `MultiIndex` (hierarchical), count along a 
            particular `level`, collapsing into a `DataFrame`. 
            A `str` specifies the level name. 
        numeric_only : bool, default False 
            Include only `float`, `int` or `boolean` data. 
 
        Returns 
        ------- 
        Series or DataFrame 
            For each column/row the number of non-NA/null entries. 
            If `level` is specified returns a `DataFrame`. 
 
        See Also 
        -------- 
        Series.count: Number of non-NA elements in a Series. 
        DataFrame.value_counts: Count unique combinations of columns. 
        DataFrame.shape: Number of DataFrame rows and columns (including NA 
            elements). 
        DataFrame.isna: Boolean same-sized DataFrame showing places of NA 
            elements. 
 
        Examples 
        -------- 
        Constructing DataFrame from a dictionary: 
 
        &gt;&gt;&gt; df = pd.DataFrame({&quot;Person&quot;: 
        ...                    [&quot;John&quot;, &quot;Myla&quot;, &quot;Lewis&quot;, &quot;John&quot;, &quot;Myla&quot;], 
        ...                    &quot;Age&quot;: [24., np.nan, 21., 33, 26], 
        ...                    &quot;Single&quot;: [False, True, True, True, False]}) 
        &gt;&gt;&gt; df 
           Person   Age  Single 
        0    John  24.0   False 
        1    Myla   NaN    True 
        2   Lewis  21.0    True 
        3    John  33.0    True 
        4    Myla  26.0   False 
 
        Notice the uncounted NA values: 
 
        &gt;&gt;&gt; df.count() 
        Person    5 
        Age       4 
        Single    5 
        dtype: int64 
 
        Counts for each **row**: 
 
        &gt;&gt;&gt; df.count(axis='columns') 
        0    3 
        1    2 
        2    3 
        3    3 
        4    3 
        dtype: int64 
        &quot;&quot;&quot;</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>
        <span class="s2">if </span><span class="s1">level </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;Using the level keyword in DataFrame and Series aggregations is &quot;</span>
                <span class="s4">&quot;deprecated and will be removed in a future version. Use groupby &quot;</span>
                <span class="s4">&quot;instead. df.count(level=1) should use df.groupby(level=1).count().&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">self._count_level(level</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only)</span>

        <span class="s2">if </span><span class="s1">numeric_only:</span>
            <span class="s1">frame = self._get_numeric_data()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">frame = self</span>

        <span class="s3"># GH #423</span>
        <span class="s2">if </span><span class="s1">len(frame._get_axis(axis)) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s1">result = self._constructor_sliced(</span><span class="s5">0</span><span class="s2">, </span><span class="s1">index=frame._get_agg_axis(axis))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if </span><span class="s1">frame._is_mixed_type </span><span class="s2">or </span><span class="s1">frame._mgr.any_extension_types:</span>
                <span class="s3"># the or any_extension_types is really only hit for single-</span>
                <span class="s3"># column frames with an extension array</span>
                <span class="s1">result = notna(frame).sum(axis=axis)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># GH13407</span>
                <span class="s1">series_counts = notna(frame).sum(axis=axis)</span>
                <span class="s1">counts = series_counts.values</span>
                <span class="s1">result = self._constructor_sliced(</span>
                    <span class="s1">counts</span><span class="s2">, </span><span class="s1">index=frame._get_agg_axis(axis)</span>
                <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">result.astype(</span><span class="s4">&quot;int64&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_count_level(self</span><span class="s2">, </span><span class="s1">level: Level</span><span class="s2">, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">numeric_only: bool = </span><span class="s2">False</span><span class="s1">):</span>
        <span class="s2">if </span><span class="s1">numeric_only:</span>
            <span class="s1">frame = self._get_numeric_data()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">frame = self</span>

        <span class="s1">count_axis = frame._get_axis(axis)</span>
        <span class="s1">agg_axis = frame._get_agg_axis(axis)</span>

        <span class="s2">if not </span><span class="s1">isinstance(count_axis</span><span class="s2">, </span><span class="s1">MultiIndex):</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span>
                <span class="s4">f&quot;Can only count levels on hierarchical </span><span class="s2">{</span><span class="s1">self._get_axis_name(axis)</span><span class="s2">}</span><span class="s4">.&quot;</span>
            <span class="s1">)</span>

        <span class="s3"># Mask NaNs: Mask rows or columns where the index level is NaN, and all</span>
        <span class="s3"># values in the DataFrame that are NaN</span>
        <span class="s2">if </span><span class="s1">frame._is_mixed_type:</span>
            <span class="s3"># Since we have mixed types, calling notna(frame.values) might</span>
            <span class="s3"># upcast everything to object</span>
            <span class="s1">values_mask = notna(frame).values</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># But use the speedup when we have homogeneous dtypes</span>
            <span class="s1">values_mask = notna(frame.values)</span>

        <span class="s1">index_mask = notna(count_axis.get_level_values(level=level))</span>
        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">mask = index_mask &amp; values_mask</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">mask = index_mask.reshape(-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) &amp; values_mask</span>

        <span class="s2">if </span><span class="s1">isinstance(level</span><span class="s2">, </span><span class="s1">str):</span>
            <span class="s1">level = count_axis._get_level_number(level)</span>

        <span class="s1">level_name = count_axis._names[level]</span>
        <span class="s1">level_index = count_axis.levels[level]._rename(name=level_name)</span>
        <span class="s1">level_codes = ensure_platform_int(count_axis.codes[level])</span>
        <span class="s1">counts = lib.count_level_2d(mask</span><span class="s2">, </span><span class="s1">level_codes</span><span class="s2">, </span><span class="s1">len(level_index)</span><span class="s2">, </span><span class="s1">axis=axis)</span>

        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">result = self._constructor(counts</span><span class="s2">, </span><span class="s1">index=agg_axis</span><span class="s2">, </span><span class="s1">columns=level_index)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = self._constructor(counts</span><span class="s2">, </span><span class="s1">index=level_index</span><span class="s2">, </span><span class="s1">columns=agg_axis)</span>

        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_reduce(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">op</span><span class="s2">,</span>
        <span class="s1">name: str</span><span class="s2">,</span>
        <span class="s1">*</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">skipna: bool = </span><span class="s2">True,</span>
        <span class="s1">numeric_only: bool | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">filter_type=</span><span class="s2">None,</span>
        <span class="s1">**kwds</span><span class="s2">,</span>
    <span class="s1">):</span>

        <span class="s2">assert </span><span class="s1">filter_type </span><span class="s2">is None or </span><span class="s1">filter_type == </span><span class="s4">&quot;bool&quot;</span><span class="s2">, </span><span class="s1">filter_type</span>
        <span class="s1">out_dtype = </span><span class="s4">&quot;bool&quot; </span><span class="s2">if </span><span class="s1">filter_type == </span><span class="s4">&quot;bool&quot; </span><span class="s2">else None</span>

        <span class="s2">if </span><span class="s1">numeric_only </span><span class="s2">is None and </span><span class="s1">name </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;mean&quot;</span><span class="s2">, </span><span class="s4">&quot;median&quot;</span><span class="s1">]:</span>
            <span class="s1">own_dtypes = [arr.dtype </span><span class="s2">for </span><span class="s1">arr </span><span class="s2">in </span><span class="s1">self._mgr.arrays]</span>

            <span class="s1">dtype_is_dt = np.array(</span>
                <span class="s1">[is_datetime64_any_dtype(dtype) </span><span class="s2">for </span><span class="s1">dtype </span><span class="s2">in </span><span class="s1">own_dtypes]</span><span class="s2">,</span>
                <span class="s1">dtype=bool</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s2">if </span><span class="s1">dtype_is_dt.any():</span>
                <span class="s1">warnings.warn(</span>
                    <span class="s4">&quot;DataFrame.mean and DataFrame.median with numeric_only=None &quot;</span>
                    <span class="s4">&quot;will include datetime64 and datetime64tz columns in a &quot;</span>
                    <span class="s4">&quot;future version.&quot;</span><span class="s2">,</span>
                    <span class="s1">FutureWarning</span><span class="s2">,</span>
                    <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
                <span class="s1">)</span>
                <span class="s3"># Non-copy equivalent to</span>
                <span class="s3">#  dt64_cols = self.dtypes.apply(is_datetime64_any_dtype)</span>
                <span class="s3">#  cols = self.columns[~dt64_cols]</span>
                <span class="s3">#  self = self[cols]</span>
                <span class="s1">predicate = </span><span class="s2">lambda </span><span class="s1">x: </span><span class="s2">not </span><span class="s1">is_datetime64_any_dtype(x.dtype)</span>
                <span class="s1">mgr = self._mgr._get_data_subset(predicate)</span>
                <span class="s1">self = type(self)(mgr)</span>

        <span class="s3"># TODO: Make other agg func handle axis=None properly GH#21597</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>
        <span class="s1">labels = self._get_agg_axis(axis)</span>
        <span class="s2">assert </span><span class="s1">axis </span><span class="s2">in </span><span class="s1">[</span><span class="s5">0</span><span class="s2">, </span><span class="s5">1</span><span class="s1">]</span>

        <span class="s2">def </span><span class="s1">func(values: np.ndarray):</span>
            <span class="s3"># We only use this in the case that operates on self.values</span>
            <span class="s2">return </span><span class="s1">op(values</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s2">def </span><span class="s1">blk_func(values</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">ExtensionArray):</span>
                <span class="s2">if not </span><span class="s1">is_1d_only_ea_obj(values) </span><span class="s2">and not </span><span class="s1">isinstance(</span>
                    <span class="s1">self._mgr</span><span class="s2">, </span><span class="s1">ArrayManager</span>
                <span class="s1">):</span>
                    <span class="s2">return </span><span class="s1">values._reduce(name</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">**kwds)</span>
                <span class="s2">return </span><span class="s1">values._reduce(name</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">**kwds)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">op(values</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">**kwds)</span>

        <span class="s2">def </span><span class="s1">_get_data() -&gt; DataFrame:</span>
            <span class="s2">if </span><span class="s1">filter_type </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s1">data = self._get_numeric_data()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># GH#25101, GH#24434</span>
                <span class="s2">assert </span><span class="s1">filter_type == </span><span class="s4">&quot;bool&quot;</span>
                <span class="s1">data = self._get_bool_data()</span>
            <span class="s2">return </span><span class="s1">data</span>

        <span class="s2">if </span><span class="s1">numeric_only </span><span class="s2">is not None or </span><span class="s1">axis == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># For numeric_only non-None and axis non-None, we know</span>
            <span class="s3">#  which blocks to use and no try/except is needed.</span>
            <span class="s3">#  For numeric_only=None only the case with axis==0 and no object</span>
            <span class="s3">#  dtypes are unambiguous can be handled with BlockManager.reduce</span>
            <span class="s3"># Case with EAs see GH#35881</span>
            <span class="s1">df = self</span>
            <span class="s2">if </span><span class="s1">numeric_only </span><span class="s2">is True</span><span class="s1">:</span>
                <span class="s1">df = _get_data()</span>
            <span class="s2">if </span><span class="s1">axis == </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">df = df.T</span>
                <span class="s1">axis = </span><span class="s5">0</span>

            <span class="s1">ignore_failures = numeric_only </span><span class="s2">is None</span>

            <span class="s3"># After possibly _get_data and transposing, we are now in the</span>
            <span class="s3">#  simple case where we can use BlockManager.reduce</span>
            <span class="s1">res</span><span class="s2">, </span><span class="s1">_ = df._mgr.reduce(blk_func</span><span class="s2">, </span><span class="s1">ignore_failures=ignore_failures)</span>
            <span class="s1">out = df._constructor(res).iloc[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s2">if </span><span class="s1">out_dtype </span><span class="s2">is not None</span><span class="s1">:</span>
                <span class="s1">out = out.astype(out_dtype)</span>
            <span class="s2">if </span><span class="s1">axis == </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">len(self) == </span><span class="s5">0 </span><span class="s2">and </span><span class="s1">name </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;sum&quot;</span><span class="s2">, </span><span class="s4">&quot;prod&quot;</span><span class="s1">]:</span>
                <span class="s3"># Even if we are object dtype, follow numpy and return</span>
                <span class="s3">#  float64, see test_apply_funcs_over_empty</span>
                <span class="s1">out = out.astype(np.float64)</span>

            <span class="s2">if </span><span class="s1">numeric_only </span><span class="s2">is None and </span><span class="s1">out.shape[</span><span class="s5">0</span><span class="s1">] != df.shape[</span><span class="s5">1</span><span class="s1">]:</span>
                <span class="s3"># columns have been dropped GH#41480</span>
                <span class="s1">arg_name = </span><span class="s4">&quot;numeric_only&quot;</span>
                <span class="s2">if </span><span class="s1">name </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;all&quot;</span><span class="s2">, </span><span class="s4">&quot;any&quot;</span><span class="s1">]:</span>
                    <span class="s1">arg_name = </span><span class="s4">&quot;bool_only&quot;</span>
                <span class="s1">warnings.warn(</span>
                    <span class="s4">&quot;Dropping of nuisance columns in DataFrame reductions &quot;</span>
                    <span class="s4">f&quot;(with '</span><span class="s2">{</span><span class="s1">arg_name</span><span class="s2">}</span><span class="s4">=None') is deprecated; in a future &quot;</span>
                    <span class="s4">&quot;version this will raise TypeError.  Select only valid &quot;</span>
                    <span class="s4">&quot;columns before calling the reduction.&quot;</span><span class="s2">,</span>
                    <span class="s1">FutureWarning</span><span class="s2">,</span>
                    <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
                <span class="s1">)</span>

            <span class="s2">return </span><span class="s1">out</span>

        <span class="s2">assert </span><span class="s1">numeric_only </span><span class="s2">is None</span>

        <span class="s1">data = self</span>
        <span class="s1">values = data.values</span>

        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">result = func(values)</span>

        <span class="s2">except </span><span class="s1">TypeError:</span>
            <span class="s3"># e.g. in nanops trying to convert strs to float</span>

            <span class="s1">data = _get_data()</span>
            <span class="s1">labels = data._get_agg_axis(axis)</span>

            <span class="s1">values = data.values</span>
            <span class="s2">with </span><span class="s1">np.errstate(all=</span><span class="s4">&quot;ignore&quot;</span><span class="s1">):</span>
                <span class="s1">result = func(values)</span>

            <span class="s3"># columns have been dropped GH#41480</span>
            <span class="s1">arg_name = </span><span class="s4">&quot;numeric_only&quot;</span>
            <span class="s2">if </span><span class="s1">name </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;all&quot;</span><span class="s2">, </span><span class="s4">&quot;any&quot;</span><span class="s1">]:</span>
                <span class="s1">arg_name = </span><span class="s4">&quot;bool_only&quot;</span>
            <span class="s1">warnings.warn(</span>
                <span class="s4">&quot;Dropping of nuisance columns in DataFrame reductions &quot;</span>
                <span class="s4">f&quot;(with '</span><span class="s2">{</span><span class="s1">arg_name</span><span class="s2">}</span><span class="s4">=None') is deprecated; in a future &quot;</span>
                <span class="s4">&quot;version this will raise TypeError.  Select only valid &quot;</span>
                <span class="s4">&quot;columns before calling the reduction.&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s2">if </span><span class="s1">hasattr(result</span><span class="s2">, </span><span class="s4">&quot;dtype&quot;</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">filter_type == </span><span class="s4">&quot;bool&quot; </span><span class="s2">and </span><span class="s1">notna(result).all():</span>
                <span class="s1">result = result.astype(np.bool_)</span>
            <span class="s2">elif </span><span class="s1">filter_type </span><span class="s2">is None and </span><span class="s1">is_object_dtype(result.dtype):</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">result = result.astype(np.float64)</span>
                <span class="s2">except </span><span class="s1">(ValueError</span><span class="s2">, </span><span class="s1">TypeError):</span>
                    <span class="s3"># try to coerce to the original dtypes item by item if we can</span>
                    <span class="s2">pass</span>

        <span class="s1">result = self._constructor_sliced(result</span><span class="s2">, </span><span class="s1">index=labels)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_reduce_axis1(self</span><span class="s2">, </span><span class="s1">name: str</span><span class="s2">, </span><span class="s1">func</span><span class="s2">, </span><span class="s1">skipna: bool) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Special case for _reduce to try to avoid a potentially-expensive transpose. 
 
        Apply the reduction block-wise along axis=1 and then reduce the resulting 
        1D arrays. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">name == </span><span class="s4">&quot;all&quot;</span><span class="s1">:</span>
            <span class="s1">result = np.ones(len(self)</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
            <span class="s1">ufunc = np.logical_and</span>
        <span class="s2">elif </span><span class="s1">name == </span><span class="s4">&quot;any&quot;</span><span class="s1">:</span>
            <span class="s1">result = np.zeros(len(self)</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
            <span class="s3"># error: Incompatible types in assignment</span>
            <span class="s3"># (expression has type &quot;_UFunc_Nin2_Nout1[Literal['logical_or'],</span>
            <span class="s3"># Literal[20], Literal[False]]&quot;, variable has type</span>
            <span class="s3"># &quot;_UFunc_Nin2_Nout1[Literal['logical_and'], Literal[20],</span>
            <span class="s3"># Literal[True]]&quot;)</span>
            <span class="s1">ufunc = np.logical_or  </span><span class="s3"># type: ignore[assignment]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">NotImplementedError(name)</span>

        <span class="s2">for </span><span class="s1">arr </span><span class="s2">in </span><span class="s1">self._mgr.arrays:</span>
            <span class="s1">middle = func(arr</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">skipna=skipna)</span>
            <span class="s1">result = ufunc(result</span><span class="s2">, </span><span class="s1">middle)</span>

        <span class="s1">res_ser = self._constructor_sliced(result</span><span class="s2">, </span><span class="s1">index=self.index)</span>
        <span class="s2">return </span><span class="s1">res_ser</span>

    <span class="s2">def </span><span class="s1">nunique(self</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Count number of distinct elements in specified axis. 
 
        Return Series with number of distinct elements. Can ignore NaN 
        values. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for 
            column-wise. 
        dropna : bool, default True 
            Don't include NaN in the counts. 
 
        Returns 
        ------- 
        Series 
 
        See Also 
        -------- 
        Series.nunique: Method nunique for Series. 
        DataFrame.count: Count non-NA cells for each column or row. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]}) 
        &gt;&gt;&gt; df.nunique() 
        A    3 
        B    2 
        dtype: int64 
 
        &gt;&gt;&gt; df.nunique(axis=1) 
        0    1 
        1    2 
        2    2 
        dtype: int64 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.apply(Series.nunique</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">dropna=dropna)</span>

    <span class="s2">def </span><span class="s1">idxmin(self</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">skipna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return index of first occurrence of minimum over requested axis. 
 
        NA/null values are excluded. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise. 
        skipna : bool, default True 
            Exclude NA/null values. If an entire row/column is NA, the result 
            will be NA. 
 
        Returns 
        ------- 
        Series 
            Indexes of minima along the specified axis. 
 
        Raises 
        ------ 
        ValueError 
            * If the row/column is empty 
 
        See Also 
        -------- 
        Series.idxmin : Return index of the minimum element. 
 
        Notes 
        ----- 
        This method is the DataFrame version of ``ndarray.argmin``. 
 
        Examples 
        -------- 
        Consider a dataset containing food consumption in Argentina. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48], 
        ...                    'co2_emissions': [37.2, 19.66, 1712]}, 
        ...                    index=['Pork', 'Wheat Products', 'Beef']) 
 
        &gt;&gt;&gt; df 
                        consumption  co2_emissions 
        Pork                  10.51         37.20 
        Wheat Products       103.11         19.66 
        Beef                  55.48       1712.00 
 
        By default, it returns the index for the minimum value in each column. 
 
        &gt;&gt;&gt; df.idxmin() 
        consumption                Pork 
        co2_emissions    Wheat Products 
        dtype: object 
 
        To return the index for the minimum value in each row, use ``axis=&quot;columns&quot;``. 
 
        &gt;&gt;&gt; df.idxmin(axis=&quot;columns&quot;) 
        Pork                consumption 
        Wheat Products    co2_emissions 
        Beef                consumption 
        dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>

        <span class="s1">res = self._reduce(</span>
            <span class="s1">nanops.nanargmin</span><span class="s2">, </span><span class="s4">&quot;argmin&quot;</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">numeric_only=</span><span class="s2">False</span>
        <span class="s1">)</span>
        <span class="s1">indices = res._values</span>

        <span class="s3"># indices will always be np.ndarray since axis is not None and</span>
        <span class="s3"># values is a 2d array for DataFrame</span>
        <span class="s3"># error: Item &quot;int&quot; of &quot;Union[int, Any]&quot; has no attribute &quot;__iter__&quot;</span>
        <span class="s2">assert </span><span class="s1">isinstance(indices</span><span class="s2">, </span><span class="s1">np.ndarray)  </span><span class="s3"># for mypy</span>

        <span class="s1">index = self._get_axis(axis)</span>
        <span class="s1">result = [index[i] </span><span class="s2">if </span><span class="s1">i &gt;= </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">np.nan </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">indices]</span>
        <span class="s2">return </span><span class="s1">self._constructor_sliced(result</span><span class="s2">, </span><span class="s1">index=self._get_agg_axis(axis))</span>

    <span class="s2">def </span><span class="s1">idxmax(self</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">skipna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; Series:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return index of first occurrence of maximum over requested axis. 
 
        NA/null values are excluded. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for column-wise. 
        skipna : bool, default True 
            Exclude NA/null values. If an entire row/column is NA, the result 
            will be NA. 
 
        Returns 
        ------- 
        Series 
            Indexes of maxima along the specified axis. 
 
        Raises 
        ------ 
        ValueError 
            * If the row/column is empty 
 
        See Also 
        -------- 
        Series.idxmax : Return index of the maximum element. 
 
        Notes 
        ----- 
        This method is the DataFrame version of ``ndarray.argmax``. 
 
        Examples 
        -------- 
        Consider a dataset containing food consumption in Argentina. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'consumption': [10.51, 103.11, 55.48], 
        ...                    'co2_emissions': [37.2, 19.66, 1712]}, 
        ...                    index=['Pork', 'Wheat Products', 'Beef']) 
 
        &gt;&gt;&gt; df 
                        consumption  co2_emissions 
        Pork                  10.51         37.20 
        Wheat Products       103.11         19.66 
        Beef                  55.48       1712.00 
 
        By default, it returns the index for the maximum value in each column. 
 
        &gt;&gt;&gt; df.idxmax() 
        consumption     Wheat Products 
        co2_emissions             Beef 
        dtype: object 
 
        To return the index for the maximum value in each row, use ``axis=&quot;columns&quot;``. 
 
        &gt;&gt;&gt; df.idxmax(axis=&quot;columns&quot;) 
        Pork              co2_emissions 
        Wheat Products     consumption 
        Beef              co2_emissions 
        dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>

        <span class="s1">res = self._reduce(</span>
            <span class="s1">nanops.nanargmax</span><span class="s2">, </span><span class="s4">&quot;argmax&quot;</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">skipna=skipna</span><span class="s2">, </span><span class="s1">numeric_only=</span><span class="s2">False</span>
        <span class="s1">)</span>
        <span class="s1">indices = res._values</span>

        <span class="s3"># indices will always be np.ndarray since axis is not None and</span>
        <span class="s3"># values is a 2d array for DataFrame</span>
        <span class="s3"># error: Item &quot;int&quot; of &quot;Union[int, Any]&quot; has no attribute &quot;__iter__&quot;</span>
        <span class="s2">assert </span><span class="s1">isinstance(indices</span><span class="s2">, </span><span class="s1">np.ndarray)  </span><span class="s3"># for mypy</span>

        <span class="s1">index = self._get_axis(axis)</span>
        <span class="s1">result = [index[i] </span><span class="s2">if </span><span class="s1">i &gt;= </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">np.nan </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">indices]</span>
        <span class="s2">return </span><span class="s1">self._constructor_sliced(result</span><span class="s2">, </span><span class="s1">index=self._get_agg_axis(axis))</span>

    <span class="s2">def </span><span class="s1">_get_agg_axis(self</span><span class="s2">, </span><span class="s1">axis_num: int) -&gt; Index:</span>
        <span class="s0">&quot;&quot;&quot; 
        Let's be explicit about this. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">axis_num == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.columns</span>
        <span class="s2">elif </span><span class="s1">axis_num == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.index</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;Axis must be 0 or 1 (got </span><span class="s2">{</span><span class="s1">repr(axis_num)</span><span class="s2">}</span><span class="s4">)&quot;</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">mode(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">numeric_only: bool = </span><span class="s2">False, </span><span class="s1">dropna: bool = </span><span class="s2">True</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Get the mode(s) of each element along the selected axis. 
 
        The mode of a set of values is the value that appears most often. 
        It can be multiple values. 
 
        Parameters 
        ---------- 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to iterate over while searching for the mode: 
 
            * 0 or 'index' : get mode of each column 
            * 1 or 'columns' : get mode of each row. 
 
        numeric_only : bool, default False 
            If True, only apply to numeric columns. 
        dropna : bool, default True 
            Don't consider counts of NaN/NaT. 
 
        Returns 
        ------- 
        DataFrame 
            The modes of each column or row. 
 
        See Also 
        -------- 
        Series.mode : Return the highest frequency value in a Series. 
        Series.value_counts : Return the counts of values in a Series. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame([('bird', 2, 2), 
        ...                    ('mammal', 4, np.nan), 
        ...                    ('arthropod', 8, 0), 
        ...                    ('bird', 2, np.nan)], 
        ...                   index=('falcon', 'horse', 'spider', 'ostrich'), 
        ...                   columns=('species', 'legs', 'wings')) 
        &gt;&gt;&gt; df 
                   species  legs  wings 
        falcon        bird     2    2.0 
        horse       mammal     4    NaN 
        spider   arthropod     8    0.0 
        ostrich       bird     2    NaN 
 
        By default, missing values are not considered, and the mode of wings 
        are both 0 and 2. Because the resulting DataFrame has two rows, 
        the second row of ``species`` and ``legs`` contains ``NaN``. 
 
        &gt;&gt;&gt; df.mode() 
          species  legs  wings 
        0    bird   2.0    0.0 
        1     NaN   NaN    2.0 
 
        Setting ``dropna=False`` ``NaN`` values are considered and they can be 
        the mode (like for wings). 
 
        &gt;&gt;&gt; df.mode(dropna=False) 
          species  legs  wings 
        0    bird     2    NaN 
 
        Setting ``numeric_only=True``, only the mode of numeric columns is 
        computed, and columns of other types are ignored. 
 
        &gt;&gt;&gt; df.mode(numeric_only=True) 
           legs  wings 
        0   2.0    0.0 
        1   NaN    2.0 
 
        To compute the mode over columns and not rows, use the axis parameter: 
 
        &gt;&gt;&gt; df.mode(axis='columns', numeric_only=True) 
                   0    1 
        falcon   2.0  NaN 
        horse    4.0  NaN 
        spider   0.0  8.0 
        ostrich  2.0  NaN 
        &quot;&quot;&quot;</span>
        <span class="s1">data = self </span><span class="s2">if not </span><span class="s1">numeric_only </span><span class="s2">else </span><span class="s1">self._get_numeric_data()</span>

        <span class="s2">def </span><span class="s1">f(s):</span>
            <span class="s2">return </span><span class="s1">s.mode(dropna=dropna)</span>

        <span class="s1">data = data.apply(f</span><span class="s2">, </span><span class="s1">axis=axis)</span>
        <span class="s3"># Ensure index is type stable (should always use int index)</span>
        <span class="s2">if </span><span class="s1">data.empty:</span>
            <span class="s1">data.index = default_index(</span><span class="s5">0</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">data</span>

    <span class="s2">def </span><span class="s1">quantile(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">q=</span><span class="s5">0.5</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">numeric_only: bool = </span><span class="s2">True,</span>
        <span class="s1">interpolation: str = </span><span class="s4">&quot;linear&quot;</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return values at the given quantile over requested axis. 
 
        Parameters 
        ---------- 
        q : float or array-like, default 0.5 (50% quantile) 
            Value between 0 &lt;= q &lt;= 1, the quantile(s) to compute. 
        axis : {0, 1, 'index', 'columns'}, default 0 
            Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise. 
        numeric_only : bool, default True 
            If False, the quantile of datetime and timedelta data will be 
            computed as well. 
        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'} 
            This optional parameter specifies the interpolation method to use, 
            when the desired quantile lies between two data points `i` and `j`: 
 
            * linear: `i + (j - i) * fraction`, where `fraction` is the 
              fractional part of the index surrounded by `i` and `j`. 
            * lower: `i`. 
            * higher: `j`. 
            * nearest: `i` or `j` whichever is nearest. 
            * midpoint: (`i` + `j`) / 2. 
 
        Returns 
        ------- 
        Series or DataFrame 
 
            If ``q`` is an array, a DataFrame will be returned where the 
              index is ``q``, the columns are the columns of self, and the 
              values are the quantiles. 
            If ``q`` is a float, a Series will be returned where the 
              index is the columns of self and the values are the quantiles. 
 
        See Also 
        -------- 
        core.window.Rolling.quantile: Rolling quantile. 
        numpy.percentile: Numpy function to compute the percentile. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]), 
        ...                   columns=['a', 'b']) 
        &gt;&gt;&gt; df.quantile(.1) 
        a    1.3 
        b    3.7 
        Name: 0.1, dtype: float64 
        &gt;&gt;&gt; df.quantile([.1, .5]) 
               a     b 
        0.1  1.3   3.7 
        0.5  2.5  55.0 
 
        Specifying `numeric_only=False` will also compute the quantile of 
        datetime and timedelta data. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'A': [1, 2], 
        ...                    'B': [pd.Timestamp('2010'), 
        ...                          pd.Timestamp('2011')], 
        ...                    'C': [pd.Timedelta('1 days'), 
        ...                          pd.Timedelta('2 days')]}) 
        &gt;&gt;&gt; df.quantile(0.5, numeric_only=False) 
        A                    1.5 
        B    2010-07-02 12:00:00 
        C        1 days 12:00:00 
        Name: 0.5, dtype: object 
        &quot;&quot;&quot;</span>
        <span class="s1">validate_percentile(q)</span>

        <span class="s2">if not </span><span class="s1">is_list_like(q):</span>
            <span class="s3"># BlockManager.quantile expects listlike, so we wrap and unwrap here</span>
            <span class="s1">res = self.quantile(</span>
                <span class="s1">[q]</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">numeric_only=numeric_only</span><span class="s2">, </span><span class="s1">interpolation=interpolation</span>
            <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">res.iloc[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s1">q = Index(q</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>
        <span class="s1">data = self._get_numeric_data() </span><span class="s2">if </span><span class="s1">numeric_only </span><span class="s2">else </span><span class="s1">self</span>
        <span class="s1">axis = self._get_axis_number(axis)</span>

        <span class="s2">if </span><span class="s1">axis == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s1">data = data.T</span>

        <span class="s2">if </span><span class="s1">len(data.columns) == </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s3"># GH#23925 _get_numeric_data may have dropped all columns</span>
            <span class="s1">cols = Index([]</span><span class="s2">, </span><span class="s1">name=self.columns.name)</span>
            <span class="s2">if </span><span class="s1">is_list_like(q):</span>
                <span class="s2">return </span><span class="s1">self._constructor([]</span><span class="s2">, </span><span class="s1">index=q</span><span class="s2">, </span><span class="s1">columns=cols)</span>
            <span class="s2">return </span><span class="s1">self._constructor_sliced([]</span><span class="s2">, </span><span class="s1">index=cols</span><span class="s2">, </span><span class="s1">name=q</span><span class="s2">, </span><span class="s1">dtype=np.float64)</span>

        <span class="s1">res = data._mgr.quantile(qs=q</span><span class="s2">, </span><span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">interpolation=interpolation)</span>

        <span class="s1">result = self._constructor(res)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">@doc(NDFrame.asfreq</span><span class="s2">, </span><span class="s1">**_shared_doc_kwargs)</span>
    <span class="s2">def </span><span class="s1">asfreq(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">freq: Frequency</span><span class="s2">,</span>
        <span class="s1">method=</span><span class="s2">None,</span>
        <span class="s1">how: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">normalize: bool = </span><span class="s2">False,</span>
        <span class="s1">fill_value=</span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s2">return </span><span class="s1">super().asfreq(</span>
            <span class="s1">freq=freq</span><span class="s2">,</span>
            <span class="s1">method=method</span><span class="s2">,</span>
            <span class="s1">how=how</span><span class="s2">,</span>
            <span class="s1">normalize=normalize</span><span class="s2">,</span>
            <span class="s1">fill_value=fill_value</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@doc(NDFrame.resample</span><span class="s2">, </span><span class="s1">**_shared_doc_kwargs)</span>
    <span class="s2">def </span><span class="s1">resample(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">rule</span><span class="s2">,</span>
        <span class="s1">axis=</span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">closed: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">label: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">convention: str = </span><span class="s4">&quot;start&quot;</span><span class="s2">,</span>
        <span class="s1">kind: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">loffset=</span><span class="s2">None,</span>
        <span class="s1">base: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">on=</span><span class="s2">None,</span>
        <span class="s1">level=</span><span class="s2">None,</span>
        <span class="s1">origin: str | TimestampConvertibleTypes = </span><span class="s4">&quot;start_day&quot;</span><span class="s2">,</span>
        <span class="s1">offset: TimedeltaConvertibleTypes | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">) -&gt; Resampler:</span>
        <span class="s2">return </span><span class="s1">super().resample(</span>
            <span class="s1">rule=rule</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">closed=closed</span><span class="s2">,</span>
            <span class="s1">label=label</span><span class="s2">,</span>
            <span class="s1">convention=convention</span><span class="s2">,</span>
            <span class="s1">kind=kind</span><span class="s2">,</span>
            <span class="s1">loffset=loffset</span><span class="s2">,</span>
            <span class="s1">base=base</span><span class="s2">,</span>
            <span class="s1">on=on</span><span class="s2">,</span>
            <span class="s1">level=level</span><span class="s2">,</span>
            <span class="s1">origin=origin</span><span class="s2">,</span>
            <span class="s1">offset=offset</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s2">def </span><span class="s1">to_timestamp(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">freq: Frequency | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">how: str = </span><span class="s4">&quot;start&quot;</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">copy: bool = </span><span class="s2">True,</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Cast to DatetimeIndex of timestamps, at *beginning* of period. 
 
        Parameters 
        ---------- 
        freq : str, default frequency of PeriodIndex 
            Desired frequency. 
        how : {'s', 'e', 'start', 'end'} 
            Convention for converting period to timestamp; start of period 
            vs. end. 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to convert (the index by default). 
        copy : bool, default True 
            If False then underlying input data is not copied. 
 
        Returns 
        ------- 
        DataFrame with DatetimeIndex 
        &quot;&quot;&quot;</span>
        <span class="s1">new_obj = self.copy(deep=copy)</span>

        <span class="s1">axis_name = self._get_axis_name(axis)</span>
        <span class="s1">old_ax = getattr(self</span><span class="s2">, </span><span class="s1">axis_name)</span>
        <span class="s2">if not </span><span class="s1">isinstance(old_ax</span><span class="s2">, </span><span class="s1">PeriodIndex):</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;unsupported Type </span><span class="s2">{</span><span class="s1">type(old_ax).__name__</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

        <span class="s1">new_ax = old_ax.to_timestamp(freq=freq</span><span class="s2">, </span><span class="s1">how=how)</span>

        <span class="s1">setattr(new_obj</span><span class="s2">, </span><span class="s1">axis_name</span><span class="s2">, </span><span class="s1">new_ax)</span>
        <span class="s2">return </span><span class="s1">new_obj</span>

    <span class="s2">def </span><span class="s1">to_period(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">freq: Frequency | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None, </span><span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">, </span><span class="s1">copy: bool = </span><span class="s2">True</span>
    <span class="s1">) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Convert DataFrame from DatetimeIndex to PeriodIndex. 
 
        Convert DataFrame from DatetimeIndex to PeriodIndex with desired 
        frequency (inferred from index if not passed). 
 
        Parameters 
        ---------- 
        freq : str, default 
            Frequency of the PeriodIndex. 
        axis : {0 or 'index', 1 or 'columns'}, default 0 
            The axis to convert (the index by default). 
        copy : bool, default True 
            If False then underlying input data is not copied. 
 
        Returns 
        ------- 
        DataFrame with PeriodIndex 
 
        Examples 
        -------- 
        &gt;&gt;&gt; idx = pd.to_datetime( 
        ...     [ 
        ...         &quot;2001-03-31 00:00:00&quot;, 
        ...         &quot;2002-05-31 00:00:00&quot;, 
        ...         &quot;2003-08-31 00:00:00&quot;, 
        ...     ] 
        ... ) 
 
        &gt;&gt;&gt; idx 
        DatetimeIndex(['2001-03-31', '2002-05-31', '2003-08-31'], 
        dtype='datetime64[ns]', freq=None) 
 
        &gt;&gt;&gt; idx.to_period(&quot;M&quot;) 
        PeriodIndex(['2001-03', '2002-05', '2003-08'], dtype='period[M]') 
 
        For the yearly frequency 
 
        &gt;&gt;&gt; idx.to_period(&quot;Y&quot;) 
        PeriodIndex(['2001', '2002', '2003'], dtype='period[A-DEC]') 
        &quot;&quot;&quot;</span>
        <span class="s1">new_obj = self.copy(deep=copy)</span>

        <span class="s1">axis_name = self._get_axis_name(axis)</span>
        <span class="s1">old_ax = getattr(self</span><span class="s2">, </span><span class="s1">axis_name)</span>
        <span class="s2">if not </span><span class="s1">isinstance(old_ax</span><span class="s2">, </span><span class="s1">DatetimeIndex):</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;unsupported Type </span><span class="s2">{</span><span class="s1">type(old_ax).__name__</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

        <span class="s1">new_ax = old_ax.to_period(freq=freq)</span>

        <span class="s1">setattr(new_obj</span><span class="s2">, </span><span class="s1">axis_name</span><span class="s2">, </span><span class="s1">new_ax)</span>
        <span class="s2">return </span><span class="s1">new_obj</span>

    <span class="s2">def </span><span class="s1">isin(self</span><span class="s2">, </span><span class="s1">values) -&gt; DataFrame:</span>
        <span class="s0">&quot;&quot;&quot; 
        Whether each element in the DataFrame is contained in values. 
 
        Parameters 
        ---------- 
        values : iterable, Series, DataFrame or dict 
            The result will only be true at a location if all the 
            labels match. If `values` is a Series, that's the index. If 
            `values` is a dict, the keys must be the column names, 
            which must match. If `values` is a DataFrame, 
            then both the index and column labels must match. 
 
        Returns 
        ------- 
        DataFrame 
            DataFrame of booleans showing whether each element in the DataFrame 
            is contained in values. 
 
        See Also 
        -------- 
        DataFrame.eq: Equality test for DataFrame. 
        Series.isin: Equivalent method on Series. 
        Series.str.contains: Test if pattern or regex is contained within a 
            string of a Series or Index. 
 
        Examples 
        -------- 
        &gt;&gt;&gt; df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]}, 
        ...                   index=['falcon', 'dog']) 
        &gt;&gt;&gt; df 
                num_legs  num_wings 
        falcon         2          2 
        dog            4          0 
 
        When ``values`` is a list check whether every value in the DataFrame 
        is present in the list (which animals have 0 or 2 legs or wings) 
 
        &gt;&gt;&gt; df.isin([0, 2]) 
                num_legs  num_wings 
        falcon      True       True 
        dog        False       True 
 
        To check if ``values`` is *not* in the DataFrame, use the ``~`` operator: 
 
        &gt;&gt;&gt; ~df.isin([0, 2]) 
                num_legs  num_wings 
        falcon     False      False 
        dog         True      False 
 
        When ``values`` is a dict, we can pass values to check for each 
        column separately: 
 
        &gt;&gt;&gt; df.isin({'num_wings': [0, 3]}) 
                num_legs  num_wings 
        falcon     False      False 
        dog        False       True 
 
        When ``values`` is a Series or DataFrame the index and column must 
        match. Note that 'falcon' does not match based on the number of legs 
        in other. 
 
        &gt;&gt;&gt; other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]}, 
        ...                      index=['spider', 'falcon']) 
        &gt;&gt;&gt; df.isin(other) 
                num_legs  num_wings 
        falcon     False       True 
        dog        False      False 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">dict):</span>
            <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

            <span class="s1">values = collections.defaultdict(list</span><span class="s2">, </span><span class="s1">values)</span>
            <span class="s2">return </span><span class="s1">concat(</span>
                <span class="s1">(</span>
                    <span class="s1">self.iloc[:</span><span class="s2">, </span><span class="s1">[i]].isin(values[col])</span>
                    <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">col </span><span class="s2">in </span><span class="s1">enumerate(self.columns)</span>
                <span class="s1">)</span><span class="s2">,</span>
                <span class="s1">axis=</span><span class="s5">1</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">Series):</span>
            <span class="s2">if not </span><span class="s1">values.index.is_unique:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;cannot compute isin with a duplicate axis.&quot;</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">self.eq(values.reindex_like(self)</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">&quot;index&quot;</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">DataFrame):</span>
            <span class="s2">if not </span><span class="s1">(values.columns.is_unique </span><span class="s2">and </span><span class="s1">values.index.is_unique):</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;cannot compute isin with a duplicate axis.&quot;</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">self.eq(values.reindex_like(self))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">if not </span><span class="s1">is_list_like(values):</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span>
                    <span class="s4">&quot;only list-like or dict-like objects are allowed &quot;</span>
                    <span class="s4">&quot;to be passed to DataFrame.isin(), &quot;</span>
                    <span class="s4">f&quot;you passed a '</span><span class="s2">{</span><span class="s1">type(values).__name__</span><span class="s2">}</span><span class="s4">'&quot;</span>
                <span class="s1">)</span>
            <span class="s2">return </span><span class="s1">self._constructor(</span>
                <span class="s1">algorithms.isin(self.values.ravel()</span><span class="s2">, </span><span class="s1">values).reshape(self.shape)</span><span class="s2">,</span>
                <span class="s1">self.index</span><span class="s2">,</span>
                <span class="s1">self.columns</span><span class="s2">,</span>
            <span class="s1">)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Add index and columns</span>
    <span class="s1">_AXIS_ORDERS = [</span><span class="s4">&quot;index&quot;</span><span class="s2">, </span><span class="s4">&quot;columns&quot;</span><span class="s1">]</span>
    <span class="s1">_AXIS_TO_AXIS_NUMBER: dict[Axis</span><span class="s2">, </span><span class="s1">int] = {</span>
        <span class="s1">**NDFrame._AXIS_TO_AXIS_NUMBER</span><span class="s2">,</span>
        <span class="s5">1</span><span class="s1">: </span><span class="s5">1</span><span class="s2">,</span>
        <span class="s4">&quot;columns&quot;</span><span class="s1">: </span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">}</span>
    <span class="s1">_AXIS_LEN = len(_AXIS_ORDERS)</span>
    <span class="s1">_info_axis_number = </span><span class="s5">1</span>
    <span class="s1">_info_axis_name = </span><span class="s4">&quot;columns&quot;</span>

    <span class="s1">index: Index = properties.AxisProperty(</span>
        <span class="s1">axis=</span><span class="s5">1</span><span class="s2">, </span><span class="s1">doc=</span><span class="s4">&quot;The index (row labels) of the DataFrame.&quot;</span>
    <span class="s1">)</span>
    <span class="s1">columns: Index = properties.AxisProperty(</span>
        <span class="s1">axis=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">doc=</span><span class="s4">&quot;The column labels of the DataFrame.&quot;</span>
    <span class="s1">)</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_AXIS_NUMBERS(self) -&gt; dict[str</span><span class="s2">, </span><span class="s1">int]:</span>
        <span class="s0">&quot;&quot;&quot;.. deprecated:: 1.1.0&quot;&quot;&quot;</span>
        <span class="s1">super()._AXIS_NUMBERS</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s4">&quot;index&quot;</span><span class="s1">: </span><span class="s5">0</span><span class="s2">, </span><span class="s4">&quot;columns&quot;</span><span class="s1">: </span><span class="s5">1</span><span class="s1">}</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">_AXIS_NAMES(self) -&gt; dict[int</span><span class="s2">, </span><span class="s1">str]:</span>
        <span class="s0">&quot;&quot;&quot;.. deprecated:: 1.1.0&quot;&quot;&quot;</span>
        <span class="s1">super()._AXIS_NAMES</span>
        <span class="s2">return </span><span class="s1">{</span><span class="s5">0</span><span class="s1">: </span><span class="s4">&quot;index&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">: </span><span class="s4">&quot;columns&quot;</span><span class="s1">}</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Add plotting methods to DataFrame</span>
    <span class="s1">plot = CachedAccessor(</span><span class="s4">&quot;plot&quot;</span><span class="s2">, </span><span class="s1">pandas.plotting.PlotAccessor)</span>
    <span class="s1">hist = pandas.plotting.hist_frame</span>
    <span class="s1">boxplot = pandas.plotting.boxplot_frame</span>
    <span class="s1">sparse = CachedAccessor(</span><span class="s4">&quot;sparse&quot;</span><span class="s2">, </span><span class="s1">SparseFrameAccessor)</span>

    <span class="s3"># ----------------------------------------------------------------------</span>
    <span class="s3"># Internal Interface Methods</span>

    <span class="s2">def </span><span class="s1">_to_dict_of_blocks(self</span><span class="s2">, </span><span class="s1">copy: bool = </span><span class="s2">True</span><span class="s1">):</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a dict of dtype -&gt; Constructor Types that 
        each is a homogeneous dtype. 
 
        Internal ONLY - only works for BlockManager 
        &quot;&quot;&quot;</span>
        <span class="s1">mgr = self._mgr</span>
        <span class="s3"># convert to BlockManager if needed -&gt; this way support ArrayManager as well</span>
        <span class="s1">mgr = mgr_to_mgr(mgr</span><span class="s2">, </span><span class="s4">&quot;block&quot;</span><span class="s1">)</span>
        <span class="s1">mgr = cast(BlockManager</span><span class="s2">, </span><span class="s1">mgr)</span>
        <span class="s2">return </span><span class="s1">{</span>
            <span class="s1">k: self._constructor(v).__finalize__(self)</span>
            <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v</span><span class="s2">, in </span><span class="s1">mgr.to_dict(copy=copy).items()</span>
        <span class="s1">}</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">values(self) -&gt; np.ndarray:</span>
        <span class="s0">&quot;&quot;&quot; 
        Return a Numpy representation of the DataFrame. 
 
        .. warning:: 
 
           We recommend using :meth:`DataFrame.to_numpy` instead. 
 
        Only the values in the DataFrame will be returned, the axes labels 
        will be removed. 
 
        Returns 
        ------- 
        numpy.ndarray 
            The values of the DataFrame. 
 
        See Also 
        -------- 
        DataFrame.to_numpy : Recommended alternative to this method. 
        DataFrame.index : Retrieve the index labels. 
        DataFrame.columns : Retrieving the column names. 
 
        Notes 
        ----- 
        The dtype will be a lower-common-denominator dtype (implicit 
        upcasting); that is to say if the dtypes (even of numeric types) 
        are mixed, the one that accommodates all will be chosen. Use this 
        with care if you are not dealing with the blocks. 
 
        e.g. If the dtypes are float16 and float32, dtype will be upcast to 
        float32.  If dtypes are int32 and uint8, dtype will be upcast to 
        int32. By :func:`numpy.find_common_type` convention, mixing int64 
        and uint64 will result in a float64 dtype. 
 
        Examples 
        -------- 
        A DataFrame where all columns are the same type (e.g., int64) results 
        in an array of the same type. 
 
        &gt;&gt;&gt; df = pd.DataFrame({'age':    [ 3,  29], 
        ...                    'height': [94, 170], 
        ...                    'weight': [31, 115]}) 
        &gt;&gt;&gt; df 
           age  height  weight 
        0    3      94      31 
        1   29     170     115 
        &gt;&gt;&gt; df.dtypes 
        age       int64 
        height    int64 
        weight    int64 
        dtype: object 
        &gt;&gt;&gt; df.values 
        array([[  3,  94,  31], 
               [ 29, 170, 115]]) 
 
        A DataFrame with mixed type columns(e.g., str/object, int64, float32) 
        results in an ndarray of the broadest type that accommodates these 
        mixed types (e.g., object). 
 
        &gt;&gt;&gt; df2 = pd.DataFrame([('parrot',   24.0, 'second'), 
        ...                     ('lion',     80.5, 1), 
        ...                     ('monkey', np.nan, None)], 
        ...                   columns=('name', 'max_speed', 'rank')) 
        &gt;&gt;&gt; df2.dtypes 
        name          object 
        max_speed    float64 
        rank          object 
        dtype: object 
        &gt;&gt;&gt; df2.values 
        array([['parrot', 24.0, 'second'], 
               ['lion', 80.5, 1], 
               ['monkey', nan, None]], dtype=object) 
        &quot;&quot;&quot;</span>
        <span class="s1">self._consolidate_inplace()</span>
        <span class="s2">return </span><span class="s1">self._mgr.as_array()</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">ffill(</span>
        <span class="s1">self: DataFrame</span><span class="s2">,</span>
        <span class="s1">axis: </span><span class="s2">None </span><span class="s1">| Axis = </span><span class="s2">None,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">limit: </span><span class="s2">None </span><span class="s1">| int = </span><span class="s2">None,</span>
        <span class="s1">downcast=</span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">super().ffill(axis</span><span class="s2">, </span><span class="s1">inplace</span><span class="s2">, </span><span class="s1">limit</span><span class="s2">, </span><span class="s1">downcast)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">bfill(</span>
        <span class="s1">self: DataFrame</span><span class="s2">,</span>
        <span class="s1">axis: </span><span class="s2">None </span><span class="s1">| Axis = </span><span class="s2">None,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">limit: </span><span class="s2">None </span><span class="s1">| int = </span><span class="s2">None,</span>
        <span class="s1">downcast=</span><span class="s2">None,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">super().bfill(axis</span><span class="s2">, </span><span class="s1">inplace</span><span class="s2">, </span><span class="s1">limit</span><span class="s2">, </span><span class="s1">downcast)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(</span>
        <span class="s1">version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;lower&quot;</span><span class="s2">, </span><span class="s4">&quot;upper&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">clip(</span>
        <span class="s1">self: DataFrame</span><span class="s2">,</span>
        <span class="s1">lower=</span><span class="s2">None,</span>
        <span class="s1">upper=</span><span class="s2">None,</span>
        <span class="s1">axis: Axis | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">*args</span><span class="s2">,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">super().clip(lower</span><span class="s2">, </span><span class="s1">upper</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">inplace</span><span class="s2">, </span><span class="s1">*args</span><span class="s2">, </span><span class="s1">**kwargs)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;method&quot;</span><span class="s1">])</span>
    <span class="s2">def </span><span class="s1">interpolate(</span>
        <span class="s1">self: DataFrame</span><span class="s2">,</span>
        <span class="s1">method: str = </span><span class="s4">&quot;linear&quot;</span><span class="s2">,</span>
        <span class="s1">axis: Axis = </span><span class="s5">0</span><span class="s2">,</span>
        <span class="s1">limit: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">inplace: bool = </span><span class="s2">False,</span>
        <span class="s1">limit_direction: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">limit_area: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">downcast: str | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
        <span class="s1">**kwargs</span><span class="s2">,</span>
    <span class="s1">) -&gt; DataFrame | </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">super().interpolate(</span>
            <span class="s1">method</span><span class="s2">,</span>
            <span class="s1">axis</span><span class="s2">,</span>
            <span class="s1">limit</span><span class="s2">,</span>
            <span class="s1">inplace</span><span class="s2">,</span>
            <span class="s1">limit_direction</span><span class="s2">,</span>
            <span class="s1">limit_area</span><span class="s2">,</span>
            <span class="s1">downcast</span><span class="s2">,</span>
            <span class="s1">**kwargs</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(</span>
        <span class="s1">version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;cond&quot;</span><span class="s2">, </span><span class="s4">&quot;other&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">where(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">cond</span><span class="s2">,</span>
        <span class="s1">other=lib.no_default</span><span class="s2">,</span>
        <span class="s1">inplace=</span><span class="s2">False,</span>
        <span class="s1">axis=</span><span class="s2">None,</span>
        <span class="s1">level=</span><span class="s2">None,</span>
        <span class="s1">errors=</span><span class="s4">&quot;raise&quot;</span><span class="s2">,</span>
        <span class="s1">try_cast=lib.no_default</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s2">return </span><span class="s1">super().where(cond</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">inplace</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">errors</span><span class="s2">, </span><span class="s1">try_cast)</span>

    <span class="s1">@deprecate_nonkeyword_arguments(</span>
        <span class="s1">version=</span><span class="s2">None, </span><span class="s1">allowed_args=[</span><span class="s4">&quot;self&quot;</span><span class="s2">, </span><span class="s4">&quot;cond&quot;</span><span class="s2">, </span><span class="s4">&quot;other&quot;</span><span class="s1">]</span>
    <span class="s1">)</span>
    <span class="s2">def </span><span class="s1">mask(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">cond</span><span class="s2">,</span>
        <span class="s1">other=np.nan</span><span class="s2">,</span>
        <span class="s1">inplace=</span><span class="s2">False,</span>
        <span class="s1">axis=</span><span class="s2">None,</span>
        <span class="s1">level=</span><span class="s2">None,</span>
        <span class="s1">errors=</span><span class="s4">&quot;raise&quot;</span><span class="s2">,</span>
        <span class="s1">try_cast=lib.no_default</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s2">return </span><span class="s1">super().mask(cond</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">inplace</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">level</span><span class="s2">, </span><span class="s1">errors</span><span class="s2">, </span><span class="s1">try_cast)</span>


<span class="s1">DataFrame._add_numeric_operations()</span>

<span class="s1">ops.add_flex_arithmetic_methods(DataFrame)</span>


<span class="s2">def </span><span class="s1">_from_nested_dict(data) -&gt; collections.defaultdict:</span>
    <span class="s1">new_data: collections.defaultdict = collections.defaultdict(dict)</span>
    <span class="s2">for </span><span class="s1">index</span><span class="s2">, </span><span class="s1">s </span><span class="s2">in </span><span class="s1">data.items():</span>
        <span class="s2">for </span><span class="s1">col</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">s.items():</span>
            <span class="s1">new_data[col][index] = v</span>
    <span class="s2">return </span><span class="s1">new_data</span>


<span class="s2">def </span><span class="s1">_reindex_for_setitem(value: DataFrame | Series</span><span class="s2">, </span><span class="s1">index: Index) -&gt; ArrayLike:</span>
    <span class="s3"># reindex if necessary</span>

    <span class="s2">if </span><span class="s1">value.index.equals(index) </span><span class="s2">or not </span><span class="s1">len(index):</span>
        <span class="s2">return </span><span class="s1">value._values.copy()</span>

    <span class="s3"># GH#4107</span>
    <span class="s2">try</span><span class="s1">:</span>
        <span class="s1">reindexed_value = value.reindex(index)._values</span>
    <span class="s2">except </span><span class="s1">ValueError </span><span class="s2">as </span><span class="s1">err:</span>
        <span class="s3"># raised in MultiIndex.from_tuples, see test_insert_error_msmgs</span>
        <span class="s2">if not </span><span class="s1">value.index.is_unique:</span>
            <span class="s3"># duplicate axis</span>
            <span class="s2">raise </span><span class="s1">err</span>

        <span class="s2">raise </span><span class="s1">TypeError(</span>
            <span class="s4">&quot;incompatible index of inserted column with frame index&quot;</span>
        <span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>
    <span class="s2">return </span><span class="s1">reindexed_value</span>
</pre>
</body>
</html>