<html>
<head>
<title>algorithms.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
algorithms.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Generic data algorithms. This module is experimental at the moment and not 
intended for public consumption 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">import </span><span class="s1">operator</span>
<span class="s2">from </span><span class="s1">textwrap </span><span class="s2">import </span><span class="s1">dedent</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">TYPE_CHECKING</span><span class="s2">,</span>
    <span class="s1">Hashable</span><span class="s2">,</span>
    <span class="s1">Literal</span><span class="s2">,</span>
    <span class="s1">Sequence</span><span class="s2">,</span>
    <span class="s1">Union</span><span class="s2">,</span>
    <span class="s1">cast</span><span class="s2">,</span>
    <span class="s1">final</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">warnings </span><span class="s2">import </span><span class="s1">warn</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>

<span class="s2">from </span><span class="s1">pandas._libs </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">algos</span><span class="s2">,</span>
    <span class="s1">hashtable </span><span class="s2">as </span><span class="s1">htable</span><span class="s2">,</span>
    <span class="s1">iNaT</span><span class="s2">,</span>
    <span class="s1">lib</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas._typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">AnyArrayLike</span><span class="s2">,</span>
    <span class="s1">ArrayLike</span><span class="s2">,</span>
    <span class="s1">DtypeObj</span><span class="s2">,</span>
    <span class="s1">IndexLabel</span><span class="s2">,</span>
    <span class="s1">Scalar</span><span class="s2">,</span>
    <span class="s1">TakeIndexer</span><span class="s2">,</span>
    <span class="s1">npt</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.util._decorators </span><span class="s2">import </span><span class="s1">doc</span>
<span class="s2">from </span><span class="s1">pandas.util._exceptions </span><span class="s2">import </span><span class="s1">find_stack_level</span>

<span class="s2">from </span><span class="s1">pandas.core.dtypes.cast </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">construct_1d_object_array_from_listlike</span><span class="s2">,</span>
    <span class="s1">infer_dtype_from_array</span><span class="s2">,</span>
    <span class="s1">sanitize_to_nanoseconds</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.common </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ensure_float64</span><span class="s2">,</span>
    <span class="s1">ensure_object</span><span class="s2">,</span>
    <span class="s1">ensure_platform_int</span><span class="s2">,</span>
    <span class="s1">is_array_like</span><span class="s2">,</span>
    <span class="s1">is_bool_dtype</span><span class="s2">,</span>
    <span class="s1">is_categorical_dtype</span><span class="s2">,</span>
    <span class="s1">is_complex_dtype</span><span class="s2">,</span>
    <span class="s1">is_datetime64_dtype</span><span class="s2">,</span>
    <span class="s1">is_extension_array_dtype</span><span class="s2">,</span>
    <span class="s1">is_float_dtype</span><span class="s2">,</span>
    <span class="s1">is_integer</span><span class="s2">,</span>
    <span class="s1">is_integer_dtype</span><span class="s2">,</span>
    <span class="s1">is_list_like</span><span class="s2">,</span>
    <span class="s1">is_numeric_dtype</span><span class="s2">,</span>
    <span class="s1">is_object_dtype</span><span class="s2">,</span>
    <span class="s1">is_scalar</span><span class="s2">,</span>
    <span class="s1">is_timedelta64_dtype</span><span class="s2">,</span>
    <span class="s1">needs_i8_conversion</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.concat </span><span class="s2">import </span><span class="s1">concat_compat</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.dtypes </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ExtensionDtype</span><span class="s2">,</span>
    <span class="s1">PandasDtype</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.generic </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">ABCDatetimeArray</span><span class="s2">,</span>
    <span class="s1">ABCExtensionArray</span><span class="s2">,</span>
    <span class="s1">ABCIndex</span><span class="s2">,</span>
    <span class="s1">ABCMultiIndex</span><span class="s2">,</span>
    <span class="s1">ABCRangeIndex</span><span class="s2">,</span>
    <span class="s1">ABCSeries</span><span class="s2">,</span>
    <span class="s1">ABCTimedeltaArray</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.dtypes.missing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">isna</span><span class="s2">,</span>
    <span class="s1">na_value_for_dtype</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s2">from </span><span class="s1">pandas.core.array_algos.take </span><span class="s2">import </span><span class="s1">take_nd</span>
<span class="s2">from </span><span class="s1">pandas.core.construction </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">array </span><span class="s2">as </span><span class="s1">pd_array</span><span class="s2">,</span>
    <span class="s1">ensure_wrapped_if_datetimelike</span><span class="s2">,</span>
    <span class="s1">extract_array</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">from </span><span class="s1">pandas.core.indexers </span><span class="s2">import </span><span class="s1">validate_indices</span>

<span class="s2">if </span><span class="s1">TYPE_CHECKING:</span>

    <span class="s2">from </span><span class="s1">pandas._typing </span><span class="s2">import </span><span class="s1">(</span>
        <span class="s1">NumpySorter</span><span class="s2">,</span>
        <span class="s1">NumpyValueArrayLike</span><span class="s2">,</span>
    <span class="s1">)</span>

    <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">(</span>
        <span class="s1">Categorical</span><span class="s2">,</span>
        <span class="s1">DataFrame</span><span class="s2">,</span>
        <span class="s1">Index</span><span class="s2">,</span>
        <span class="s1">Series</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s2">from </span><span class="s1">pandas.core.arrays </span><span class="s2">import </span><span class="s1">(</span>
        <span class="s1">DatetimeArray</span><span class="s2">,</span>
        <span class="s1">ExtensionArray</span><span class="s2">,</span>
        <span class="s1">TimedeltaArray</span><span class="s2">,</span>
    <span class="s1">)</span>


<span class="s3"># --------------- #</span>
<span class="s3"># dtype access    #</span>
<span class="s3"># --------------- #</span>
<span class="s2">def </span><span class="s1">_ensure_data(values: ArrayLike) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot; 
    routine to ensure that our data is of the correct 
    input dtype for lower-level routines 
 
    This will coerce: 
    - ints -&gt; int64 
    - uint -&gt; uint64 
    - bool -&gt; uint8 
    - datetimelike -&gt; i8 
    - datetime64tz -&gt; i8 (in local tz) 
    - categorical -&gt; codes 
 
    Parameters 
    ---------- 
    values : np.ndarray or ExtensionArray 
 
    Returns 
    ------- 
    np.ndarray 
    &quot;&quot;&quot;</span>

    <span class="s2">if not </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">ABCMultiIndex):</span>
        <span class="s3"># extract_array would raise</span>
        <span class="s1">values = extract_array(values</span><span class="s2">, </span><span class="s1">extract_numpy=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s3"># we check some simple dtypes first</span>
    <span class="s2">if </span><span class="s1">is_object_dtype(values.dtype):</span>
        <span class="s2">return </span><span class="s1">ensure_object(np.asarray(values))</span>

    <span class="s2">elif </span><span class="s1">is_bool_dtype(values.dtype):</span>
        <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
            <span class="s3"># i.e. actually dtype == np.dtype(&quot;bool&quot;)</span>
            <span class="s2">return </span><span class="s1">np.asarray(values).view(</span><span class="s4">&quot;uint8&quot;</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s3"># i.e. all-bool Categorical, BooleanArray</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">np.asarray(values).astype(</span><span class="s4">&quot;uint8&quot;</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
            <span class="s2">except </span><span class="s1">(TypeError</span><span class="s2">, </span><span class="s1">ValueError):</span>
                <span class="s3"># GH#42107 we have pd.NAs present</span>
                <span class="s2">return </span><span class="s1">np.asarray(values)</span>

    <span class="s2">elif </span><span class="s1">is_integer_dtype(values.dtype):</span>
        <span class="s2">return </span><span class="s1">np.asarray(values)</span>

    <span class="s2">elif </span><span class="s1">is_float_dtype(values.dtype):</span>
        <span class="s3"># Note: checking `values.dtype == &quot;float128&quot;` raises on Windows and 32bit</span>
        <span class="s3"># error: Item &quot;ExtensionDtype&quot; of &quot;Union[Any, ExtensionDtype, dtype[Any]]&quot;</span>
        <span class="s3"># has no attribute &quot;itemsize&quot;</span>
        <span class="s2">if </span><span class="s1">values.dtype.itemsize </span><span class="s2">in </span><span class="s1">[</span><span class="s5">2</span><span class="s2">, </span><span class="s5">12</span><span class="s2">, </span><span class="s5">16</span><span class="s1">]:  </span><span class="s3"># type: ignore[union-attr]</span>
            <span class="s3"># we dont (yet) have float128 hashtable support</span>
            <span class="s2">return </span><span class="s1">ensure_float64(values)</span>
        <span class="s2">return </span><span class="s1">np.asarray(values)</span>

    <span class="s2">elif </span><span class="s1">is_complex_dtype(values.dtype):</span>
        <span class="s3"># Incompatible return value type (got &quot;Tuple[Union[Any, ExtensionArray,</span>
        <span class="s3"># ndarray[Any, Any]], Union[Any, ExtensionDtype]]&quot;, expected</span>
        <span class="s3"># &quot;Tuple[ndarray[Any, Any], Union[dtype[Any], ExtensionDtype]]&quot;)</span>
        <span class="s2">return </span><span class="s1">values  </span><span class="s3"># type: ignore[return-value]</span>

    <span class="s3"># datetimelike</span>
    <span class="s2">elif </span><span class="s1">needs_i8_conversion(values.dtype):</span>
        <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
            <span class="s1">values = sanitize_to_nanoseconds(values)</span>
        <span class="s1">npvalues = values.view(</span><span class="s4">&quot;i8&quot;</span><span class="s1">)</span>
        <span class="s1">npvalues = cast(np.ndarray</span><span class="s2">, </span><span class="s1">npvalues)</span>
        <span class="s2">return </span><span class="s1">npvalues</span>

    <span class="s2">elif </span><span class="s1">is_categorical_dtype(values.dtype):</span>
        <span class="s1">values = cast(</span><span class="s4">&quot;Categorical&quot;</span><span class="s2">, </span><span class="s1">values)</span>
        <span class="s1">values = values.codes</span>
        <span class="s2">return </span><span class="s1">values</span>

    <span class="s3"># we have failed, return object</span>
    <span class="s1">values = np.asarray(values</span><span class="s2">, </span><span class="s1">dtype=object)</span>
    <span class="s2">return </span><span class="s1">ensure_object(values)</span>


<span class="s2">def </span><span class="s1">_reconstruct_data(</span>
    <span class="s1">values: ArrayLike</span><span class="s2">, </span><span class="s1">dtype: DtypeObj</span><span class="s2">, </span><span class="s1">original: AnyArrayLike</span>
<span class="s1">) -&gt; ArrayLike:</span>
    <span class="s0">&quot;&quot;&quot; 
    reverse of _ensure_data 
 
    Parameters 
    ---------- 
    values : np.ndarray or ExtensionArray 
    dtype : np.dtype or ExtensionDtype 
    original : AnyArrayLike 
 
    Returns 
    ------- 
    ExtensionArray or np.ndarray 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">ABCExtensionArray) </span><span class="s2">and </span><span class="s1">values.dtype == dtype:</span>
        <span class="s3"># Catch DatetimeArray/TimedeltaArray</span>
        <span class="s2">return </span><span class="s1">values</span>

    <span class="s2">if not </span><span class="s1">isinstance(dtype</span><span class="s2">, </span><span class="s1">np.dtype):</span>
        <span class="s3"># i.e. ExtensionDtype</span>
        <span class="s1">cls = dtype.construct_array_type()</span>
        <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">cls) </span><span class="s2">and </span><span class="s1">values.dtype == dtype:</span>
            <span class="s2">return </span><span class="s1">values</span>

        <span class="s1">values = cls._from_sequence(values</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
    <span class="s2">elif </span><span class="s1">is_bool_dtype(dtype):</span>
        <span class="s1">values = values.astype(dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

        <span class="s3"># we only support object dtypes bool Index</span>
        <span class="s2">if </span><span class="s1">isinstance(original</span><span class="s2">, </span><span class="s1">ABCIndex):</span>
            <span class="s1">values = values.astype(object</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">dtype </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">is_datetime64_dtype(dtype):</span>
            <span class="s1">dtype = np.dtype(</span><span class="s4">&quot;datetime64[ns]&quot;</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">is_timedelta64_dtype(dtype):</span>
            <span class="s1">dtype = np.dtype(</span><span class="s4">&quot;timedelta64[ns]&quot;</span><span class="s1">)</span>

        <span class="s1">values = values.astype(dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">values</span>


<span class="s2">def </span><span class="s1">_ensure_arraylike(values) -&gt; ArrayLike:</span>
    <span class="s0">&quot;&quot;&quot; 
    ensure that we are arraylike if not already 
    &quot;&quot;&quot;</span>
    <span class="s2">if not </span><span class="s1">is_array_like(values):</span>
        <span class="s1">inferred = lib.infer_dtype(values</span><span class="s2">, </span><span class="s1">skipna=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">inferred </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;mixed&quot;</span><span class="s2">, </span><span class="s4">&quot;string&quot;</span><span class="s2">, </span><span class="s4">&quot;mixed-integer&quot;</span><span class="s1">]:</span>
            <span class="s3"># &quot;mixed-integer&quot; to ensure we do not cast [&quot;ss&quot;, 42] to str GH#22160</span>
            <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">tuple):</span>
                <span class="s1">values = list(values)</span>
            <span class="s1">values = construct_1d_object_array_from_listlike(values)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">values = np.asarray(values)</span>
    <span class="s2">return </span><span class="s1">values</span>


<span class="s1">_hashtables = {</span>
    <span class="s4">&quot;complex128&quot;</span><span class="s1">: htable.Complex128HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;complex64&quot;</span><span class="s1">: htable.Complex64HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;float64&quot;</span><span class="s1">: htable.Float64HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;float32&quot;</span><span class="s1">: htable.Float32HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;uint64&quot;</span><span class="s1">: htable.UInt64HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;uint32&quot;</span><span class="s1">: htable.UInt32HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;uint16&quot;</span><span class="s1">: htable.UInt16HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;uint8&quot;</span><span class="s1">: htable.UInt8HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;int64&quot;</span><span class="s1">: htable.Int64HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;int32&quot;</span><span class="s1">: htable.Int32HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;int16&quot;</span><span class="s1">: htable.Int16HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;int8&quot;</span><span class="s1">: htable.Int8HashTable</span><span class="s2">,</span>
    <span class="s4">&quot;string&quot;</span><span class="s1">: htable.StringHashTable</span><span class="s2">,</span>
    <span class="s4">&quot;object&quot;</span><span class="s1">: htable.PyObjectHashTable</span><span class="s2">,</span>
<span class="s1">}</span>


<span class="s2">def </span><span class="s1">_get_hashtable_algo(values: np.ndarray):</span>
    <span class="s0">&quot;&quot;&quot; 
    Parameters 
    ---------- 
    values : np.ndarray 
 
    Returns 
    ------- 
    htable : HashTable subclass 
    values : ndarray 
    &quot;&quot;&quot;</span>
    <span class="s1">values = _ensure_data(values)</span>

    <span class="s1">ndtype = _check_object_for_strings(values)</span>
    <span class="s1">htable = _hashtables[ndtype]</span>
    <span class="s2">return </span><span class="s1">htable</span><span class="s2">, </span><span class="s1">values</span>


<span class="s2">def </span><span class="s1">_get_values_for_rank(values: ArrayLike) -&gt; np.ndarray:</span>

    <span class="s1">values = _ensure_data(values)</span>
    <span class="s2">if </span><span class="s1">values.dtype.kind </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;i&quot;</span><span class="s2">, </span><span class="s4">&quot;u&quot;</span><span class="s2">, </span><span class="s4">&quot;f&quot;</span><span class="s1">]:</span>
        <span class="s3"># rank_t includes only object, int64, uint64, float64</span>
        <span class="s1">dtype = values.dtype.kind + </span><span class="s4">&quot;8&quot;</span>
        <span class="s1">values = values.astype(dtype</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">values</span>


<span class="s2">def </span><span class="s1">_get_data_algo(values: ArrayLike):</span>
    <span class="s1">values = _get_values_for_rank(values)</span>

    <span class="s1">ndtype = _check_object_for_strings(values)</span>
    <span class="s1">htable = _hashtables.get(ndtype</span><span class="s2">, </span><span class="s1">_hashtables[</span><span class="s4">&quot;object&quot;</span><span class="s1">])</span>

    <span class="s2">return </span><span class="s1">htable</span><span class="s2">, </span><span class="s1">values</span>


<span class="s2">def </span><span class="s1">_check_object_for_strings(values: np.ndarray) -&gt; str:</span>
    <span class="s0">&quot;&quot;&quot; 
    Check if we can use string hashtable instead of object hashtable. 
 
    Parameters 
    ---------- 
    values : ndarray 
 
    Returns 
    ------- 
    str 
    &quot;&quot;&quot;</span>
    <span class="s1">ndtype = values.dtype.name</span>
    <span class="s2">if </span><span class="s1">ndtype == </span><span class="s4">&quot;object&quot;</span><span class="s1">:</span>

        <span class="s3"># it's cheaper to use a String Hash Table than Object; we infer</span>
        <span class="s3"># including nulls because that is the only difference between</span>
        <span class="s3"># StringHashTable and ObjectHashtable</span>
        <span class="s2">if </span><span class="s1">lib.infer_dtype(values</span><span class="s2">, </span><span class="s1">skipna=</span><span class="s2">False</span><span class="s1">) </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;string&quot;</span><span class="s1">]:</span>
            <span class="s1">ndtype = </span><span class="s4">&quot;string&quot;</span>
    <span class="s2">return </span><span class="s1">ndtype</span>


<span class="s3"># --------------- #</span>
<span class="s3"># top-level algos #</span>
<span class="s3"># --------------- #</span>


<span class="s2">def </span><span class="s1">unique(values):</span>
    <span class="s0">&quot;&quot;&quot; 
    Return unique values based on a hash table. 
 
    Uniques are returned in order of appearance. This does NOT sort. 
 
    Significantly faster than numpy.unique for long enough sequences. 
    Includes NA values. 
 
    Parameters 
    ---------- 
    values : 1d array-like 
 
    Returns 
    ------- 
    numpy.ndarray or ExtensionArray 
 
        The return can be: 
 
        * Index : when the input is an Index 
        * Categorical : when the input is a Categorical dtype 
        * ndarray : when the input is a Series/ndarray 
 
        Return numpy.ndarray or ExtensionArray. 
 
    See Also 
    -------- 
    Index.unique : Return unique values from an Index. 
    Series.unique : Return unique values of Series object. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; pd.unique(pd.Series([2, 1, 3, 3])) 
    array([2, 1, 3]) 
 
    &gt;&gt;&gt; pd.unique(pd.Series([2] + [1] * 5)) 
    array([2, 1]) 
 
    &gt;&gt;&gt; pd.unique(pd.Series([pd.Timestamp(&quot;20160101&quot;), pd.Timestamp(&quot;20160101&quot;)])) 
    array(['2016-01-01T00:00:00.000000000'], dtype='datetime64[ns]') 
 
    &gt;&gt;&gt; pd.unique( 
    ...     pd.Series( 
    ...         [ 
    ...             pd.Timestamp(&quot;20160101&quot;, tz=&quot;US/Eastern&quot;), 
    ...             pd.Timestamp(&quot;20160101&quot;, tz=&quot;US/Eastern&quot;), 
    ...         ] 
    ...     ) 
    ... ) 
    &lt;DatetimeArray&gt; 
    ['2016-01-01 00:00:00-05:00'] 
    Length: 1, dtype: datetime64[ns, US/Eastern] 
 
    &gt;&gt;&gt; pd.unique( 
    ...     pd.Index( 
    ...         [ 
    ...             pd.Timestamp(&quot;20160101&quot;, tz=&quot;US/Eastern&quot;), 
    ...             pd.Timestamp(&quot;20160101&quot;, tz=&quot;US/Eastern&quot;), 
    ...         ] 
    ...     ) 
    ... ) 
    DatetimeIndex(['2016-01-01 00:00:00-05:00'], 
            dtype='datetime64[ns, US/Eastern]', 
            freq=None) 
 
    &gt;&gt;&gt; pd.unique(list(&quot;baabc&quot;)) 
    array(['b', 'a', 'c'], dtype=object) 
 
    An unordered Categorical will return categories in the 
    order of appearance. 
 
    &gt;&gt;&gt; pd.unique(pd.Series(pd.Categorical(list(&quot;baabc&quot;)))) 
    ['b', 'a', 'c'] 
    Categories (3, object): ['a', 'b', 'c'] 
 
    &gt;&gt;&gt; pd.unique(pd.Series(pd.Categorical(list(&quot;baabc&quot;), categories=list(&quot;abc&quot;)))) 
    ['b', 'a', 'c'] 
    Categories (3, object): ['a', 'b', 'c'] 
 
    An ordered Categorical preserves the category ordering. 
 
    &gt;&gt;&gt; pd.unique( 
    ...     pd.Series( 
    ...         pd.Categorical(list(&quot;baabc&quot;), categories=list(&quot;abc&quot;), ordered=True) 
    ...     ) 
    ... ) 
    ['b', 'a', 'c'] 
    Categories (3, object): ['a' &lt; 'b' &lt; 'c'] 
 
    An array of tuples 
 
    &gt;&gt;&gt; pd.unique([(&quot;a&quot;, &quot;b&quot;), (&quot;b&quot;, &quot;a&quot;), (&quot;a&quot;, &quot;c&quot;), (&quot;b&quot;, &quot;a&quot;)]) 
    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object) 
    &quot;&quot;&quot;</span>
    <span class="s1">values = _ensure_arraylike(values)</span>

    <span class="s2">if </span><span class="s1">is_extension_array_dtype(values.dtype):</span>
        <span class="s3"># Dispatch to extension dtype's unique.</span>
        <span class="s2">return </span><span class="s1">values.unique()</span>

    <span class="s1">original = values</span>
    <span class="s1">htable</span><span class="s2">, </span><span class="s1">values = _get_hashtable_algo(values)</span>

    <span class="s1">table = htable(len(values))</span>
    <span class="s1">uniques = table.unique(values)</span>
    <span class="s1">uniques = _reconstruct_data(uniques</span><span class="s2">, </span><span class="s1">original.dtype</span><span class="s2">, </span><span class="s1">original)</span>
    <span class="s2">return </span><span class="s1">uniques</span>


<span class="s1">unique1d = unique</span>


<span class="s2">def </span><span class="s1">isin(comps: AnyArrayLike</span><span class="s2">, </span><span class="s1">values: AnyArrayLike) -&gt; npt.NDArray[np.bool_]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Compute the isin boolean array. 
 
    Parameters 
    ---------- 
    comps : array-like 
    values : array-like 
 
    Returns 
    ------- 
    ndarray[bool] 
        Same length as `comps`. 
    &quot;&quot;&quot;</span>
    <span class="s2">if not </span><span class="s1">is_list_like(comps):</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span>
            <span class="s4">&quot;only list-like objects are allowed to be passed &quot;</span>
            <span class="s4">f&quot;to isin(), you passed a [</span><span class="s2">{</span><span class="s1">type(comps).__name__</span><span class="s2">}</span><span class="s4">]&quot;</span>
        <span class="s1">)</span>
    <span class="s2">if not </span><span class="s1">is_list_like(values):</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span>
            <span class="s4">&quot;only list-like objects are allowed to be passed &quot;</span>
            <span class="s4">f&quot;to isin(), you passed a [</span><span class="s2">{</span><span class="s1">type(values).__name__</span><span class="s2">}</span><span class="s4">]&quot;</span>
        <span class="s1">)</span>

    <span class="s2">if not </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">(ABCIndex</span><span class="s2">, </span><span class="s1">ABCSeries</span><span class="s2">, </span><span class="s1">ABCExtensionArray</span><span class="s2">, </span><span class="s1">np.ndarray)):</span>
        <span class="s1">values = _ensure_arraylike(list(values))</span>
    <span class="s2">elif </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">ABCMultiIndex):</span>
        <span class="s3"># Avoid raising in extract_array</span>
        <span class="s1">values = np.array(values)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">values = extract_array(values</span><span class="s2">, </span><span class="s1">extract_numpy=</span><span class="s2">True, </span><span class="s1">extract_range=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s1">comps = _ensure_arraylike(comps)</span>
    <span class="s1">comps = extract_array(comps</span><span class="s2">, </span><span class="s1">extract_numpy=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">if not </span><span class="s1">isinstance(comps</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
        <span class="s3"># i.e. Extension Array</span>
        <span class="s2">return </span><span class="s1">comps.isin(values)</span>

    <span class="s2">elif </span><span class="s1">needs_i8_conversion(comps.dtype):</span>
        <span class="s3"># Dispatch to DatetimeLikeArrayMixin.isin</span>
        <span class="s2">return </span><span class="s1">pd_array(comps).isin(values)</span>
    <span class="s2">elif </span><span class="s1">needs_i8_conversion(values.dtype) </span><span class="s2">and not </span><span class="s1">is_object_dtype(comps.dtype):</span>
        <span class="s3"># e.g. comps are integers and values are datetime64s</span>
        <span class="s2">return </span><span class="s1">np.zeros(comps.shape</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
        <span class="s3"># TODO: not quite right ... Sparse/Categorical</span>
    <span class="s2">elif </span><span class="s1">needs_i8_conversion(values.dtype):</span>
        <span class="s2">return </span><span class="s1">isin(comps</span><span class="s2">, </span><span class="s1">values.astype(object))</span>

    <span class="s2">elif </span><span class="s1">isinstance(values.dtype</span><span class="s2">, </span><span class="s1">ExtensionDtype):</span>
        <span class="s2">return </span><span class="s1">isin(np.asarray(comps)</span><span class="s2">, </span><span class="s1">np.asarray(values))</span>

    <span class="s3"># GH16012</span>
    <span class="s3"># Ensure np.in1d doesn't get object types or it *may* throw an exception</span>
    <span class="s3"># Albeit hashmap has O(1) look-up (vs. O(logn) in sorted array),</span>
    <span class="s3"># in1d is faster for small sizes</span>
    <span class="s2">if </span><span class="s1">len(comps) &gt; </span><span class="s5">1_000_000 </span><span class="s2">and </span><span class="s1">len(values) &lt;= </span><span class="s5">26 </span><span class="s2">and not </span><span class="s1">is_object_dtype(comps):</span>
        <span class="s3"># If the values include nan we need to check for nan explicitly</span>
        <span class="s3"># since np.nan it not equal to np.nan</span>
        <span class="s2">if </span><span class="s1">isna(values).any():</span>

            <span class="s2">def </span><span class="s1">f(c</span><span class="s2">, </span><span class="s1">v):</span>
                <span class="s2">return </span><span class="s1">np.logical_or(np.in1d(c</span><span class="s2">, </span><span class="s1">v)</span><span class="s2">, </span><span class="s1">np.isnan(c))</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">f = np.in1d</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">common = np.find_common_type([values.dtype</span><span class="s2">, </span><span class="s1">comps.dtype]</span><span class="s2">, </span><span class="s1">[])</span>
        <span class="s1">values = values.astype(common</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">comps = comps.astype(common</span><span class="s2">, </span><span class="s1">copy=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s1">f = htable.ismember</span>

    <span class="s2">return </span><span class="s1">f(comps</span><span class="s2">, </span><span class="s1">values)</span>


<span class="s2">def </span><span class="s1">factorize_array(</span>
    <span class="s1">values: np.ndarray</span><span class="s2">,</span>
    <span class="s1">na_sentinel: int = -</span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">size_hint: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">na_value=</span><span class="s2">None,</span>
    <span class="s1">mask: np.ndarray | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
<span class="s1">) -&gt; tuple[npt.NDArray[np.intp]</span><span class="s2">, </span><span class="s1">np.ndarray]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Factorize a numpy array to codes and uniques. 
 
    This doesn't do any coercion of types or unboxing before factorization. 
 
    Parameters 
    ---------- 
    values : ndarray 
    na_sentinel : int, default -1 
    size_hint : int, optional 
        Passed through to the hashtable's 'get_labels' method 
    na_value : object, optional 
        A value in `values` to consider missing. Note: only use this 
        parameter when you know that you don't have any values pandas would 
        consider missing in the array (NaN for float data, iNaT for 
        datetimes, etc.). 
    mask : ndarray[bool], optional 
        If not None, the mask is used as indicator for missing values 
        (True = missing, False = valid) instead of `na_value` or 
        condition &quot;val != val&quot;. 
 
    Returns 
    ------- 
    codes : ndarray[np.intp] 
    uniques : ndarray 
    &quot;&quot;&quot;</span>
    <span class="s1">hash_klass</span><span class="s2">, </span><span class="s1">values = _get_data_algo(values)</span>

    <span class="s1">table = hash_klass(size_hint </span><span class="s2">or </span><span class="s1">len(values))</span>
    <span class="s1">uniques</span><span class="s2">, </span><span class="s1">codes = table.factorize(</span>
        <span class="s1">values</span><span class="s2">, </span><span class="s1">na_sentinel=na_sentinel</span><span class="s2">, </span><span class="s1">na_value=na_value</span><span class="s2">, </span><span class="s1">mask=mask</span>
    <span class="s1">)</span>

    <span class="s1">codes = ensure_platform_int(codes)</span>
    <span class="s2">return </span><span class="s1">codes</span><span class="s2">, </span><span class="s1">uniques</span>


<span class="s1">@doc(</span>
    <span class="s1">values=dedent(</span>
        <span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
    </span><span class="s4">values : sequence 
        A 1-D sequence. Sequences that aren't pandas objects are 
        coerced to ndarrays before factorization. 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span><span class="s2">,</span>
    <span class="s1">sort=dedent(</span>
        <span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
    </span><span class="s4">sort : bool, default False 
        Sort `uniques` and shuffle `codes` to maintain the 
        relationship. 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span><span class="s2">,</span>
    <span class="s1">size_hint=dedent(</span>
        <span class="s4">&quot;&quot;&quot;</span><span class="s2">\ 
    </span><span class="s4">size_hint : int, optional 
        Hint to the hashtable sizer. 
    &quot;&quot;&quot;</span>
    <span class="s1">)</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s2">def </span><span class="s1">factorize(</span>
    <span class="s1">values</span><span class="s2">,</span>
    <span class="s1">sort: bool = </span><span class="s2">False,</span>
    <span class="s1">na_sentinel: int | </span><span class="s2">None </span><span class="s1">= -</span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">size_hint: int | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
<span class="s1">) -&gt; tuple[np.ndarray</span><span class="s2">, </span><span class="s1">np.ndarray | Index]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Encode the object as an enumerated type or categorical variable. 
 
    This method is useful for obtaining a numeric representation of an 
    array when all that matters is identifying distinct values. `factorize` 
    is available as both a top-level function :func:`pandas.factorize`, 
    and as a method :meth:`Series.factorize` and :meth:`Index.factorize`. 
 
    Parameters 
    ---------- 
    {values}{sort} 
    na_sentinel : int or None, default -1 
        Value to mark &quot;not found&quot;. If None, will not drop the NaN 
        from the uniques of the values. 
 
        .. versionchanged:: 1.1.2 
    {size_hint}\ 
 
    Returns 
    ------- 
    codes : ndarray 
        An integer ndarray that's an indexer into `uniques`. 
        ``uniques.take(codes)`` will have the same values as `values`. 
    uniques : ndarray, Index, or Categorical 
        The unique valid values. When `values` is Categorical, `uniques` 
        is a Categorical. When `values` is some other pandas object, an 
        `Index` is returned. Otherwise, a 1-D ndarray is returned. 
 
        .. note:: 
 
           Even if there's a missing value in `values`, `uniques` will 
           *not* contain an entry for it. 
 
    See Also 
    -------- 
    cut : Discretize continuous-valued array. 
    unique : Find the unique value in an array. 
 
    Examples 
    -------- 
    These examples all show factorize as a top-level method like 
    ``pd.factorize(values)``. The results are identical for methods like 
    :meth:`Series.factorize`. 
 
    &gt;&gt;&gt; codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b']) 
    &gt;&gt;&gt; codes 
    array([0, 0, 1, 2, 0]...) 
    &gt;&gt;&gt; uniques 
    array(['b', 'a', 'c'], dtype=object) 
 
    With ``sort=True``, the `uniques` will be sorted, and `codes` will be 
    shuffled so that the relationship is the maintained. 
 
    &gt;&gt;&gt; codes, uniques = pd.factorize(['b', 'b', 'a', 'c', 'b'], sort=True) 
    &gt;&gt;&gt; codes 
    array([1, 1, 0, 2, 1]...) 
    &gt;&gt;&gt; uniques 
    array(['a', 'b', 'c'], dtype=object) 
 
    Missing values are indicated in `codes` with `na_sentinel` 
    (``-1`` by default). Note that missing values are never 
    included in `uniques`. 
 
    &gt;&gt;&gt; codes, uniques = pd.factorize(['b', None, 'a', 'c', 'b']) 
    &gt;&gt;&gt; codes 
    array([ 0, -1,  1,  2,  0]...) 
    &gt;&gt;&gt; uniques 
    array(['b', 'a', 'c'], dtype=object) 
 
    Thus far, we've only factorized lists (which are internally coerced to 
    NumPy arrays). When factorizing pandas objects, the type of `uniques` 
    will differ. For Categoricals, a `Categorical` is returned. 
 
    &gt;&gt;&gt; cat = pd.Categorical(['a', 'a', 'c'], categories=['a', 'b', 'c']) 
    &gt;&gt;&gt; codes, uniques = pd.factorize(cat) 
    &gt;&gt;&gt; codes 
    array([0, 0, 1]...) 
    &gt;&gt;&gt; uniques 
    ['a', 'c'] 
    Categories (3, object): ['a', 'b', 'c'] 
 
    Notice that ``'b'`` is in ``uniques.categories``, despite not being 
    present in ``cat.values``. 
 
    For all other pandas objects, an Index of the appropriate type is 
    returned. 
 
    &gt;&gt;&gt; cat = pd.Series(['a', 'a', 'c']) 
    &gt;&gt;&gt; codes, uniques = pd.factorize(cat) 
    &gt;&gt;&gt; codes 
    array([0, 0, 1]...) 
    &gt;&gt;&gt; uniques 
    Index(['a', 'c'], dtype='object') 
 
    If NaN is in the values, and we want to include NaN in the uniques of the 
    values, it can be achieved by setting ``na_sentinel=None``. 
 
    &gt;&gt;&gt; values = np.array([1, 2, 1, np.nan]) 
    &gt;&gt;&gt; codes, uniques = pd.factorize(values)  # default: na_sentinel=-1 
    &gt;&gt;&gt; codes 
    array([ 0,  1,  0, -1]) 
    &gt;&gt;&gt; uniques 
    array([1., 2.]) 
 
    &gt;&gt;&gt; codes, uniques = pd.factorize(values, na_sentinel=None) 
    &gt;&gt;&gt; codes 
    array([0, 1, 0, 2]) 
    &gt;&gt;&gt; uniques 
    array([ 1.,  2., nan]) 
    &quot;&quot;&quot;</span>
    <span class="s3"># Implementation notes: This method is responsible for 3 things</span>
    <span class="s3"># 1.) coercing data to array-like (ndarray, Index, extension array)</span>
    <span class="s3"># 2.) factorizing codes and uniques</span>
    <span class="s3"># 3.) Maybe boxing the uniques in an Index</span>
    <span class="s3">#</span>
    <span class="s3"># Step 2 is dispatched to extension types (like Categorical). They are</span>
    <span class="s3"># responsible only for factorization. All data coercion, sorting and boxing</span>
    <span class="s3"># should happen here.</span>

    <span class="s2">if </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">ABCRangeIndex):</span>
        <span class="s2">return </span><span class="s1">values.factorize(sort=sort)</span>

    <span class="s1">values = _ensure_arraylike(values)</span>
    <span class="s1">original = values</span>
    <span class="s2">if not </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">ABCMultiIndex):</span>
        <span class="s1">values = extract_array(values</span><span class="s2">, </span><span class="s1">extract_numpy=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s3"># GH35667, if na_sentinel=None, we will not dropna NaNs from the uniques</span>
    <span class="s3"># of values, assign na_sentinel=-1 to replace code value for NaN.</span>
    <span class="s1">dropna = </span><span class="s2">True</span>
    <span class="s2">if </span><span class="s1">na_sentinel </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">na_sentinel = -</span><span class="s5">1</span>
        <span class="s1">dropna = </span><span class="s2">False</span>

    <span class="s2">if </span><span class="s1">(</span>
        <span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">(ABCDatetimeArray</span><span class="s2">, </span><span class="s1">ABCTimedeltaArray))</span>
        <span class="s2">and </span><span class="s1">values.freq </span><span class="s2">is not None</span>
    <span class="s1">):</span>
        <span class="s1">codes</span><span class="s2">, </span><span class="s1">uniques = values.factorize(sort=sort)</span>
        <span class="s2">if </span><span class="s1">isinstance(original</span><span class="s2">, </span><span class="s1">ABCIndex):</span>
            <span class="s1">uniques = original._shallow_copy(uniques</span><span class="s2">, </span><span class="s1">name=</span><span class="s2">None</span><span class="s1">)</span>
        <span class="s2">elif </span><span class="s1">isinstance(original</span><span class="s2">, </span><span class="s1">ABCSeries):</span>
            <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">Index</span>

            <span class="s1">uniques = Index(uniques)</span>
        <span class="s2">return </span><span class="s1">codes</span><span class="s2">, </span><span class="s1">uniques</span>

    <span class="s2">if not </span><span class="s1">isinstance(values.dtype</span><span class="s2">, </span><span class="s1">np.dtype):</span>
        <span class="s3"># i.e. ExtensionDtype</span>
        <span class="s1">codes</span><span class="s2">, </span><span class="s1">uniques = values.factorize(na_sentinel=na_sentinel)</span>
        <span class="s1">dtype = original.dtype</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">dtype = values.dtype</span>
        <span class="s1">values = _ensure_data(values)</span>
        <span class="s1">na_value: Scalar</span>

        <span class="s2">if </span><span class="s1">original.dtype.kind </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;m&quot;</span><span class="s2">, </span><span class="s4">&quot;M&quot;</span><span class="s1">]:</span>
            <span class="s3"># Note: factorize_array will cast NaT bc it has a __int__</span>
            <span class="s3">#  method, but will not cast the more-correct dtype.type(&quot;nat&quot;)</span>
            <span class="s1">na_value = iNaT</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">na_value = </span><span class="s2">None</span>

        <span class="s1">codes</span><span class="s2">, </span><span class="s1">uniques = factorize_array(</span>
            <span class="s1">values</span><span class="s2">, </span><span class="s1">na_sentinel=na_sentinel</span><span class="s2">, </span><span class="s1">size_hint=size_hint</span><span class="s2">, </span><span class="s1">na_value=na_value</span>
        <span class="s1">)</span>

    <span class="s2">if </span><span class="s1">sort </span><span class="s2">and </span><span class="s1">len(uniques) &gt; </span><span class="s5">0</span><span class="s1">:</span>
        <span class="s1">uniques</span><span class="s2">, </span><span class="s1">codes = safe_sort(</span>
            <span class="s1">uniques</span><span class="s2">, </span><span class="s1">codes</span><span class="s2">, </span><span class="s1">na_sentinel=na_sentinel</span><span class="s2">, </span><span class="s1">assume_unique=</span><span class="s2">True, </span><span class="s1">verify=</span><span class="s2">False</span>
        <span class="s1">)</span>

    <span class="s1">code_is_na = codes == na_sentinel</span>
    <span class="s2">if not </span><span class="s1">dropna </span><span class="s2">and </span><span class="s1">code_is_na.any():</span>
        <span class="s3"># na_value is set based on the dtype of uniques, and compat set to False is</span>
        <span class="s3"># because we do not want na_value to be 0 for integers</span>
        <span class="s1">na_value = na_value_for_dtype(uniques.dtype</span><span class="s2">, </span><span class="s1">compat=</span><span class="s2">False</span><span class="s1">)</span>
        <span class="s3"># Argument 2 to &quot;append&quot; has incompatible type &quot;List[Union[str, float, Period,</span>
        <span class="s3"># Timestamp, Timedelta, Any]]&quot;; expected &quot;Union[_SupportsArray[dtype[Any]],</span>
        <span class="s3"># _NestedSequence[_SupportsArray[dtype[Any]]]</span>
        <span class="s3"># , bool, int, float, complex, str, bytes, _NestedSequence[Union[bool, int,</span>
        <span class="s3"># float, complex, str, bytes]]]&quot;  [arg-type]</span>
        <span class="s1">uniques = np.append(uniques</span><span class="s2">, </span><span class="s1">[na_value])  </span><span class="s3"># type: ignore[arg-type]</span>
        <span class="s1">codes = np.where(code_is_na</span><span class="s2">, </span><span class="s1">len(uniques) - </span><span class="s5">1</span><span class="s2">, </span><span class="s1">codes)</span>

    <span class="s1">uniques = _reconstruct_data(uniques</span><span class="s2">, </span><span class="s1">dtype</span><span class="s2">, </span><span class="s1">original)</span>

    <span class="s3"># return original tenor</span>
    <span class="s2">if </span><span class="s1">isinstance(original</span><span class="s2">, </span><span class="s1">ABCIndex):</span>
        <span class="s2">if </span><span class="s1">original.dtype.kind </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;m&quot;</span><span class="s2">, </span><span class="s4">&quot;M&quot;</span><span class="s1">] </span><span class="s2">and </span><span class="s1">isinstance(uniques</span><span class="s2">, </span><span class="s1">np.ndarray):</span>
            <span class="s1">original._data = cast(</span>
                <span class="s4">&quot;Union[DatetimeArray, TimedeltaArray]&quot;</span><span class="s2">, </span><span class="s1">original._data</span>
            <span class="s1">)</span>
            <span class="s1">uniques = type(original._data)._simple_new(uniques</span><span class="s2">, </span><span class="s1">dtype=original.dtype)</span>
        <span class="s1">uniques = original._shallow_copy(uniques</span><span class="s2">, </span><span class="s1">name=</span><span class="s2">None</span><span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">isinstance(original</span><span class="s2">, </span><span class="s1">ABCSeries):</span>
        <span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">Index</span>

        <span class="s1">uniques = Index(uniques)</span>

    <span class="s2">return </span><span class="s1">codes</span><span class="s2">, </span><span class="s1">uniques</span>


<span class="s2">def </span><span class="s1">value_counts(</span>
    <span class="s1">values</span><span class="s2">,</span>
    <span class="s1">sort: bool = </span><span class="s2">True,</span>
    <span class="s1">ascending: bool = </span><span class="s2">False,</span>
    <span class="s1">normalize: bool = </span><span class="s2">False,</span>
    <span class="s1">bins=</span><span class="s2">None,</span>
    <span class="s1">dropna: bool = </span><span class="s2">True,</span>
<span class="s1">) -&gt; Series:</span>
    <span class="s0">&quot;&quot;&quot; 
    Compute a histogram of the counts of non-null values. 
 
    Parameters 
    ---------- 
    values : ndarray (1-d) 
    sort : bool, default True 
        Sort by values 
    ascending : bool, default False 
        Sort in ascending order 
    normalize: bool, default False 
        If True then compute a relative histogram 
    bins : integer, optional 
        Rather than count values, group them into half-open bins, 
        convenience for pd.cut, only works with numeric data 
    dropna : bool, default True 
        Don't include counts of NaN 
 
    Returns 
    ------- 
    Series 
    &quot;&quot;&quot;</span>
    <span class="s2">from </span><span class="s1">pandas.core.series </span><span class="s2">import </span><span class="s1">Series</span>

    <span class="s1">name = getattr(values</span><span class="s2">, </span><span class="s4">&quot;name&quot;</span><span class="s2">, None</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">bins </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s2">from </span><span class="s1">pandas.core.reshape.tile </span><span class="s2">import </span><span class="s1">cut</span>

        <span class="s1">values = Series(values)</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">ii = cut(values</span><span class="s2">, </span><span class="s1">bins</span><span class="s2">, </span><span class="s1">include_lowest=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">except </span><span class="s1">TypeError </span><span class="s2">as </span><span class="s1">err:</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;bins argument only works with numeric data.&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>

        <span class="s3"># count, remove nulls (from the index), and but the bins</span>
        <span class="s1">result = ii.value_counts(dropna=dropna)</span>
        <span class="s1">result = result[result.index.notna()]</span>
        <span class="s1">result.index = result.index.astype(</span><span class="s4">&quot;interval&quot;</span><span class="s1">)</span>
        <span class="s1">result = result.sort_index()</span>

        <span class="s3"># if we are dropna and we have NO values</span>
        <span class="s2">if </span><span class="s1">dropna </span><span class="s2">and </span><span class="s1">(result._values == </span><span class="s5">0</span><span class="s1">).all():</span>
            <span class="s1">result = result.iloc[</span><span class="s5">0</span><span class="s1">:</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s3"># normalizing is by len of all (regardless of dropna)</span>
        <span class="s1">counts = np.array([len(ii)])</span>

    <span class="s2">else</span><span class="s1">:</span>

        <span class="s2">if </span><span class="s1">is_extension_array_dtype(values):</span>

            <span class="s3"># handle Categorical and sparse,</span>
            <span class="s1">result = Series(values)._values.value_counts(dropna=dropna)</span>
            <span class="s1">result.name = name</span>
            <span class="s1">counts = result._values</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">keys</span><span class="s2">, </span><span class="s1">counts = value_counts_arraylike(values</span><span class="s2">, </span><span class="s1">dropna)</span>

            <span class="s1">result = Series(counts</span><span class="s2">, </span><span class="s1">index=keys</span><span class="s2">, </span><span class="s1">name=name)</span>

    <span class="s2">if </span><span class="s1">sort:</span>
        <span class="s1">result = result.sort_values(ascending=ascending)</span>

    <span class="s2">if </span><span class="s1">normalize:</span>
        <span class="s1">result = result / counts.sum()</span>

    <span class="s2">return </span><span class="s1">result</span>


<span class="s3"># Called once from SparseArray, otherwise could be private</span>
<span class="s2">def </span><span class="s1">value_counts_arraylike(values</span><span class="s2">, </span><span class="s1">dropna: bool):</span>
    <span class="s0">&quot;&quot;&quot; 
    Parameters 
    ---------- 
    values : arraylike 
    dropna : bool 
 
    Returns 
    ------- 
    uniques : np.ndarray or ExtensionArray 
    counts : np.ndarray 
    &quot;&quot;&quot;</span>
    <span class="s1">values = _ensure_arraylike(values)</span>
    <span class="s1">original = values</span>
    <span class="s1">values = _ensure_data(values)</span>

    <span class="s1">keys</span><span class="s2">, </span><span class="s1">counts = htable.value_count(values</span><span class="s2">, </span><span class="s1">dropna)</span>

    <span class="s2">if </span><span class="s1">needs_i8_conversion(original.dtype):</span>
        <span class="s3"># datetime, timedelta, or period</span>

        <span class="s2">if </span><span class="s1">dropna:</span>
            <span class="s1">msk = keys != iNaT</span>
            <span class="s1">keys</span><span class="s2">, </span><span class="s1">counts = keys[msk]</span><span class="s2">, </span><span class="s1">counts[msk]</span>

    <span class="s1">res_keys = _reconstruct_data(keys</span><span class="s2">, </span><span class="s1">original.dtype</span><span class="s2">, </span><span class="s1">original)</span>
    <span class="s2">return </span><span class="s1">res_keys</span><span class="s2">, </span><span class="s1">counts</span>


<span class="s2">def </span><span class="s1">duplicated(</span>
    <span class="s1">values: ArrayLike</span><span class="s2">, </span><span class="s1">keep: Literal[</span><span class="s4">&quot;first&quot;</span><span class="s2">, </span><span class="s4">&quot;last&quot;</span><span class="s2">, False</span><span class="s1">] = </span><span class="s4">&quot;first&quot;</span>
<span class="s1">) -&gt; npt.NDArray[np.bool_]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Return boolean ndarray denoting duplicate values. 
 
    Parameters 
    ---------- 
    values : nd.array, ExtensionArray or Series 
        Array over which to check for duplicate values. 
    keep : {'first', 'last', False}, default 'first' 
        - ``first`` : Mark duplicates as ``True`` except for the first 
          occurrence. 
        - ``last`` : Mark duplicates as ``True`` except for the last 
          occurrence. 
        - False : Mark all duplicates as ``True``. 
 
    Returns 
    ------- 
    duplicated : ndarray[bool] 
    &quot;&quot;&quot;</span>
    <span class="s1">values = _ensure_data(values)</span>
    <span class="s2">return </span><span class="s1">htable.duplicated(values</span><span class="s2">, </span><span class="s1">keep=keep)</span>


<span class="s2">def </span><span class="s1">mode(values: ArrayLike</span><span class="s2">, </span><span class="s1">dropna: bool = </span><span class="s2">True</span><span class="s1">) -&gt; ArrayLike:</span>
    <span class="s0">&quot;&quot;&quot; 
    Returns the mode(s) of an array. 
 
    Parameters 
    ---------- 
    values : array-like 
        Array over which to check for duplicate values. 
    dropna : bool, default True 
        Don't consider counts of NaN/NaT. 
 
    Returns 
    ------- 
    np.ndarray or ExtensionArray 
    &quot;&quot;&quot;</span>
    <span class="s1">values = _ensure_arraylike(values)</span>
    <span class="s1">original = values</span>

    <span class="s2">if </span><span class="s1">needs_i8_conversion(values.dtype):</span>
        <span class="s3"># Got here with ndarray; dispatch to DatetimeArray/TimedeltaArray.</span>
        <span class="s1">values = ensure_wrapped_if_datetimelike(values)</span>
        <span class="s3"># error: Item &quot;ndarray[Any, Any]&quot; of &quot;Union[ExtensionArray,</span>
        <span class="s3"># ndarray[Any, Any]]&quot; has no attribute &quot;_mode&quot;</span>
        <span class="s2">return </span><span class="s1">values._mode(dropna=dropna)  </span><span class="s3"># type: ignore[union-attr]</span>

    <span class="s1">values = _ensure_data(values)</span>

    <span class="s1">npresult = htable.mode(values</span><span class="s2">, </span><span class="s1">dropna=dropna)</span>
    <span class="s2">try</span><span class="s1">:</span>
        <span class="s1">npresult = np.sort(npresult)</span>
    <span class="s2">except </span><span class="s1">TypeError </span><span class="s2">as </span><span class="s1">err:</span>
        <span class="s1">warn(</span><span class="s4">f&quot;Unable to sort modes: </span><span class="s2">{</span><span class="s1">err</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

    <span class="s1">result = _reconstruct_data(npresult</span><span class="s2">, </span><span class="s1">original.dtype</span><span class="s2">, </span><span class="s1">original)</span>
    <span class="s2">return </span><span class="s1">result</span>


<span class="s2">def </span><span class="s1">rank(</span>
    <span class="s1">values: ArrayLike</span><span class="s2">,</span>
    <span class="s1">axis: int = </span><span class="s5">0</span><span class="s2">,</span>
    <span class="s1">method: str = </span><span class="s4">&quot;average&quot;</span><span class="s2">,</span>
    <span class="s1">na_option: str = </span><span class="s4">&quot;keep&quot;</span><span class="s2">,</span>
    <span class="s1">ascending: bool = </span><span class="s2">True,</span>
    <span class="s1">pct: bool = </span><span class="s2">False,</span>
<span class="s1">) -&gt; npt.NDArray[np.float64]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Rank the values along a given axis. 
 
    Parameters 
    ---------- 
    values : np.ndarray or ExtensionArray 
        Array whose values will be ranked. The number of dimensions in this 
        array must not exceed 2. 
    axis : int, default 0 
        Axis over which to perform rankings. 
    method : {'average', 'min', 'max', 'first', 'dense'}, default 'average' 
        The method by which tiebreaks are broken during the ranking. 
    na_option : {'keep', 'top'}, default 'keep' 
        The method by which NaNs are placed in the ranking. 
        - ``keep``: rank each NaN value with a NaN ranking 
        - ``top``: replace each NaN with either +/- inf so that they 
                   there are ranked at the top 
    ascending : bool, default True 
        Whether or not the elements should be ranked in ascending order. 
    pct : bool, default False 
        Whether or not to the display the returned rankings in integer form 
        (e.g. 1, 2, 3) or in percentile form (e.g. 0.333..., 0.666..., 1). 
    &quot;&quot;&quot;</span>
    <span class="s1">is_datetimelike = needs_i8_conversion(values.dtype)</span>
    <span class="s1">values = _get_values_for_rank(values)</span>
    <span class="s2">if </span><span class="s1">values.ndim == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s1">ranks = algos.rank_1d(</span>
            <span class="s1">values</span><span class="s2">,</span>
            <span class="s1">is_datetimelike=is_datetimelike</span><span class="s2">,</span>
            <span class="s1">ties_method=method</span><span class="s2">,</span>
            <span class="s1">ascending=ascending</span><span class="s2">,</span>
            <span class="s1">na_option=na_option</span><span class="s2">,</span>
            <span class="s1">pct=pct</span><span class="s2">,</span>
        <span class="s1">)</span>
    <span class="s2">elif </span><span class="s1">values.ndim == </span><span class="s5">2</span><span class="s1">:</span>
        <span class="s1">ranks = algos.rank_2d(</span>
            <span class="s1">values</span><span class="s2">,</span>
            <span class="s1">axis=axis</span><span class="s2">,</span>
            <span class="s1">is_datetimelike=is_datetimelike</span><span class="s2">,</span>
            <span class="s1">ties_method=method</span><span class="s2">,</span>
            <span class="s1">ascending=ascending</span><span class="s2">,</span>
            <span class="s1">na_option=na_option</span><span class="s2">,</span>
            <span class="s1">pct=pct</span><span class="s2">,</span>
        <span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">&quot;Array with ndim &gt; 2 are not supported.&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">ranks</span>


<span class="s2">def </span><span class="s1">checked_add_with_arr(</span>
    <span class="s1">arr: np.ndarray</span><span class="s2">,</span>
    <span class="s1">b</span><span class="s2">,</span>
    <span class="s1">arr_mask: npt.NDArray[np.bool_] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
    <span class="s1">b_mask: npt.NDArray[np.bool_] | </span><span class="s2">None </span><span class="s1">= </span><span class="s2">None,</span>
<span class="s1">) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot; 
    Perform array addition that checks for underflow and overflow. 
 
    Performs the addition of an int64 array and an int64 integer (or array) 
    but checks that they do not result in overflow first. For elements that 
    are indicated to be NaN, whether or not there is overflow for that element 
    is automatically ignored. 
 
    Parameters 
    ---------- 
    arr : array addend. 
    b : array or scalar addend. 
    arr_mask : np.ndarray[bool] or None, default None 
        array indicating which elements to exclude from checking 
    b_mask : np.ndarray[bool] or None, default None 
        array or scalar indicating which element(s) to exclude from checking 
 
    Returns 
    ------- 
    sum : An array for elements x + b for each element x in arr if b is 
          a scalar or an array for elements x + y for each element pair 
          (x, y) in (arr, b). 
 
    Raises 
    ------ 
    OverflowError if any x + y exceeds the maximum or minimum int64 value. 
    &quot;&quot;&quot;</span>
    <span class="s3"># For performance reasons, we broadcast 'b' to the new array 'b2'</span>
    <span class="s3"># so that it has the same size as 'arr'.</span>
    <span class="s1">b2 = np.broadcast_to(b</span><span class="s2">, </span><span class="s1">arr.shape)</span>
    <span class="s2">if </span><span class="s1">b_mask </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s3"># We do the same broadcasting for b_mask as well.</span>
        <span class="s1">b2_mask = np.broadcast_to(b_mask</span><span class="s2">, </span><span class="s1">arr.shape)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">b2_mask = </span><span class="s2">None</span>

    <span class="s3"># For elements that are NaN, regardless of their value, we should</span>
    <span class="s3"># ignore whether they overflow or not when doing the checked add.</span>
    <span class="s2">if </span><span class="s1">arr_mask </span><span class="s2">is not None and </span><span class="s1">b2_mask </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">not_nan = np.logical_not(arr_mask | b2_mask)</span>
    <span class="s2">elif </span><span class="s1">arr_mask </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">not_nan = np.logical_not(arr_mask)</span>
    <span class="s2">elif </span><span class="s1">b_mask </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s3"># Argument 1 to &quot;__call__&quot; of &quot;_UFunc_Nin1_Nout1&quot; has incompatible type</span>
        <span class="s3"># &quot;Optional[ndarray[Any, dtype[bool_]]]&quot;; expected</span>
        <span class="s3"># &quot;Union[_SupportsArray[dtype[Any]], _NestedSequence[_SupportsArray[dtype[An</span>
        <span class="s3"># y]]], bool, int, float, complex, str, bytes, _NestedSequence[Union[bool,</span>
        <span class="s3"># int, float, complex, str, bytes]]]&quot;  [arg-type]</span>
        <span class="s1">not_nan = np.logical_not(b2_mask)  </span><span class="s3"># type: ignore[arg-type]</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">not_nan = np.empty(arr.shape</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
        <span class="s1">not_nan.fill(</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s3"># gh-14324: For each element in 'arr' and its corresponding element</span>
    <span class="s3"># in 'b2', we check the sign of the element in 'b2'. If it is positive,</span>
    <span class="s3"># we then check whether its sum with the element in 'arr' exceeds</span>
    <span class="s3"># np.iinfo(np.int64).max. If so, we have an overflow error. If it</span>
    <span class="s3"># it is negative, we then check whether its sum with the element in</span>
    <span class="s3"># 'arr' exceeds np.iinfo(np.int64).min. If so, we have an overflow</span>
    <span class="s3"># error as well.</span>
    <span class="s1">i8max = lib.i8max</span>
    <span class="s1">i8min = iNaT</span>

    <span class="s1">mask1 = b2 &gt; </span><span class="s5">0</span>
    <span class="s1">mask2 = b2 &lt; </span><span class="s5">0</span>

    <span class="s2">if not </span><span class="s1">mask1.any():</span>
        <span class="s1">to_raise = ((i8min - b2 &gt; arr) &amp; not_nan).any()</span>
    <span class="s2">elif not </span><span class="s1">mask2.any():</span>
        <span class="s1">to_raise = ((i8max - b2 &lt; arr) &amp; not_nan).any()</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">to_raise = ((i8max - b2[mask1] &lt; arr[mask1]) &amp; not_nan[mask1]).any() </span><span class="s2">or </span><span class="s1">(</span>
            <span class="s1">(i8min - b2[mask2] &gt; arr[mask2]) &amp; not_nan[mask2]</span>
        <span class="s1">).any()</span>

    <span class="s2">if </span><span class="s1">to_raise:</span>
        <span class="s2">raise </span><span class="s1">OverflowError(</span><span class="s4">&quot;Overflow in int64 addition&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">arr + b</span>


<span class="s3"># --------------- #</span>
<span class="s3"># select n        #</span>
<span class="s3"># --------------- #</span>


<span class="s2">class </span><span class="s1">SelectN:</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">obj</span><span class="s2">, </span><span class="s1">n: int</span><span class="s2">, </span><span class="s1">keep: str):</span>
        <span class="s1">self.obj = obj</span>
        <span class="s1">self.n = n</span>
        <span class="s1">self.keep = keep</span>

        <span class="s2">if </span><span class="s1">self.keep </span><span class="s2">not in </span><span class="s1">(</span><span class="s4">&quot;first&quot;</span><span class="s2">, </span><span class="s4">&quot;last&quot;</span><span class="s2">, </span><span class="s4">&quot;all&quot;</span><span class="s1">):</span>
            <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">'keep must be either &quot;first&quot;, &quot;last&quot; or &quot;all&quot;'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">compute(self</span><span class="s2">, </span><span class="s1">method: str) -&gt; DataFrame | Series:</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError</span>

    <span class="s1">@final</span>
    <span class="s2">def </span><span class="s1">nlargest(self):</span>
        <span class="s2">return </span><span class="s1">self.compute(</span><span class="s4">&quot;nlargest&quot;</span><span class="s1">)</span>

    <span class="s1">@final</span>
    <span class="s2">def </span><span class="s1">nsmallest(self):</span>
        <span class="s2">return </span><span class="s1">self.compute(</span><span class="s4">&quot;nsmallest&quot;</span><span class="s1">)</span>

    <span class="s1">@final</span>
    <span class="s1">@staticmethod</span>
    <span class="s2">def </span><span class="s1">is_valid_dtype_n_method(dtype: DtypeObj) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot; 
        Helper function to determine if dtype is valid for 
        nsmallest/nlargest methods 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">(</span>
            <span class="s1">is_numeric_dtype(dtype) </span><span class="s2">and not </span><span class="s1">is_complex_dtype(dtype)</span>
        <span class="s1">) </span><span class="s2">or </span><span class="s1">needs_i8_conversion(dtype)</span>


<span class="s2">class </span><span class="s1">SelectNSeries(SelectN):</span>
    <span class="s0">&quot;&quot;&quot; 
    Implement n largest/smallest for Series 
 
    Parameters 
    ---------- 
    obj : Series 
    n : int 
    keep : {'first', 'last'}, default 'first' 
 
    Returns 
    ------- 
    nordered : Series 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">compute(self</span><span class="s2">, </span><span class="s1">method: str) -&gt; Series:</span>

        <span class="s2">from </span><span class="s1">pandas.core.reshape.concat </span><span class="s2">import </span><span class="s1">concat</span>

        <span class="s1">n = self.n</span>
        <span class="s1">dtype = self.obj.dtype</span>
        <span class="s2">if not </span><span class="s1">self.is_valid_dtype_n_method(dtype):</span>
            <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s4">f&quot;Cannot use method '</span><span class="s2">{</span><span class="s1">method</span><span class="s2">}</span><span class="s4">' with dtype </span><span class="s2">{</span><span class="s1">dtype</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">n &lt;= </span><span class="s5">0</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">self.obj[[]]</span>

        <span class="s1">dropped = self.obj.dropna()</span>
        <span class="s1">nan_index = self.obj.drop(dropped.index)</span>

        <span class="s2">if </span><span class="s1">is_extension_array_dtype(dropped.dtype):</span>
            <span class="s3"># GH#41816 bc we have dropped NAs above, MaskedArrays can use the</span>
            <span class="s3">#  numpy logic.</span>
            <span class="s2">from </span><span class="s1">pandas.core.arrays </span><span class="s2">import </span><span class="s1">BaseMaskedArray</span>

            <span class="s1">arr = dropped._values</span>
            <span class="s2">if </span><span class="s1">isinstance(arr</span><span class="s2">, </span><span class="s1">BaseMaskedArray):</span>
                <span class="s1">ser = type(dropped)(arr._data</span><span class="s2">, </span><span class="s1">index=dropped.index</span><span class="s2">, </span><span class="s1">name=dropped.name)</span>

                <span class="s1">result = type(self)(ser</span><span class="s2">, </span><span class="s1">n=self.n</span><span class="s2">, </span><span class="s1">keep=self.keep).compute(method)</span>
                <span class="s2">return </span><span class="s1">result.astype(arr.dtype)</span>

        <span class="s3"># slow method</span>
        <span class="s2">if </span><span class="s1">n &gt;= len(self.obj):</span>
            <span class="s1">ascending = method == </span><span class="s4">&quot;nsmallest&quot;</span>
            <span class="s2">return </span><span class="s1">self.obj.sort_values(ascending=ascending).head(n)</span>

        <span class="s3"># fast method</span>
        <span class="s1">new_dtype = dropped.dtype</span>
        <span class="s1">arr = _ensure_data(dropped.values)</span>
        <span class="s2">if </span><span class="s1">method == </span><span class="s4">&quot;nlargest&quot;</span><span class="s1">:</span>
            <span class="s1">arr = -arr</span>
            <span class="s2">if </span><span class="s1">is_integer_dtype(new_dtype):</span>
                <span class="s3"># GH 21426: ensure reverse ordering at boundaries</span>
                <span class="s1">arr -= </span><span class="s5">1</span>

            <span class="s2">elif </span><span class="s1">is_bool_dtype(new_dtype):</span>
                <span class="s3"># GH 26154: ensure False is smaller than True</span>
                <span class="s1">arr = </span><span class="s5">1 </span><span class="s1">- (-arr)</span>

        <span class="s2">if </span><span class="s1">self.keep == </span><span class="s4">&quot;last&quot;</span><span class="s1">:</span>
            <span class="s1">arr = arr[::-</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">nbase = n</span>
        <span class="s1">findex = len(self.obj)</span>
        <span class="s1">narr = len(arr)</span>
        <span class="s1">n = min(n</span><span class="s2">, </span><span class="s1">narr)</span>

        <span class="s3"># arr passed into kth_smallest must be contiguous. We copy</span>
        <span class="s3"># here because kth_smallest will modify its input</span>
        <span class="s1">kth_val = algos.kth_smallest(arr.copy(order=</span><span class="s4">&quot;C&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">n - </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s1">(ns</span><span class="s2">,</span><span class="s1">) = np.nonzero(arr &lt;= kth_val)</span>
        <span class="s1">inds = ns[arr[ns].argsort(kind=</span><span class="s4">&quot;mergesort&quot;</span><span class="s1">)]</span>

        <span class="s2">if </span><span class="s1">self.keep != </span><span class="s4">&quot;all&quot;</span><span class="s1">:</span>
            <span class="s1">inds = inds[:n]</span>
            <span class="s1">findex = nbase</span>

        <span class="s2">if </span><span class="s1">self.keep == </span><span class="s4">&quot;last&quot;</span><span class="s1">:</span>
            <span class="s3"># reverse indices</span>
            <span class="s1">inds = narr - </span><span class="s5">1 </span><span class="s1">- inds</span>

        <span class="s2">return </span><span class="s1">concat([dropped.iloc[inds]</span><span class="s2">, </span><span class="s1">nan_index]).iloc[:findex]</span>


<span class="s2">class </span><span class="s1">SelectNFrame(SelectN):</span>
    <span class="s0">&quot;&quot;&quot; 
    Implement n largest/smallest for DataFrame 
 
    Parameters 
    ---------- 
    obj : DataFrame 
    n : int 
    keep : {'first', 'last'}, default 'first' 
    columns : list or str 
 
    Returns 
    ------- 
    nordered : DataFrame 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">obj: DataFrame</span><span class="s2">, </span><span class="s1">n: int</span><span class="s2">, </span><span class="s1">keep: str</span><span class="s2">, </span><span class="s1">columns: IndexLabel):</span>
        <span class="s1">super().__init__(obj</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">keep)</span>
        <span class="s2">if not </span><span class="s1">is_list_like(columns) </span><span class="s2">or </span><span class="s1">isinstance(columns</span><span class="s2">, </span><span class="s1">tuple):</span>
            <span class="s1">columns = [columns]</span>

        <span class="s1">columns = cast(Sequence[Hashable]</span><span class="s2">, </span><span class="s1">columns)</span>
        <span class="s1">columns = list(columns)</span>
        <span class="s1">self.columns = columns</span>

    <span class="s2">def </span><span class="s1">compute(self</span><span class="s2">, </span><span class="s1">method: str) -&gt; DataFrame:</span>

        <span class="s2">from </span><span class="s1">pandas.core.api </span><span class="s2">import </span><span class="s1">Int64Index</span>

        <span class="s1">n = self.n</span>
        <span class="s1">frame = self.obj</span>
        <span class="s1">columns = self.columns</span>

        <span class="s2">for </span><span class="s1">column </span><span class="s2">in </span><span class="s1">columns:</span>
            <span class="s1">dtype = frame[column].dtype</span>
            <span class="s2">if not </span><span class="s1">self.is_valid_dtype_n_method(dtype):</span>
                <span class="s2">raise </span><span class="s1">TypeError(</span>
                    <span class="s4">f&quot;Column </span><span class="s2">{</span><span class="s1">repr(column)</span><span class="s2">} </span><span class="s4">has dtype </span><span class="s2">{</span><span class="s1">dtype</span><span class="s2">}</span><span class="s4">, &quot;</span>
                    <span class="s4">f&quot;cannot use method </span><span class="s2">{</span><span class="s1">repr(method)</span><span class="s2">} </span><span class="s4">with this dtype&quot;</span>
                <span class="s1">)</span>

        <span class="s2">def </span><span class="s1">get_indexer(current_indexer</span><span class="s2">, </span><span class="s1">other_indexer):</span>
            <span class="s0">&quot;&quot;&quot; 
            Helper function to concat `current_indexer` and `other_indexer` 
            depending on `method` 
            &quot;&quot;&quot;</span>
            <span class="s2">if </span><span class="s1">method == </span><span class="s4">&quot;nsmallest&quot;</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">current_indexer.append(other_indexer)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">other_indexer.append(current_indexer)</span>

        <span class="s3"># Below we save and reset the index in case index contains duplicates</span>
        <span class="s1">original_index = frame.index</span>
        <span class="s1">cur_frame = frame = frame.reset_index(drop=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s1">cur_n = n</span>
        <span class="s1">indexer = Int64Index([])</span>

        <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">column </span><span class="s2">in </span><span class="s1">enumerate(columns):</span>
            <span class="s3"># For each column we apply method to cur_frame[column].</span>
            <span class="s3"># If it's the last column or if we have the number of</span>
            <span class="s3"># results desired we are done.</span>
            <span class="s3"># Otherwise there are duplicates of the largest/smallest</span>
            <span class="s3"># value and we need to look at the rest of the columns</span>
            <span class="s3"># to determine which of the rows with the largest/smallest</span>
            <span class="s3"># value in the column to keep.</span>
            <span class="s1">series = cur_frame[column]</span>
            <span class="s1">is_last_column = len(columns) - </span><span class="s5">1 </span><span class="s1">== i</span>
            <span class="s1">values = getattr(series</span><span class="s2">, </span><span class="s1">method)(</span>
                <span class="s1">cur_n</span><span class="s2">, </span><span class="s1">keep=self.keep </span><span class="s2">if </span><span class="s1">is_last_column </span><span class="s2">else </span><span class="s4">&quot;all&quot;</span>
            <span class="s1">)</span>

            <span class="s2">if </span><span class="s1">is_last_column </span><span class="s2">or </span><span class="s1">len(values) &lt;= cur_n:</span>
                <span class="s1">indexer = get_indexer(indexer</span><span class="s2">, </span><span class="s1">values.index)</span>
                <span class="s2">break</span>

            <span class="s3"># Now find all values which are equal to</span>
            <span class="s3"># the (nsmallest: largest)/(nlargest: smallest)</span>
            <span class="s3"># from our series.</span>
            <span class="s1">border_value = values == values[values.index[-</span><span class="s5">1</span><span class="s1">]]</span>

            <span class="s3"># Some of these values are among the top-n</span>
            <span class="s3"># some aren't.</span>
            <span class="s1">unsafe_values = values[border_value]</span>

            <span class="s3"># These values are definitely among the top-n</span>
            <span class="s1">safe_values = values[~border_value]</span>
            <span class="s1">indexer = get_indexer(indexer</span><span class="s2">, </span><span class="s1">safe_values.index)</span>

            <span class="s3"># Go on and separate the unsafe_values on the remaining</span>
            <span class="s3"># columns.</span>
            <span class="s1">cur_frame = cur_frame.loc[unsafe_values.index]</span>
            <span class="s1">cur_n = n - len(indexer)</span>

        <span class="s1">frame = frame.take(indexer)</span>

        <span class="s3"># Restore the index on frame</span>
        <span class="s1">frame.index = original_index.take(indexer)</span>

        <span class="s3"># If there is only one column, the frame is already sorted.</span>
        <span class="s2">if </span><span class="s1">len(columns) == </span><span class="s5">1</span><span class="s1">:</span>
            <span class="s2">return </span><span class="s1">frame</span>

        <span class="s1">ascending = method == </span><span class="s4">&quot;nsmallest&quot;</span>

        <span class="s2">return </span><span class="s1">frame.sort_values(columns</span><span class="s2">, </span><span class="s1">ascending=ascending</span><span class="s2">, </span><span class="s1">kind=</span><span class="s4">&quot;mergesort&quot;</span><span class="s1">)</span>


<span class="s3"># ---- #</span>
<span class="s3"># take #</span>
<span class="s3"># ---- #</span>


<span class="s2">def </span><span class="s1">take(</span>
    <span class="s1">arr</span><span class="s2">,</span>
    <span class="s1">indices: TakeIndexer</span><span class="s2">,</span>
    <span class="s1">axis: int = </span><span class="s5">0</span><span class="s2">,</span>
    <span class="s1">allow_fill: bool = </span><span class="s2">False,</span>
    <span class="s1">fill_value=</span><span class="s2">None,</span>
<span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    Take elements from an array. 
 
    Parameters 
    ---------- 
    arr : array-like or scalar value 
        Non array-likes (sequences/scalars without a dtype) are coerced 
        to an ndarray. 
    indices : sequence of int or one-dimensional np.ndarray of int 
        Indices to be taken. 
    axis : int, default 0 
        The axis over which to select values. 
    allow_fill : bool, default False 
        How to handle negative values in `indices`. 
 
        * False: negative values in `indices` indicate positional indices 
          from the right (the default). This is similar to :func:`numpy.take`. 
 
        * True: negative values in `indices` indicate 
          missing values. These values are set to `fill_value`. Any other 
          negative values raise a ``ValueError``. 
 
    fill_value : any, optional 
        Fill value to use for NA-indices when `allow_fill` is True. 
        This may be ``None``, in which case the default NA value for 
        the type (``self.dtype.na_value``) is used. 
 
        For multi-dimensional `arr`, each *element* is filled with 
        `fill_value`. 
 
    Returns 
    ------- 
    ndarray or ExtensionArray 
        Same type as the input. 
 
    Raises 
    ------ 
    IndexError 
        When `indices` is out of bounds for the array. 
    ValueError 
        When the indexer contains negative values other than ``-1`` 
        and `allow_fill` is True. 
 
    Notes 
    ----- 
    When `allow_fill` is False, `indices` may be whatever dimensionality 
    is accepted by NumPy for `arr`. 
 
    When `allow_fill` is True, `indices` should be 1-D. 
 
    See Also 
    -------- 
    numpy.take : Take elements from an array along an axis. 
 
    Examples 
    -------- 
    &gt;&gt;&gt; from pandas.api.extensions import take 
 
    With the default ``allow_fill=False``, negative numbers indicate 
    positional indices from the right. 
 
    &gt;&gt;&gt; take(np.array([10, 20, 30]), [0, 0, -1]) 
    array([10, 10, 30]) 
 
    Setting ``allow_fill=True`` will place `fill_value` in those positions. 
 
    &gt;&gt;&gt; take(np.array([10, 20, 30]), [0, 0, -1], allow_fill=True) 
    array([10., 10., nan]) 
 
    &gt;&gt;&gt; take(np.array([10, 20, 30]), [0, 0, -1], allow_fill=True, 
    ...      fill_value=-10) 
    array([ 10,  10, -10]) 
    &quot;&quot;&quot;</span>
    <span class="s2">if not </span><span class="s1">is_array_like(arr):</span>
        <span class="s1">arr = np.asarray(arr)</span>

    <span class="s1">indices = np.asarray(indices</span><span class="s2">, </span><span class="s1">dtype=np.intp)</span>

    <span class="s2">if </span><span class="s1">allow_fill:</span>
        <span class="s3"># Pandas style, -1 means NA</span>
        <span class="s1">validate_indices(indices</span><span class="s2">, </span><span class="s1">arr.shape[axis])</span>
        <span class="s1">result = take_nd(</span>
            <span class="s1">arr</span><span class="s2">, </span><span class="s1">indices</span><span class="s2">, </span><span class="s1">axis=axis</span><span class="s2">, </span><span class="s1">allow_fill=</span><span class="s2">True, </span><span class="s1">fill_value=fill_value</span>
        <span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s3"># NumPy style</span>
        <span class="s1">result = arr.take(indices</span><span class="s2">, </span><span class="s1">axis=axis)</span>
    <span class="s2">return </span><span class="s1">result</span>


<span class="s3"># ------------ #</span>
<span class="s3"># searchsorted #</span>
<span class="s3"># ------------ #</span>


<span class="s2">def </span><span class="s1">searchsorted(</span>
    <span class="s1">arr: ArrayLike</span><span class="s2">,</span>
    <span class="s1">value: NumpyValueArrayLike | ExtensionArray</span><span class="s2">,</span>
    <span class="s1">side: Literal[</span><span class="s4">&quot;left&quot;</span><span class="s2">, </span><span class="s4">&quot;right&quot;</span><span class="s1">] = </span><span class="s4">&quot;left&quot;</span><span class="s2">,</span>
    <span class="s1">sorter: NumpySorter = </span><span class="s2">None,</span>
<span class="s1">) -&gt; npt.NDArray[np.intp] | np.intp:</span>
    <span class="s0">&quot;&quot;&quot; 
    Find indices where elements should be inserted to maintain order. 
 
    .. versionadded:: 0.25.0 
 
    Find the indices into a sorted array `arr` (a) such that, if the 
    corresponding elements in `value` were inserted before the indices, 
    the order of `arr` would be preserved. 
 
    Assuming that `arr` is sorted: 
 
    ======  ================================ 
    `side`  returned index `i` satisfies 
    ======  ================================ 
    left    ``arr[i-1] &lt; value &lt;= self[i]`` 
    right   ``arr[i-1] &lt;= value &lt; self[i]`` 
    ======  ================================ 
 
    Parameters 
    ---------- 
    arr: np.ndarray, ExtensionArray, Series 
        Input array. If `sorter` is None, then it must be sorted in 
        ascending order, otherwise `sorter` must be an array of indices 
        that sort it. 
    value : array-like or scalar 
        Values to insert into `arr`. 
    side : {'left', 'right'}, optional 
        If 'left', the index of the first suitable location found is given. 
        If 'right', return the last such index.  If there is no suitable 
        index, return either 0 or N (where N is the length of `self`). 
    sorter : 1-D array-like, optional 
        Optional array of integer indices that sort array a into ascending 
        order. They are typically the result of argsort. 
 
    Returns 
    ------- 
    array of ints or int 
        If value is array-like, array of insertion points. 
        If value is scalar, a single integer. 
 
    See Also 
    -------- 
    numpy.searchsorted : Similar method from NumPy. 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">sorter </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">sorter = ensure_platform_int(sorter)</span>

    <span class="s2">if </span><span class="s1">(</span>
        <span class="s1">isinstance(arr</span><span class="s2">, </span><span class="s1">np.ndarray)</span>
        <span class="s2">and </span><span class="s1">is_integer_dtype(arr.dtype)</span>
        <span class="s2">and </span><span class="s1">(is_integer(value) </span><span class="s2">or </span><span class="s1">is_integer_dtype(value))</span>
    <span class="s1">):</span>
        <span class="s3"># if `arr` and `value` have different dtypes, `arr` would be</span>
        <span class="s3"># recast by numpy, causing a slow search.</span>
        <span class="s3"># Before searching below, we therefore try to give `value` the</span>
        <span class="s3"># same dtype as `arr`, while guarding against integer overflows.</span>
        <span class="s1">iinfo = np.iinfo(arr.dtype.type)</span>
        <span class="s1">value_arr = np.array([value]) </span><span class="s2">if </span><span class="s1">is_scalar(value) </span><span class="s2">else </span><span class="s1">np.array(value)</span>
        <span class="s2">if </span><span class="s1">(value_arr &gt;= iinfo.min).all() </span><span class="s2">and </span><span class="s1">(value_arr &lt;= iinfo.max).all():</span>
            <span class="s3"># value within bounds, so no overflow, so can convert value dtype</span>
            <span class="s3"># to dtype of arr</span>
            <span class="s1">dtype = arr.dtype</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dtype = value_arr.dtype</span>

        <span class="s2">if </span><span class="s1">is_scalar(value):</span>
            <span class="s3"># We know that value is int</span>
            <span class="s1">value = cast(int</span><span class="s2">, </span><span class="s1">dtype.type(value))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">value = pd_array(cast(ArrayLike</span><span class="s2">, </span><span class="s1">value)</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s3"># E.g. if `arr` is an array with dtype='datetime64[ns]'</span>
        <span class="s3"># and `value` is a pd.Timestamp, we may need to convert value</span>
        <span class="s1">arr = ensure_wrapped_if_datetimelike(arr)</span>

    <span class="s3"># Argument 1 to &quot;searchsorted&quot; of &quot;ndarray&quot; has incompatible type</span>
    <span class="s3"># &quot;Union[NumpyValueArrayLike, ExtensionArray]&quot;; expected &quot;NumpyValueArrayLike&quot;</span>
    <span class="s2">return </span><span class="s1">arr.searchsorted(value</span><span class="s2">, </span><span class="s1">side=side</span><span class="s2">, </span><span class="s1">sorter=sorter)  </span><span class="s3"># type: ignore[arg-type]</span>


<span class="s3"># ---- #</span>
<span class="s3"># diff #</span>
<span class="s3"># ---- #</span>

<span class="s1">_diff_special = {</span><span class="s4">&quot;float64&quot;</span><span class="s2">, </span><span class="s4">&quot;float32&quot;</span><span class="s2">, </span><span class="s4">&quot;int64&quot;</span><span class="s2">, </span><span class="s4">&quot;int32&quot;</span><span class="s2">, </span><span class="s4">&quot;int16&quot;</span><span class="s2">, </span><span class="s4">&quot;int8&quot;</span><span class="s1">}</span>


<span class="s2">def </span><span class="s1">diff(arr</span><span class="s2">, </span><span class="s1">n: int</span><span class="s2">, </span><span class="s1">axis: int = </span><span class="s5">0</span><span class="s1">):</span>
    <span class="s0">&quot;&quot;&quot; 
    difference of n between self, 
    analogous to s-s.shift(n) 
 
    Parameters 
    ---------- 
    arr : ndarray or ExtensionArray 
    n : int 
        number of periods 
    axis : {0, 1} 
        axis to shift on 
    stacklevel : int, default 3 
        The stacklevel for the lost dtype warning. 
 
    Returns 
    ------- 
    shifted 
    &quot;&quot;&quot;</span>

    <span class="s1">n = int(n)</span>
    <span class="s1">na = np.nan</span>
    <span class="s1">dtype = arr.dtype</span>

    <span class="s1">is_bool = is_bool_dtype(dtype)</span>
    <span class="s2">if </span><span class="s1">is_bool:</span>
        <span class="s1">op = operator.xor</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">op = operator.sub</span>

    <span class="s2">if </span><span class="s1">isinstance(dtype</span><span class="s2">, </span><span class="s1">PandasDtype):</span>
        <span class="s3"># PandasArray cannot necessarily hold shifted versions of itself.</span>
        <span class="s1">arr = arr.to_numpy()</span>
        <span class="s1">dtype = arr.dtype</span>

    <span class="s2">if not </span><span class="s1">isinstance(dtype</span><span class="s2">, </span><span class="s1">np.dtype):</span>
        <span class="s3"># i.e ExtensionDtype</span>
        <span class="s2">if </span><span class="s1">hasattr(arr</span><span class="s2">, </span><span class="s4">f&quot;__</span><span class="s2">{</span><span class="s1">op.__name__</span><span class="s2">}</span><span class="s4">__&quot;</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">axis != </span><span class="s5">0</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">f&quot;cannot diff </span><span class="s2">{</span><span class="s1">type(arr).__name__</span><span class="s2">} </span><span class="s4">on axis=</span><span class="s2">{</span><span class="s1">axis</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span>
            <span class="s2">return </span><span class="s1">op(arr</span><span class="s2">, </span><span class="s1">arr.shift(n))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">warn(</span>
                <span class="s4">&quot;dtype lost in 'diff()'. In the future this will raise a &quot;</span>
                <span class="s4">&quot;TypeError. Convert to a suitable dtype prior to calling 'diff'.&quot;</span><span class="s2">,</span>
                <span class="s1">FutureWarning</span><span class="s2">,</span>
                <span class="s1">stacklevel=find_stack_level()</span><span class="s2">,</span>
            <span class="s1">)</span>
            <span class="s1">arr = np.asarray(arr)</span>
            <span class="s1">dtype = arr.dtype</span>

    <span class="s1">is_timedelta = </span><span class="s2">False</span>
    <span class="s2">if </span><span class="s1">needs_i8_conversion(arr.dtype):</span>
        <span class="s1">dtype = np.int64</span>
        <span class="s1">arr = arr.view(</span><span class="s4">&quot;i8&quot;</span><span class="s1">)</span>
        <span class="s1">na = iNaT</span>
        <span class="s1">is_timedelta = </span><span class="s2">True</span>

    <span class="s2">elif </span><span class="s1">is_bool:</span>
        <span class="s3"># We have to cast in order to be able to hold np.nan</span>
        <span class="s1">dtype = np.object_</span>

    <span class="s2">elif </span><span class="s1">is_integer_dtype(dtype):</span>
        <span class="s3"># We have to cast in order to be able to hold np.nan</span>

        <span class="s3"># int8, int16 are incompatible with float64,</span>
        <span class="s3"># see https://github.com/cython/cython/issues/2646</span>
        <span class="s2">if </span><span class="s1">arr.dtype.name </span><span class="s2">in </span><span class="s1">[</span><span class="s4">&quot;int8&quot;</span><span class="s2">, </span><span class="s4">&quot;int16&quot;</span><span class="s1">]:</span>
            <span class="s1">dtype = np.float32</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dtype = np.float64</span>

    <span class="s1">orig_ndim = arr.ndim</span>
    <span class="s2">if </span><span class="s1">orig_ndim == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s3"># reshape so we can always use algos.diff_2d</span>
        <span class="s1">arr = arr.reshape(-</span><span class="s5">1</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>
        <span class="s3"># TODO: require axis == 0</span>

    <span class="s1">dtype = np.dtype(dtype)</span>
    <span class="s1">out_arr = np.empty(arr.shape</span><span class="s2">, </span><span class="s1">dtype=dtype)</span>

    <span class="s1">na_indexer = [slice(</span><span class="s2">None</span><span class="s1">)] * </span><span class="s5">2</span>
    <span class="s1">na_indexer[axis] = slice(</span><span class="s2">None, </span><span class="s1">n) </span><span class="s2">if </span><span class="s1">n &gt;= </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">slice(n</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s1">out_arr[tuple(na_indexer)] = na</span>

    <span class="s2">if </span><span class="s1">arr.dtype.name </span><span class="s2">in </span><span class="s1">_diff_special:</span>
        <span class="s3"># TODO: can diff_2d dtype specialization troubles be fixed by defining</span>
        <span class="s3">#  out_arr inside diff_2d?</span>
        <span class="s1">algos.diff_2d(arr</span><span class="s2">, </span><span class="s1">out_arr</span><span class="s2">, </span><span class="s1">n</span><span class="s2">, </span><span class="s1">axis</span><span class="s2">, </span><span class="s1">datetimelike=is_timedelta)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s3"># To keep mypy happy, _res_indexer is a list while res_indexer is</span>
        <span class="s3">#  a tuple, ditto for lag_indexer.</span>
        <span class="s1">_res_indexer = [slice(</span><span class="s2">None</span><span class="s1">)] * </span><span class="s5">2</span>
        <span class="s1">_res_indexer[axis] = slice(n</span><span class="s2">, None</span><span class="s1">) </span><span class="s2">if </span><span class="s1">n &gt;= </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">slice(</span><span class="s2">None, </span><span class="s1">n)</span>
        <span class="s1">res_indexer = tuple(_res_indexer)</span>

        <span class="s1">_lag_indexer = [slice(</span><span class="s2">None</span><span class="s1">)] * </span><span class="s5">2</span>
        <span class="s1">_lag_indexer[axis] = slice(</span><span class="s2">None, </span><span class="s1">-n) </span><span class="s2">if </span><span class="s1">n &gt; </span><span class="s5">0 </span><span class="s2">else </span><span class="s1">slice(-n</span><span class="s2">, None</span><span class="s1">)</span>
        <span class="s1">lag_indexer = tuple(_lag_indexer)</span>

        <span class="s1">out_arr[res_indexer] = op(arr[res_indexer]</span><span class="s2">, </span><span class="s1">arr[lag_indexer])</span>

    <span class="s2">if </span><span class="s1">is_timedelta:</span>
        <span class="s1">out_arr = out_arr.view(</span><span class="s4">&quot;timedelta64[ns]&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">orig_ndim == </span><span class="s5">1</span><span class="s1">:</span>
        <span class="s1">out_arr = out_arr[:</span><span class="s2">, </span><span class="s5">0</span><span class="s1">]</span>
    <span class="s2">return </span><span class="s1">out_arr</span>


<span class="s3"># --------------------------------------------------------------------</span>
<span class="s3"># Helper functions</span>

<span class="s3"># Note: safe_sort is in algorithms.py instead of sorting.py because it is</span>
<span class="s3">#  low-dependency, is used in this module, and used private methods from</span>
<span class="s3">#  this module.</span>
<span class="s2">def </span><span class="s1">safe_sort(</span>
    <span class="s1">values</span><span class="s2">,</span>
    <span class="s1">codes=</span><span class="s2">None,</span>
    <span class="s1">na_sentinel: int = -</span><span class="s5">1</span><span class="s2">,</span>
    <span class="s1">assume_unique: bool = </span><span class="s2">False,</span>
    <span class="s1">verify: bool = </span><span class="s2">True,</span>
<span class="s1">) -&gt; np.ndarray | tuple[np.ndarray</span><span class="s2">, </span><span class="s1">np.ndarray]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Sort ``values`` and reorder corresponding ``codes``. 
 
    ``values`` should be unique if ``codes`` is not None. 
    Safe for use with mixed types (int, str), orders ints before strs. 
 
    Parameters 
    ---------- 
    values : list-like 
        Sequence; must be unique if ``codes`` is not None. 
    codes : list_like, optional 
        Indices to ``values``. All out of bound indices are treated as 
        &quot;not found&quot; and will be masked with ``na_sentinel``. 
    na_sentinel : int, default -1 
        Value in ``codes`` to mark &quot;not found&quot;. 
        Ignored when ``codes`` is None. 
    assume_unique : bool, default False 
        When True, ``values`` are assumed to be unique, which can speed up 
        the calculation. Ignored when ``codes`` is None. 
    verify : bool, default True 
        Check if codes are out of bound for the values and put out of bound 
        codes equal to na_sentinel. If ``verify=False``, it is assumed there 
        are no out of bound codes. Ignored when ``codes`` is None. 
 
        .. versionadded:: 0.25.0 
 
    Returns 
    ------- 
    ordered : ndarray 
        Sorted ``values`` 
    new_codes : ndarray 
        Reordered ``codes``; returned when ``codes`` is not None. 
 
    Raises 
    ------ 
    TypeError 
        * If ``values`` is not list-like or if ``codes`` is neither None 
        nor list-like 
        * If ``values`` cannot be sorted 
    ValueError 
        * If ``codes`` is not None and ``values`` contain duplicates. 
    &quot;&quot;&quot;</span>
    <span class="s2">if not </span><span class="s1">is_list_like(values):</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span>
            <span class="s4">&quot;Only list-like objects are allowed to be passed to safe_sort as values&quot;</span>
        <span class="s1">)</span>

    <span class="s2">if not </span><span class="s1">isinstance(values</span><span class="s2">, </span><span class="s1">(np.ndarray</span><span class="s2">, </span><span class="s1">ABCExtensionArray)):</span>
        <span class="s3"># don't convert to string types</span>
        <span class="s1">dtype</span><span class="s2">, </span><span class="s1">_ = infer_dtype_from_array(values)</span>
        <span class="s3"># error: Argument &quot;dtype&quot; to &quot;asarray&quot; has incompatible type &quot;Union[dtype[Any],</span>
        <span class="s3"># ExtensionDtype]&quot;; expected &quot;Union[dtype[Any], None, type, _SupportsDType, str,</span>
        <span class="s3"># Union[Tuple[Any, int], Tuple[Any, Union[int, Sequence[int]]], List[Any],</span>
        <span class="s3"># _DTypeDict, Tuple[Any, Any]]]&quot;</span>
        <span class="s1">values = np.asarray(values</span><span class="s2">, </span><span class="s1">dtype=dtype)  </span><span class="s3"># type: ignore[arg-type]</span>

    <span class="s1">sorter = </span><span class="s2">None</span>

    <span class="s2">if </span><span class="s1">(</span>
        <span class="s2">not </span><span class="s1">is_extension_array_dtype(values)</span>
        <span class="s2">and </span><span class="s1">lib.infer_dtype(values</span><span class="s2">, </span><span class="s1">skipna=</span><span class="s2">False</span><span class="s1">) == </span><span class="s4">&quot;mixed-integer&quot;</span>
    <span class="s1">):</span>
        <span class="s1">ordered = _sort_mixed(values)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">sorter = values.argsort()</span>
            <span class="s1">ordered = values.take(sorter)</span>
        <span class="s2">except </span><span class="s1">TypeError:</span>
            <span class="s3"># Previous sorters failed or were not applicable, try `_sort_mixed`</span>
            <span class="s3"># which would work, but which fails for special case of 1d arrays</span>
            <span class="s3"># with tuples.</span>
            <span class="s2">if </span><span class="s1">values.size </span><span class="s2">and </span><span class="s1">isinstance(values[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">tuple):</span>
                <span class="s1">ordered = _sort_tuples(values)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">ordered = _sort_mixed(values)</span>

    <span class="s3"># codes:</span>

    <span class="s2">if </span><span class="s1">codes </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">ordered</span>

    <span class="s2">if not </span><span class="s1">is_list_like(codes):</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span>
            <span class="s4">&quot;Only list-like objects or None are allowed to &quot;</span>
            <span class="s4">&quot;be passed to safe_sort as codes&quot;</span>
        <span class="s1">)</span>
    <span class="s1">codes = ensure_platform_int(np.asarray(codes))</span>

    <span class="s2">if not </span><span class="s1">assume_unique </span><span class="s2">and not </span><span class="s1">len(unique(values)) == len(values):</span>
        <span class="s2">raise </span><span class="s1">ValueError(</span><span class="s4">&quot;values should be unique if codes is not None&quot;</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">sorter </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s3"># mixed types</span>
        <span class="s1">hash_klass</span><span class="s2">, </span><span class="s1">values = _get_data_algo(values)</span>
        <span class="s1">t = hash_klass(len(values))</span>
        <span class="s1">t.map_locations(values)</span>
        <span class="s1">sorter = ensure_platform_int(t.lookup(ordered))</span>

    <span class="s2">if </span><span class="s1">na_sentinel == -</span><span class="s5">1</span><span class="s1">:</span>
        <span class="s3"># take_nd is faster, but only works for na_sentinels of -1</span>
        <span class="s1">order2 = sorter.argsort()</span>
        <span class="s1">new_codes = take_nd(order2</span><span class="s2">, </span><span class="s1">codes</span><span class="s2">, </span><span class="s1">fill_value=-</span><span class="s5">1</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">verify:</span>
            <span class="s1">mask = (codes &lt; -len(values)) | (codes &gt;= len(values))</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">mask = </span><span class="s2">None</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">reverse_indexer = np.empty(len(sorter)</span><span class="s2">, </span><span class="s1">dtype=np.int_)</span>
        <span class="s1">reverse_indexer.put(sorter</span><span class="s2">, </span><span class="s1">np.arange(len(sorter)))</span>
        <span class="s3"># Out of bound indices will be masked with `na_sentinel` next, so we</span>
        <span class="s3"># may deal with them here without performance loss using `mode='wrap'`</span>
        <span class="s1">new_codes = reverse_indexer.take(codes</span><span class="s2">, </span><span class="s1">mode=</span><span class="s4">&quot;wrap&quot;</span><span class="s1">)</span>

        <span class="s1">mask = codes == na_sentinel</span>
        <span class="s2">if </span><span class="s1">verify:</span>
            <span class="s1">mask = mask | (codes &lt; -len(values)) | (codes &gt;= len(values))</span>

    <span class="s2">if </span><span class="s1">mask </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">np.putmask(new_codes</span><span class="s2">, </span><span class="s1">mask</span><span class="s2">, </span><span class="s1">na_sentinel)</span>

    <span class="s2">return </span><span class="s1">ordered</span><span class="s2">, </span><span class="s1">ensure_platform_int(new_codes)</span>


<span class="s2">def </span><span class="s1">_sort_mixed(values) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot;order ints before strings in 1d arrays, safe in py3&quot;&quot;&quot;</span>
    <span class="s1">str_pos = np.array([isinstance(x</span><span class="s2">, </span><span class="s1">str) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">values]</span><span class="s2">, </span><span class="s1">dtype=bool)</span>
    <span class="s1">nums = np.sort(values[~str_pos])</span>
    <span class="s1">strs = np.sort(values[str_pos])</span>
    <span class="s2">return </span><span class="s1">np.concatenate([nums</span><span class="s2">, </span><span class="s1">np.asarray(strs</span><span class="s2">, </span><span class="s1">dtype=object)])</span>


<span class="s2">def </span><span class="s1">_sort_tuples(values: np.ndarray) -&gt; np.ndarray:</span>
    <span class="s0">&quot;&quot;&quot; 
    Convert array of tuples (1d) to array or array (2d). 
    We need to keep the columns separately as they contain different types and 
    nans (can't use `np.sort` as it may fail when str and nan are mixed in a 
    column as types cannot be compared). 
    &quot;&quot;&quot;</span>
    <span class="s2">from </span><span class="s1">pandas.core.internals.construction </span><span class="s2">import </span><span class="s1">to_arrays</span>
    <span class="s2">from </span><span class="s1">pandas.core.sorting </span><span class="s2">import </span><span class="s1">lexsort_indexer</span>

    <span class="s1">arrays</span><span class="s2">, </span><span class="s1">_ = to_arrays(values</span><span class="s2">, None</span><span class="s1">)</span>
    <span class="s1">indexer = lexsort_indexer(arrays</span><span class="s2">, </span><span class="s1">orders=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">values[indexer]</span>


<span class="s2">def </span><span class="s1">union_with_duplicates(lvals: ArrayLike</span><span class="s2">, </span><span class="s1">rvals: ArrayLike) -&gt; ArrayLike:</span>
    <span class="s0">&quot;&quot;&quot; 
    Extracts the union from lvals and rvals with respect to duplicates and nans in 
    both arrays. 
 
    Parameters 
    ---------- 
    lvals: np.ndarray or ExtensionArray 
        left values which is ordered in front. 
    rvals: np.ndarray or ExtensionArray 
        right values ordered after lvals. 
 
    Returns 
    ------- 
    np.ndarray or ExtensionArray 
        Containing the unsorted union of both arrays. 
 
    Notes 
    ----- 
    Caller is responsible for ensuring lvals.dtype == rvals.dtype. 
    &quot;&quot;&quot;</span>
    <span class="s1">indexer = []</span>
    <span class="s1">l_count = value_counts(lvals</span><span class="s2">, </span><span class="s1">dropna=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">r_count = value_counts(rvals</span><span class="s2">, </span><span class="s1">dropna=</span><span class="s2">False</span><span class="s1">)</span>
    <span class="s1">l_count</span><span class="s2">, </span><span class="s1">r_count = l_count.align(r_count</span><span class="s2">, </span><span class="s1">fill_value=</span><span class="s5">0</span><span class="s1">)</span>
    <span class="s1">unique_array = unique(concat_compat([lvals</span><span class="s2">, </span><span class="s1">rvals]))</span>
    <span class="s1">unique_array = ensure_wrapped_if_datetimelike(unique_array)</span>

    <span class="s2">for </span><span class="s1">i</span><span class="s2">, </span><span class="s1">value </span><span class="s2">in </span><span class="s1">enumerate(unique_array):</span>
        <span class="s1">indexer += [i] * int(max(l_count.at[value]</span><span class="s2">, </span><span class="s1">r_count.at[value]))</span>
    <span class="s2">return </span><span class="s1">unique_array.take(indexer)</span>
</pre>
</body>
</html>