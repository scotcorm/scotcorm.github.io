<html>
<head>
<title>lexer.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
lexer.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot;Implements a Jinja / Python combination lexer. The ``Lexer`` class 
is used to do some preprocessing. It filters out invalid operators like 
the bitshift operators we don't allow in templates. It separates 
template code and python code in expressions. 
&quot;&quot;&quot;</span>
<span class="s2">import </span><span class="s1">re</span>
<span class="s2">import </span><span class="s1">typing </span><span class="s2">as </span><span class="s1">t</span>
<span class="s2">from </span><span class="s1">ast </span><span class="s2">import </span><span class="s1">literal_eval</span>
<span class="s2">from </span><span class="s1">collections </span><span class="s2">import </span><span class="s1">deque</span>
<span class="s2">from </span><span class="s1">sys </span><span class="s2">import </span><span class="s1">intern</span>

<span class="s2">from </span><span class="s1">._identifier </span><span class="s2">import </span><span class="s1">pattern </span><span class="s2">as </span><span class="s1">name_re</span>
<span class="s2">from </span><span class="s1">.exceptions </span><span class="s2">import </span><span class="s1">TemplateSyntaxError</span>
<span class="s2">from </span><span class="s1">.utils </span><span class="s2">import </span><span class="s1">LRUCache</span>

<span class="s2">if </span><span class="s1">t.TYPE_CHECKING:</span>
    <span class="s2">import </span><span class="s1">typing_extensions </span><span class="s2">as </span><span class="s1">te</span>
    <span class="s2">from </span><span class="s1">.environment </span><span class="s2">import </span><span class="s1">Environment</span>

<span class="s3"># cache for the lexers. Exists in order to be able to have multiple</span>
<span class="s3"># environments with the same lexer</span>
<span class="s1">_lexer_cache: t.MutableMapping[t.Tuple</span><span class="s2">, </span><span class="s4">&quot;Lexer&quot;</span><span class="s1">] = LRUCache(</span><span class="s5">50</span><span class="s1">)  </span><span class="s3"># type: ignore</span>

<span class="s3"># static regular expressions</span>
<span class="s1">whitespace_re = re.compile(</span><span class="s4">r&quot;\s+&quot;</span><span class="s1">)</span>
<span class="s1">newline_re = re.compile(</span><span class="s4">r&quot;(\r\n|\r|\n)&quot;</span><span class="s1">)</span>
<span class="s1">string_re = re.compile(</span>
    <span class="s4">r&quot;('([^'\\]*(?:\\.[^'\\]*)*)'&quot; r'|&quot;([^&quot;\\]*(?:\\.[^&quot;\\]*)*)&quot;)'</span><span class="s2">, </span><span class="s1">re.S</span>
<span class="s1">)</span>
<span class="s1">integer_re = re.compile(</span>
    <span class="s4">r&quot;&quot;&quot; 
    ( 
        0b(_?[0-1])+ # binary 
    | 
        0o(_?[0-7])+ # octal 
    | 
        0x(_?[\da-f])+ # hex 
    | 
        [1-9](_?\d)* # decimal 
    | 
        0(_?0)* # decimal zero 
    ) 
    &quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s1">re.IGNORECASE | re.VERBOSE</span><span class="s2">,</span>
<span class="s1">)</span>
<span class="s1">float_re = re.compile(</span>
    <span class="s4">r&quot;&quot;&quot; 
    (?&lt;!\.)  # doesn't start with a . 
    (\d+_)*\d+  # digits, possibly _ separated 
    ( 
        (\.(\d+_)*\d+)?  # optional fractional part 
        e[+\-]?(\d+_)*\d+  # exponent part 
    | 
        \.(\d+_)*\d+  # required fractional part 
    ) 
    &quot;&quot;&quot;</span><span class="s2">,</span>
    <span class="s1">re.IGNORECASE | re.VERBOSE</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s3"># internal the tokens and keep references to them</span>
<span class="s1">TOKEN_ADD = intern(</span><span class="s4">&quot;add&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_ASSIGN = intern(</span><span class="s4">&quot;assign&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_COLON = intern(</span><span class="s4">&quot;colon&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_COMMA = intern(</span><span class="s4">&quot;comma&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_DIV = intern(</span><span class="s4">&quot;div&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_DOT = intern(</span><span class="s4">&quot;dot&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_EQ = intern(</span><span class="s4">&quot;eq&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_FLOORDIV = intern(</span><span class="s4">&quot;floordiv&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_GT = intern(</span><span class="s4">&quot;gt&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_GTEQ = intern(</span><span class="s4">&quot;gteq&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LBRACE = intern(</span><span class="s4">&quot;lbrace&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LBRACKET = intern(</span><span class="s4">&quot;lbracket&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LPAREN = intern(</span><span class="s4">&quot;lparen&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LT = intern(</span><span class="s4">&quot;lt&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LTEQ = intern(</span><span class="s4">&quot;lteq&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_MOD = intern(</span><span class="s4">&quot;mod&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_MUL = intern(</span><span class="s4">&quot;mul&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_NE = intern(</span><span class="s4">&quot;ne&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_PIPE = intern(</span><span class="s4">&quot;pipe&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_POW = intern(</span><span class="s4">&quot;pow&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_RBRACE = intern(</span><span class="s4">&quot;rbrace&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_RBRACKET = intern(</span><span class="s4">&quot;rbracket&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_RPAREN = intern(</span><span class="s4">&quot;rparen&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_SEMICOLON = intern(</span><span class="s4">&quot;semicolon&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_SUB = intern(</span><span class="s4">&quot;sub&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_TILDE = intern(</span><span class="s4">&quot;tilde&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_WHITESPACE = intern(</span><span class="s4">&quot;whitespace&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_FLOAT = intern(</span><span class="s4">&quot;float&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_INTEGER = intern(</span><span class="s4">&quot;integer&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_NAME = intern(</span><span class="s4">&quot;name&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_STRING = intern(</span><span class="s4">&quot;string&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_OPERATOR = intern(</span><span class="s4">&quot;operator&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_BLOCK_BEGIN = intern(</span><span class="s4">&quot;block_begin&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_BLOCK_END = intern(</span><span class="s4">&quot;block_end&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_VARIABLE_BEGIN = intern(</span><span class="s4">&quot;variable_begin&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_VARIABLE_END = intern(</span><span class="s4">&quot;variable_end&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_RAW_BEGIN = intern(</span><span class="s4">&quot;raw_begin&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_RAW_END = intern(</span><span class="s4">&quot;raw_end&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_COMMENT_BEGIN = intern(</span><span class="s4">&quot;comment_begin&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_COMMENT_END = intern(</span><span class="s4">&quot;comment_end&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_COMMENT = intern(</span><span class="s4">&quot;comment&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LINESTATEMENT_BEGIN = intern(</span><span class="s4">&quot;linestatement_begin&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LINESTATEMENT_END = intern(</span><span class="s4">&quot;linestatement_end&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LINECOMMENT_BEGIN = intern(</span><span class="s4">&quot;linecomment_begin&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LINECOMMENT_END = intern(</span><span class="s4">&quot;linecomment_end&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_LINECOMMENT = intern(</span><span class="s4">&quot;linecomment&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_DATA = intern(</span><span class="s4">&quot;data&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_INITIAL = intern(</span><span class="s4">&quot;initial&quot;</span><span class="s1">)</span>
<span class="s1">TOKEN_EOF = intern(</span><span class="s4">&quot;eof&quot;</span><span class="s1">)</span>

<span class="s3"># bind operators to token types</span>
<span class="s1">operators = {</span>
    <span class="s4">&quot;+&quot;</span><span class="s1">: TOKEN_ADD</span><span class="s2">,</span>
    <span class="s4">&quot;-&quot;</span><span class="s1">: TOKEN_SUB</span><span class="s2">,</span>
    <span class="s4">&quot;/&quot;</span><span class="s1">: TOKEN_DIV</span><span class="s2">,</span>
    <span class="s4">&quot;//&quot;</span><span class="s1">: TOKEN_FLOORDIV</span><span class="s2">,</span>
    <span class="s4">&quot;*&quot;</span><span class="s1">: TOKEN_MUL</span><span class="s2">,</span>
    <span class="s4">&quot;%&quot;</span><span class="s1">: TOKEN_MOD</span><span class="s2">,</span>
    <span class="s4">&quot;**&quot;</span><span class="s1">: TOKEN_POW</span><span class="s2">,</span>
    <span class="s4">&quot;~&quot;</span><span class="s1">: TOKEN_TILDE</span><span class="s2">,</span>
    <span class="s4">&quot;[&quot;</span><span class="s1">: TOKEN_LBRACKET</span><span class="s2">,</span>
    <span class="s4">&quot;]&quot;</span><span class="s1">: TOKEN_RBRACKET</span><span class="s2">,</span>
    <span class="s4">&quot;(&quot;</span><span class="s1">: TOKEN_LPAREN</span><span class="s2">,</span>
    <span class="s4">&quot;)&quot;</span><span class="s1">: TOKEN_RPAREN</span><span class="s2">,</span>
    <span class="s4">&quot;{&quot;</span><span class="s1">: TOKEN_LBRACE</span><span class="s2">,</span>
    <span class="s4">&quot;}&quot;</span><span class="s1">: TOKEN_RBRACE</span><span class="s2">,</span>
    <span class="s4">&quot;==&quot;</span><span class="s1">: TOKEN_EQ</span><span class="s2">,</span>
    <span class="s4">&quot;!=&quot;</span><span class="s1">: TOKEN_NE</span><span class="s2">,</span>
    <span class="s4">&quot;&gt;&quot;</span><span class="s1">: TOKEN_GT</span><span class="s2">,</span>
    <span class="s4">&quot;&gt;=&quot;</span><span class="s1">: TOKEN_GTEQ</span><span class="s2">,</span>
    <span class="s4">&quot;&lt;&quot;</span><span class="s1">: TOKEN_LT</span><span class="s2">,</span>
    <span class="s4">&quot;&lt;=&quot;</span><span class="s1">: TOKEN_LTEQ</span><span class="s2">,</span>
    <span class="s4">&quot;=&quot;</span><span class="s1">: TOKEN_ASSIGN</span><span class="s2">,</span>
    <span class="s4">&quot;.&quot;</span><span class="s1">: TOKEN_DOT</span><span class="s2">,</span>
    <span class="s4">&quot;:&quot;</span><span class="s1">: TOKEN_COLON</span><span class="s2">,</span>
    <span class="s4">&quot;|&quot;</span><span class="s1">: TOKEN_PIPE</span><span class="s2">,</span>
    <span class="s4">&quot;,&quot;</span><span class="s1">: TOKEN_COMMA</span><span class="s2">,</span>
    <span class="s4">&quot;;&quot;</span><span class="s1">: TOKEN_SEMICOLON</span><span class="s2">,</span>
<span class="s1">}</span>

<span class="s1">reverse_operators = {v: k </span><span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">operators.items()}</span>
<span class="s2">assert </span><span class="s1">len(operators) == len(reverse_operators)</span><span class="s2">, </span><span class="s4">&quot;operators dropped&quot;</span>
<span class="s1">operator_re = re.compile(</span>
    <span class="s4">f&quot;(</span><span class="s2">{</span><span class="s4">'|'</span><span class="s1">.join(re.escape(x) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">sorted(operators</span><span class="s2">, </span><span class="s1">key=</span><span class="s2">lambda </span><span class="s1">x: -len(x)))</span><span class="s2">}</span><span class="s4">)&quot;</span>
<span class="s1">)</span>

<span class="s1">ignored_tokens = frozenset(</span>
    <span class="s1">[</span>
        <span class="s1">TOKEN_COMMENT_BEGIN</span><span class="s2">,</span>
        <span class="s1">TOKEN_COMMENT</span><span class="s2">,</span>
        <span class="s1">TOKEN_COMMENT_END</span><span class="s2">,</span>
        <span class="s1">TOKEN_WHITESPACE</span><span class="s2">,</span>
        <span class="s1">TOKEN_LINECOMMENT_BEGIN</span><span class="s2">,</span>
        <span class="s1">TOKEN_LINECOMMENT_END</span><span class="s2">,</span>
        <span class="s1">TOKEN_LINECOMMENT</span><span class="s2">,</span>
    <span class="s1">]</span>
<span class="s1">)</span>
<span class="s1">ignore_if_empty = frozenset(</span>
    <span class="s1">[TOKEN_WHITESPACE</span><span class="s2">, </span><span class="s1">TOKEN_DATA</span><span class="s2">, </span><span class="s1">TOKEN_COMMENT</span><span class="s2">, </span><span class="s1">TOKEN_LINECOMMENT]</span>
<span class="s1">)</span>


<span class="s2">def </span><span class="s1">_describe_token_type(token_type: str) -&gt; str:</span>
    <span class="s2">if </span><span class="s1">token_type </span><span class="s2">in </span><span class="s1">reverse_operators:</span>
        <span class="s2">return </span><span class="s1">reverse_operators[token_type]</span>

    <span class="s2">return </span><span class="s1">{</span>
        <span class="s1">TOKEN_COMMENT_BEGIN: </span><span class="s4">&quot;begin of comment&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_COMMENT_END: </span><span class="s4">&quot;end of comment&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_COMMENT: </span><span class="s4">&quot;comment&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_LINECOMMENT: </span><span class="s4">&quot;comment&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_BLOCK_BEGIN: </span><span class="s4">&quot;begin of statement block&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_BLOCK_END: </span><span class="s4">&quot;end of statement block&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_VARIABLE_BEGIN: </span><span class="s4">&quot;begin of print statement&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_VARIABLE_END: </span><span class="s4">&quot;end of print statement&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_LINESTATEMENT_BEGIN: </span><span class="s4">&quot;begin of line statement&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_LINESTATEMENT_END: </span><span class="s4">&quot;end of line statement&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_DATA: </span><span class="s4">&quot;template data / text&quot;</span><span class="s2">,</span>
        <span class="s1">TOKEN_EOF: </span><span class="s4">&quot;end of template&quot;</span><span class="s2">,</span>
    <span class="s1">}.get(token_type</span><span class="s2">, </span><span class="s1">token_type)</span>


<span class="s2">def </span><span class="s1">describe_token(token: </span><span class="s4">&quot;Token&quot;</span><span class="s1">) -&gt; str:</span>
    <span class="s0">&quot;&quot;&quot;Returns a description of the token.&quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">token.type == TOKEN_NAME:</span>
        <span class="s2">return </span><span class="s1">token.value</span>

    <span class="s2">return </span><span class="s1">_describe_token_type(token.type)</span>


<span class="s2">def </span><span class="s1">describe_token_expr(expr: str) -&gt; str:</span>
    <span class="s0">&quot;&quot;&quot;Like `describe_token` but for token expressions.&quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s4">&quot;:&quot; </span><span class="s2">in </span><span class="s1">expr:</span>
        <span class="s1">type</span><span class="s2">, </span><span class="s1">value = expr.split(</span><span class="s4">&quot;:&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">type == TOKEN_NAME:</span>
            <span class="s2">return </span><span class="s1">value</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">type = expr</span>

    <span class="s2">return </span><span class="s1">_describe_token_type(type)</span>


<span class="s2">def </span><span class="s1">count_newlines(value: str) -&gt; int:</span>
    <span class="s0">&quot;&quot;&quot;Count the number of newline characters in the string.  This is 
    useful for extensions that filter a stream. 
    &quot;&quot;&quot;</span>
    <span class="s2">return </span><span class="s1">len(newline_re.findall(value))</span>


<span class="s2">def </span><span class="s1">compile_rules(environment: </span><span class="s4">&quot;Environment&quot;</span><span class="s1">) -&gt; t.List[t.Tuple[str</span><span class="s2">, </span><span class="s1">str]]:</span>
    <span class="s0">&quot;&quot;&quot;Compiles all the rules from the environment into a list of rules.&quot;&quot;&quot;</span>
    <span class="s1">e = re.escape</span>
    <span class="s1">rules = [</span>
        <span class="s1">(</span>
            <span class="s1">len(environment.comment_start_string)</span><span class="s2">,</span>
            <span class="s1">TOKEN_COMMENT_BEGIN</span><span class="s2">,</span>
            <span class="s1">e(environment.comment_start_string)</span><span class="s2">,</span>
        <span class="s1">)</span><span class="s2">,</span>
        <span class="s1">(</span>
            <span class="s1">len(environment.block_start_string)</span><span class="s2">,</span>
            <span class="s1">TOKEN_BLOCK_BEGIN</span><span class="s2">,</span>
            <span class="s1">e(environment.block_start_string)</span><span class="s2">,</span>
        <span class="s1">)</span><span class="s2">,</span>
        <span class="s1">(</span>
            <span class="s1">len(environment.variable_start_string)</span><span class="s2">,</span>
            <span class="s1">TOKEN_VARIABLE_BEGIN</span><span class="s2">,</span>
            <span class="s1">e(environment.variable_start_string)</span><span class="s2">,</span>
        <span class="s1">)</span><span class="s2">,</span>
    <span class="s1">]</span>

    <span class="s2">if </span><span class="s1">environment.line_statement_prefix </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">rules.append(</span>
            <span class="s1">(</span>
                <span class="s1">len(environment.line_statement_prefix)</span><span class="s2">,</span>
                <span class="s1">TOKEN_LINESTATEMENT_BEGIN</span><span class="s2">,</span>
                <span class="s4">r&quot;^[ \t\v]*&quot; </span><span class="s1">+ e(environment.line_statement_prefix)</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s1">)</span>
    <span class="s2">if </span><span class="s1">environment.line_comment_prefix </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">rules.append(</span>
            <span class="s1">(</span>
                <span class="s1">len(environment.line_comment_prefix)</span><span class="s2">,</span>
                <span class="s1">TOKEN_LINECOMMENT_BEGIN</span><span class="s2">,</span>
                <span class="s4">r&quot;(?:^|(?&lt;=\S))[^\S\r\n]*&quot; </span><span class="s1">+ e(environment.line_comment_prefix)</span><span class="s2">,</span>
            <span class="s1">)</span>
        <span class="s1">)</span>

    <span class="s2">return </span><span class="s1">[x[</span><span class="s5">1</span><span class="s1">:] </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">sorted(rules</span><span class="s2">, </span><span class="s1">reverse=</span><span class="s2">True</span><span class="s1">)]</span>


<span class="s2">class </span><span class="s1">Failure:</span>
    <span class="s0">&quot;&quot;&quot;Class that raises a `TemplateSyntaxError` if called. 
    Used by the `Lexer` to specify known errors. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">, </span><span class="s1">message: str</span><span class="s2">, </span><span class="s1">cls: t.Type[TemplateSyntaxError] = TemplateSyntaxError</span>
    <span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">self.message = message</span>
        <span class="s1">self.error_class = cls</span>

    <span class="s2">def </span><span class="s1">__call__(self</span><span class="s2">, </span><span class="s1">lineno: int</span><span class="s2">, </span><span class="s1">filename: str) -&gt; </span><span class="s4">&quot;te.NoReturn&quot;</span><span class="s1">:</span>
        <span class="s2">raise </span><span class="s1">self.error_class(self.message</span><span class="s2">, </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">filename)</span>


<span class="s2">class </span><span class="s1">Token(t.NamedTuple):</span>
    <span class="s1">lineno: int</span>
    <span class="s1">type: str</span>
    <span class="s1">value: str</span>

    <span class="s2">def </span><span class="s1">__str__(self) -&gt; str:</span>
        <span class="s2">return </span><span class="s1">describe_token(self)</span>

    <span class="s2">def </span><span class="s1">test(self</span><span class="s2">, </span><span class="s1">expr: str) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot;Test a token against a token expression.  This can either be a 
        token type or ``'token_type:token_value'``.  This can only test 
        against string values and types. 
        &quot;&quot;&quot;</span>
        <span class="s3"># here we do a regular string equality check as test_any is usually</span>
        <span class="s3"># passed an iterable of not interned strings.</span>
        <span class="s2">if </span><span class="s1">self.type == expr:</span>
            <span class="s2">return True</span>

        <span class="s2">if </span><span class="s4">&quot;:&quot; </span><span class="s2">in </span><span class="s1">expr:</span>
            <span class="s2">return </span><span class="s1">expr.split(</span><span class="s4">&quot;:&quot;</span><span class="s2">, </span><span class="s5">1</span><span class="s1">) == [self.type</span><span class="s2">, </span><span class="s1">self.value]</span>

        <span class="s2">return False</span>

    <span class="s2">def </span><span class="s1">test_any(self</span><span class="s2">, </span><span class="s1">*iterable: str) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot;Test against multiple token expressions.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">any(self.test(expr) </span><span class="s2">for </span><span class="s1">expr </span><span class="s2">in </span><span class="s1">iterable)</span>


<span class="s2">class </span><span class="s1">TokenStreamIterator:</span>
    <span class="s0">&quot;&quot;&quot;The iterator for tokenstreams.  Iterate over the stream 
    until the eof token is reached. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">stream: </span><span class="s4">&quot;TokenStream&quot;</span><span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">self.stream = stream</span>

    <span class="s2">def </span><span class="s1">__iter__(self) -&gt; </span><span class="s4">&quot;TokenStreamIterator&quot;</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">__next__(self) -&gt; Token:</span>
        <span class="s1">token = self.stream.current</span>

        <span class="s2">if </span><span class="s1">token.type </span><span class="s2">is </span><span class="s1">TOKEN_EOF:</span>
            <span class="s1">self.stream.close()</span>
            <span class="s2">raise </span><span class="s1">StopIteration</span>

        <span class="s1">next(self.stream)</span>
        <span class="s2">return </span><span class="s1">token</span>


<span class="s2">class </span><span class="s1">TokenStream:</span>
    <span class="s0">&quot;&quot;&quot;A token stream is an iterable that yields :class:`Token`\\s.  The 
    parser however does not iterate over it but calls :meth:`next` to go 
    one token ahead.  The current active token is stored as :attr:`current`. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">generator: t.Iterable[Token]</span><span class="s2">,</span>
        <span class="s1">name: t.Optional[str]</span><span class="s2">,</span>
        <span class="s1">filename: t.Optional[str]</span><span class="s2">,</span>
    <span class="s1">):</span>
        <span class="s1">self._iter = iter(generator)</span>
        <span class="s1">self._pushed: </span><span class="s4">&quot;te.Deque[Token]&quot; </span><span class="s1">= deque()</span>
        <span class="s1">self.name = name</span>
        <span class="s1">self.filename = filename</span>
        <span class="s1">self.closed = </span><span class="s2">False</span>
        <span class="s1">self.current = Token(</span><span class="s5">1</span><span class="s2">, </span><span class="s1">TOKEN_INITIAL</span><span class="s2">, </span><span class="s4">&quot;&quot;</span><span class="s1">)</span>
        <span class="s1">next(self)</span>

    <span class="s2">def </span><span class="s1">__iter__(self) -&gt; TokenStreamIterator:</span>
        <span class="s2">return </span><span class="s1">TokenStreamIterator(self)</span>

    <span class="s2">def </span><span class="s1">__bool__(self) -&gt; bool:</span>
        <span class="s2">return </span><span class="s1">bool(self._pushed) </span><span class="s2">or </span><span class="s1">self.current.type </span><span class="s2">is not </span><span class="s1">TOKEN_EOF</span>

    <span class="s1">@property</span>
    <span class="s2">def </span><span class="s1">eos(self) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot;Are we at the end of the stream?&quot;&quot;&quot;</span>
        <span class="s2">return not </span><span class="s1">self</span>

    <span class="s2">def </span><span class="s1">push(self</span><span class="s2">, </span><span class="s1">token: Token) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot;Push a token back to the stream.&quot;&quot;&quot;</span>
        <span class="s1">self._pushed.append(token)</span>

    <span class="s2">def </span><span class="s1">look(self) -&gt; Token:</span>
        <span class="s0">&quot;&quot;&quot;Look at the next token.&quot;&quot;&quot;</span>
        <span class="s1">old_token = next(self)</span>
        <span class="s1">result = self.current</span>
        <span class="s1">self.push(result)</span>
        <span class="s1">self.current = old_token</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">skip(self</span><span class="s2">, </span><span class="s1">n: int = </span><span class="s5">1</span><span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot;Got n tokens ahead.&quot;&quot;&quot;</span>
        <span class="s2">for </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">range(n):</span>
            <span class="s1">next(self)</span>

    <span class="s2">def </span><span class="s1">next_if(self</span><span class="s2">, </span><span class="s1">expr: str) -&gt; t.Optional[Token]:</span>
        <span class="s0">&quot;&quot;&quot;Perform the token test and return the token if it matched. 
        Otherwise the return value is `None`. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.current.test(expr):</span>
            <span class="s2">return </span><span class="s1">next(self)</span>

        <span class="s2">return None</span>

    <span class="s2">def </span><span class="s1">skip_if(self</span><span class="s2">, </span><span class="s1">expr: str) -&gt; bool:</span>
        <span class="s0">&quot;&quot;&quot;Like :meth:`next_if` but only returns `True` or `False`.&quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.next_if(expr) </span><span class="s2">is not None</span>

    <span class="s2">def </span><span class="s1">__next__(self) -&gt; Token:</span>
        <span class="s0">&quot;&quot;&quot;Go one token ahead and return the old one. 
 
        Use the built-in :func:`next` instead of calling this directly. 
        &quot;&quot;&quot;</span>
        <span class="s1">rv = self.current</span>

        <span class="s2">if </span><span class="s1">self._pushed:</span>
            <span class="s1">self.current = self._pushed.popleft()</span>
        <span class="s2">elif </span><span class="s1">self.current.type </span><span class="s2">is not </span><span class="s1">TOKEN_EOF:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">self.current = next(self._iter)</span>
            <span class="s2">except </span><span class="s1">StopIteration:</span>
                <span class="s1">self.close()</span>

        <span class="s2">return </span><span class="s1">rv</span>

    <span class="s2">def </span><span class="s1">close(self) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s0">&quot;&quot;&quot;Close the stream.&quot;&quot;&quot;</span>
        <span class="s1">self.current = Token(self.current.lineno</span><span class="s2">, </span><span class="s1">TOKEN_EOF</span><span class="s2">, </span><span class="s4">&quot;&quot;</span><span class="s1">)</span>
        <span class="s1">self._iter = iter(())</span>
        <span class="s1">self.closed = </span><span class="s2">True</span>

    <span class="s2">def </span><span class="s1">expect(self</span><span class="s2">, </span><span class="s1">expr: str) -&gt; Token:</span>
        <span class="s0">&quot;&quot;&quot;Expect a given token type and return it.  This accepts the same 
        argument as :meth:`jinja2.lexer.Token.test`. 
        &quot;&quot;&quot;</span>
        <span class="s2">if not </span><span class="s1">self.current.test(expr):</span>
            <span class="s1">expr = describe_token_expr(expr)</span>

            <span class="s2">if </span><span class="s1">self.current.type </span><span class="s2">is </span><span class="s1">TOKEN_EOF:</span>
                <span class="s2">raise </span><span class="s1">TemplateSyntaxError(</span>
                    <span class="s4">f&quot;unexpected end of template, expected </span><span class="s2">{</span><span class="s1">expr</span><span class="s2">!r}</span><span class="s4">.&quot;</span><span class="s2">,</span>
                    <span class="s1">self.current.lineno</span><span class="s2">,</span>
                    <span class="s1">self.name</span><span class="s2">,</span>
                    <span class="s1">self.filename</span><span class="s2">,</span>
                <span class="s1">)</span>

            <span class="s2">raise </span><span class="s1">TemplateSyntaxError(</span>
                <span class="s4">f&quot;expected token </span><span class="s2">{</span><span class="s1">expr</span><span class="s2">!r}</span><span class="s4">, got </span><span class="s2">{</span><span class="s1">describe_token(self.current)</span><span class="s2">!r}</span><span class="s4">&quot;</span><span class="s2">,</span>
                <span class="s1">self.current.lineno</span><span class="s2">,</span>
                <span class="s1">self.name</span><span class="s2">,</span>
                <span class="s1">self.filename</span><span class="s2">,</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">next(self)</span>


<span class="s2">def </span><span class="s1">get_lexer(environment: </span><span class="s4">&quot;Environment&quot;</span><span class="s1">) -&gt; </span><span class="s4">&quot;Lexer&quot;</span><span class="s1">:</span>
    <span class="s0">&quot;&quot;&quot;Return a lexer which is probably cached.&quot;&quot;&quot;</span>
    <span class="s1">key = (</span>
        <span class="s1">environment.block_start_string</span><span class="s2">,</span>
        <span class="s1">environment.block_end_string</span><span class="s2">,</span>
        <span class="s1">environment.variable_start_string</span><span class="s2">,</span>
        <span class="s1">environment.variable_end_string</span><span class="s2">,</span>
        <span class="s1">environment.comment_start_string</span><span class="s2">,</span>
        <span class="s1">environment.comment_end_string</span><span class="s2">,</span>
        <span class="s1">environment.line_statement_prefix</span><span class="s2">,</span>
        <span class="s1">environment.line_comment_prefix</span><span class="s2">,</span>
        <span class="s1">environment.trim_blocks</span><span class="s2">,</span>
        <span class="s1">environment.lstrip_blocks</span><span class="s2">,</span>
        <span class="s1">environment.newline_sequence</span><span class="s2">,</span>
        <span class="s1">environment.keep_trailing_newline</span><span class="s2">,</span>
    <span class="s1">)</span>
    <span class="s1">lexer = _lexer_cache.get(key)</span>

    <span class="s2">if </span><span class="s1">lexer </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">_lexer_cache[key] = lexer = Lexer(environment)</span>

    <span class="s2">return </span><span class="s1">lexer</span>


<span class="s2">class </span><span class="s1">OptionalLStrip(tuple):</span>
    <span class="s0">&quot;&quot;&quot;A special tuple for marking a point in the state that can have 
    lstrip applied. 
    &quot;&quot;&quot;</span>

    <span class="s1">__slots__ = ()</span>

    <span class="s3"># Even though it looks like a no-op, creating instances fails</span>
    <span class="s3"># without this.</span>
    <span class="s2">def </span><span class="s1">__new__(cls</span><span class="s2">, </span><span class="s1">*members</span><span class="s2">, </span><span class="s1">**kwargs):  </span><span class="s3"># type: ignore</span>
        <span class="s2">return </span><span class="s1">super().__new__(cls</span><span class="s2">, </span><span class="s1">members)</span>


<span class="s2">class </span><span class="s1">_Rule(t.NamedTuple):</span>
    <span class="s1">pattern: t.Pattern[str]</span>
    <span class="s1">tokens: t.Union[str</span><span class="s2">, </span><span class="s1">t.Tuple[str</span><span class="s2">, </span><span class="s1">...]</span><span class="s2">, </span><span class="s1">t.Tuple[Failure]]</span>
    <span class="s1">command: t.Optional[str]</span>


<span class="s2">class </span><span class="s1">Lexer:</span>
    <span class="s0">&quot;&quot;&quot;Class that implements a lexer for a given environment. Automatically 
    created by the environment class, usually you don't have to do that. 
 
    Note that the lexer is not automatically bound to an environment. 
    Multiple environments can share the same lexer. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">environment: </span><span class="s4">&quot;Environment&quot;</span><span class="s1">) -&gt; </span><span class="s2">None</span><span class="s1">:</span>
        <span class="s3"># shortcuts</span>
        <span class="s1">e = re.escape</span>

        <span class="s2">def </span><span class="s1">c(x: str) -&gt; t.Pattern[str]:</span>
            <span class="s2">return </span><span class="s1">re.compile(x</span><span class="s2">, </span><span class="s1">re.M | re.S)</span>

        <span class="s3"># lexing rules for tags</span>
        <span class="s1">tag_rules: t.List[_Rule] = [</span>
            <span class="s1">_Rule(whitespace_re</span><span class="s2">, </span><span class="s1">TOKEN_WHITESPACE</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">_Rule(float_re</span><span class="s2">, </span><span class="s1">TOKEN_FLOAT</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">_Rule(integer_re</span><span class="s2">, </span><span class="s1">TOKEN_INTEGER</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">_Rule(name_re</span><span class="s2">, </span><span class="s1">TOKEN_NAME</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">_Rule(string_re</span><span class="s2">, </span><span class="s1">TOKEN_STRING</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">_Rule(operator_re</span><span class="s2">, </span><span class="s1">TOKEN_OPERATOR</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
        <span class="s1">]</span>

        <span class="s3"># assemble the root lexing rule. because &quot;|&quot; is ungreedy</span>
        <span class="s3"># we have to sort by length so that the lexer continues working</span>
        <span class="s3"># as expected when we have parsing rules like &lt;% for block and</span>
        <span class="s3"># &lt;%= for variables. (if someone wants asp like syntax)</span>
        <span class="s3"># variables are just part of the rules if variable processing</span>
        <span class="s3"># is required.</span>
        <span class="s1">root_tag_rules = compile_rules(environment)</span>

        <span class="s1">block_start_re = e(environment.block_start_string)</span>
        <span class="s1">block_end_re = e(environment.block_end_string)</span>
        <span class="s1">comment_end_re = e(environment.comment_end_string)</span>
        <span class="s1">variable_end_re = e(environment.variable_end_string)</span>

        <span class="s3"># block suffix if trimming is enabled</span>
        <span class="s1">block_suffix_re = </span><span class="s4">&quot;</span><span class="s2">\\</span><span class="s4">n?&quot; </span><span class="s2">if </span><span class="s1">environment.trim_blocks </span><span class="s2">else </span><span class="s4">&quot;&quot;</span>

        <span class="s3"># If lstrip is enabled, it should not be applied if there is any</span>
        <span class="s3"># non-whitespace between the newline and block.</span>
        <span class="s1">self.lstrip_unless_re = c(</span><span class="s4">r&quot;[^ \t]&quot;</span><span class="s1">) </span><span class="s2">if </span><span class="s1">environment.lstrip_blocks </span><span class="s2">else None</span>

        <span class="s1">self.newline_sequence = environment.newline_sequence</span>
        <span class="s1">self.keep_trailing_newline = environment.keep_trailing_newline</span>

        <span class="s1">root_raw_re = (</span>
            <span class="s4">fr&quot;(?P&lt;raw_begin&gt;</span><span class="s2">{</span><span class="s1">block_start_re</span><span class="s2">}</span><span class="s4">(\-|\+|)\s*raw\s*&quot;</span>
            <span class="s4">fr&quot;(?:\-</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}</span><span class="s4">\s*|</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}</span><span class="s4">))&quot;</span>
        <span class="s1">)</span>
        <span class="s1">root_parts_re = </span><span class="s4">&quot;|&quot;</span><span class="s1">.join(</span>
            <span class="s1">[root_raw_re] + [</span><span class="s4">fr&quot;(?P&lt;</span><span class="s2">{</span><span class="s1">n</span><span class="s2">}</span><span class="s4">&gt;</span><span class="s2">{</span><span class="s1">r</span><span class="s2">}</span><span class="s4">(\-|\+|))&quot; </span><span class="s2">for </span><span class="s1">n</span><span class="s2">, </span><span class="s1">r </span><span class="s2">in </span><span class="s1">root_tag_rules]</span>
        <span class="s1">)</span>

        <span class="s3"># global lexing rules</span>
        <span class="s1">self.rules: t.Dict[str</span><span class="s2">, </span><span class="s1">t.List[_Rule]] = {</span>
            <span class="s4">&quot;root&quot;</span><span class="s1">: [</span>
                <span class="s3"># directives</span>
                <span class="s1">_Rule(</span>
                    <span class="s1">c(</span><span class="s4">fr&quot;(.*?)(?:</span><span class="s2">{</span><span class="s1">root_parts_re</span><span class="s2">}</span><span class="s4">)&quot;</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">OptionalLStrip(TOKEN_DATA</span><span class="s2">, </span><span class="s4">&quot;#bygroup&quot;</span><span class="s1">)</span><span class="s2">,  </span><span class="s3"># type: ignore</span>
                    <span class="s4">&quot;#bygroup&quot;</span><span class="s2">,</span>
                <span class="s1">)</span><span class="s2">,</span>
                <span class="s3"># data</span>
                <span class="s1">_Rule(c(</span><span class="s4">&quot;.+&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">TOKEN_DATA</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">]</span><span class="s2">,</span>
            <span class="s3"># comments</span>
            <span class="s1">TOKEN_COMMENT_BEGIN: [</span>
                <span class="s1">_Rule(</span>
                    <span class="s1">c(</span>
                        <span class="s4">fr&quot;(.*?)((?:\+</span><span class="s2">{</span><span class="s1">comment_end_re</span><span class="s2">}</span><span class="s4">|\-</span><span class="s2">{</span><span class="s1">comment_end_re</span><span class="s2">}</span><span class="s4">\s*&quot;</span>
                        <span class="s4">fr&quot;|</span><span class="s2">{</span><span class="s1">comment_end_re</span><span class="s2">}{</span><span class="s1">block_suffix_re</span><span class="s2">}</span><span class="s4">))&quot;</span>
                    <span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(TOKEN_COMMENT</span><span class="s2">, </span><span class="s1">TOKEN_COMMENT_END)</span><span class="s2">,</span>
                    <span class="s4">&quot;#pop&quot;</span><span class="s2">,</span>
                <span class="s1">)</span><span class="s2">,</span>
                <span class="s1">_Rule(c(</span><span class="s4">r&quot;(.)&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(Failure(</span><span class="s4">&quot;Missing end of comment tag&quot;</span><span class="s1">)</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">]</span><span class="s2">,</span>
            <span class="s3"># blocks</span>
            <span class="s1">TOKEN_BLOCK_BEGIN: [</span>
                <span class="s1">_Rule(</span>
                    <span class="s1">c(</span>
                        <span class="s4">fr&quot;(?:\+</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}</span><span class="s4">|\-</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}</span><span class="s4">\s*&quot;</span>
                        <span class="s4">fr&quot;|</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}{</span><span class="s1">block_suffix_re</span><span class="s2">}</span><span class="s4">)&quot;</span>
                    <span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">TOKEN_BLOCK_END</span><span class="s2">,</span>
                    <span class="s4">&quot;#pop&quot;</span><span class="s2">,</span>
                <span class="s1">)</span><span class="s2">,</span>
            <span class="s1">]</span>
            <span class="s1">+ tag_rules</span><span class="s2">,</span>
            <span class="s3"># variables</span>
            <span class="s1">TOKEN_VARIABLE_BEGIN: [</span>
                <span class="s1">_Rule(</span>
                    <span class="s1">c(</span><span class="s4">fr&quot;\-</span><span class="s2">{</span><span class="s1">variable_end_re</span><span class="s2">}</span><span class="s4">\s*|</span><span class="s2">{</span><span class="s1">variable_end_re</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">TOKEN_VARIABLE_END</span><span class="s2">,</span>
                    <span class="s4">&quot;#pop&quot;</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s1">]</span>
            <span class="s1">+ tag_rules</span><span class="s2">,</span>
            <span class="s3"># raw block</span>
            <span class="s1">TOKEN_RAW_BEGIN: [</span>
                <span class="s1">_Rule(</span>
                    <span class="s1">c(</span>
                        <span class="s4">fr&quot;(.*?)((?:</span><span class="s2">{</span><span class="s1">block_start_re</span><span class="s2">}</span><span class="s4">(\-|\+|))\s*endraw\s*&quot;</span>
                        <span class="s4">fr&quot;(?:\+</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}</span><span class="s4">|\-</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}</span><span class="s4">\s*&quot;</span>
                        <span class="s4">fr&quot;|</span><span class="s2">{</span><span class="s1">block_end_re</span><span class="s2">}{</span><span class="s1">block_suffix_re</span><span class="s2">}</span><span class="s4">))&quot;</span>
                    <span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">OptionalLStrip(TOKEN_DATA</span><span class="s2">, </span><span class="s1">TOKEN_RAW_END)</span><span class="s2">,  </span><span class="s3"># type: ignore</span>
                    <span class="s4">&quot;#pop&quot;</span><span class="s2">,</span>
                <span class="s1">)</span><span class="s2">,</span>
                <span class="s1">_Rule(c(</span><span class="s4">r&quot;(.)&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">(Failure(</span><span class="s4">&quot;Missing end of raw directive&quot;</span><span class="s1">)</span><span class="s2">,</span><span class="s1">)</span><span class="s2">, None</span><span class="s1">)</span><span class="s2">,</span>
            <span class="s1">]</span><span class="s2">,</span>
            <span class="s3"># line statements</span>
            <span class="s1">TOKEN_LINESTATEMENT_BEGIN: [</span>
                <span class="s1">_Rule(c(</span><span class="s4">r&quot;\s*(\n|$)&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s1">TOKEN_LINESTATEMENT_END</span><span class="s2">, </span><span class="s4">&quot;#pop&quot;</span><span class="s1">)</span>
            <span class="s1">]</span>
            <span class="s1">+ tag_rules</span><span class="s2">,</span>
            <span class="s3"># line comments</span>
            <span class="s1">TOKEN_LINECOMMENT_BEGIN: [</span>
                <span class="s1">_Rule(</span>
                    <span class="s1">c(</span><span class="s4">r&quot;(.*?)()(?=\n|$)&quot;</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">(TOKEN_LINECOMMENT</span><span class="s2">, </span><span class="s1">TOKEN_LINECOMMENT_END)</span><span class="s2">,</span>
                    <span class="s4">&quot;#pop&quot;</span><span class="s2">,</span>
                <span class="s1">)</span>
            <span class="s1">]</span><span class="s2">,</span>
        <span class="s1">}</span>

    <span class="s2">def </span><span class="s1">_normalize_newlines(self</span><span class="s2">, </span><span class="s1">value: str) -&gt; str:</span>
        <span class="s0">&quot;&quot;&quot;Replace all newlines with the configured sequence in strings 
        and template data. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">newline_re.sub(self.newline_sequence</span><span class="s2">, </span><span class="s1">value)</span>

    <span class="s2">def </span><span class="s1">tokenize(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">source: str</span><span class="s2">,</span>
        <span class="s1">name: t.Optional[str] = </span><span class="s2">None,</span>
        <span class="s1">filename: t.Optional[str] = </span><span class="s2">None,</span>
        <span class="s1">state: t.Optional[str] = </span><span class="s2">None,</span>
    <span class="s1">) -&gt; TokenStream:</span>
        <span class="s0">&quot;&quot;&quot;Calls tokeniter + tokenize and wraps it in a token stream.&quot;&quot;&quot;</span>
        <span class="s1">stream = self.tokeniter(source</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">filename</span><span class="s2">, </span><span class="s1">state)</span>
        <span class="s2">return </span><span class="s1">TokenStream(self.wrap(stream</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">filename)</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">filename)</span>

    <span class="s2">def </span><span class="s1">wrap(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">stream: t.Iterable[t.Tuple[int</span><span class="s2">, </span><span class="s1">str</span><span class="s2">, </span><span class="s1">str]]</span><span class="s2">,</span>
        <span class="s1">name: t.Optional[str] = </span><span class="s2">None,</span>
        <span class="s1">filename: t.Optional[str] = </span><span class="s2">None,</span>
    <span class="s1">) -&gt; t.Iterator[Token]:</span>
        <span class="s0">&quot;&quot;&quot;This is called with the stream as returned by `tokenize` and wraps 
        every token in a :class:`Token` and converts the value. 
        &quot;&quot;&quot;</span>
        <span class="s2">for </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">token</span><span class="s2">, </span><span class="s1">value_str </span><span class="s2">in </span><span class="s1">stream:</span>
            <span class="s2">if </span><span class="s1">token </span><span class="s2">in </span><span class="s1">ignored_tokens:</span>
                <span class="s2">continue</span>

            <span class="s1">value: t.Any = value_str</span>

            <span class="s2">if </span><span class="s1">token == TOKEN_LINESTATEMENT_BEGIN:</span>
                <span class="s1">token = TOKEN_BLOCK_BEGIN</span>
            <span class="s2">elif </span><span class="s1">token == TOKEN_LINESTATEMENT_END:</span>
                <span class="s1">token = TOKEN_BLOCK_END</span>
            <span class="s3"># we are not interested in those tokens in the parser</span>
            <span class="s2">elif </span><span class="s1">token </span><span class="s2">in </span><span class="s1">(TOKEN_RAW_BEGIN</span><span class="s2">, </span><span class="s1">TOKEN_RAW_END):</span>
                <span class="s2">continue</span>
            <span class="s2">elif </span><span class="s1">token == TOKEN_DATA:</span>
                <span class="s1">value = self._normalize_newlines(value_str)</span>
            <span class="s2">elif </span><span class="s1">token == </span><span class="s4">&quot;keyword&quot;</span><span class="s1">:</span>
                <span class="s1">token = value_str</span>
            <span class="s2">elif </span><span class="s1">token == TOKEN_NAME:</span>
                <span class="s1">value = value_str</span>

                <span class="s2">if not </span><span class="s1">value.isidentifier():</span>
                    <span class="s2">raise </span><span class="s1">TemplateSyntaxError(</span>
                        <span class="s4">&quot;Invalid character in identifier&quot;</span><span class="s2">, </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">filename</span>
                    <span class="s1">)</span>
            <span class="s2">elif </span><span class="s1">token == TOKEN_STRING:</span>
                <span class="s3"># try to unescape string</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">value = (</span>
                        <span class="s1">self._normalize_newlines(value_str[</span><span class="s5">1</span><span class="s1">:-</span><span class="s5">1</span><span class="s1">])</span>
                        <span class="s1">.encode(</span><span class="s4">&quot;ascii&quot;</span><span class="s2">, </span><span class="s4">&quot;backslashreplace&quot;</span><span class="s1">)</span>
                        <span class="s1">.decode(</span><span class="s4">&quot;unicode-escape&quot;</span><span class="s1">)</span>
                    <span class="s1">)</span>
                <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">e:</span>
                    <span class="s1">msg = str(e).split(</span><span class="s4">&quot;:&quot;</span><span class="s1">)[-</span><span class="s5">1</span><span class="s1">].strip()</span>
                    <span class="s2">raise </span><span class="s1">TemplateSyntaxError(msg</span><span class="s2">, </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">filename) </span><span class="s2">from </span><span class="s1">e</span>
            <span class="s2">elif </span><span class="s1">token == TOKEN_INTEGER:</span>
                <span class="s1">value = int(value_str.replace(</span><span class="s4">&quot;_&quot;</span><span class="s2">, </span><span class="s4">&quot;&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s5">0</span><span class="s1">)</span>
            <span class="s2">elif </span><span class="s1">token == TOKEN_FLOAT:</span>
                <span class="s3"># remove all &quot;_&quot; first to support more Python versions</span>
                <span class="s1">value = literal_eval(value_str.replace(</span><span class="s4">&quot;_&quot;</span><span class="s2">, </span><span class="s4">&quot;&quot;</span><span class="s1">))</span>
            <span class="s2">elif </span><span class="s1">token == TOKEN_OPERATOR:</span>
                <span class="s1">token = operators[value_str]</span>

            <span class="s2">yield </span><span class="s1">Token(lineno</span><span class="s2">, </span><span class="s1">token</span><span class="s2">, </span><span class="s1">value)</span>

    <span class="s2">def </span><span class="s1">tokeniter(</span>
        <span class="s1">self</span><span class="s2">,</span>
        <span class="s1">source: str</span><span class="s2">,</span>
        <span class="s1">name: t.Optional[str]</span><span class="s2">,</span>
        <span class="s1">filename: t.Optional[str] = </span><span class="s2">None,</span>
        <span class="s1">state: t.Optional[str] = </span><span class="s2">None,</span>
    <span class="s1">) -&gt; t.Iterator[t.Tuple[int</span><span class="s2">, </span><span class="s1">str</span><span class="s2">, </span><span class="s1">str]]:</span>
        <span class="s0">&quot;&quot;&quot;This method tokenizes the text and returns the tokens in a 
        generator. Use this method if you just want to tokenize a template. 
 
        .. versionchanged:: 3.0 
            Only ``\\n``, ``\\r\\n`` and ``\\r`` are treated as line 
            breaks. 
        &quot;&quot;&quot;</span>
        <span class="s1">lines = newline_re.split(source)[::</span><span class="s5">2</span><span class="s1">]</span>

        <span class="s2">if not </span><span class="s1">self.keep_trailing_newline </span><span class="s2">and </span><span class="s1">lines[-</span><span class="s5">1</span><span class="s1">] == </span><span class="s4">&quot;&quot;</span><span class="s1">:</span>
            <span class="s2">del </span><span class="s1">lines[-</span><span class="s5">1</span><span class="s1">]</span>

        <span class="s1">source = </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">.join(lines)</span>
        <span class="s1">pos = </span><span class="s5">0</span>
        <span class="s1">lineno = </span><span class="s5">1</span>
        <span class="s1">stack = [</span><span class="s4">&quot;root&quot;</span><span class="s1">]</span>

        <span class="s2">if </span><span class="s1">state </span><span class="s2">is not None and </span><span class="s1">state != </span><span class="s4">&quot;root&quot;</span><span class="s1">:</span>
            <span class="s2">assert </span><span class="s1">state </span><span class="s2">in </span><span class="s1">(</span><span class="s4">&quot;variable&quot;</span><span class="s2">, </span><span class="s4">&quot;block&quot;</span><span class="s1">)</span><span class="s2">, </span><span class="s4">&quot;invalid state&quot;</span>
            <span class="s1">stack.append(state + </span><span class="s4">&quot;_begin&quot;</span><span class="s1">)</span>

        <span class="s1">statetokens = self.rules[stack[-</span><span class="s5">1</span><span class="s1">]]</span>
        <span class="s1">source_length = len(source)</span>
        <span class="s1">balancing_stack: t.List[str] = []</span>
        <span class="s1">lstrip_unless_re = self.lstrip_unless_re</span>
        <span class="s1">newlines_stripped = </span><span class="s5">0</span>
        <span class="s1">line_starting = </span><span class="s2">True</span>

        <span class="s2">while True</span><span class="s1">:</span>
            <span class="s3"># tokenizer loop</span>
            <span class="s2">for </span><span class="s1">regex</span><span class="s2">, </span><span class="s1">tokens</span><span class="s2">, </span><span class="s1">new_state </span><span class="s2">in </span><span class="s1">statetokens:</span>
                <span class="s1">m = regex.match(source</span><span class="s2">, </span><span class="s1">pos)</span>

                <span class="s3"># if no match we try again with the next rule</span>
                <span class="s2">if </span><span class="s1">m </span><span class="s2">is None</span><span class="s1">:</span>
                    <span class="s2">continue</span>

                <span class="s3"># we only match blocks and variables if braces / parentheses</span>
                <span class="s3"># are balanced. continue parsing with the lower rule which</span>
                <span class="s3"># is the operator rule. do this only if the end tags look</span>
                <span class="s3"># like operators</span>
                <span class="s2">if </span><span class="s1">balancing_stack </span><span class="s2">and </span><span class="s1">tokens </span><span class="s2">in </span><span class="s1">(</span>
                    <span class="s1">TOKEN_VARIABLE_END</span><span class="s2">,</span>
                    <span class="s1">TOKEN_BLOCK_END</span><span class="s2">,</span>
                    <span class="s1">TOKEN_LINESTATEMENT_END</span><span class="s2">,</span>
                <span class="s1">):</span>
                    <span class="s2">continue</span>

                <span class="s3"># tuples support more options</span>
                <span class="s2">if </span><span class="s1">isinstance(tokens</span><span class="s2">, </span><span class="s1">tuple):</span>
                    <span class="s1">groups = m.groups()</span>

                    <span class="s2">if </span><span class="s1">isinstance(tokens</span><span class="s2">, </span><span class="s1">OptionalLStrip):</span>
                        <span class="s3"># Rule supports lstrip. Match will look like</span>
                        <span class="s3"># text, block type, whitespace control, type, control, ...</span>
                        <span class="s1">text = groups[</span><span class="s5">0</span><span class="s1">]</span>
                        <span class="s3"># Skipping the text and first type, every other group is the</span>
                        <span class="s3"># whitespace control for each type. One of the groups will be</span>
                        <span class="s3"># -, +, or empty string instead of None.</span>
                        <span class="s1">strip_sign = next(g </span><span class="s2">for </span><span class="s1">g </span><span class="s2">in </span><span class="s1">groups[</span><span class="s5">2</span><span class="s1">::</span><span class="s5">2</span><span class="s1">] </span><span class="s2">if </span><span class="s1">g </span><span class="s2">is not None</span><span class="s1">)</span>

                        <span class="s2">if </span><span class="s1">strip_sign == </span><span class="s4">&quot;-&quot;</span><span class="s1">:</span>
                            <span class="s3"># Strip all whitespace between the text and the tag.</span>
                            <span class="s1">stripped = text.rstrip()</span>
                            <span class="s1">newlines_stripped = text[len(stripped) :].count(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">)</span>
                            <span class="s1">groups = [stripped</span><span class="s2">, </span><span class="s1">*groups[</span><span class="s5">1</span><span class="s1">:]]</span>
                        <span class="s2">elif </span><span class="s1">(</span>
                            <span class="s3"># Not marked for preserving whitespace.</span>
                            <span class="s1">strip_sign != </span><span class="s4">&quot;+&quot;</span>
                            <span class="s3"># lstrip is enabled.</span>
                            <span class="s2">and </span><span class="s1">lstrip_unless_re </span><span class="s2">is not None</span>
                            <span class="s3"># Not a variable expression.</span>
                            <span class="s2">and not </span><span class="s1">m.groupdict().get(TOKEN_VARIABLE_BEGIN)</span>
                        <span class="s1">):</span>
                            <span class="s3"># The start of text between the last newline and the tag.</span>
                            <span class="s1">l_pos = text.rfind(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">) + </span><span class="s5">1</span>

                            <span class="s2">if </span><span class="s1">l_pos &gt; </span><span class="s5">0 </span><span class="s2">or </span><span class="s1">line_starting:</span>
                                <span class="s3"># If there's only whitespace between the newline and the</span>
                                <span class="s3"># tag, strip it.</span>
                                <span class="s2">if not </span><span class="s1">lstrip_unless_re.search(text</span><span class="s2">, </span><span class="s1">l_pos):</span>
                                    <span class="s1">groups = [text[:l_pos]</span><span class="s2">, </span><span class="s1">*groups[</span><span class="s5">1</span><span class="s1">:]]</span>

                    <span class="s2">for </span><span class="s1">idx</span><span class="s2">, </span><span class="s1">token </span><span class="s2">in </span><span class="s1">enumerate(tokens):</span>
                        <span class="s3"># failure group</span>
                        <span class="s2">if </span><span class="s1">token.__class__ </span><span class="s2">is </span><span class="s1">Failure:</span>
                            <span class="s2">raise </span><span class="s1">token(lineno</span><span class="s2">, </span><span class="s1">filename)</span>
                        <span class="s3"># bygroup is a bit more complex, in that case we</span>
                        <span class="s3"># yield for the current token the first named</span>
                        <span class="s3"># group that matched</span>
                        <span class="s2">elif </span><span class="s1">token == </span><span class="s4">&quot;#bygroup&quot;</span><span class="s1">:</span>
                            <span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value </span><span class="s2">in </span><span class="s1">m.groupdict().items():</span>
                                <span class="s2">if </span><span class="s1">value </span><span class="s2">is not None</span><span class="s1">:</span>
                                    <span class="s2">yield </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value</span>
                                    <span class="s1">lineno += value.count(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">)</span>
                                    <span class="s2">break</span>
                            <span class="s2">else</span><span class="s1">:</span>
                                <span class="s2">raise </span><span class="s1">RuntimeError(</span>
                                    <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">regex</span><span class="s2">!r} </span><span class="s4">wanted to resolve the token dynamically&quot;</span>
                                    <span class="s4">&quot; but no group matched&quot;</span>
                                <span class="s1">)</span>
                        <span class="s3"># normal group</span>
                        <span class="s2">else</span><span class="s1">:</span>
                            <span class="s1">data = groups[idx]</span>

                            <span class="s2">if </span><span class="s1">data </span><span class="s2">or </span><span class="s1">token </span><span class="s2">not in </span><span class="s1">ignore_if_empty:</span>
                                <span class="s2">yield </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">token</span><span class="s2">, </span><span class="s1">data</span>

                            <span class="s1">lineno += data.count(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">) + newlines_stripped</span>
                            <span class="s1">newlines_stripped = </span><span class="s5">0</span>

                <span class="s3"># strings as token just are yielded as it.</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">data = m.group()</span>

                    <span class="s3"># update brace/parentheses balance</span>
                    <span class="s2">if </span><span class="s1">tokens == TOKEN_OPERATOR:</span>
                        <span class="s2">if </span><span class="s1">data == </span><span class="s4">&quot;{&quot;</span><span class="s1">:</span>
                            <span class="s1">balancing_stack.append(</span><span class="s4">&quot;}&quot;</span><span class="s1">)</span>
                        <span class="s2">elif </span><span class="s1">data == </span><span class="s4">&quot;(&quot;</span><span class="s1">:</span>
                            <span class="s1">balancing_stack.append(</span><span class="s4">&quot;)&quot;</span><span class="s1">)</span>
                        <span class="s2">elif </span><span class="s1">data == </span><span class="s4">&quot;[&quot;</span><span class="s1">:</span>
                            <span class="s1">balancing_stack.append(</span><span class="s4">&quot;]&quot;</span><span class="s1">)</span>
                        <span class="s2">elif </span><span class="s1">data </span><span class="s2">in </span><span class="s1">(</span><span class="s4">&quot;}&quot;</span><span class="s2">, </span><span class="s4">&quot;)&quot;</span><span class="s2">, </span><span class="s4">&quot;]&quot;</span><span class="s1">):</span>
                            <span class="s2">if not </span><span class="s1">balancing_stack:</span>
                                <span class="s2">raise </span><span class="s1">TemplateSyntaxError(</span>
                                    <span class="s4">f&quot;unexpected '</span><span class="s2">{</span><span class="s1">data</span><span class="s2">}</span><span class="s4">'&quot;</span><span class="s2">, </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">filename</span>
                                <span class="s1">)</span>

                            <span class="s1">expected_op = balancing_stack.pop()</span>

                            <span class="s2">if </span><span class="s1">expected_op != data:</span>
                                <span class="s2">raise </span><span class="s1">TemplateSyntaxError(</span>
                                    <span class="s4">f&quot;unexpected '</span><span class="s2">{</span><span class="s1">data</span><span class="s2">}</span><span class="s4">', expected '</span><span class="s2">{</span><span class="s1">expected_op</span><span class="s2">}</span><span class="s4">'&quot;</span><span class="s2">,</span>
                                    <span class="s1">lineno</span><span class="s2">,</span>
                                    <span class="s1">name</span><span class="s2">,</span>
                                    <span class="s1">filename</span><span class="s2">,</span>
                                <span class="s1">)</span>

                    <span class="s3"># yield items</span>
                    <span class="s2">if </span><span class="s1">data </span><span class="s2">or </span><span class="s1">tokens </span><span class="s2">not in </span><span class="s1">ignore_if_empty:</span>
                        <span class="s2">yield </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">tokens</span><span class="s2">, </span><span class="s1">data</span>

                    <span class="s1">lineno += data.count(</span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">)</span>

                <span class="s1">line_starting = m.group()[-</span><span class="s5">1</span><span class="s1">:] == </span><span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span>
                <span class="s3"># fetch new position into new variable so that we can check</span>
                <span class="s3"># if there is a internal parsing error which would result</span>
                <span class="s3"># in an infinite loop</span>
                <span class="s1">pos2 = m.end()</span>

                <span class="s3"># handle state changes</span>
                <span class="s2">if </span><span class="s1">new_state </span><span class="s2">is not None</span><span class="s1">:</span>
                    <span class="s3"># remove the uppermost state</span>
                    <span class="s2">if </span><span class="s1">new_state == </span><span class="s4">&quot;#pop&quot;</span><span class="s1">:</span>
                        <span class="s1">stack.pop()</span>
                    <span class="s3"># resolve the new state by group checking</span>
                    <span class="s2">elif </span><span class="s1">new_state == </span><span class="s4">&quot;#bygroup&quot;</span><span class="s1">:</span>
                        <span class="s2">for </span><span class="s1">key</span><span class="s2">, </span><span class="s1">value </span><span class="s2">in </span><span class="s1">m.groupdict().items():</span>
                            <span class="s2">if </span><span class="s1">value </span><span class="s2">is not None</span><span class="s1">:</span>
                                <span class="s1">stack.append(key)</span>
                                <span class="s2">break</span>
                        <span class="s2">else</span><span class="s1">:</span>
                            <span class="s2">raise </span><span class="s1">RuntimeError(</span>
                                <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">regex</span><span class="s2">!r} </span><span class="s4">wanted to resolve the new state dynamically&quot;</span>
                                <span class="s4">f&quot; but no group matched&quot;</span>
                            <span class="s1">)</span>
                    <span class="s3"># direct state name given</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">stack.append(new_state)</span>

                    <span class="s1">statetokens = self.rules[stack[-</span><span class="s5">1</span><span class="s1">]]</span>
                <span class="s3"># we are still at the same position and no stack change.</span>
                <span class="s3"># this means a loop without break condition, avoid that and</span>
                <span class="s3"># raise error</span>
                <span class="s2">elif </span><span class="s1">pos2 == pos:</span>
                    <span class="s2">raise </span><span class="s1">RuntimeError(</span>
                        <span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">regex</span><span class="s2">!r} </span><span class="s4">yielded empty string without stack change&quot;</span>
                    <span class="s1">)</span>

                <span class="s3"># publish new function and start again</span>
                <span class="s1">pos = pos2</span>
                <span class="s2">break</span>
            <span class="s3"># if loop terminated without break we haven't found a single match</span>
            <span class="s3"># either we are at the end of the file or we have a problem</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s3"># end of text</span>
                <span class="s2">if </span><span class="s1">pos &gt;= source_length:</span>
                    <span class="s2">return</span>

                <span class="s3"># something went wrong</span>
                <span class="s2">raise </span><span class="s1">TemplateSyntaxError(</span>
                    <span class="s4">f&quot;unexpected char </span><span class="s2">{</span><span class="s1">source[pos]</span><span class="s2">!r} </span><span class="s4">at </span><span class="s2">{</span><span class="s1">pos</span><span class="s2">}</span><span class="s4">&quot;</span><span class="s2">, </span><span class="s1">lineno</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">filename</span>
                <span class="s1">)</span>
</pre>
</body>
</html>