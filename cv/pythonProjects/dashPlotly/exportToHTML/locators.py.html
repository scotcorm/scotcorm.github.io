<html>
<head>
<title>locators.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #629755; font-style: italic;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
locators.py</font>
</center></td></tr></table>
<pre><span class="s0"># -*- coding: utf-8 -*-</span>
<span class="s0">#</span>
<span class="s0"># Copyright (C) 2012-2015 Vinay Sajip.</span>
<span class="s0"># Licensed to the Python Software Foundation under a contributor agreement.</span>
<span class="s0"># See LICENSE.txt and CONTRIBUTORS.txt.</span>
<span class="s0">#</span>

<span class="s2">import </span><span class="s1">gzip</span>
<span class="s2">from </span><span class="s1">io </span><span class="s2">import </span><span class="s1">BytesIO</span>
<span class="s2">import </span><span class="s1">json</span>
<span class="s2">import </span><span class="s1">logging</span>
<span class="s2">import </span><span class="s1">os</span>
<span class="s2">import </span><span class="s1">posixpath</span>
<span class="s2">import </span><span class="s1">re</span>
<span class="s2">try</span><span class="s1">:</span>
    <span class="s2">import </span><span class="s1">threading</span>
<span class="s2">except </span><span class="s1">ImportError:  </span><span class="s0"># pragma: no cover</span>
    <span class="s2">import </span><span class="s1">dummy_threading </span><span class="s2">as </span><span class="s1">threading</span>
<span class="s2">import </span><span class="s1">zlib</span>

<span class="s2">from </span><span class="s1">. </span><span class="s2">import </span><span class="s1">DistlibException</span>
<span class="s2">from </span><span class="s1">.compat </span><span class="s2">import </span><span class="s1">(urljoin</span><span class="s2">, </span><span class="s1">urlparse</span><span class="s2">, </span><span class="s1">urlunparse</span><span class="s2">, </span><span class="s1">url2pathname</span><span class="s2">, </span><span class="s1">pathname2url</span><span class="s2">,</span>
                     <span class="s1">queue</span><span class="s2">, </span><span class="s1">quote</span><span class="s2">, </span><span class="s1">unescape</span><span class="s2">, </span><span class="s1">build_opener</span><span class="s2">,</span>
                     <span class="s1">HTTPRedirectHandler </span><span class="s2">as </span><span class="s1">BaseRedirectHandler</span><span class="s2">, </span><span class="s1">text_type</span><span class="s2">,</span>
                     <span class="s1">Request</span><span class="s2">, </span><span class="s1">HTTPError</span><span class="s2">, </span><span class="s1">URLError)</span>
<span class="s2">from </span><span class="s1">.database </span><span class="s2">import </span><span class="s1">Distribution</span><span class="s2">, </span><span class="s1">DistributionPath</span><span class="s2">, </span><span class="s1">make_dist</span>
<span class="s2">from </span><span class="s1">.metadata </span><span class="s2">import </span><span class="s1">Metadata</span><span class="s2">, </span><span class="s1">MetadataInvalidError</span>
<span class="s2">from </span><span class="s1">.util </span><span class="s2">import </span><span class="s1">(cached_property</span><span class="s2">, </span><span class="s1">ensure_slash</span><span class="s2">, </span><span class="s1">split_filename</span><span class="s2">, </span><span class="s1">get_project_data</span><span class="s2">,</span>
                   <span class="s1">parse_requirement</span><span class="s2">, </span><span class="s1">parse_name_and_version</span><span class="s2">, </span><span class="s1">ServerProxy</span><span class="s2">,</span>
                   <span class="s1">normalize_name)</span>
<span class="s2">from </span><span class="s1">.version </span><span class="s2">import </span><span class="s1">get_scheme</span><span class="s2">, </span><span class="s1">UnsupportedVersionError</span>
<span class="s2">from </span><span class="s1">.wheel </span><span class="s2">import </span><span class="s1">Wheel</span><span class="s2">, </span><span class="s1">is_compatible</span>

<span class="s1">logger = logging.getLogger(__name__)</span>

<span class="s1">HASHER_HASH = re.compile(</span><span class="s3">r'^(\w+)=([a-f0-9]+)'</span><span class="s1">)</span>
<span class="s1">CHARSET = re.compile(</span><span class="s3">r';\s*charset\s*=\s*(.*)\s*$'</span><span class="s2">, </span><span class="s1">re.I)</span>
<span class="s1">HTML_CONTENT_TYPE = re.compile(</span><span class="s3">'text/html|application/x(ht)?ml'</span><span class="s1">)</span>
<span class="s1">DEFAULT_INDEX = </span><span class="s3">'https://pypi.org/pypi'</span>

<span class="s2">def </span><span class="s1">get_all_distribution_names(url=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s4">&quot;&quot;&quot; 
    Return all distribution names known by an index. 
    :param url: The URL of the index. 
    :return: A list of all known distribution names. 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">url </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">url = DEFAULT_INDEX</span>
    <span class="s1">client = ServerProxy(url</span><span class="s2">, </span><span class="s1">timeout=</span><span class="s5">3.0</span><span class="s1">)</span>
    <span class="s2">try</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">client.list_packages()</span>
    <span class="s2">finally</span><span class="s1">:</span>
        <span class="s1">client(</span><span class="s3">'close'</span><span class="s1">)()</span>

<span class="s2">class </span><span class="s1">RedirectHandler(BaseRedirectHandler):</span>
    <span class="s4">&quot;&quot;&quot; 
    A class to work around a bug in some Python 3.2.x releases. 
    &quot;&quot;&quot;</span>
    <span class="s0"># There's a bug in the base version for some 3.2.x</span>
    <span class="s0"># (e.g. 3.2.2 on Ubuntu Oneiric). If a Location header</span>
    <span class="s0"># returns e.g. /abc, it bails because it says the scheme ''</span>
    <span class="s0"># is bogus, when actually it should use the request's</span>
    <span class="s0"># URL for the scheme. See Python issue #13696.</span>
    <span class="s2">def </span><span class="s1">http_error_302(self</span><span class="s2">, </span><span class="s1">req</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">code</span><span class="s2">, </span><span class="s1">msg</span><span class="s2">, </span><span class="s1">headers):</span>
        <span class="s0"># Some servers (incorrectly) return multiple Location headers</span>
        <span class="s0"># (so probably same goes for URI).  Use first header.</span>
        <span class="s1">newurl = </span><span class="s2">None</span>
        <span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">(</span><span class="s3">'location'</span><span class="s2">, </span><span class="s3">'uri'</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">key </span><span class="s2">in </span><span class="s1">headers:</span>
                <span class="s1">newurl = headers[key]</span>
                <span class="s2">break</span>
        <span class="s2">if </span><span class="s1">newurl </span><span class="s2">is None</span><span class="s1">:  </span><span class="s0"># pragma: no cover</span>
            <span class="s2">return</span>
        <span class="s1">urlparts = urlparse(newurl)</span>
        <span class="s2">if </span><span class="s1">urlparts.scheme == </span><span class="s3">''</span><span class="s1">:</span>
            <span class="s1">newurl = urljoin(req.get_full_url()</span><span class="s2">, </span><span class="s1">newurl)</span>
            <span class="s2">if </span><span class="s1">hasattr(headers</span><span class="s2">, </span><span class="s3">'replace_header'</span><span class="s1">):</span>
                <span class="s1">headers.replace_header(key</span><span class="s2">, </span><span class="s1">newurl)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">headers[key] = newurl</span>
        <span class="s2">return </span><span class="s1">BaseRedirectHandler.http_error_302(self</span><span class="s2">, </span><span class="s1">req</span><span class="s2">, </span><span class="s1">fp</span><span class="s2">, </span><span class="s1">code</span><span class="s2">, </span><span class="s1">msg</span><span class="s2">,</span>
                                                  <span class="s1">headers)</span>

    <span class="s1">http_error_301 = http_error_303 = http_error_307 = http_error_302</span>

<span class="s2">class </span><span class="s1">Locator(object):</span>
    <span class="s4">&quot;&quot;&quot; 
    A base class for locators - things that locate distributions. 
    &quot;&quot;&quot;</span>
    <span class="s1">source_extensions = (</span><span class="s3">'.tar.gz'</span><span class="s2">, </span><span class="s3">'.tar.bz2'</span><span class="s2">, </span><span class="s3">'.tar'</span><span class="s2">, </span><span class="s3">'.zip'</span><span class="s2">, </span><span class="s3">'.tgz'</span><span class="s2">, </span><span class="s3">'.tbz'</span><span class="s1">)</span>
    <span class="s1">binary_extensions = (</span><span class="s3">'.egg'</span><span class="s2">, </span><span class="s3">'.exe'</span><span class="s2">, </span><span class="s3">'.whl'</span><span class="s1">)</span>
    <span class="s1">excluded_extensions = (</span><span class="s3">'.pdf'</span><span class="s2">,</span><span class="s1">)</span>

    <span class="s0"># A list of tags indicating which wheels you want to match. The default</span>
    <span class="s0"># value of None matches against the tags compatible with the running</span>
    <span class="s0"># Python. If you want to match other values, set wheel_tags on a locator</span>
    <span class="s0"># instance to a list of tuples (pyver, abi, arch) which you want to match.</span>
    <span class="s1">wheel_tags = </span><span class="s2">None</span>

    <span class="s1">downloadable_extensions = source_extensions + (</span><span class="s3">'.whl'</span><span class="s2">,</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">scheme=</span><span class="s3">'default'</span><span class="s1">):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance. 
        :param scheme: Because locators look for most recent versions, they 
                       need to know the version scheme to use. This specifies 
                       the current PEP-recommended scheme - use ``'legacy'`` 
                       if you need to support existing distributions on PyPI. 
        &quot;&quot;&quot;</span>
        <span class="s1">self._cache = {}</span>
        <span class="s1">self.scheme = scheme</span>
        <span class="s0"># Because of bugs in some of the handlers on some of the platforms,</span>
        <span class="s0"># we use our own opener rather than just using urlopen.</span>
        <span class="s1">self.opener = build_opener(RedirectHandler())</span>
        <span class="s0"># If get_project() is called from locate(), the matcher instance</span>
        <span class="s0"># is set from the requirement passed to locate(). See issue #18 for</span>
        <span class="s0"># why this can be useful to know.</span>
        <span class="s1">self.matcher = </span><span class="s2">None</span>
        <span class="s1">self.errors = queue.Queue()</span>

    <span class="s2">def </span><span class="s1">get_errors(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return any errors which have occurred. 
        &quot;&quot;&quot;</span>
        <span class="s1">result = []</span>
        <span class="s2">while not </span><span class="s1">self.errors.empty():  </span><span class="s0"># pragma: no cover</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">e = self.errors.get(</span><span class="s2">False</span><span class="s1">)</span>
                <span class="s1">result.append(e)</span>
            <span class="s2">except </span><span class="s1">self.errors.Empty:</span>
                <span class="s2">continue</span>
            <span class="s1">self.errors.task_done()</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">clear_errors(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Clear any errors which may have been logged. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Just get the errors and throw them away</span>
        <span class="s1">self.get_errors()</span>

    <span class="s2">def </span><span class="s1">clear_cache(self):</span>
        <span class="s1">self._cache.clear()</span>

    <span class="s2">def </span><span class="s1">_get_scheme(self):</span>
        <span class="s2">return </span><span class="s1">self._scheme</span>

    <span class="s2">def </span><span class="s1">_set_scheme(self</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s1">self._scheme = value</span>

    <span class="s1">scheme = property(_get_scheme</span><span class="s2">, </span><span class="s1">_set_scheme)</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s4">&quot;&quot;&quot; 
        For a given project, get a dictionary mapping available versions to Distribution 
        instances. 
 
        This should be implemented in subclasses. 
 
        If called from a locate() request, self.matcher will be set to a 
        matcher for the requirement to satisfy, otherwise it will be None. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">'Please implement in the subclass'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">get_distribution_names(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return all the distribution names known to this locator. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">'Please implement in the subclass'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s4">&quot;&quot;&quot; 
        For a given project, get a dictionary mapping available versions to Distribution 
        instances. 
 
        This calls _get_project to do all the work, and just implements a caching layer on top. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self._cache </span><span class="s2">is None</span><span class="s1">:  </span><span class="s0"># pragma: no cover</span>
            <span class="s1">result = self._get_project(name)</span>
        <span class="s2">elif </span><span class="s1">name </span><span class="s2">in </span><span class="s1">self._cache:</span>
            <span class="s1">result = self._cache[name]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">self.clear_errors()</span>
            <span class="s1">result = self._get_project(name)</span>
            <span class="s1">self._cache[name] = result</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">score_url(self</span><span class="s2">, </span><span class="s1">url):</span>
        <span class="s4">&quot;&quot;&quot; 
        Give an url a score which can be used to choose preferred URLs 
        for a given project release. 
        &quot;&quot;&quot;</span>
        <span class="s1">t = urlparse(url)</span>
        <span class="s1">basename = posixpath.basename(t.path)</span>
        <span class="s1">compatible = </span><span class="s2">True</span>
        <span class="s1">is_wheel = basename.endswith(</span><span class="s3">'.whl'</span><span class="s1">)</span>
        <span class="s1">is_downloadable = basename.endswith(self.downloadable_extensions)</span>
        <span class="s2">if </span><span class="s1">is_wheel:</span>
            <span class="s1">compatible = is_compatible(Wheel(basename)</span><span class="s2">, </span><span class="s1">self.wheel_tags)</span>
        <span class="s2">return </span><span class="s1">(t.scheme == </span><span class="s3">'https'</span><span class="s2">, </span><span class="s3">'pypi.org' </span><span class="s2">in </span><span class="s1">t.netloc</span><span class="s2">,</span>
                <span class="s1">is_downloadable</span><span class="s2">, </span><span class="s1">is_wheel</span><span class="s2">, </span><span class="s1">compatible</span><span class="s2">, </span><span class="s1">basename)</span>

    <span class="s2">def </span><span class="s1">prefer_url(self</span><span class="s2">, </span><span class="s1">url1</span><span class="s2">, </span><span class="s1">url2):</span>
        <span class="s4">&quot;&quot;&quot; 
        Choose one of two URLs where both are candidates for distribution 
        archives for the same version of a distribution (for example, 
        .tar.gz vs. zip). 
 
        The current implementation favours https:// URLs over http://, archives 
        from PyPI over those from other locations, wheel compatibility (if a 
        wheel) and then the archive name. 
        &quot;&quot;&quot;</span>
        <span class="s1">result = url2</span>
        <span class="s2">if </span><span class="s1">url1:</span>
            <span class="s1">s1 = self.score_url(url1)</span>
            <span class="s1">s2 = self.score_url(url2)</span>
            <span class="s2">if </span><span class="s1">s1 &gt; s2:</span>
                <span class="s1">result = url1</span>
            <span class="s2">if </span><span class="s1">result != url2:</span>
                <span class="s1">logger.debug(</span><span class="s3">'Not replacing %r with %r'</span><span class="s2">, </span><span class="s1">url1</span><span class="s2">, </span><span class="s1">url2)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">logger.debug(</span><span class="s3">'Replacing %r with %r'</span><span class="s2">, </span><span class="s1">url1</span><span class="s2">, </span><span class="s1">url2)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">split_filename(self</span><span class="s2">, </span><span class="s1">filename</span><span class="s2">, </span><span class="s1">project_name):</span>
        <span class="s4">&quot;&quot;&quot; 
        Attempt to split a filename in project name, version and Python version. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">split_filename(filename</span><span class="s2">, </span><span class="s1">project_name)</span>

    <span class="s2">def </span><span class="s1">convert_url_to_download_info(self</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">project_name):</span>
        <span class="s4">&quot;&quot;&quot; 
        See if a URL is a candidate for a download URL for a project (the URL 
        has typically been scraped from an HTML page). 
 
        If it is, a dictionary is returned with keys &quot;name&quot;, &quot;version&quot;, 
        &quot;filename&quot; and &quot;url&quot;; otherwise, None is returned. 
        &quot;&quot;&quot;</span>
        <span class="s2">def </span><span class="s1">same_project(name1</span><span class="s2">, </span><span class="s1">name2):</span>
            <span class="s2">return </span><span class="s1">normalize_name(name1) == normalize_name(name2)</span>

        <span class="s1">result = </span><span class="s2">None</span>
        <span class="s1">scheme</span><span class="s2">, </span><span class="s1">netloc</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">query</span><span class="s2">, </span><span class="s1">frag = urlparse(url)</span>
        <span class="s2">if </span><span class="s1">frag.lower().startswith(</span><span class="s3">'egg='</span><span class="s1">):  </span><span class="s0"># pragma: no cover</span>
            <span class="s1">logger.debug(</span><span class="s3">'%s: version hint in fragment: %r'</span><span class="s2">,</span>
                         <span class="s1">project_name</span><span class="s2">, </span><span class="s1">frag)</span>
        <span class="s1">m = HASHER_HASH.match(frag)</span>
        <span class="s2">if </span><span class="s1">m:</span>
            <span class="s1">algo</span><span class="s2">, </span><span class="s1">digest = m.groups()</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">algo</span><span class="s2">, </span><span class="s1">digest = </span><span class="s2">None, None</span>
        <span class="s1">origpath = path</span>
        <span class="s2">if </span><span class="s1">path </span><span class="s2">and </span><span class="s1">path[-</span><span class="s5">1</span><span class="s1">] == </span><span class="s3">'/'</span><span class="s1">:  </span><span class="s0"># pragma: no cover</span>
            <span class="s1">path = path[:-</span><span class="s5">1</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">path.endswith(</span><span class="s3">'.whl'</span><span class="s1">):</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">wheel = Wheel(path)</span>
                <span class="s2">if not </span><span class="s1">is_compatible(wheel</span><span class="s2">, </span><span class="s1">self.wheel_tags):</span>
                    <span class="s1">logger.debug(</span><span class="s3">'Wheel not compatible: %s'</span><span class="s2">, </span><span class="s1">path)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s2">if </span><span class="s1">project_name </span><span class="s2">is None</span><span class="s1">:</span>
                        <span class="s1">include = </span><span class="s2">True</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">include = same_project(wheel.name</span><span class="s2">, </span><span class="s1">project_name)</span>
                    <span class="s2">if </span><span class="s1">include:</span>
                        <span class="s1">result = {</span>
                            <span class="s3">'name'</span><span class="s1">: wheel.name</span><span class="s2">,</span>
                            <span class="s3">'version'</span><span class="s1">: wheel.version</span><span class="s2">,</span>
                            <span class="s3">'filename'</span><span class="s1">: wheel.filename</span><span class="s2">,</span>
                            <span class="s3">'url'</span><span class="s1">: urlunparse((scheme</span><span class="s2">, </span><span class="s1">netloc</span><span class="s2">, </span><span class="s1">origpath</span><span class="s2">,</span>
                                               <span class="s1">params</span><span class="s2">, </span><span class="s1">query</span><span class="s2">, </span><span class="s3">''</span><span class="s1">))</span><span class="s2">,</span>
                            <span class="s3">'python-version'</span><span class="s1">: </span><span class="s3">', '</span><span class="s1">.join(</span>
                                <span class="s1">[</span><span class="s3">'.'</span><span class="s1">.join(list(v[</span><span class="s5">2</span><span class="s1">:])) </span><span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">wheel.pyver])</span><span class="s2">,</span>
                        <span class="s1">}</span>
            <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">e:  </span><span class="s0"># pragma: no cover</span>
                <span class="s1">logger.warning(</span><span class="s3">'invalid path for wheel: %s'</span><span class="s2">, </span><span class="s1">path)</span>
        <span class="s2">elif not </span><span class="s1">path.endswith(self.downloadable_extensions):  </span><span class="s0"># pragma: no cover</span>
            <span class="s1">logger.debug(</span><span class="s3">'Not downloadable: %s'</span><span class="s2">, </span><span class="s1">path)</span>
        <span class="s2">else</span><span class="s1">:  </span><span class="s0"># downloadable extension</span>
            <span class="s1">path = filename = posixpath.basename(path)</span>
            <span class="s2">for </span><span class="s1">ext </span><span class="s2">in </span><span class="s1">self.downloadable_extensions:</span>
                <span class="s2">if </span><span class="s1">path.endswith(ext):</span>
                    <span class="s1">path = path[:-len(ext)]</span>
                    <span class="s1">t = self.split_filename(path</span><span class="s2">, </span><span class="s1">project_name)</span>
                    <span class="s2">if not </span><span class="s1">t:  </span><span class="s0"># pragma: no cover</span>
                        <span class="s1">logger.debug(</span><span class="s3">'No match for project/version: %s'</span><span class="s2">, </span><span class="s1">path)</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">name</span><span class="s2">, </span><span class="s1">version</span><span class="s2">, </span><span class="s1">pyver = t</span>
                        <span class="s2">if not </span><span class="s1">project_name </span><span class="s2">or </span><span class="s1">same_project(project_name</span><span class="s2">, </span><span class="s1">name):</span>
                            <span class="s1">result = {</span>
                                <span class="s3">'name'</span><span class="s1">: name</span><span class="s2">,</span>
                                <span class="s3">'version'</span><span class="s1">: version</span><span class="s2">,</span>
                                <span class="s3">'filename'</span><span class="s1">: filename</span><span class="s2">,</span>
                                <span class="s3">'url'</span><span class="s1">: urlunparse((scheme</span><span class="s2">, </span><span class="s1">netloc</span><span class="s2">, </span><span class="s1">origpath</span><span class="s2">,</span>
                                                   <span class="s1">params</span><span class="s2">, </span><span class="s1">query</span><span class="s2">, </span><span class="s3">''</span><span class="s1">))</span><span class="s2">,</span>
                                <span class="s0">#'packagetype': 'sdist',</span>
                            <span class="s1">}</span>
                            <span class="s2">if </span><span class="s1">pyver:  </span><span class="s0"># pragma: no cover</span>
                                <span class="s1">result[</span><span class="s3">'python-version'</span><span class="s1">] = pyver</span>
                    <span class="s2">break</span>
        <span class="s2">if </span><span class="s1">result </span><span class="s2">and </span><span class="s1">algo:</span>
            <span class="s1">result[</span><span class="s3">'%s_digest' </span><span class="s1">% algo] = digest</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_get_digest(self</span><span class="s2">, </span><span class="s1">info):</span>
        <span class="s4">&quot;&quot;&quot; 
        Get a digest from a dictionary by looking at a &quot;digests&quot; dictionary 
        or keys of the form 'algo_digest'. 
 
        Returns a 2-tuple (algo, digest) if found, else None. Currently 
        looks only for SHA256, then MD5. 
        &quot;&quot;&quot;</span>
        <span class="s1">result = </span><span class="s2">None</span>
        <span class="s2">if </span><span class="s3">'digests' </span><span class="s2">in </span><span class="s1">info:</span>
            <span class="s1">digests = info[</span><span class="s3">'digests'</span><span class="s1">]</span>
            <span class="s2">for </span><span class="s1">algo </span><span class="s2">in </span><span class="s1">(</span><span class="s3">'sha256'</span><span class="s2">, </span><span class="s3">'md5'</span><span class="s1">):</span>
                <span class="s2">if </span><span class="s1">algo </span><span class="s2">in </span><span class="s1">digests:</span>
                    <span class="s1">result = (algo</span><span class="s2">, </span><span class="s1">digests[algo])</span>
                    <span class="s2">break</span>
        <span class="s2">if not </span><span class="s1">result:</span>
            <span class="s2">for </span><span class="s1">algo </span><span class="s2">in </span><span class="s1">(</span><span class="s3">'sha256'</span><span class="s2">, </span><span class="s3">'md5'</span><span class="s1">):</span>
                <span class="s1">key = </span><span class="s3">'%s_digest' </span><span class="s1">% algo</span>
                <span class="s2">if </span><span class="s1">key </span><span class="s2">in </span><span class="s1">info:</span>
                    <span class="s1">result = (algo</span><span class="s2">, </span><span class="s1">info[key])</span>
                    <span class="s2">break</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_update_version_data(self</span><span class="s2">, </span><span class="s1">result</span><span class="s2">, </span><span class="s1">info):</span>
        <span class="s4">&quot;&quot;&quot; 
        Update a result dictionary (the final result from _get_project) with a 
        dictionary for a specific version, which typically holds information 
        gleaned from a filename or URL for an archive for the distribution. 
        &quot;&quot;&quot;</span>
        <span class="s1">name = info.pop(</span><span class="s3">'name'</span><span class="s1">)</span>
        <span class="s1">version = info.pop(</span><span class="s3">'version'</span><span class="s1">)</span>
        <span class="s2">if </span><span class="s1">version </span><span class="s2">in </span><span class="s1">result:</span>
            <span class="s1">dist = result[version]</span>
            <span class="s1">md = dist.metadata</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dist = make_dist(name</span><span class="s2">, </span><span class="s1">version</span><span class="s2">, </span><span class="s1">scheme=self.scheme)</span>
            <span class="s1">md = dist.metadata</span>
        <span class="s1">dist.digest = digest = self._get_digest(info)</span>
        <span class="s1">url = info[</span><span class="s3">'url'</span><span class="s1">]</span>
        <span class="s1">result[</span><span class="s3">'digests'</span><span class="s1">][url] = digest</span>
        <span class="s2">if </span><span class="s1">md.source_url != info[</span><span class="s3">'url'</span><span class="s1">]:</span>
            <span class="s1">md.source_url = self.prefer_url(md.source_url</span><span class="s2">, </span><span class="s1">url)</span>
            <span class="s1">result[</span><span class="s3">'urls'</span><span class="s1">].setdefault(version</span><span class="s2">, </span><span class="s1">set()).add(url)</span>
        <span class="s1">dist.locator = self</span>
        <span class="s1">result[version] = dist</span>

    <span class="s2">def </span><span class="s1">locate(self</span><span class="s2">, </span><span class="s1">requirement</span><span class="s2">, </span><span class="s1">prereleases=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s4">&quot;&quot;&quot; 
        Find the most recent distribution which matches the given 
        requirement. 
 
        :param requirement: A requirement of the form 'foo (1.0)' or perhaps 
                            'foo (&gt;= 1.0, &lt; 2.0, != 1.3)' 
        :param prereleases: If ``True``, allow pre-release versions 
                            to be located. Otherwise, pre-release versions 
                            are not returned. 
        :return: A :class:`Distribution` instance, or ``None`` if no such 
                 distribution could be located. 
        &quot;&quot;&quot;</span>
        <span class="s1">result = </span><span class="s2">None</span>
        <span class="s1">r = parse_requirement(requirement)</span>
        <span class="s2">if </span><span class="s1">r </span><span class="s2">is None</span><span class="s1">:  </span><span class="s0"># pragma: no cover</span>
            <span class="s2">raise </span><span class="s1">DistlibException(</span><span class="s3">'Not a valid requirement: %r' </span><span class="s1">% requirement)</span>
        <span class="s1">scheme = get_scheme(self.scheme)</span>
        <span class="s1">self.matcher = matcher = scheme.matcher(r.requirement)</span>
        <span class="s1">logger.debug(</span><span class="s3">'matcher: %s (%s)'</span><span class="s2">, </span><span class="s1">matcher</span><span class="s2">, </span><span class="s1">type(matcher).__name__)</span>
        <span class="s1">versions = self.get_project(r.name)</span>
        <span class="s2">if </span><span class="s1">len(versions) &gt; </span><span class="s5">2</span><span class="s1">:   </span><span class="s0"># urls and digests keys are present</span>
            <span class="s0"># sometimes, versions are invalid</span>
            <span class="s1">slist = []</span>
            <span class="s1">vcls = matcher.version_class</span>
            <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">versions:</span>
                <span class="s2">if </span><span class="s1">k </span><span class="s2">in </span><span class="s1">(</span><span class="s3">'urls'</span><span class="s2">, </span><span class="s3">'digests'</span><span class="s1">):</span>
                    <span class="s2">continue</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s2">if not </span><span class="s1">matcher.match(k):</span>
                        <span class="s2">pass  </span><span class="s0"># logger.debug('%s did not match %r', matcher, k)</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s2">if </span><span class="s1">prereleases </span><span class="s2">or not </span><span class="s1">vcls(k).is_prerelease:</span>
                            <span class="s1">slist.append(k)</span>
                        <span class="s0"># else:</span>
                            <span class="s0"># logger.debug('skipping pre-release '</span>
                                         <span class="s0"># 'version %s of %s', k, matcher.name)</span>
                <span class="s2">except </span><span class="s1">Exception:  </span><span class="s0"># pragma: no cover</span>
                    <span class="s1">logger.warning(</span><span class="s3">'error matching %s with %r'</span><span class="s2">, </span><span class="s1">matcher</span><span class="s2">, </span><span class="s1">k)</span>
                    <span class="s2">pass </span><span class="s0"># slist.append(k)</span>
            <span class="s2">if </span><span class="s1">len(slist) &gt; </span><span class="s5">1</span><span class="s1">:</span>
                <span class="s1">slist = sorted(slist</span><span class="s2">, </span><span class="s1">key=scheme.key)</span>
            <span class="s2">if </span><span class="s1">slist:</span>
                <span class="s1">logger.debug(</span><span class="s3">'sorted list: %s'</span><span class="s2">, </span><span class="s1">slist)</span>
                <span class="s1">version = slist[-</span><span class="s5">1</span><span class="s1">]</span>
                <span class="s1">result = versions[version]</span>
        <span class="s2">if </span><span class="s1">result:</span>
            <span class="s2">if </span><span class="s1">r.extras:</span>
                <span class="s1">result.extras = r.extras</span>
            <span class="s1">result.download_urls = versions.get(</span><span class="s3">'urls'</span><span class="s2">, </span><span class="s1">{}).get(version</span><span class="s2">, </span><span class="s1">set())</span>
            <span class="s1">d = {}</span>
            <span class="s1">sd = versions.get(</span><span class="s3">'digests'</span><span class="s2">, </span><span class="s1">{})</span>
            <span class="s2">for </span><span class="s1">url </span><span class="s2">in </span><span class="s1">result.download_urls:</span>
                <span class="s2">if </span><span class="s1">url </span><span class="s2">in </span><span class="s1">sd:  </span><span class="s0"># pragma: no cover</span>
                    <span class="s1">d[url] = sd[url]</span>
            <span class="s1">result.digests = d</span>
        <span class="s1">self.matcher = </span><span class="s2">None</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s2">class </span><span class="s1">PyPIRPCLocator(Locator):</span>
    <span class="s4">&quot;&quot;&quot; 
    This locator uses XML-RPC to locate distributions. It therefore 
    cannot be used with simple mirrors (that only mirror file content). 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance. 
 
        :param url: The URL to use for XML-RPC. 
        :param kwargs: Passed to the superclass constructor. 
        &quot;&quot;&quot;</span>
        <span class="s1">super(PyPIRPCLocator</span><span class="s2">, </span><span class="s1">self).__init__(**kwargs)</span>
        <span class="s1">self.base_url = url</span>
        <span class="s1">self.client = ServerProxy(url</span><span class="s2">, </span><span class="s1">timeout=</span><span class="s5">3.0</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">get_distribution_names(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return all the distribution names known to this locator. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">set(self.client.list_packages())</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s1">result = {</span><span class="s3">'urls'</span><span class="s1">: {}</span><span class="s2">, </span><span class="s3">'digests'</span><span class="s1">: {}}</span>
        <span class="s1">versions = self.client.package_releases(name</span><span class="s2">, True</span><span class="s1">)</span>
        <span class="s2">for </span><span class="s1">v </span><span class="s2">in </span><span class="s1">versions:</span>
            <span class="s1">urls = self.client.release_urls(name</span><span class="s2">, </span><span class="s1">v)</span>
            <span class="s1">data = self.client.release_data(name</span><span class="s2">, </span><span class="s1">v)</span>
            <span class="s1">metadata = Metadata(scheme=self.scheme)</span>
            <span class="s1">metadata.name = data[</span><span class="s3">'name'</span><span class="s1">]</span>
            <span class="s1">metadata.version = data[</span><span class="s3">'version'</span><span class="s1">]</span>
            <span class="s1">metadata.license = data.get(</span><span class="s3">'license'</span><span class="s1">)</span>
            <span class="s1">metadata.keywords = data.get(</span><span class="s3">'keywords'</span><span class="s2">, </span><span class="s1">[])</span>
            <span class="s1">metadata.summary = data.get(</span><span class="s3">'summary'</span><span class="s1">)</span>
            <span class="s1">dist = Distribution(metadata)</span>
            <span class="s2">if </span><span class="s1">urls:</span>
                <span class="s1">info = urls[</span><span class="s5">0</span><span class="s1">]</span>
                <span class="s1">metadata.source_url = info[</span><span class="s3">'url'</span><span class="s1">]</span>
                <span class="s1">dist.digest = self._get_digest(info)</span>
                <span class="s1">dist.locator = self</span>
                <span class="s1">result[v] = dist</span>
                <span class="s2">for </span><span class="s1">info </span><span class="s2">in </span><span class="s1">urls:</span>
                    <span class="s1">url = info[</span><span class="s3">'url'</span><span class="s1">]</span>
                    <span class="s1">digest = self._get_digest(info)</span>
                    <span class="s1">result[</span><span class="s3">'urls'</span><span class="s1">].setdefault(v</span><span class="s2">, </span><span class="s1">set()).add(url)</span>
                    <span class="s1">result[</span><span class="s3">'digests'</span><span class="s1">][url] = digest</span>
        <span class="s2">return </span><span class="s1">result</span>

<span class="s2">class </span><span class="s1">PyPIJSONLocator(Locator):</span>
    <span class="s4">&quot;&quot;&quot; 
    This locator uses PyPI's JSON interface. It's very limited in functionality 
    and probably not worth using. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s1">super(PyPIJSONLocator</span><span class="s2">, </span><span class="s1">self).__init__(**kwargs)</span>
        <span class="s1">self.base_url = ensure_slash(url)</span>

    <span class="s2">def </span><span class="s1">get_distribution_names(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return all the distribution names known to this locator. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">'Not available from this locator'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s1">result = {</span><span class="s3">'urls'</span><span class="s1">: {}</span><span class="s2">, </span><span class="s3">'digests'</span><span class="s1">: {}}</span>
        <span class="s1">url = urljoin(self.base_url</span><span class="s2">, </span><span class="s3">'%s/json' </span><span class="s1">% quote(name))</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">resp = self.opener.open(url)</span>
            <span class="s1">data = resp.read().decode() </span><span class="s0"># for now</span>
            <span class="s1">d = json.loads(data)</span>
            <span class="s1">md = Metadata(scheme=self.scheme)</span>
            <span class="s1">data = d[</span><span class="s3">'info'</span><span class="s1">]</span>
            <span class="s1">md.name = data[</span><span class="s3">'name'</span><span class="s1">]</span>
            <span class="s1">md.version = data[</span><span class="s3">'version'</span><span class="s1">]</span>
            <span class="s1">md.license = data.get(</span><span class="s3">'license'</span><span class="s1">)</span>
            <span class="s1">md.keywords = data.get(</span><span class="s3">'keywords'</span><span class="s2">, </span><span class="s1">[])</span>
            <span class="s1">md.summary = data.get(</span><span class="s3">'summary'</span><span class="s1">)</span>
            <span class="s1">dist = Distribution(md)</span>
            <span class="s1">dist.locator = self</span>
            <span class="s1">urls = d[</span><span class="s3">'urls'</span><span class="s1">]</span>
            <span class="s1">result[md.version] = dist</span>
            <span class="s2">for </span><span class="s1">info </span><span class="s2">in </span><span class="s1">d[</span><span class="s3">'urls'</span><span class="s1">]:</span>
                <span class="s1">url = info[</span><span class="s3">'url'</span><span class="s1">]</span>
                <span class="s1">dist.download_urls.add(url)</span>
                <span class="s1">dist.digests[url] = self._get_digest(info)</span>
                <span class="s1">result[</span><span class="s3">'urls'</span><span class="s1">].setdefault(md.version</span><span class="s2">, </span><span class="s1">set()).add(url)</span>
                <span class="s1">result[</span><span class="s3">'digests'</span><span class="s1">][url] = self._get_digest(info)</span>
            <span class="s0"># Now get other releases</span>
            <span class="s2">for </span><span class="s1">version</span><span class="s2">, </span><span class="s1">infos </span><span class="s2">in </span><span class="s1">d[</span><span class="s3">'releases'</span><span class="s1">].items():</span>
                <span class="s2">if </span><span class="s1">version == md.version:</span>
                    <span class="s2">continue    </span><span class="s0"># already done</span>
                <span class="s1">omd = Metadata(scheme=self.scheme)</span>
                <span class="s1">omd.name = md.name</span>
                <span class="s1">omd.version = version</span>
                <span class="s1">odist = Distribution(omd)</span>
                <span class="s1">odist.locator = self</span>
                <span class="s1">result[version] = odist</span>
                <span class="s2">for </span><span class="s1">info </span><span class="s2">in </span><span class="s1">infos:</span>
                    <span class="s1">url = info[</span><span class="s3">'url'</span><span class="s1">]</span>
                    <span class="s1">odist.download_urls.add(url)</span>
                    <span class="s1">odist.digests[url] = self._get_digest(info)</span>
                    <span class="s1">result[</span><span class="s3">'urls'</span><span class="s1">].setdefault(version</span><span class="s2">, </span><span class="s1">set()).add(url)</span>
                    <span class="s1">result[</span><span class="s3">'digests'</span><span class="s1">][url] = self._get_digest(info)</span>
<span class="s0">#            for info in urls:</span>
<span class="s0">#                md.source_url = info['url']</span>
<span class="s0">#                dist.digest = self._get_digest(info)</span>
<span class="s0">#                dist.locator = self</span>
<span class="s0">#                for info in urls:</span>
<span class="s0">#                    url = info['url']</span>
<span class="s0">#                    result['urls'].setdefault(md.version, set()).add(url)</span>
<span class="s0">#                    result['digests'][url] = self._get_digest(info)</span>
        <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">e:</span>
            <span class="s1">self.errors.put(text_type(e))</span>
            <span class="s1">logger.exception(</span><span class="s3">'JSON fetch failed: %s'</span><span class="s2">, </span><span class="s1">e)</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s2">class </span><span class="s1">Page(object):</span>
    <span class="s4">&quot;&quot;&quot; 
    This class represents a scraped HTML page. 
    &quot;&quot;&quot;</span>
    <span class="s0"># The following slightly hairy-looking regex just looks for the contents of</span>
    <span class="s0"># an anchor link, which has an attribute &quot;href&quot; either immediately preceded</span>
    <span class="s0"># or immediately followed by a &quot;rel&quot; attribute. The attribute values can be</span>
    <span class="s0"># declared with double quotes, single quotes or no quotes - which leads to</span>
    <span class="s0"># the length of the expression.</span>
    <span class="s1">_href = re.compile(</span><span class="s3">&quot;&quot;&quot; 
(rel</span><span class="s2">\\</span><span class="s3">s*=</span><span class="s2">\\</span><span class="s3">s*(?:&quot;(?P&lt;rel1&gt;[^&quot;]*)&quot;|'(?P&lt;rel2&gt;[^']*)'|(?P&lt;rel3&gt;[^&gt;</span><span class="s2">\\</span><span class="s3">s</span><span class="s2">\n</span><span class="s3">]*))</span><span class="s2">\\</span><span class="s3">s+)? 
href</span><span class="s2">\\</span><span class="s3">s*=</span><span class="s2">\\</span><span class="s3">s*(?:&quot;(?P&lt;url1&gt;[^&quot;]*)&quot;|'(?P&lt;url2&gt;[^']*)'|(?P&lt;url3&gt;[^&gt;</span><span class="s2">\\</span><span class="s3">s</span><span class="s2">\n</span><span class="s3">]*)) 
(</span><span class="s2">\\</span><span class="s3">s+rel</span><span class="s2">\\</span><span class="s3">s*=</span><span class="s2">\\</span><span class="s3">s*(?:&quot;(?P&lt;rel4&gt;[^&quot;]*)&quot;|'(?P&lt;rel5&gt;[^']*)'|(?P&lt;rel6&gt;[^&gt;</span><span class="s2">\\</span><span class="s3">s</span><span class="s2">\n</span><span class="s3">]*)))? 
&quot;&quot;&quot;</span><span class="s2">, </span><span class="s1">re.I | re.S | re.X)</span>
    <span class="s1">_base = re.compile(</span><span class="s3">r&quot;&quot;&quot;&lt;base\s+href\s*=\s*['&quot;]?([^'&quot;&gt;]+)&quot;&quot;&quot;</span><span class="s2">, </span><span class="s1">re.I | re.S)</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">data</span><span class="s2">, </span><span class="s1">url):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance with the Unicode page contents and the URL they 
        came from. 
        &quot;&quot;&quot;</span>
        <span class="s1">self.data = data</span>
        <span class="s1">self.base_url = self.url = url</span>
        <span class="s1">m = self._base.search(self.data)</span>
        <span class="s2">if </span><span class="s1">m:</span>
            <span class="s1">self.base_url = m.group(</span><span class="s5">1</span><span class="s1">)</span>

    <span class="s1">_clean_re = re.compile(</span><span class="s3">r'[^a-z0-9$&amp;+,/:;=?@.#%_\\|-]'</span><span class="s2">, </span><span class="s1">re.I)</span>

    <span class="s1">@cached_property</span>
    <span class="s2">def </span><span class="s1">links(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return the URLs of all the links on a page together with information 
        about their &quot;rel&quot; attribute, for determining which ones to treat as 
        downloads and which ones to queue for further scraping. 
        &quot;&quot;&quot;</span>
        <span class="s2">def </span><span class="s1">clean(url):</span>
            <span class="s4">&quot;Tidy up an URL.&quot;</span>
            <span class="s1">scheme</span><span class="s2">, </span><span class="s1">netloc</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">params</span><span class="s2">, </span><span class="s1">query</span><span class="s2">, </span><span class="s1">frag = urlparse(url)</span>
            <span class="s2">return </span><span class="s1">urlunparse((scheme</span><span class="s2">, </span><span class="s1">netloc</span><span class="s2">, </span><span class="s1">quote(path)</span><span class="s2">,</span>
                               <span class="s1">params</span><span class="s2">, </span><span class="s1">query</span><span class="s2">, </span><span class="s1">frag))</span>

        <span class="s1">result = set()</span>
        <span class="s2">for </span><span class="s1">match </span><span class="s2">in </span><span class="s1">self._href.finditer(self.data):</span>
            <span class="s1">d = match.groupdict(</span><span class="s3">''</span><span class="s1">)</span>
            <span class="s1">rel = (d[</span><span class="s3">'rel1'</span><span class="s1">] </span><span class="s2">or </span><span class="s1">d[</span><span class="s3">'rel2'</span><span class="s1">] </span><span class="s2">or </span><span class="s1">d[</span><span class="s3">'rel3'</span><span class="s1">] </span><span class="s2">or</span>
                   <span class="s1">d[</span><span class="s3">'rel4'</span><span class="s1">] </span><span class="s2">or </span><span class="s1">d[</span><span class="s3">'rel5'</span><span class="s1">] </span><span class="s2">or </span><span class="s1">d[</span><span class="s3">'rel6'</span><span class="s1">])</span>
            <span class="s1">url = d[</span><span class="s3">'url1'</span><span class="s1">] </span><span class="s2">or </span><span class="s1">d[</span><span class="s3">'url2'</span><span class="s1">] </span><span class="s2">or </span><span class="s1">d[</span><span class="s3">'url3'</span><span class="s1">]</span>
            <span class="s1">url = urljoin(self.base_url</span><span class="s2">, </span><span class="s1">url)</span>
            <span class="s1">url = unescape(url)</span>
            <span class="s1">url = self._clean_re.sub(</span><span class="s2">lambda </span><span class="s1">m: </span><span class="s3">'%%%2x' </span><span class="s1">% ord(m.group(</span><span class="s5">0</span><span class="s1">))</span><span class="s2">, </span><span class="s1">url)</span>
            <span class="s1">result.add((url</span><span class="s2">, </span><span class="s1">rel))</span>
        <span class="s0"># We sort the result, hoping to bring the most recent versions</span>
        <span class="s0"># to the front</span>
        <span class="s1">result = sorted(result</span><span class="s2">, </span><span class="s1">key=</span><span class="s2">lambda </span><span class="s1">t: t[</span><span class="s5">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">reverse=</span><span class="s2">True</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s2">class </span><span class="s1">SimpleScrapingLocator(Locator):</span>
    <span class="s4">&quot;&quot;&quot; 
    A locator which scrapes HTML pages to locate downloads for a distribution. 
    This runs multiple threads to do the I/O; performance is at least as good 
    as pip's PackageFinder, which works in an analogous fashion. 
    &quot;&quot;&quot;</span>

    <span class="s0"># These are used to deal with various Content-Encoding schemes.</span>
    <span class="s1">decoders = {</span>
        <span class="s3">'deflate'</span><span class="s1">: zlib.decompress</span><span class="s2">,</span>
        <span class="s3">'gzip'</span><span class="s1">: </span><span class="s2">lambda </span><span class="s1">b: gzip.GzipFile(fileobj=BytesIO(b)).read()</span><span class="s2">,</span>
        <span class="s3">'none'</span><span class="s1">: </span><span class="s2">lambda </span><span class="s1">b: b</span><span class="s2">,</span>
    <span class="s1">}</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">timeout=</span><span class="s2">None, </span><span class="s1">num_workers=</span><span class="s5">10</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance. 
        :param url: The root URL to use for scraping. 
        :param timeout: The timeout, in seconds, to be applied to requests. 
                        This defaults to ``None`` (no timeout specified). 
        :param num_workers: The number of worker threads you want to do I/O, 
                            This defaults to 10. 
        :param kwargs: Passed to the superclass. 
        &quot;&quot;&quot;</span>
        <span class="s1">super(SimpleScrapingLocator</span><span class="s2">, </span><span class="s1">self).__init__(**kwargs)</span>
        <span class="s1">self.base_url = ensure_slash(url)</span>
        <span class="s1">self.timeout = timeout</span>
        <span class="s1">self._page_cache = {}</span>
        <span class="s1">self._seen = set()</span>
        <span class="s1">self._to_fetch = queue.Queue()</span>
        <span class="s1">self._bad_hosts = set()</span>
        <span class="s1">self.skip_externals = </span><span class="s2">False</span>
        <span class="s1">self.num_workers = num_workers</span>
        <span class="s1">self._lock = threading.RLock()</span>
        <span class="s0"># See issue #45: we need to be resilient when the locator is used</span>
        <span class="s0"># in a thread, e.g. with concurrent.futures. We can't use self._lock</span>
        <span class="s0"># as it is for coordinating our internal threads - the ones created</span>
        <span class="s0"># in _prepare_threads.</span>
        <span class="s1">self._gplock = threading.RLock()</span>
        <span class="s1">self.platform_check = </span><span class="s2">False  </span><span class="s0"># See issue #112</span>

    <span class="s2">def </span><span class="s1">_prepare_threads(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Threads are created only when get_project is called, and terminate 
        before it returns. They are there primarily to parallelise I/O (i.e. 
        fetching web pages). 
        &quot;&quot;&quot;</span>
        <span class="s1">self._threads = []</span>
        <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(self.num_workers):</span>
            <span class="s1">t = threading.Thread(target=self._fetch)</span>
            <span class="s1">t.daemon = </span><span class="s2">True</span>
            <span class="s1">t.start()</span>
            <span class="s1">self._threads.append(t)</span>

    <span class="s2">def </span><span class="s1">_wait_threads(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Tell all the threads to terminate (by sending a sentinel value) and 
        wait for them to do so. 
        &quot;&quot;&quot;</span>
        <span class="s0"># Note that you need two loops, since you can't say which</span>
        <span class="s0"># thread will get each sentinel</span>
        <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">self._threads:</span>
            <span class="s1">self._to_fetch.put(</span><span class="s2">None</span><span class="s1">)    </span><span class="s0"># sentinel</span>
        <span class="s2">for </span><span class="s1">t </span><span class="s2">in </span><span class="s1">self._threads:</span>
            <span class="s1">t.join()</span>
        <span class="s1">self._threads = []</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s1">result = {</span><span class="s3">'urls'</span><span class="s1">: {}</span><span class="s2">, </span><span class="s3">'digests'</span><span class="s1">: {}}</span>
        <span class="s2">with </span><span class="s1">self._gplock:</span>
            <span class="s1">self.result = result</span>
            <span class="s1">self.project_name = name</span>
            <span class="s1">url = urljoin(self.base_url</span><span class="s2">, </span><span class="s3">'%s/' </span><span class="s1">% quote(name))</span>
            <span class="s1">self._seen.clear()</span>
            <span class="s1">self._page_cache.clear()</span>
            <span class="s1">self._prepare_threads()</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">logger.debug(</span><span class="s3">'Queueing %s'</span><span class="s2">, </span><span class="s1">url)</span>
                <span class="s1">self._to_fetch.put(url)</span>
                <span class="s1">self._to_fetch.join()</span>
            <span class="s2">finally</span><span class="s1">:</span>
                <span class="s1">self._wait_threads()</span>
            <span class="s2">del </span><span class="s1">self.result</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">platform_dependent = re.compile(</span><span class="s3">r'\b(linux_(i\d86|x86_64|arm\w+)|'</span>
                                    <span class="s3">r'win(32|_amd64)|macosx_?\d+)\b'</span><span class="s2">, </span><span class="s1">re.I)</span>

    <span class="s2">def </span><span class="s1">_is_platform_dependent(self</span><span class="s2">, </span><span class="s1">url):</span>
        <span class="s4">&quot;&quot;&quot; 
        Does an URL refer to a platform-specific download? 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">self.platform_dependent.search(url)</span>

    <span class="s2">def </span><span class="s1">_process_download(self</span><span class="s2">, </span><span class="s1">url):</span>
        <span class="s4">&quot;&quot;&quot; 
        See if an URL is a suitable download for a project. 
 
        If it is, register information in the result dictionary (for 
        _get_project) about the specific version it's for. 
 
        Note that the return value isn't actually used other than as a boolean 
        value. 
        &quot;&quot;&quot;</span>
        <span class="s2">if </span><span class="s1">self.platform_check </span><span class="s2">and </span><span class="s1">self._is_platform_dependent(url):</span>
            <span class="s1">info = </span><span class="s2">None</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">info = self.convert_url_to_download_info(url</span><span class="s2">, </span><span class="s1">self.project_name)</span>
        <span class="s1">logger.debug(</span><span class="s3">'process_download: %s -&gt; %s'</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">info)</span>
        <span class="s2">if </span><span class="s1">info:</span>
            <span class="s2">with </span><span class="s1">self._lock:    </span><span class="s0"># needed because self.result is shared</span>
                <span class="s1">self._update_version_data(self.result</span><span class="s2">, </span><span class="s1">info)</span>
        <span class="s2">return </span><span class="s1">info</span>

    <span class="s2">def </span><span class="s1">_should_queue(self</span><span class="s2">, </span><span class="s1">link</span><span class="s2">, </span><span class="s1">referrer</span><span class="s2">, </span><span class="s1">rel):</span>
        <span class="s4">&quot;&quot;&quot; 
        Determine whether a link URL from a referring page and with a 
        particular &quot;rel&quot; attribute should be queued for scraping. 
        &quot;&quot;&quot;</span>
        <span class="s1">scheme</span><span class="s2">, </span><span class="s1">netloc</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = urlparse(link)</span>
        <span class="s2">if </span><span class="s1">path.endswith(self.source_extensions + self.binary_extensions +</span>
                         <span class="s1">self.excluded_extensions):</span>
            <span class="s1">result = </span><span class="s2">False</span>
        <span class="s2">elif </span><span class="s1">self.skip_externals </span><span class="s2">and not </span><span class="s1">link.startswith(self.base_url):</span>
            <span class="s1">result = </span><span class="s2">False</span>
        <span class="s2">elif not </span><span class="s1">referrer.startswith(self.base_url):</span>
            <span class="s1">result = </span><span class="s2">False</span>
        <span class="s2">elif </span><span class="s1">rel </span><span class="s2">not in </span><span class="s1">(</span><span class="s3">'homepage'</span><span class="s2">, </span><span class="s3">'download'</span><span class="s1">):</span>
            <span class="s1">result = </span><span class="s2">False</span>
        <span class="s2">elif </span><span class="s1">scheme </span><span class="s2">not in </span><span class="s1">(</span><span class="s3">'http'</span><span class="s2">, </span><span class="s3">'https'</span><span class="s2">, </span><span class="s3">'ftp'</span><span class="s1">):</span>
            <span class="s1">result = </span><span class="s2">False</span>
        <span class="s2">elif </span><span class="s1">self._is_platform_dependent(link):</span>
            <span class="s1">result = </span><span class="s2">False</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">host = netloc.split(</span><span class="s3">':'</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s2">if </span><span class="s1">host.lower() == </span><span class="s3">'localhost'</span><span class="s1">:</span>
                <span class="s1">result = </span><span class="s2">False</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">result = </span><span class="s2">True</span>
        <span class="s1">logger.debug(</span><span class="s3">'should_queue: %s (%s) from %s -&gt; %s'</span><span class="s2">, </span><span class="s1">link</span><span class="s2">, </span><span class="s1">rel</span><span class="s2">,</span>
                     <span class="s1">referrer</span><span class="s2">, </span><span class="s1">result)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">_fetch(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Get a URL to fetch from the work queue, get the HTML page, examine its 
        links for download candidates and candidates for further scraping. 
 
        This is a handy method to run in a thread. 
        &quot;&quot;&quot;</span>
        <span class="s2">while True</span><span class="s1">:</span>
            <span class="s1">url = self._to_fetch.get()</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">url:</span>
                    <span class="s1">page = self.get_page(url)</span>
                    <span class="s2">if </span><span class="s1">page </span><span class="s2">is None</span><span class="s1">:    </span><span class="s0"># e.g. after an error</span>
                        <span class="s2">continue</span>
                    <span class="s2">for </span><span class="s1">link</span><span class="s2">, </span><span class="s1">rel </span><span class="s2">in </span><span class="s1">page.links:</span>
                        <span class="s2">if </span><span class="s1">link </span><span class="s2">not in </span><span class="s1">self._seen:</span>
                            <span class="s2">try</span><span class="s1">:</span>
                                <span class="s1">self._seen.add(link)</span>
                                <span class="s2">if </span><span class="s1">(</span><span class="s2">not </span><span class="s1">self._process_download(link) </span><span class="s2">and</span>
                                    <span class="s1">self._should_queue(link</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">rel)):</span>
                                    <span class="s1">logger.debug(</span><span class="s3">'Queueing %s from %s'</span><span class="s2">, </span><span class="s1">link</span><span class="s2">, </span><span class="s1">url)</span>
                                    <span class="s1">self._to_fetch.put(link)</span>
                            <span class="s2">except </span><span class="s1">MetadataInvalidError:  </span><span class="s0"># e.g. invalid versions</span>
                                <span class="s2">pass</span>
            <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">e:  </span><span class="s0"># pragma: no cover</span>
                <span class="s1">self.errors.put(text_type(e))</span>
            <span class="s2">finally</span><span class="s1">:</span>
                <span class="s0"># always do this, to avoid hangs :-)</span>
                <span class="s1">self._to_fetch.task_done()</span>
            <span class="s2">if not </span><span class="s1">url:</span>
                <span class="s0">#logger.debug('Sentinel seen, quitting.')</span>
                <span class="s2">break</span>

    <span class="s2">def </span><span class="s1">get_page(self</span><span class="s2">, </span><span class="s1">url):</span>
        <span class="s4">&quot;&quot;&quot; 
        Get the HTML for an URL, possibly from an in-memory cache. 
 
        XXX TODO Note: this cache is never actually cleared. It's assumed that 
        the data won't get stale over the lifetime of a locator instance (not 
        necessarily true for the default_locator). 
        &quot;&quot;&quot;</span>
        <span class="s0"># http://peak.telecommunity.com/DevCenter/EasyInstall#package-index-api</span>
        <span class="s1">scheme</span><span class="s2">, </span><span class="s1">netloc</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ = urlparse(url)</span>
        <span class="s2">if </span><span class="s1">scheme == </span><span class="s3">'file' </span><span class="s2">and </span><span class="s1">os.path.isdir(url2pathname(path)):</span>
            <span class="s1">url = urljoin(ensure_slash(url)</span><span class="s2">, </span><span class="s3">'index.html'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">url </span><span class="s2">in </span><span class="s1">self._page_cache:</span>
            <span class="s1">result = self._page_cache[url]</span>
            <span class="s1">logger.debug(</span><span class="s3">'Returning %s from cache: %s'</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">result)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">host = netloc.split(</span><span class="s3">':'</span><span class="s2">, </span><span class="s5">1</span><span class="s1">)[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">result = </span><span class="s2">None</span>
            <span class="s2">if </span><span class="s1">host </span><span class="s2">in </span><span class="s1">self._bad_hosts:</span>
                <span class="s1">logger.debug(</span><span class="s3">'Skipping %s due to bad host %s'</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">host)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">req = Request(url</span><span class="s2">, </span><span class="s1">headers={</span><span class="s3">'Accept-encoding'</span><span class="s1">: </span><span class="s3">'identity'</span><span class="s1">})</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">logger.debug(</span><span class="s3">'Fetching %s'</span><span class="s2">, </span><span class="s1">url)</span>
                    <span class="s1">resp = self.opener.open(req</span><span class="s2">, </span><span class="s1">timeout=self.timeout)</span>
                    <span class="s1">logger.debug(</span><span class="s3">'Fetched %s'</span><span class="s2">, </span><span class="s1">url)</span>
                    <span class="s1">headers = resp.info()</span>
                    <span class="s1">content_type = headers.get(</span><span class="s3">'Content-Type'</span><span class="s2">, </span><span class="s3">''</span><span class="s1">)</span>
                    <span class="s2">if </span><span class="s1">HTML_CONTENT_TYPE.match(content_type):</span>
                        <span class="s1">final_url = resp.geturl()</span>
                        <span class="s1">data = resp.read()</span>
                        <span class="s1">encoding = headers.get(</span><span class="s3">'Content-Encoding'</span><span class="s1">)</span>
                        <span class="s2">if </span><span class="s1">encoding:</span>
                            <span class="s1">decoder = self.decoders[encoding]   </span><span class="s0"># fail if not found</span>
                            <span class="s1">data = decoder(data)</span>
                        <span class="s1">encoding = </span><span class="s3">'utf-8'</span>
                        <span class="s1">m = CHARSET.search(content_type)</span>
                        <span class="s2">if </span><span class="s1">m:</span>
                            <span class="s1">encoding = m.group(</span><span class="s5">1</span><span class="s1">)</span>
                        <span class="s2">try</span><span class="s1">:</span>
                            <span class="s1">data = data.decode(encoding)</span>
                        <span class="s2">except </span><span class="s1">UnicodeError:  </span><span class="s0"># pragma: no cover</span>
                            <span class="s1">data = data.decode(</span><span class="s3">'latin-1'</span><span class="s1">)    </span><span class="s0"># fallback</span>
                        <span class="s1">result = Page(data</span><span class="s2">, </span><span class="s1">final_url)</span>
                        <span class="s1">self._page_cache[final_url] = result</span>
                <span class="s2">except </span><span class="s1">HTTPError </span><span class="s2">as </span><span class="s1">e:</span>
                    <span class="s2">if </span><span class="s1">e.code != </span><span class="s5">404</span><span class="s1">:</span>
                        <span class="s1">logger.exception(</span><span class="s3">'Fetch failed: %s: %s'</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">e)</span>
                <span class="s2">except </span><span class="s1">URLError </span><span class="s2">as </span><span class="s1">e:  </span><span class="s0"># pragma: no cover</span>
                    <span class="s1">logger.exception(</span><span class="s3">'Fetch failed: %s: %s'</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">e)</span>
                    <span class="s2">with </span><span class="s1">self._lock:</span>
                        <span class="s1">self._bad_hosts.add(host)</span>
                <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">e:  </span><span class="s0"># pragma: no cover</span>
                    <span class="s1">logger.exception(</span><span class="s3">'Fetch failed: %s: %s'</span><span class="s2">, </span><span class="s1">url</span><span class="s2">, </span><span class="s1">e)</span>
                <span class="s2">finally</span><span class="s1">:</span>
                    <span class="s1">self._page_cache[url] = result   </span><span class="s0"># even if None (failure)</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s1">_distname_re = re.compile(</span><span class="s3">'&lt;a href=[^&gt;]*&gt;([^&lt;]+)&lt;'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">get_distribution_names(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return all the distribution names known to this locator. 
        &quot;&quot;&quot;</span>
        <span class="s1">result = set()</span>
        <span class="s1">page = self.get_page(self.base_url)</span>
        <span class="s2">if not </span><span class="s1">page:</span>
            <span class="s2">raise </span><span class="s1">DistlibException(</span><span class="s3">'Unable to get %s' </span><span class="s1">% self.base_url)</span>
        <span class="s2">for </span><span class="s1">match </span><span class="s2">in </span><span class="s1">self._distname_re.finditer(page.data):</span>
            <span class="s1">result.add(match.group(</span><span class="s5">1</span><span class="s1">))</span>
        <span class="s2">return </span><span class="s1">result</span>

<span class="s2">class </span><span class="s1">DirectoryLocator(Locator):</span>
    <span class="s4">&quot;&quot;&quot; 
    This class locates distributions in a directory tree. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance. 
        :param path: The root of the directory tree to search. 
        :param kwargs: Passed to the superclass constructor, 
                       except for: 
                       * recursive - if True (the default), subdirectories are 
                         recursed into. If False, only the top-level directory 
                         is searched, 
        &quot;&quot;&quot;</span>
        <span class="s1">self.recursive = kwargs.pop(</span><span class="s3">'recursive'</span><span class="s2">, True</span><span class="s1">)</span>
        <span class="s1">super(DirectoryLocator</span><span class="s2">, </span><span class="s1">self).__init__(**kwargs)</span>
        <span class="s1">path = os.path.abspath(path)</span>
        <span class="s2">if not </span><span class="s1">os.path.isdir(path):  </span><span class="s0"># pragma: no cover</span>
            <span class="s2">raise </span><span class="s1">DistlibException(</span><span class="s3">'Not a directory: %r' </span><span class="s1">% path)</span>
        <span class="s1">self.base_dir = path</span>

    <span class="s2">def </span><span class="s1">should_include(self</span><span class="s2">, </span><span class="s1">filename</span><span class="s2">, </span><span class="s1">parent):</span>
        <span class="s4">&quot;&quot;&quot; 
        Should a filename be considered as a candidate for a distribution 
        archive? As well as the filename, the directory which contains it 
        is provided, though not used by the current implementation. 
        &quot;&quot;&quot;</span>
        <span class="s2">return </span><span class="s1">filename.endswith(self.downloadable_extensions)</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s1">result = {</span><span class="s3">'urls'</span><span class="s1">: {}</span><span class="s2">, </span><span class="s3">'digests'</span><span class="s1">: {}}</span>
        <span class="s2">for </span><span class="s1">root</span><span class="s2">, </span><span class="s1">dirs</span><span class="s2">, </span><span class="s1">files </span><span class="s2">in </span><span class="s1">os.walk(self.base_dir):</span>
            <span class="s2">for </span><span class="s1">fn </span><span class="s2">in </span><span class="s1">files:</span>
                <span class="s2">if </span><span class="s1">self.should_include(fn</span><span class="s2">, </span><span class="s1">root):</span>
                    <span class="s1">fn = os.path.join(root</span><span class="s2">, </span><span class="s1">fn)</span>
                    <span class="s1">url = urlunparse((</span><span class="s3">'file'</span><span class="s2">, </span><span class="s3">''</span><span class="s2">,</span>
                                      <span class="s1">pathname2url(os.path.abspath(fn))</span><span class="s2">,</span>
                                      <span class="s3">''</span><span class="s2">, </span><span class="s3">''</span><span class="s2">, </span><span class="s3">''</span><span class="s1">))</span>
                    <span class="s1">info = self.convert_url_to_download_info(url</span><span class="s2">, </span><span class="s1">name)</span>
                    <span class="s2">if </span><span class="s1">info:</span>
                        <span class="s1">self._update_version_data(result</span><span class="s2">, </span><span class="s1">info)</span>
            <span class="s2">if not </span><span class="s1">self.recursive:</span>
                <span class="s2">break</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">get_distribution_names(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return all the distribution names known to this locator. 
        &quot;&quot;&quot;</span>
        <span class="s1">result = set()</span>
        <span class="s2">for </span><span class="s1">root</span><span class="s2">, </span><span class="s1">dirs</span><span class="s2">, </span><span class="s1">files </span><span class="s2">in </span><span class="s1">os.walk(self.base_dir):</span>
            <span class="s2">for </span><span class="s1">fn </span><span class="s2">in </span><span class="s1">files:</span>
                <span class="s2">if </span><span class="s1">self.should_include(fn</span><span class="s2">, </span><span class="s1">root):</span>
                    <span class="s1">fn = os.path.join(root</span><span class="s2">, </span><span class="s1">fn)</span>
                    <span class="s1">url = urlunparse((</span><span class="s3">'file'</span><span class="s2">, </span><span class="s3">''</span><span class="s2">,</span>
                                      <span class="s1">pathname2url(os.path.abspath(fn))</span><span class="s2">,</span>
                                      <span class="s3">''</span><span class="s2">, </span><span class="s3">''</span><span class="s2">, </span><span class="s3">''</span><span class="s1">))</span>
                    <span class="s1">info = self.convert_url_to_download_info(url</span><span class="s2">, None</span><span class="s1">)</span>
                    <span class="s2">if </span><span class="s1">info:</span>
                        <span class="s1">result.add(info[</span><span class="s3">'name'</span><span class="s1">])</span>
            <span class="s2">if not </span><span class="s1">self.recursive:</span>
                <span class="s2">break</span>
        <span class="s2">return </span><span class="s1">result</span>

<span class="s2">class </span><span class="s1">JSONLocator(Locator):</span>
    <span class="s4">&quot;&quot;&quot; 
    This locator uses special extended metadata (not available on PyPI) and is 
    the basis of performant dependency resolution in distlib. Other locators 
    require archive downloads before dependencies can be determined! As you 
    might imagine, that can be slow. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">get_distribution_names(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return all the distribution names known to this locator. 
        &quot;&quot;&quot;</span>
        <span class="s2">raise </span><span class="s1">NotImplementedError(</span><span class="s3">'Not available from this locator'</span><span class="s1">)</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s1">result = {</span><span class="s3">'urls'</span><span class="s1">: {}</span><span class="s2">, </span><span class="s3">'digests'</span><span class="s1">: {}}</span>
        <span class="s1">data = get_project_data(name)</span>
        <span class="s2">if </span><span class="s1">data:</span>
            <span class="s2">for </span><span class="s1">info </span><span class="s2">in </span><span class="s1">data.get(</span><span class="s3">'files'</span><span class="s2">, </span><span class="s1">[]):</span>
                <span class="s2">if </span><span class="s1">info[</span><span class="s3">'ptype'</span><span class="s1">] != </span><span class="s3">'sdist' </span><span class="s2">or </span><span class="s1">info[</span><span class="s3">'pyversion'</span><span class="s1">] != </span><span class="s3">'source'</span><span class="s1">:</span>
                    <span class="s2">continue</span>
                <span class="s0"># We don't store summary in project metadata as it makes</span>
                <span class="s0"># the data bigger for no benefit during dependency</span>
                <span class="s0"># resolution</span>
                <span class="s1">dist = make_dist(data[</span><span class="s3">'name'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">info[</span><span class="s3">'version'</span><span class="s1">]</span><span class="s2">,</span>
                                 <span class="s1">summary=data.get(</span><span class="s3">'summary'</span><span class="s2">,</span>
                                                  <span class="s3">'Placeholder for summary'</span><span class="s1">)</span><span class="s2">,</span>
                                 <span class="s1">scheme=self.scheme)</span>
                <span class="s1">md = dist.metadata</span>
                <span class="s1">md.source_url = info[</span><span class="s3">'url'</span><span class="s1">]</span>
                <span class="s0"># TODO SHA256 digest</span>
                <span class="s2">if </span><span class="s3">'digest' </span><span class="s2">in </span><span class="s1">info </span><span class="s2">and </span><span class="s1">info[</span><span class="s3">'digest'</span><span class="s1">]:</span>
                    <span class="s1">dist.digest = (</span><span class="s3">'md5'</span><span class="s2">, </span><span class="s1">info[</span><span class="s3">'digest'</span><span class="s1">])</span>
                <span class="s1">md.dependencies = info.get(</span><span class="s3">'requirements'</span><span class="s2">, </span><span class="s1">{})</span>
                <span class="s1">dist.exports = info.get(</span><span class="s3">'exports'</span><span class="s2">, </span><span class="s1">{})</span>
                <span class="s1">result[dist.version] = dist</span>
                <span class="s1">result[</span><span class="s3">'urls'</span><span class="s1">].setdefault(dist.version</span><span class="s2">, </span><span class="s1">set()).add(info[</span><span class="s3">'url'</span><span class="s1">])</span>
        <span class="s2">return </span><span class="s1">result</span>

<span class="s2">class </span><span class="s1">DistPathLocator(Locator):</span>
    <span class="s4">&quot;&quot;&quot; 
    This locator finds installed distributions in a path. It can be useful for 
    adding to an :class:`AggregatingLocator`. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">distpath</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance. 
 
        :param distpath: A :class:`DistributionPath` instance to search. 
        &quot;&quot;&quot;</span>
        <span class="s1">super(DistPathLocator</span><span class="s2">, </span><span class="s1">self).__init__(**kwargs)</span>
        <span class="s2">assert </span><span class="s1">isinstance(distpath</span><span class="s2">, </span><span class="s1">DistributionPath)</span>
        <span class="s1">self.distpath = distpath</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s1">dist = self.distpath.get_distribution(name)</span>
        <span class="s2">if </span><span class="s1">dist </span><span class="s2">is None</span><span class="s1">:</span>
            <span class="s1">result = {</span><span class="s3">'urls'</span><span class="s1">: {}</span><span class="s2">, </span><span class="s3">'digests'</span><span class="s1">: {}}</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">result = {</span>
                <span class="s1">dist.version: dist</span><span class="s2">,</span>
                <span class="s3">'urls'</span><span class="s1">: {dist.version: set([dist.source_url])}</span><span class="s2">,</span>
                <span class="s3">'digests'</span><span class="s1">: {dist.version: set([</span><span class="s2">None</span><span class="s1">])}</span>
            <span class="s1">}</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s2">class </span><span class="s1">AggregatingLocator(Locator):</span>
    <span class="s4">&quot;&quot;&quot; 
    This class allows you to chain and/or merge a list of locators. 
    &quot;&quot;&quot;</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">*locators</span><span class="s2">, </span><span class="s1">**kwargs):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance. 
 
        :param locators: The list of locators to search. 
        :param kwargs: Passed to the superclass constructor, 
                       except for: 
                       * merge - if False (the default), the first successful 
                         search from any of the locators is returned. If True, 
                         the results from all locators are merged (this can be 
                         slow). 
        &quot;&quot;&quot;</span>
        <span class="s1">self.merge = kwargs.pop(</span><span class="s3">'merge'</span><span class="s2">, False</span><span class="s1">)</span>
        <span class="s1">self.locators = locators</span>
        <span class="s1">super(AggregatingLocator</span><span class="s2">, </span><span class="s1">self).__init__(**kwargs)</span>

    <span class="s2">def </span><span class="s1">clear_cache(self):</span>
        <span class="s1">super(AggregatingLocator</span><span class="s2">, </span><span class="s1">self).clear_cache()</span>
        <span class="s2">for </span><span class="s1">locator </span><span class="s2">in </span><span class="s1">self.locators:</span>
            <span class="s1">locator.clear_cache()</span>

    <span class="s2">def </span><span class="s1">_set_scheme(self</span><span class="s2">, </span><span class="s1">value):</span>
        <span class="s1">self._scheme = value</span>
        <span class="s2">for </span><span class="s1">locator </span><span class="s2">in </span><span class="s1">self.locators:</span>
            <span class="s1">locator.scheme = value</span>

    <span class="s1">scheme = property(Locator.scheme.fget</span><span class="s2">, </span><span class="s1">_set_scheme)</span>

    <span class="s2">def </span><span class="s1">_get_project(self</span><span class="s2">, </span><span class="s1">name):</span>
        <span class="s1">result = {}</span>
        <span class="s2">for </span><span class="s1">locator </span><span class="s2">in </span><span class="s1">self.locators:</span>
            <span class="s1">d = locator.get_project(name)</span>
            <span class="s2">if </span><span class="s1">d:</span>
                <span class="s2">if </span><span class="s1">self.merge:</span>
                    <span class="s1">files = result.get(</span><span class="s3">'urls'</span><span class="s2">, </span><span class="s1">{})</span>
                    <span class="s1">digests = result.get(</span><span class="s3">'digests'</span><span class="s2">, </span><span class="s1">{})</span>
                    <span class="s0"># next line could overwrite result['urls'], result['digests']</span>
                    <span class="s1">result.update(d)</span>
                    <span class="s1">df = result.get(</span><span class="s3">'urls'</span><span class="s1">)</span>
                    <span class="s2">if </span><span class="s1">files </span><span class="s2">and </span><span class="s1">df:</span>
                        <span class="s2">for </span><span class="s1">k</span><span class="s2">, </span><span class="s1">v </span><span class="s2">in </span><span class="s1">files.items():</span>
                            <span class="s2">if </span><span class="s1">k </span><span class="s2">in </span><span class="s1">df:</span>
                                <span class="s1">df[k] |= v</span>
                            <span class="s2">else</span><span class="s1">:</span>
                                <span class="s1">df[k] = v</span>
                    <span class="s1">dd = result.get(</span><span class="s3">'digests'</span><span class="s1">)</span>
                    <span class="s2">if </span><span class="s1">digests </span><span class="s2">and </span><span class="s1">dd:</span>
                        <span class="s1">dd.update(digests)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s0"># See issue #18. If any dists are found and we're looking</span>
                    <span class="s0"># for specific constraints, we only return something if</span>
                    <span class="s0"># a match is found. For example, if a DirectoryLocator</span>
                    <span class="s0"># returns just foo (1.0) while we're looking for</span>
                    <span class="s0"># foo (&gt;= 2.0), we'll pretend there was nothing there so</span>
                    <span class="s0"># that subsequent locators can be queried. Otherwise we</span>
                    <span class="s0"># would just return foo (1.0) which would then lead to a</span>
                    <span class="s0"># failure to find foo (&gt;= 2.0), because other locators</span>
                    <span class="s0"># weren't searched. Note that this only matters when</span>
                    <span class="s0"># merge=False.</span>
                    <span class="s2">if </span><span class="s1">self.matcher </span><span class="s2">is None</span><span class="s1">:</span>
                        <span class="s1">found = </span><span class="s2">True</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">found = </span><span class="s2">False</span>
                        <span class="s2">for </span><span class="s1">k </span><span class="s2">in </span><span class="s1">d:</span>
                            <span class="s2">if </span><span class="s1">self.matcher.match(k):</span>
                                <span class="s1">found = </span><span class="s2">True</span>
                                <span class="s2">break</span>
                    <span class="s2">if </span><span class="s1">found:</span>
                        <span class="s1">result = d</span>
                        <span class="s2">break</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">get_distribution_names(self):</span>
        <span class="s4">&quot;&quot;&quot; 
        Return all the distribution names known to this locator. 
        &quot;&quot;&quot;</span>
        <span class="s1">result = set()</span>
        <span class="s2">for </span><span class="s1">locator </span><span class="s2">in </span><span class="s1">self.locators:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s1">result |= locator.get_distribution_names()</span>
            <span class="s2">except </span><span class="s1">NotImplementedError:</span>
                <span class="s2">pass</span>
        <span class="s2">return </span><span class="s1">result</span>


<span class="s0"># We use a legacy scheme simply because most of the dists on PyPI use legacy</span>
<span class="s0"># versions which don't conform to PEP 426 / PEP 440.</span>
<span class="s1">default_locator = AggregatingLocator(</span>
                    <span class="s1">JSONLocator()</span><span class="s2">,</span>
                    <span class="s1">SimpleScrapingLocator(</span><span class="s3">'https://pypi.org/simple/'</span><span class="s2">,</span>
                                          <span class="s1">timeout=</span><span class="s5">3.0</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">scheme=</span><span class="s3">'legacy'</span><span class="s1">)</span>

<span class="s1">locate = default_locator.locate</span>


<span class="s2">class </span><span class="s1">DependencyFinder(object):</span>
    <span class="s4">&quot;&quot;&quot; 
    Locate dependencies for distributions. 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">locator=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s4">&quot;&quot;&quot; 
        Initialise an instance, using the specified locator 
        to locate distributions. 
        &quot;&quot;&quot;</span>
        <span class="s1">self.locator = locator </span><span class="s2">or </span><span class="s1">default_locator</span>
        <span class="s1">self.scheme = get_scheme(self.locator.scheme)</span>

    <span class="s2">def </span><span class="s1">add_distribution(self</span><span class="s2">, </span><span class="s1">dist):</span>
        <span class="s4">&quot;&quot;&quot; 
        Add a distribution to the finder. This will update internal information 
        about who provides what. 
        :param dist: The distribution to add. 
        &quot;&quot;&quot;</span>
        <span class="s1">logger.debug(</span><span class="s3">'adding distribution %s'</span><span class="s2">, </span><span class="s1">dist)</span>
        <span class="s1">name = dist.key</span>
        <span class="s1">self.dists_by_name[name] = dist</span>
        <span class="s1">self.dists[(name</span><span class="s2">, </span><span class="s1">dist.version)] = dist</span>
        <span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">dist.provides:</span>
            <span class="s1">name</span><span class="s2">, </span><span class="s1">version = parse_name_and_version(p)</span>
            <span class="s1">logger.debug(</span><span class="s3">'Add to provided: %s, %s, %s'</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">version</span><span class="s2">, </span><span class="s1">dist)</span>
            <span class="s1">self.provided.setdefault(name</span><span class="s2">, </span><span class="s1">set()).add((version</span><span class="s2">, </span><span class="s1">dist))</span>

    <span class="s2">def </span><span class="s1">remove_distribution(self</span><span class="s2">, </span><span class="s1">dist):</span>
        <span class="s4">&quot;&quot;&quot; 
        Remove a distribution from the finder. This will update internal 
        information about who provides what. 
        :param dist: The distribution to remove. 
        &quot;&quot;&quot;</span>
        <span class="s1">logger.debug(</span><span class="s3">'removing distribution %s'</span><span class="s2">, </span><span class="s1">dist)</span>
        <span class="s1">name = dist.key</span>
        <span class="s2">del </span><span class="s1">self.dists_by_name[name]</span>
        <span class="s2">del </span><span class="s1">self.dists[(name</span><span class="s2">, </span><span class="s1">dist.version)]</span>
        <span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">dist.provides:</span>
            <span class="s1">name</span><span class="s2">, </span><span class="s1">version = parse_name_and_version(p)</span>
            <span class="s1">logger.debug(</span><span class="s3">'Remove from provided: %s, %s, %s'</span><span class="s2">, </span><span class="s1">name</span><span class="s2">, </span><span class="s1">version</span><span class="s2">, </span><span class="s1">dist)</span>
            <span class="s1">s = self.provided[name]</span>
            <span class="s1">s.remove((version</span><span class="s2">, </span><span class="s1">dist))</span>
            <span class="s2">if not </span><span class="s1">s:</span>
                <span class="s2">del </span><span class="s1">self.provided[name]</span>

    <span class="s2">def </span><span class="s1">get_matcher(self</span><span class="s2">, </span><span class="s1">reqt):</span>
        <span class="s4">&quot;&quot;&quot; 
        Get a version matcher for a requirement. 
        :param reqt: The requirement 
        :type reqt: str 
        :return: A version matcher (an instance of 
                 :class:`distlib.version.Matcher`). 
        &quot;&quot;&quot;</span>
        <span class="s2">try</span><span class="s1">:</span>
            <span class="s1">matcher = self.scheme.matcher(reqt)</span>
        <span class="s2">except </span><span class="s1">UnsupportedVersionError:  </span><span class="s0"># pragma: no cover</span>
            <span class="s0"># XXX compat-mode if cannot read the version</span>
            <span class="s1">name = reqt.split()[</span><span class="s5">0</span><span class="s1">]</span>
            <span class="s1">matcher = self.scheme.matcher(name)</span>
        <span class="s2">return </span><span class="s1">matcher</span>

    <span class="s2">def </span><span class="s1">find_providers(self</span><span class="s2">, </span><span class="s1">reqt):</span>
        <span class="s4">&quot;&quot;&quot; 
        Find the distributions which can fulfill a requirement. 
 
        :param reqt: The requirement. 
         :type reqt: str 
        :return: A set of distribution which can fulfill the requirement. 
        &quot;&quot;&quot;</span>
        <span class="s1">matcher = self.get_matcher(reqt)</span>
        <span class="s1">name = matcher.key   </span><span class="s0"># case-insensitive</span>
        <span class="s1">result = set()</span>
        <span class="s1">provided = self.provided</span>
        <span class="s2">if </span><span class="s1">name </span><span class="s2">in </span><span class="s1">provided:</span>
            <span class="s2">for </span><span class="s1">version</span><span class="s2">, </span><span class="s1">provider </span><span class="s2">in </span><span class="s1">provided[name]:</span>
                <span class="s2">try</span><span class="s1">:</span>
                    <span class="s1">match = matcher.match(version)</span>
                <span class="s2">except </span><span class="s1">UnsupportedVersionError:</span>
                    <span class="s1">match = </span><span class="s2">False</span>

                <span class="s2">if </span><span class="s1">match:</span>
                    <span class="s1">result.add(provider)</span>
                    <span class="s2">break</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">try_to_replace(self</span><span class="s2">, </span><span class="s1">provider</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">problems):</span>
        <span class="s4">&quot;&quot;&quot; 
        Attempt to replace one provider with another. This is typically used 
        when resolving dependencies from multiple sources, e.g. A requires 
        (B &gt;= 1.0) while C requires (B &gt;= 1.1). 
 
        For successful replacement, ``provider`` must meet all the requirements 
        which ``other`` fulfills. 
 
        :param provider: The provider we are trying to replace with. 
        :param other: The provider we're trying to replace. 
        :param problems: If False is returned, this will contain what 
                         problems prevented replacement. This is currently 
                         a tuple of the literal string 'cantreplace', 
                         ``provider``, ``other``  and the set of requirements 
                         that ``provider`` couldn't fulfill. 
        :return: True if we can replace ``other`` with ``provider``, else 
                 False. 
        &quot;&quot;&quot;</span>
        <span class="s1">rlist = self.reqts[other]</span>
        <span class="s1">unmatched = set()</span>
        <span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">rlist:</span>
            <span class="s1">matcher = self.get_matcher(s)</span>
            <span class="s2">if not </span><span class="s1">matcher.match(provider.version):</span>
                <span class="s1">unmatched.add(s)</span>
        <span class="s2">if </span><span class="s1">unmatched:</span>
            <span class="s0"># can't replace other with provider</span>
            <span class="s1">problems.add((</span><span class="s3">'cantreplace'</span><span class="s2">, </span><span class="s1">provider</span><span class="s2">, </span><span class="s1">other</span><span class="s2">,</span>
                          <span class="s1">frozenset(unmatched)))</span>
            <span class="s1">result = </span><span class="s2">False</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># can replace other with provider</span>
            <span class="s1">self.remove_distribution(other)</span>
            <span class="s2">del </span><span class="s1">self.reqts[other]</span>
            <span class="s2">for </span><span class="s1">s </span><span class="s2">in </span><span class="s1">rlist:</span>
                <span class="s1">self.reqts.setdefault(provider</span><span class="s2">, </span><span class="s1">set()).add(s)</span>
            <span class="s1">self.add_distribution(provider)</span>
            <span class="s1">result = </span><span class="s2">True</span>
        <span class="s2">return </span><span class="s1">result</span>

    <span class="s2">def </span><span class="s1">find(self</span><span class="s2">, </span><span class="s1">requirement</span><span class="s2">, </span><span class="s1">meta_extras=</span><span class="s2">None, </span><span class="s1">prereleases=</span><span class="s2">False</span><span class="s1">):</span>
        <span class="s4">&quot;&quot;&quot; 
        Find a distribution and all distributions it depends on. 
 
        :param requirement: The requirement specifying the distribution to 
                            find, or a Distribution instance. 
        :param meta_extras: A list of meta extras such as :test:, :build: and 
                            so on. 
        :param prereleases: If ``True``, allow pre-release versions to be 
                            returned - otherwise, don't return prereleases 
                            unless they're all that's available. 
 
        Return a set of :class:`Distribution` instances and a set of 
        problems. 
 
        The distributions returned should be such that they have the 
        :attr:`required` attribute set to ``True`` if they were 
        from the ``requirement`` passed to ``find()``, and they have the 
        :attr:`build_time_dependency` attribute set to ``True`` unless they 
        are post-installation dependencies of the ``requirement``. 
 
        The problems should be a tuple consisting of the string 
        ``'unsatisfied'`` and the requirement which couldn't be satisfied 
        by any distribution known to the locator. 
        &quot;&quot;&quot;</span>

        <span class="s1">self.provided = {}</span>
        <span class="s1">self.dists = {}</span>
        <span class="s1">self.dists_by_name = {}</span>
        <span class="s1">self.reqts = {}</span>

        <span class="s1">meta_extras = set(meta_extras </span><span class="s2">or </span><span class="s1">[])</span>
        <span class="s2">if </span><span class="s3">':*:' </span><span class="s2">in </span><span class="s1">meta_extras:</span>
            <span class="s1">meta_extras.remove(</span><span class="s3">':*:'</span><span class="s1">)</span>
            <span class="s0"># :meta: and :run: are implicitly included</span>
            <span class="s1">meta_extras |= set([</span><span class="s3">':test:'</span><span class="s2">, </span><span class="s3">':build:'</span><span class="s2">, </span><span class="s3">':dev:'</span><span class="s1">])</span>

        <span class="s2">if </span><span class="s1">isinstance(requirement</span><span class="s2">, </span><span class="s1">Distribution):</span>
            <span class="s1">dist = odist = requirement</span>
            <span class="s1">logger.debug(</span><span class="s3">'passed %s as requirement'</span><span class="s2">, </span><span class="s1">odist)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">dist = odist = self.locator.locate(requirement</span><span class="s2">,</span>
                                               <span class="s1">prereleases=prereleases)</span>
            <span class="s2">if </span><span class="s1">dist </span><span class="s2">is None</span><span class="s1">:</span>
                <span class="s2">raise </span><span class="s1">DistlibException(</span><span class="s3">'Unable to locate %r' </span><span class="s1">% requirement)</span>
            <span class="s1">logger.debug(</span><span class="s3">'located %s'</span><span class="s2">, </span><span class="s1">odist)</span>
        <span class="s1">dist.requested = </span><span class="s2">True</span>
        <span class="s1">problems = set()</span>
        <span class="s1">todo = set([dist])</span>
        <span class="s1">install_dists = set([odist])</span>
        <span class="s2">while </span><span class="s1">todo:</span>
            <span class="s1">dist = todo.pop()</span>
            <span class="s1">name = dist.key     </span><span class="s0"># case-insensitive</span>
            <span class="s2">if </span><span class="s1">name </span><span class="s2">not in </span><span class="s1">self.dists_by_name:</span>
                <span class="s1">self.add_distribution(dist)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s0">#import pdb; pdb.set_trace()</span>
                <span class="s1">other = self.dists_by_name[name]</span>
                <span class="s2">if </span><span class="s1">other != dist:</span>
                    <span class="s1">self.try_to_replace(dist</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">problems)</span>

            <span class="s1">ireqts = dist.run_requires | dist.meta_requires</span>
            <span class="s1">sreqts = dist.build_requires</span>
            <span class="s1">ereqts = set()</span>
            <span class="s2">if </span><span class="s1">meta_extras </span><span class="s2">and </span><span class="s1">dist </span><span class="s2">in </span><span class="s1">install_dists:</span>
                <span class="s2">for </span><span class="s1">key </span><span class="s2">in </span><span class="s1">(</span><span class="s3">'test'</span><span class="s2">, </span><span class="s3">'build'</span><span class="s2">, </span><span class="s3">'dev'</span><span class="s1">):</span>
                    <span class="s1">e = </span><span class="s3">':%s:' </span><span class="s1">% key</span>
                    <span class="s2">if </span><span class="s1">e </span><span class="s2">in </span><span class="s1">meta_extras:</span>
                        <span class="s1">ereqts |= getattr(dist</span><span class="s2">, </span><span class="s3">'%s_requires' </span><span class="s1">% key)</span>
            <span class="s1">all_reqts = ireqts | sreqts | ereqts</span>
            <span class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span class="s1">all_reqts:</span>
                <span class="s1">providers = self.find_providers(r)</span>
                <span class="s2">if not </span><span class="s1">providers:</span>
                    <span class="s1">logger.debug(</span><span class="s3">'No providers found for %r'</span><span class="s2">, </span><span class="s1">r)</span>
                    <span class="s1">provider = self.locator.locate(r</span><span class="s2">, </span><span class="s1">prereleases=prereleases)</span>
                    <span class="s0"># If no provider is found and we didn't consider</span>
                    <span class="s0"># prereleases, consider them now.</span>
                    <span class="s2">if </span><span class="s1">provider </span><span class="s2">is None and not </span><span class="s1">prereleases:</span>
                        <span class="s1">provider = self.locator.locate(r</span><span class="s2">, </span><span class="s1">prereleases=</span><span class="s2">True</span><span class="s1">)</span>
                    <span class="s2">if </span><span class="s1">provider </span><span class="s2">is None</span><span class="s1">:</span>
                        <span class="s1">logger.debug(</span><span class="s3">'Cannot satisfy %r'</span><span class="s2">, </span><span class="s1">r)</span>
                        <span class="s1">problems.add((</span><span class="s3">'unsatisfied'</span><span class="s2">, </span><span class="s1">r))</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">n</span><span class="s2">, </span><span class="s1">v = provider.key</span><span class="s2">, </span><span class="s1">provider.version</span>
                        <span class="s2">if </span><span class="s1">(n</span><span class="s2">, </span><span class="s1">v) </span><span class="s2">not in </span><span class="s1">self.dists:</span>
                            <span class="s1">todo.add(provider)</span>
                        <span class="s1">providers.add(provider)</span>
                        <span class="s2">if </span><span class="s1">r </span><span class="s2">in </span><span class="s1">ireqts </span><span class="s2">and </span><span class="s1">dist </span><span class="s2">in </span><span class="s1">install_dists:</span>
                            <span class="s1">install_dists.add(provider)</span>
                            <span class="s1">logger.debug(</span><span class="s3">'Adding %s to install_dists'</span><span class="s2">,</span>
                                         <span class="s1">provider.name_and_version)</span>
                <span class="s2">for </span><span class="s1">p </span><span class="s2">in </span><span class="s1">providers:</span>
                    <span class="s1">name = p.key</span>
                    <span class="s2">if </span><span class="s1">name </span><span class="s2">not in </span><span class="s1">self.dists_by_name:</span>
                        <span class="s1">self.reqts.setdefault(p</span><span class="s2">, </span><span class="s1">set()).add(r)</span>
                    <span class="s2">else</span><span class="s1">:</span>
                        <span class="s1">other = self.dists_by_name[name]</span>
                        <span class="s2">if </span><span class="s1">other != p:</span>
                            <span class="s0"># see if other can be replaced by p</span>
                            <span class="s1">self.try_to_replace(p</span><span class="s2">, </span><span class="s1">other</span><span class="s2">, </span><span class="s1">problems)</span>

        <span class="s1">dists = set(self.dists.values())</span>
        <span class="s2">for </span><span class="s1">dist </span><span class="s2">in </span><span class="s1">dists:</span>
            <span class="s1">dist.build_time_dependency = dist </span><span class="s2">not in </span><span class="s1">install_dists</span>
            <span class="s2">if </span><span class="s1">dist.build_time_dependency:</span>
                <span class="s1">logger.debug(</span><span class="s3">'%s is a build-time dependency only.'</span><span class="s2">,</span>
                             <span class="s1">dist.name_and_version)</span>
        <span class="s1">logger.debug(</span><span class="s3">'find done for %s'</span><span class="s2">, </span><span class="s1">odist)</span>
        <span class="s2">return </span><span class="s1">dists</span><span class="s2">, </span><span class="s1">problems</span>
</pre>
</body>
</html>