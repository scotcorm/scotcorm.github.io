<html>
<head>
<title>test_multi_thread.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6a8759;}
.s5 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
test_multi_thread.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
Tests multithreading behaviour for reading and 
parsing files for each parser defined in parsers.py 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">contextlib </span><span class="s2">import </span><span class="s1">ExitStack</span>
<span class="s2">from </span><span class="s1">io </span><span class="s2">import </span><span class="s1">BytesIO</span>
<span class="s2">from </span><span class="s1">multiprocessing.pool </span><span class="s2">import </span><span class="s1">ThreadPool</span>

<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">pytest</span>

<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">from </span><span class="s1">pandas </span><span class="s2">import </span><span class="s1">DataFrame</span>
<span class="s2">import </span><span class="s1">pandas._testing </span><span class="s2">as </span><span class="s1">tm</span>

<span class="s3"># We'll probably always skip these for pyarrow</span>
<span class="s3"># Maybe we'll add our own tests for pyarrow too</span>
<span class="s1">pytestmark = pytest.mark.usefixtures(</span><span class="s4">&quot;pyarrow_skip&quot;</span><span class="s1">)</span>


<span class="s2">def </span><span class="s1">_construct_dataframe(num_rows):</span>
    <span class="s0">&quot;&quot;&quot; 
    Construct a DataFrame for testing. 
 
    Parameters 
    ---------- 
    num_rows : int 
        The number of rows for our DataFrame. 
 
    Returns 
    ------- 
    df : DataFrame 
    &quot;&quot;&quot;</span>
    <span class="s1">df = DataFrame(np.random.rand(num_rows</span><span class="s2">, </span><span class="s5">5</span><span class="s1">)</span><span class="s2">, </span><span class="s1">columns=list(</span><span class="s4">&quot;abcde&quot;</span><span class="s1">))</span>
    <span class="s1">df[</span><span class="s4">&quot;foo&quot;</span><span class="s1">] = </span><span class="s4">&quot;foo&quot;</span>
    <span class="s1">df[</span><span class="s4">&quot;bar&quot;</span><span class="s1">] = </span><span class="s4">&quot;bar&quot;</span>
    <span class="s1">df[</span><span class="s4">&quot;baz&quot;</span><span class="s1">] = </span><span class="s4">&quot;baz&quot;</span>
    <span class="s1">df[</span><span class="s4">&quot;date&quot;</span><span class="s1">] = pd.date_range(</span><span class="s4">&quot;20000101 09:00:00&quot;</span><span class="s2">, </span><span class="s1">periods=num_rows</span><span class="s2">, </span><span class="s1">freq=</span><span class="s4">&quot;s&quot;</span><span class="s1">)</span>
    <span class="s1">df[</span><span class="s4">&quot;int&quot;</span><span class="s1">] = np.arange(num_rows</span><span class="s2">, </span><span class="s1">dtype=</span><span class="s4">&quot;int64&quot;</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">df</span>


<span class="s1">@pytest.mark.slow</span>
<span class="s2">def </span><span class="s1">test_multi_thread_string_io_read_csv(all_parsers):</span>
    <span class="s3"># see gh-11786</span>
    <span class="s1">parser = all_parsers</span>
    <span class="s1">max_row_range = </span><span class="s5">10000</span>
    <span class="s1">num_files = </span><span class="s5">100</span>

    <span class="s1">bytes_to_df = [</span>
        <span class="s4">&quot;</span><span class="s2">\n</span><span class="s4">&quot;</span><span class="s1">.join([</span><span class="s4">f&quot;</span><span class="s2">{</span><span class="s1">i</span><span class="s2">:</span><span class="s4">d</span><span class="s2">}</span><span class="s4">,</span><span class="s2">{</span><span class="s1">i</span><span class="s2">:</span><span class="s4">d</span><span class="s2">}</span><span class="s4">,</span><span class="s2">{</span><span class="s1">i</span><span class="s2">:</span><span class="s4">d</span><span class="s2">}</span><span class="s4">&quot; </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(max_row_range)]).encode()</span>
        <span class="s2">for </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">range(num_files)</span>
    <span class="s1">]</span>

    <span class="s3"># Read all files in many threads.</span>
    <span class="s2">with </span><span class="s1">ExitStack() </span><span class="s2">as </span><span class="s1">stack:</span>
        <span class="s1">files = [stack.enter_context(BytesIO(b)) </span><span class="s2">for </span><span class="s1">b </span><span class="s2">in </span><span class="s1">bytes_to_df]</span>

        <span class="s1">pool = stack.enter_context(ThreadPool(</span><span class="s5">8</span><span class="s1">))</span>

        <span class="s1">results = pool.map(parser.read_csv</span><span class="s2">, </span><span class="s1">files)</span>
        <span class="s1">first_result = results[</span><span class="s5">0</span><span class="s1">]</span>

        <span class="s2">for </span><span class="s1">result </span><span class="s2">in </span><span class="s1">results:</span>
            <span class="s1">tm.assert_frame_equal(first_result</span><span class="s2">, </span><span class="s1">result)</span>


<span class="s2">def </span><span class="s1">_generate_multi_thread_dataframe(parser</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">num_rows</span><span class="s2">, </span><span class="s1">num_tasks):</span>
    <span class="s0">&quot;&quot;&quot; 
    Generate a DataFrame via multi-thread. 
 
    Parameters 
    ---------- 
    parser : BaseParser 
        The parser object to use for reading the data. 
    path : str 
        The location of the CSV file to read. 
    num_rows : int 
        The number of rows to read per task. 
    num_tasks : int 
        The number of tasks to use for reading this DataFrame. 
 
    Returns 
    ------- 
    df : DataFrame 
    &quot;&quot;&quot;</span>

    <span class="s2">def </span><span class="s1">reader(arg):</span>
        <span class="s0">&quot;&quot;&quot; 
        Create a reader for part of the CSV. 
 
        Parameters 
        ---------- 
        arg : tuple 
            A tuple of the following: 
 
            * start : int 
                The starting row to start for parsing CSV 
            * nrows : int 
                The number of rows to read. 
 
        Returns 
        ------- 
        df : DataFrame 
        &quot;&quot;&quot;</span>
        <span class="s1">start</span><span class="s2">, </span><span class="s1">nrows = arg</span>

        <span class="s2">if not </span><span class="s1">start:</span>
            <span class="s2">return </span><span class="s1">parser.read_csv(</span>
                <span class="s1">path</span><span class="s2">, </span><span class="s1">index_col=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">header=</span><span class="s5">0</span><span class="s2">, </span><span class="s1">nrows=nrows</span><span class="s2">, </span><span class="s1">parse_dates=[</span><span class="s4">&quot;date&quot;</span><span class="s1">]</span>
            <span class="s1">)</span>

        <span class="s2">return </span><span class="s1">parser.read_csv(</span>
            <span class="s1">path</span><span class="s2">,</span>
            <span class="s1">index_col=</span><span class="s5">0</span><span class="s2">,</span>
            <span class="s1">header=</span><span class="s2">None,</span>
            <span class="s1">skiprows=int(start) + </span><span class="s5">1</span><span class="s2">,</span>
            <span class="s1">nrows=nrows</span><span class="s2">,</span>
            <span class="s1">parse_dates=[</span><span class="s5">9</span><span class="s1">]</span><span class="s2">,</span>
        <span class="s1">)</span>

    <span class="s1">tasks = [</span>
        <span class="s1">(num_rows * i // num_tasks</span><span class="s2">, </span><span class="s1">num_rows // num_tasks) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(num_tasks)</span>
    <span class="s1">]</span>

    <span class="s2">with </span><span class="s1">ThreadPool(processes=num_tasks) </span><span class="s2">as </span><span class="s1">pool:</span>
        <span class="s1">results = pool.map(reader</span><span class="s2">, </span><span class="s1">tasks)</span>

    <span class="s1">header = results[</span><span class="s5">0</span><span class="s1">].columns</span>

    <span class="s2">for </span><span class="s1">r </span><span class="s2">in </span><span class="s1">results[</span><span class="s5">1</span><span class="s1">:]:</span>
        <span class="s1">r.columns = header</span>

    <span class="s1">final_dataframe = pd.concat(results)</span>
    <span class="s2">return </span><span class="s1">final_dataframe</span>


<span class="s1">@pytest.mark.slow</span>
<span class="s2">def </span><span class="s1">test_multi_thread_path_multipart_read_csv(all_parsers):</span>
    <span class="s3"># see gh-11786</span>
    <span class="s1">num_tasks = </span><span class="s5">4</span>
    <span class="s1">num_rows = </span><span class="s5">100000</span>

    <span class="s1">parser = all_parsers</span>
    <span class="s1">file_name = </span><span class="s4">&quot;__thread_pool_reader__.csv&quot;</span>
    <span class="s1">df = _construct_dataframe(num_rows)</span>

    <span class="s2">with </span><span class="s1">tm.ensure_clean(file_name) </span><span class="s2">as </span><span class="s1">path:</span>
        <span class="s1">df.to_csv(path)</span>

        <span class="s1">final_dataframe = _generate_multi_thread_dataframe(</span>
            <span class="s1">parser</span><span class="s2">, </span><span class="s1">path</span><span class="s2">, </span><span class="s1">num_rows</span><span class="s2">, </span><span class="s1">num_tasks</span>
        <span class="s1">)</span>
        <span class="s1">tm.assert_frame_equal(df</span><span class="s2">, </span><span class="s1">final_dataframe)</span>
</pre>
</body>
</html>