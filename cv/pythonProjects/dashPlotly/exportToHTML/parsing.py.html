<html>
<head>
<title>parsing.py</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #629755; font-style: italic;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #808080;}
.s4 { color: #6897bb;}
.s5 { color: #6a8759;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
parsing.py</font>
</center></td></tr></table>
<pre><span class="s0">&quot;&quot;&quot; 
:func:`~pandas.eval` source string parsing functions 
&quot;&quot;&quot;</span>
<span class="s2">from </span><span class="s1">__future__ </span><span class="s2">import </span><span class="s1">annotations</span>

<span class="s2">from </span><span class="s1">io </span><span class="s2">import </span><span class="s1">StringIO</span>
<span class="s2">from </span><span class="s1">keyword </span><span class="s2">import </span><span class="s1">iskeyword</span>
<span class="s2">import </span><span class="s1">token</span>
<span class="s2">import </span><span class="s1">tokenize</span>
<span class="s2">from </span><span class="s1">typing </span><span class="s2">import </span><span class="s1">(</span>
    <span class="s1">Hashable</span><span class="s2">,</span>
    <span class="s1">Iterator</span><span class="s2">,</span>
<span class="s1">)</span>

<span class="s3"># A token value Python's tokenizer probably will never use.</span>
<span class="s1">BACKTICK_QUOTED_STRING = </span><span class="s4">100</span>


<span class="s2">def </span><span class="s1">create_valid_python_identifier(name: str) -&gt; str:</span>
    <span class="s0">&quot;&quot;&quot; 
    Create valid Python identifiers from any string. 
 
    Check if name contains any special characters. If it contains any 
    special characters, the special characters will be replaced by 
    a special string and a prefix is added. 
 
    Raises 
    ------ 
    SyntaxError 
        If the returned name is not a Python valid identifier, raise an exception. 
        This can happen if there is a hashtag in the name, as the tokenizer will 
        than terminate and not find the backtick. 
        But also for characters that fall out of the range of (U+0001..U+007F). 
    &quot;&quot;&quot;</span>
    <span class="s2">if </span><span class="s1">name.isidentifier() </span><span class="s2">and not </span><span class="s1">iskeyword(name):</span>
        <span class="s2">return </span><span class="s1">name</span>

    <span class="s3"># Create a dict with the special characters and their replacement string.</span>
    <span class="s3"># EXACT_TOKEN_TYPES contains these special characters</span>
    <span class="s3"># token.tok_name contains a readable description of the replacement string.</span>
    <span class="s1">special_characters_replacements = {</span>
        <span class="s1">char: </span><span class="s5">f&quot;_</span><span class="s2">{</span><span class="s1">token.tok_name[tokval]</span><span class="s2">}</span><span class="s5">_&quot;</span>
        <span class="s2">for </span><span class="s1">char</span><span class="s2">, </span><span class="s1">tokval </span><span class="s2">in </span><span class="s1">(tokenize.EXACT_TOKEN_TYPES.items())</span>
    <span class="s1">}</span>
    <span class="s1">special_characters_replacements.update(</span>
        <span class="s1">{</span>
            <span class="s5">&quot; &quot;</span><span class="s1">: </span><span class="s5">&quot;_&quot;</span><span class="s2">,</span>
            <span class="s5">&quot;?&quot;</span><span class="s1">: </span><span class="s5">&quot;_QUESTIONMARK_&quot;</span><span class="s2">,</span>
            <span class="s5">&quot;!&quot;</span><span class="s1">: </span><span class="s5">&quot;_EXCLAMATIONMARK_&quot;</span><span class="s2">,</span>
            <span class="s5">&quot;$&quot;</span><span class="s1">: </span><span class="s5">&quot;_DOLLARSIGN_&quot;</span><span class="s2">,</span>
            <span class="s5">&quot;€&quot;</span><span class="s1">: </span><span class="s5">&quot;_EUROSIGN_&quot;</span><span class="s2">,</span>
            <span class="s5">&quot;°&quot;</span><span class="s1">: </span><span class="s5">&quot;_DEGREESIGN_&quot;</span><span class="s2">,</span>
            <span class="s3"># Including quotes works, but there are exceptions.</span>
            <span class="s5">&quot;'&quot;</span><span class="s1">: </span><span class="s5">&quot;_SINGLEQUOTE_&quot;</span><span class="s2">,</span>
            <span class="s5">'&quot;'</span><span class="s1">: </span><span class="s5">&quot;_DOUBLEQUOTE_&quot;</span><span class="s2">,</span>
            <span class="s3"># Currently not possible. Terminates parser and won't find backtick.</span>
            <span class="s3"># &quot;#&quot;: &quot;_HASH_&quot;,</span>
        <span class="s1">}</span>
    <span class="s1">)</span>

    <span class="s1">name = </span><span class="s5">&quot;&quot;</span><span class="s1">.join([special_characters_replacements.get(char</span><span class="s2">, </span><span class="s1">char) </span><span class="s2">for </span><span class="s1">char </span><span class="s2">in </span><span class="s1">name])</span>
    <span class="s1">name = </span><span class="s5">&quot;BACKTICK_QUOTED_STRING_&quot; </span><span class="s1">+ name</span>

    <span class="s2">if not </span><span class="s1">name.isidentifier():</span>
        <span class="s2">raise </span><span class="s1">SyntaxError(</span><span class="s5">f&quot;Could not convert '</span><span class="s2">{</span><span class="s1">name</span><span class="s2">}</span><span class="s5">' to a valid Python identifier.&quot;</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">name</span>


<span class="s2">def </span><span class="s1">clean_backtick_quoted_toks(tok: tuple[int</span><span class="s2">, </span><span class="s1">str]) -&gt; tuple[int</span><span class="s2">, </span><span class="s1">str]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Clean up a column name if surrounded by backticks. 
 
    Backtick quoted string are indicated by a certain tokval value. If a string 
    is a backtick quoted token it will processed by 
    :func:`_create_valid_python_identifier` so that the parser can find this 
    string when the query is executed. 
    In this case the tok will get the NAME tokval. 
 
    Parameters 
    ---------- 
    tok : tuple of int, str 
        ints correspond to the all caps constants in the tokenize module 
 
    Returns 
    ------- 
    tok : Tuple[int, str] 
        Either the input or token or the replacement values 
    &quot;&quot;&quot;</span>
    <span class="s1">toknum</span><span class="s2">, </span><span class="s1">tokval = tok</span>
    <span class="s2">if </span><span class="s1">toknum == BACKTICK_QUOTED_STRING:</span>
        <span class="s2">return </span><span class="s1">tokenize.NAME</span><span class="s2">, </span><span class="s1">create_valid_python_identifier(tokval)</span>
    <span class="s2">return </span><span class="s1">toknum</span><span class="s2">, </span><span class="s1">tokval</span>


<span class="s2">def </span><span class="s1">clean_column_name(name: Hashable) -&gt; Hashable:</span>
    <span class="s0">&quot;&quot;&quot; 
    Function to emulate the cleaning of a backtick quoted name. 
 
    The purpose for this function is to see what happens to the name of 
    identifier if it goes to the process of being parsed a Python code 
    inside a backtick quoted string and than being cleaned 
    (removed of any special characters). 
 
    Parameters 
    ---------- 
    name : hashable 
        Name to be cleaned. 
 
    Returns 
    ------- 
    name : hashable 
        Returns the name after tokenizing and cleaning. 
 
    Notes 
    ----- 
        For some cases, a name cannot be converted to a valid Python identifier. 
        In that case :func:`tokenize_string` raises a SyntaxError. 
        In that case, we just return the name unmodified. 
 
        If this name was used in the query string (this makes the query call impossible) 
        an error will be raised by :func:`tokenize_backtick_quoted_string` instead, 
        which is not caught and propagates to the user level. 
    &quot;&quot;&quot;</span>
    <span class="s2">try</span><span class="s1">:</span>
        <span class="s1">tokenized = tokenize_string(</span><span class="s5">f&quot;`</span><span class="s2">{</span><span class="s1">name</span><span class="s2">}</span><span class="s5">`&quot;</span><span class="s1">)</span>
        <span class="s1">tokval = next(tokenized)[</span><span class="s4">1</span><span class="s1">]</span>
        <span class="s2">return </span><span class="s1">create_valid_python_identifier(tokval)</span>
    <span class="s2">except </span><span class="s1">SyntaxError:</span>
        <span class="s2">return </span><span class="s1">name</span>


<span class="s2">def </span><span class="s1">tokenize_backtick_quoted_string(</span>
    <span class="s1">token_generator: Iterator[tokenize.TokenInfo]</span><span class="s2">, </span><span class="s1">source: str</span><span class="s2">, </span><span class="s1">string_start: int</span>
<span class="s1">) -&gt; tuple[int</span><span class="s2">, </span><span class="s1">str]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Creates a token from a backtick quoted string. 
 
    Moves the token_generator forwards till right after the next backtick. 
 
    Parameters 
    ---------- 
    token_generator : Iterator[tokenize.TokenInfo] 
        The generator that yields the tokens of the source string (Tuple[int, str]). 
        The generator is at the first token after the backtick (`) 
 
    source : str 
        The Python source code string. 
 
    string_start : int 
        This is the start of backtick quoted string inside the source string. 
 
    Returns 
    ------- 
    tok: Tuple[int, str] 
        The token that represents the backtick quoted string. 
        The integer is equal to BACKTICK_QUOTED_STRING (100). 
    &quot;&quot;&quot;</span>
    <span class="s2">for </span><span class="s1">_</span><span class="s2">, </span><span class="s1">tokval</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">token_generator:</span>
        <span class="s2">if </span><span class="s1">tokval == </span><span class="s5">&quot;`&quot;</span><span class="s1">:</span>
            <span class="s1">string_end = start[</span><span class="s4">1</span><span class="s1">]</span>
            <span class="s2">break</span>

    <span class="s2">return </span><span class="s1">BACKTICK_QUOTED_STRING</span><span class="s2">, </span><span class="s1">source[string_start:string_end]</span>


<span class="s2">def </span><span class="s1">tokenize_string(source: str) -&gt; Iterator[tuple[int</span><span class="s2">, </span><span class="s1">str]]:</span>
    <span class="s0">&quot;&quot;&quot; 
    Tokenize a Python source code string. 
 
    Parameters 
    ---------- 
    source : str 
        The Python source code string. 
 
    Returns 
    ------- 
    tok_generator : Iterator[Tuple[int, str]] 
        An iterator yielding all tokens with only toknum and tokval (Tuple[ing, str]). 
    &quot;&quot;&quot;</span>
    <span class="s1">line_reader = StringIO(source).readline</span>
    <span class="s1">token_generator = tokenize.generate_tokens(line_reader)</span>

    <span class="s3"># Loop over all tokens till a backtick (`) is found.</span>
    <span class="s3"># Then, take all tokens till the next backtick to form a backtick quoted string</span>
    <span class="s2">for </span><span class="s1">toknum</span><span class="s2">, </span><span class="s1">tokval</span><span class="s2">, </span><span class="s1">start</span><span class="s2">, </span><span class="s1">_</span><span class="s2">, </span><span class="s1">_ </span><span class="s2">in </span><span class="s1">token_generator:</span>
        <span class="s2">if </span><span class="s1">tokval == </span><span class="s5">&quot;`&quot;</span><span class="s1">:</span>
            <span class="s2">try</span><span class="s1">:</span>
                <span class="s2">yield </span><span class="s1">tokenize_backtick_quoted_string(</span>
                    <span class="s1">token_generator</span><span class="s2">, </span><span class="s1">source</span><span class="s2">, </span><span class="s1">string_start=start[</span><span class="s4">1</span><span class="s1">] + </span><span class="s4">1</span>
                <span class="s1">)</span>
            <span class="s2">except </span><span class="s1">Exception </span><span class="s2">as </span><span class="s1">err:</span>
                <span class="s2">raise </span><span class="s1">SyntaxError(</span><span class="s5">f&quot;Failed to parse backticks in '</span><span class="s2">{</span><span class="s1">source</span><span class="s2">}</span><span class="s5">'.&quot;</span><span class="s1">) </span><span class="s2">from </span><span class="s1">err</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">yield </span><span class="s1">toknum</span><span class="s2">, </span><span class="s1">tokval</span>
</pre>
</body>
</html>